/**
 * Returns a `Uint8Array` of the requested size. Referenced memory will
 * be initialized to 0.
 */
function alloc$1(size = 0) {
    return new Uint8Array(size);
}
/**
 * Where possible returns a Uint8Array of the requested size that references
 * uninitialized memory. Only use if you are certain you will immediately
 * overwrite every value in the returned `Uint8Array`.
 */
function allocUnsafe(size = 0) {
    return new Uint8Array(size);
}

/* eslint-disable no-fallthrough */
const N1$1 = Math.pow(2, 7);
const N2$1 = Math.pow(2, 14);
const N3$1 = Math.pow(2, 21);
const N4$1 = Math.pow(2, 28);
const N5$1 = Math.pow(2, 35);
const N6$1 = Math.pow(2, 42);
const N7$1 = Math.pow(2, 49);
/** Most significant bit of a byte */
const MSB$2 = 0x80;
/** Rest of the bits in a byte */
const REST$2 = 0x7f;
function encodingLength$1(value) {
    if (value < N1$1) {
        return 1;
    }
    if (value < N2$1) {
        return 2;
    }
    if (value < N3$1) {
        return 3;
    }
    if (value < N4$1) {
        return 4;
    }
    if (value < N5$1) {
        return 5;
    }
    if (value < N6$1) {
        return 6;
    }
    if (value < N7$1) {
        return 7;
    }
    if (Number.MAX_SAFE_INTEGER != null && value > Number.MAX_SAFE_INTEGER) {
        throw new RangeError('Could not encode varint');
    }
    return 8;
}
function encodeUint8Array(value, buf, offset = 0) {
    switch (encodingLength$1(value)) {
        case 8: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value /= 128;
        }
        case 7: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value /= 128;
        }
        case 6: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value /= 128;
        }
        case 5: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value /= 128;
        }
        case 4: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value >>>= 7;
        }
        case 3: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value >>>= 7;
        }
        case 2: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value >>>= 7;
        }
        case 1: {
            buf[offset++] = (value & 0xFF);
            value >>>= 7;
            break;
        }
        default: throw new Error('unreachable');
    }
    return buf;
}
function encodeUint8ArrayList(value, buf, offset = 0) {
    switch (encodingLength$1(value)) {
        case 8: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value /= 128;
        }
        case 7: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value /= 128;
        }
        case 6: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value /= 128;
        }
        case 5: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value /= 128;
        }
        case 4: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value >>>= 7;
        }
        case 3: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value >>>= 7;
        }
        case 2: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value >>>= 7;
        }
        case 1: {
            buf.set(offset++, (value & 0xFF));
            value >>>= 7;
            break;
        }
        default: throw new Error('unreachable');
    }
    return buf;
}
function decodeUint8Array(buf, offset) {
    let b = buf[offset];
    let res = 0;
    res += b & REST$2;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 1];
    res += (b & REST$2) << 7;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 2];
    res += (b & REST$2) << 14;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 3];
    res += (b & REST$2) << 21;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 4];
    res += (b & REST$2) * N4$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 5];
    res += (b & REST$2) * N5$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 6];
    res += (b & REST$2) * N6$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 7];
    res += (b & REST$2) * N7$1;
    if (b < MSB$2) {
        return res;
    }
    throw new RangeError('Could not decode varint');
}
function decodeUint8ArrayList(buf, offset) {
    let b = buf.get(offset);
    let res = 0;
    res += b & REST$2;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 1);
    res += (b & REST$2) << 7;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 2);
    res += (b & REST$2) << 14;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 3);
    res += (b & REST$2) << 21;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 4);
    res += (b & REST$2) * N4$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 5);
    res += (b & REST$2) * N5$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 6);
    res += (b & REST$2) * N6$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 7);
    res += (b & REST$2) * N7$1;
    if (b < MSB$2) {
        return res;
    }
    throw new RangeError('Could not decode varint');
}
function encode$8(value, buf, offset = 0) {
    if (buf == null) {
        buf = allocUnsafe(encodingLength$1(value));
    }
    if (buf instanceof Uint8Array) {
        return encodeUint8Array(value, buf, offset);
    }
    else {
        return encodeUint8ArrayList(value, buf, offset);
    }
}
function decode$8(buf, offset = 0) {
    if (buf instanceof Uint8Array) {
        return decodeUint8Array(buf, offset);
    }
    else {
        return decodeUint8ArrayList(buf, offset);
    }
}

const f32 = new Float32Array([-0]);
const f8b = new Uint8Array(f32.buffer);
/**
 * Writes a 32 bit float to a buffer using little endian byte order
 */
function writeFloatLE(val, buf, pos) {
    f32[0] = val;
    buf[pos] = f8b[0];
    buf[pos + 1] = f8b[1];
    buf[pos + 2] = f8b[2];
    buf[pos + 3] = f8b[3];
}
/**
 * Reads a 32 bit float from a buffer using little endian byte order
 */
function readFloatLE(buf, pos) {
    f8b[0] = buf[pos];
    f8b[1] = buf[pos + 1];
    f8b[2] = buf[pos + 2];
    f8b[3] = buf[pos + 3];
    return f32[0];
}
const f64 = new Float64Array([-0]);
const d8b = new Uint8Array(f64.buffer);
/**
 * Writes a 64 bit double to a buffer using little endian byte order
 */
function writeDoubleLE(val, buf, pos) {
    f64[0] = val;
    buf[pos] = d8b[0];
    buf[pos + 1] = d8b[1];
    buf[pos + 2] = d8b[2];
    buf[pos + 3] = d8b[3];
    buf[pos + 4] = d8b[4];
    buf[pos + 5] = d8b[5];
    buf[pos + 6] = d8b[6];
    buf[pos + 7] = d8b[7];
}
/**
 * Reads a 64 bit double from a buffer using little endian byte order
 */
function readDoubleLE(buf, pos) {
    d8b[0] = buf[pos];
    d8b[1] = buf[pos + 1];
    d8b[2] = buf[pos + 2];
    d8b[3] = buf[pos + 3];
    d8b[4] = buf[pos + 4];
    d8b[5] = buf[pos + 5];
    d8b[6] = buf[pos + 6];
    d8b[7] = buf[pos + 7];
    return f64[0];
}

// the largest BigInt we can safely downcast to a Number
const MAX_SAFE_NUMBER_INTEGER = BigInt(Number.MAX_SAFE_INTEGER);
const MIN_SAFE_NUMBER_INTEGER = BigInt(Number.MIN_SAFE_INTEGER);
/**
 * Constructs new long bits.
 *
 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
 * @memberof util
 * @function Object() { [native code] }
 * @param {number} lo - Low 32 bits, unsigned
 * @param {number} hi - High 32 bits, unsigned
 */
class LongBits {
    lo;
    hi;
    constructor(lo, hi) {
        // note that the casts below are theoretically unnecessary as of today, but older statically
        // generated converter code might still call the ctor with signed 32bits. kept for compat.
        /**
         * Low bits
         */
        this.lo = lo | 0;
        /**
         * High bits
         */
        this.hi = hi | 0;
    }
    /**
     * Converts this long bits to a possibly unsafe JavaScript number
     */
    toNumber(unsigned = false) {
        if (!unsigned && (this.hi >>> 31) > 0) {
            const lo = ~this.lo + 1 >>> 0;
            let hi = ~this.hi >>> 0;
            if (lo === 0) {
                hi = hi + 1 >>> 0;
            }
            return -(lo + hi * 4294967296);
        }
        return this.lo + this.hi * 4294967296;
    }
    /**
     * Converts this long bits to a bigint
     */
    toBigInt(unsigned = false) {
        if (unsigned) {
            return BigInt(this.lo >>> 0) + (BigInt(this.hi >>> 0) << 32n);
        }
        if ((this.hi >>> 31) !== 0) {
            const lo = ~this.lo + 1 >>> 0;
            let hi = ~this.hi >>> 0;
            if (lo === 0) {
                hi = hi + 1 >>> 0;
            }
            return -(BigInt(lo) + (BigInt(hi) << 32n));
        }
        return BigInt(this.lo >>> 0) + (BigInt(this.hi >>> 0) << 32n);
    }
    /**
     * Converts this long bits to a string
     */
    toString(unsigned = false) {
        return this.toBigInt(unsigned).toString();
    }
    /**
     * Zig-zag encodes this long bits
     */
    zzEncode() {
        const mask = this.hi >> 31;
        this.hi = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
        this.lo = (this.lo << 1 ^ mask) >>> 0;
        return this;
    }
    /**
     * Zig-zag decodes this long bits
     */
    zzDecode() {
        const mask = -(this.lo & 1);
        this.lo = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
        this.hi = (this.hi >>> 1 ^ mask) >>> 0;
        return this;
    }
    /**
     * Calculates the length of this longbits when encoded as a varint.
     */
    length() {
        const part0 = this.lo;
        const part1 = (this.lo >>> 28 | this.hi << 4) >>> 0;
        const part2 = this.hi >>> 24;
        return part2 === 0
            ? part1 === 0
                ? part0 < 16384
                    ? part0 < 128 ? 1 : 2
                    : part0 < 2097152 ? 3 : 4
                : part1 < 16384
                    ? part1 < 128 ? 5 : 6
                    : part1 < 2097152 ? 7 : 8
            : part2 < 128 ? 9 : 10;
    }
    /**
     * Constructs new long bits from the specified number
     */
    static fromBigInt(value) {
        if (value === 0n) {
            return zero;
        }
        if (value < MAX_SAFE_NUMBER_INTEGER && value > MIN_SAFE_NUMBER_INTEGER) {
            return this.fromNumber(Number(value));
        }
        const negative = value < 0n;
        if (negative) {
            value = -value;
        }
        let hi = value >> 32n;
        let lo = value - (hi << 32n);
        if (negative) {
            hi = ~hi | 0n;
            lo = ~lo | 0n;
            if (++lo > TWO_32) {
                lo = 0n;
                if (++hi > TWO_32) {
                    hi = 0n;
                }
            }
        }
        return new LongBits(Number(lo), Number(hi));
    }
    /**
     * Constructs new long bits from the specified number
     */
    static fromNumber(value) {
        if (value === 0) {
            return zero;
        }
        const sign = value < 0;
        if (sign) {
            value = -value;
        }
        let lo = value >>> 0;
        let hi = (value - lo) / 4294967296 >>> 0;
        if (sign) {
            hi = ~hi >>> 0;
            lo = ~lo >>> 0;
            if (++lo > 4294967295) {
                lo = 0;
                if (++hi > 4294967295) {
                    hi = 0;
                }
            }
        }
        return new LongBits(lo, hi);
    }
    /**
     * Constructs new long bits from a number, long or string
     */
    static from(value) {
        if (typeof value === 'number') {
            return LongBits.fromNumber(value);
        }
        if (typeof value === 'bigint') {
            return LongBits.fromBigInt(value);
        }
        if (typeof value === 'string') {
            return LongBits.fromBigInt(BigInt(value));
        }
        return value.low != null || value.high != null ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
    }
}
const zero = new LongBits(0, 0);
zero.toBigInt = function () { return 0n; };
zero.zzEncode = zero.zzDecode = function () { return this; };
zero.length = function () { return 1; };
const TWO_32 = 4294967296n;

/**
 * Calculates the UTF8 byte length of a string
 */
function length$1(string) {
    let len = 0;
    let c = 0;
    for (let i = 0; i < string.length; ++i) {
        c = string.charCodeAt(i);
        if (c < 128) {
            len += 1;
        }
        else if (c < 2048) {
            len += 2;
        }
        else if ((c & 0xFC00) === 0xD800 && (string.charCodeAt(i + 1) & 0xFC00) === 0xDC00) {
            ++i;
            len += 4;
        }
        else {
            len += 3;
        }
    }
    return len;
}
/**
 * Reads UTF8 bytes as a string
 */
function read$2(buffer, start, end) {
    const len = end - start;
    if (len < 1) {
        return '';
    }
    let parts;
    const chunk = [];
    let i = 0; // char offset
    let t; // temporary
    while (start < end) {
        t = buffer[start++];
        if (t < 128) {
            chunk[i++] = t;
        }
        else if (t > 191 && t < 224) {
            chunk[i++] = (t & 31) << 6 | buffer[start++] & 63;
        }
        else if (t > 239 && t < 365) {
            t = ((t & 7) << 18 | (buffer[start++] & 63) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63) - 0x10000;
            chunk[i++] = 0xD800 + (t >> 10);
            chunk[i++] = 0xDC00 + (t & 1023);
        }
        else {
            chunk[i++] = (t & 15) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63;
        }
        if (i > 8191) {
            (parts ?? (parts = [])).push(String.fromCharCode.apply(String, chunk));
            i = 0;
        }
    }
    if (parts != null) {
        if (i > 0) {
            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));
        }
        return parts.join('');
    }
    return String.fromCharCode.apply(String, chunk.slice(0, i));
}
/**
 * Writes a string as UTF8 bytes
 */
function write$1(string, buffer, offset) {
    const start = offset;
    let c1; // character 1
    let c2; // character 2
    for (let i = 0; i < string.length; ++i) {
        c1 = string.charCodeAt(i);
        if (c1 < 128) {
            buffer[offset++] = c1;
        }
        else if (c1 < 2048) {
            buffer[offset++] = c1 >> 6 | 192;
            buffer[offset++] = c1 & 63 | 128;
        }
        else if ((c1 & 0xFC00) === 0xD800 && ((c2 = string.charCodeAt(i + 1)) & 0xFC00) === 0xDC00) {
            c1 = 0x10000 + ((c1 & 0x03FF) << 10) + (c2 & 0x03FF);
            ++i;
            buffer[offset++] = c1 >> 18 | 240;
            buffer[offset++] = c1 >> 12 & 63 | 128;
            buffer[offset++] = c1 >> 6 & 63 | 128;
            buffer[offset++] = c1 & 63 | 128;
        }
        else {
            buffer[offset++] = c1 >> 12 | 224;
            buffer[offset++] = c1 >> 6 & 63 | 128;
            buffer[offset++] = c1 & 63 | 128;
        }
    }
    return offset - start;
}

/* istanbul ignore next */
function indexOutOfRange(reader, writeLength) {
    return RangeError(`index out of range: ${reader.pos} + ${writeLength ?? 1} > ${reader.len}`);
}
function readFixed32End(buf, end) {
    return (buf[end - 4] |
        buf[end - 3] << 8 |
        buf[end - 2] << 16 |
        buf[end - 1] << 24) >>> 0;
}
/**
 * Constructs a new reader instance using the specified buffer.
 */
class Uint8ArrayReader {
    buf;
    pos;
    len;
    _slice = Uint8Array.prototype.subarray;
    constructor(buffer) {
        /**
         * Read buffer
         */
        this.buf = buffer;
        /**
         * Read buffer position
         */
        this.pos = 0;
        /**
         * Read buffer length
         */
        this.len = buffer.length;
    }
    /**
     * Reads a varint as an unsigned 32 bit value
     */
    uint32() {
        let value = 4294967295;
        value = (this.buf[this.pos] & 127) >>> 0;
        if (this.buf[this.pos++] < 128)
            return value;
        value = (value | (this.buf[this.pos] & 127) << 7) >>> 0;
        if (this.buf[this.pos++] < 128)
            return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0;
        if (this.buf[this.pos++] < 128)
            return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0;
        if (this.buf[this.pos++] < 128)
            return value;
        value = (value | (this.buf[this.pos] & 15) << 28) >>> 0;
        if (this.buf[this.pos++] < 128)
            return value;
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange(this, 10);
        }
        return value;
    }
    /**
     * Reads a varint as a signed 32 bit value
     */
    int32() {
        return this.uint32() | 0;
    }
    /**
     * Reads a zig-zag encoded varint as a signed 32 bit value
     */
    sint32() {
        const value = this.uint32();
        return value >>> 1 ^ -(value & 1) | 0;
    }
    /**
     * Reads a varint as a boolean
     */
    bool() {
        return this.uint32() !== 0;
    }
    /**
     * Reads fixed 32 bits as an unsigned 32 bit integer
     */
    fixed32() {
        if (this.pos + 4 > this.len) {
            throw indexOutOfRange(this, 4);
        }
        const res = readFixed32End(this.buf, this.pos += 4);
        return res;
    }
    /**
     * Reads fixed 32 bits as a signed 32 bit integer
     */
    sfixed32() {
        if (this.pos + 4 > this.len) {
            throw indexOutOfRange(this, 4);
        }
        const res = readFixed32End(this.buf, this.pos += 4) | 0;
        return res;
    }
    /**
     * Reads a float (32 bit) as a number
     */
    float() {
        if (this.pos + 4 > this.len) {
            throw indexOutOfRange(this, 4);
        }
        const value = readFloatLE(this.buf, this.pos);
        this.pos += 4;
        return value;
    }
    /**
     * Reads a double (64 bit float) as a number
     */
    double() {
        /* istanbul ignore if */
        if (this.pos + 8 > this.len) {
            throw indexOutOfRange(this, 4);
        }
        const value = readDoubleLE(this.buf, this.pos);
        this.pos += 8;
        return value;
    }
    /**
     * Reads a sequence of bytes preceded by its length as a varint
     */
    bytes() {
        const length = this.uint32();
        const start = this.pos;
        const end = this.pos + length;
        /* istanbul ignore if */
        if (end > this.len) {
            throw indexOutOfRange(this, length);
        }
        this.pos += length;
        return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
            ? new Uint8Array(0)
            : this.buf.subarray(start, end);
    }
    /**
     * Reads a string preceded by its byte length as a varint
     */
    string() {
        const bytes = this.bytes();
        return read$2(bytes, 0, bytes.length);
    }
    /**
     * Skips the specified number of bytes if specified, otherwise skips a varint
     */
    skip(length) {
        if (typeof length === 'number') {
            /* istanbul ignore if */
            if (this.pos + length > this.len) {
                throw indexOutOfRange(this, length);
            }
            this.pos += length;
        }
        else {
            do {
                /* istanbul ignore if */
                if (this.pos >= this.len) {
                    throw indexOutOfRange(this);
                }
            } while ((this.buf[this.pos++] & 128) !== 0);
        }
        return this;
    }
    /**
     * Skips the next element of the specified wire type
     */
    skipType(wireType) {
        switch (wireType) {
            case 0:
                this.skip();
                break;
            case 1:
                this.skip(8);
                break;
            case 2:
                this.skip(this.uint32());
                break;
            case 3:
                while ((wireType = this.uint32() & 7) !== 4) {
                    this.skipType(wireType);
                }
                break;
            case 5:
                this.skip(4);
                break;
            /* istanbul ignore next */
            default:
                throw Error(`invalid wire type ${wireType} at offset ${this.pos}`);
        }
        return this;
    }
    readLongVarint() {
        // tends to deopt with local vars for octet etc.
        const bits = new LongBits(0, 0);
        let i = 0;
        if (this.len - this.pos > 4) { // fast route (lo)
            for (; i < 4; ++i) {
                // 1st..4th
                bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
                if (this.buf[this.pos++] < 128) {
                    return bits;
                }
            }
            // 5th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) >> 4) >>> 0;
            if (this.buf[this.pos++] < 128) {
                return bits;
            }
            i = 0;
        }
        else {
            for (; i < 3; ++i) {
                /* istanbul ignore if */
                if (this.pos >= this.len) {
                    throw indexOutOfRange(this);
                }
                // 1st..3th
                bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
                if (this.buf[this.pos++] < 128) {
                    return bits;
                }
            }
            // 4th
            bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
            return bits;
        }
        if (this.len - this.pos > 4) { // fast route (hi)
            for (; i < 5; ++i) {
                // 6th..10th
                bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
                if (this.buf[this.pos++] < 128) {
                    return bits;
                }
            }
        }
        else {
            for (; i < 5; ++i) {
                if (this.pos >= this.len) {
                    throw indexOutOfRange(this);
                }
                // 6th..10th
                bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
                if (this.buf[this.pos++] < 128) {
                    return bits;
                }
            }
        }
        throw Error('invalid varint encoding');
    }
    readFixed64() {
        if (this.pos + 8 > this.len) {
            throw indexOutOfRange(this, 8);
        }
        const lo = readFixed32End(this.buf, this.pos += 4);
        const hi = readFixed32End(this.buf, this.pos += 4);
        return new LongBits(lo, hi);
    }
    /**
     * Reads a varint as a signed 64 bit value
     */
    int64() {
        return this.readLongVarint().toBigInt();
    }
    /**
     * Reads a varint as a signed 64 bit value returned as a possibly unsafe
     * JavaScript number
     */
    int64Number() {
        return this.readLongVarint().toNumber();
    }
    /**
     * Reads a varint as a signed 64 bit value returned as a string
     */
    int64String() {
        return this.readLongVarint().toString();
    }
    /**
     * Reads a varint as an unsigned 64 bit value
     */
    uint64() {
        return this.readLongVarint().toBigInt(true);
    }
    /**
     * Reads a varint as an unsigned 64 bit value returned as a possibly unsafe
     * JavaScript number
     */
    uint64Number() {
        const value = decodeUint8Array(this.buf, this.pos);
        this.pos += encodingLength$1(value);
        return value;
    }
    /**
     * Reads a varint as an unsigned 64 bit value returned as a string
     */
    uint64String() {
        return this.readLongVarint().toString(true);
    }
    /**
     * Reads a zig-zag encoded varint as a signed 64 bit value
     */
    sint64() {
        return this.readLongVarint().zzDecode().toBigInt();
    }
    /**
     * Reads a zig-zag encoded varint as a signed 64 bit value returned as a
     * possibly unsafe JavaScript number
     */
    sint64Number() {
        return this.readLongVarint().zzDecode().toNumber();
    }
    /**
     * Reads a zig-zag encoded varint as a signed 64 bit value returned as a
     * string
     */
    sint64String() {
        return this.readLongVarint().zzDecode().toString();
    }
    /**
     * Reads fixed 64 bits
     */
    fixed64() {
        return this.readFixed64().toBigInt();
    }
    /**
     * Reads fixed 64 bits returned as a possibly unsafe JavaScript number
     */
    fixed64Number() {
        return this.readFixed64().toNumber();
    }
    /**
     * Reads fixed 64 bits returned as a string
     */
    fixed64String() {
        return this.readFixed64().toString();
    }
    /**
     * Reads zig-zag encoded fixed 64 bits
     */
    sfixed64() {
        return this.readFixed64().toBigInt();
    }
    /**
     * Reads zig-zag encoded fixed 64 bits returned as a possibly unsafe
     * JavaScript number
     */
    sfixed64Number() {
        return this.readFixed64().toNumber();
    }
    /**
     * Reads zig-zag encoded fixed 64 bits returned as a string
     */
    sfixed64String() {
        return this.readFixed64().toString();
    }
}
function createReader(buf) {
    return new Uint8ArrayReader(buf instanceof Uint8Array ? buf : buf.subarray());
}

function decodeMessage(buf, codec, opts) {
    const reader = createReader(buf);
    return codec.decode(reader, undefined, opts);
}

function equals$2(aa, bb) {
    if (aa === bb) {
        return true;
    }
    if (aa.byteLength !== bb.byteLength) {
        return false;
    }
    for (let ii = 0; ii < aa.byteLength; ii++) {
        if (aa[ii] !== bb[ii]) {
            return false;
        }
    }
    return true;
}
function coerce(o) {
    if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') {
        return o;
    }
    if (o instanceof ArrayBuffer) {
        return new Uint8Array(o);
    }
    if (ArrayBuffer.isView(o)) {
        return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);
    }
    throw new Error('Unknown type, must be binary type');
}
function fromString$1(str) {
    return new TextEncoder().encode(str);
}
function toString$1(b) {
    return new TextDecoder().decode(b);
}

/* eslint-disable */
// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
/**
 * @param {string} ALPHABET
 * @param {any} name
 */
function base$1(ALPHABET, name) {
    if (ALPHABET.length >= 255) {
        throw new TypeError('Alphabet too long');
    }
    var BASE_MAP = new Uint8Array(256);
    for (var j = 0; j < BASE_MAP.length; j++) {
        BASE_MAP[j] = 255;
    }
    for (var i = 0; i < ALPHABET.length; i++) {
        var x = ALPHABET.charAt(i);
        var xc = x.charCodeAt(0);
        if (BASE_MAP[xc] !== 255) {
            throw new TypeError(x + ' is ambiguous');
        }
        BASE_MAP[xc] = i;
    }
    var BASE = ALPHABET.length;
    var LEADER = ALPHABET.charAt(0);
    var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
    var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
    /**
     * @param {any[] | Iterable<number>} source
     */
    function encode(source) {
        // @ts-ignore
        if (source instanceof Uint8Array)
            ;
        else if (ArrayBuffer.isView(source)) {
            source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
        }
        else if (Array.isArray(source)) {
            source = Uint8Array.from(source);
        }
        if (!(source instanceof Uint8Array)) {
            throw new TypeError('Expected Uint8Array');
        }
        if (source.length === 0) {
            return '';
        }
        // Skip & count leading zeroes.
        var zeroes = 0;
        var length = 0;
        var pbegin = 0;
        var pend = source.length;
        while (pbegin !== pend && source[pbegin] === 0) {
            pbegin++;
            zeroes++;
        }
        // Allocate enough space in big-endian base58 representation.
        var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
        var b58 = new Uint8Array(size);
        // Process the bytes.
        while (pbegin !== pend) {
            var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
            var i = 0;
            for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
                carry += (256 * b58[it1]) >>> 0;
                b58[it1] = (carry % BASE) >>> 0;
                carry = (carry / BASE) >>> 0;
            }
            if (carry !== 0) {
                throw new Error('Non-zero carry');
            }
            length = i;
            pbegin++;
        }
        // Skip leading zeroes in base58 result.
        var it2 = size - length;
        while (it2 !== size && b58[it2] === 0) {
            it2++;
        }
        // Translate the result into a string.
        var str = LEADER.repeat(zeroes);
        for (; it2 < size; ++it2) {
            str += ALPHABET.charAt(b58[it2]);
        }
        return str;
    }
    /**
     * @param {string | string[]} source
     */
    function decodeUnsafe(source) {
        if (typeof source !== 'string') {
            throw new TypeError('Expected String');
        }
        if (source.length === 0) {
            return new Uint8Array();
        }
        var psz = 0;
        // Skip leading spaces.
        if (source[psz] === ' ') {
            return;
        }
        // Skip and count leading '1's.
        var zeroes = 0;
        var length = 0;
        while (source[psz] === LEADER) {
            zeroes++;
            psz++;
        }
        // Allocate enough space in big-endian base256 representation.
        var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
        var b256 = new Uint8Array(size);
        // Process the characters.
        while (source[psz]) {
            // Decode character
            var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
            if (carry === 255) {
                return;
            }
            var i = 0;
            for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
                carry += (BASE * b256[it3]) >>> 0;
                b256[it3] = (carry % 256) >>> 0;
                carry = (carry / 256) >>> 0;
            }
            if (carry !== 0) {
                throw new Error('Non-zero carry');
            }
            length = i;
            psz++;
        }
        // Skip trailing spaces.
        if (source[psz] === ' ') {
            return;
        }
        // Skip leading zeroes in b256.
        var it4 = size - length;
        while (it4 !== size && b256[it4] === 0) {
            it4++;
        }
        var vch = new Uint8Array(zeroes + (size - it4));
        var j = zeroes;
        while (it4 !== size) {
            vch[j++] = b256[it4++];
        }
        return vch;
    }
    /**
     * @param {string | string[]} string
     */
    function decode(string) {
        var buffer = decodeUnsafe(string);
        if (buffer) {
            return buffer;
        }
        throw new Error(`Non-${name} character`);
    }
    return {
        encode: encode,
        decodeUnsafe: decodeUnsafe,
        decode: decode
    };
}
var src = base$1;
var _brrp__multiformats_scope_baseX = src;

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 */
let Encoder$2 = class Encoder {
    name;
    prefix;
    baseEncode;
    constructor(name, prefix, baseEncode) {
        this.name = name;
        this.prefix = prefix;
        this.baseEncode = baseEncode;
    }
    encode(bytes) {
        if (bytes instanceof Uint8Array) {
            return `${this.prefix}${this.baseEncode(bytes)}`;
        }
        else {
            throw Error('Unknown type, must be binary type');
        }
    }
};
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 */
let Decoder$2 = class Decoder {
    name;
    prefix;
    baseDecode;
    prefixCodePoint;
    constructor(name, prefix, baseDecode) {
        this.name = name;
        this.prefix = prefix;
        const prefixCodePoint = prefix.codePointAt(0);
        /* c8 ignore next 3 */
        if (prefixCodePoint === undefined) {
            throw new Error('Invalid prefix character');
        }
        this.prefixCodePoint = prefixCodePoint;
        this.baseDecode = baseDecode;
    }
    decode(text) {
        if (typeof text === 'string') {
            if (text.codePointAt(0) !== this.prefixCodePoint) {
                throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);
            }
            return this.baseDecode(text.slice(this.prefix.length));
        }
        else {
            throw Error('Can only multibase decode strings');
        }
    }
    or(decoder) {
        return or$2(this, decoder);
    }
};
class ComposedDecoder {
    decoders;
    constructor(decoders) {
        this.decoders = decoders;
    }
    or(decoder) {
        return or$2(this, decoder);
    }
    decode(input) {
        const prefix = input[0];
        const decoder = this.decoders[prefix];
        if (decoder != null) {
            return decoder.decode(input);
        }
        else {
            throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);
        }
    }
}
function or$2(left, right) {
    return new ComposedDecoder({
        ...(left.decoders ?? { [left.prefix]: left }),
        ...(right.decoders ?? { [right.prefix]: right })
    });
}
class Codec {
    name;
    prefix;
    baseEncode;
    baseDecode;
    encoder;
    decoder;
    constructor(name, prefix, baseEncode, baseDecode) {
        this.name = name;
        this.prefix = prefix;
        this.baseEncode = baseEncode;
        this.baseDecode = baseDecode;
        this.encoder = new Encoder$2(name, prefix, baseEncode);
        this.decoder = new Decoder$2(name, prefix, baseDecode);
    }
    encode(input) {
        return this.encoder.encode(input);
    }
    decode(input) {
        return this.decoder.decode(input);
    }
}
function from$1({ name, prefix, encode, decode }) {
    return new Codec(name, prefix, encode, decode);
}
function baseX({ name, prefix, alphabet }) {
    const { encode, decode } = _brrp__multiformats_scope_baseX(alphabet, name);
    return from$1({
        prefix,
        name,
        encode,
        decode: (text) => coerce(decode(text))
    });
}
function decode$7(string, alphabetIdx, bitsPerChar, name) {
    // Count the padding bytes:
    let end = string.length;
    while (string[end - 1] === '=') {
        --end;
    }
    // Allocate the output:
    const out = new Uint8Array((end * bitsPerChar / 8) | 0);
    // Parse the data:
    let bits = 0; // Number of bits currently in the buffer
    let buffer = 0; // Bits waiting to be written out, MSB first
    let written = 0; // Next byte to write
    for (let i = 0; i < end; ++i) {
        // Read one character from the string:
        const value = alphabetIdx[string[i]];
        if (value === undefined) {
            throw new SyntaxError(`Non-${name} character`);
        }
        // Append the bits to the buffer:
        buffer = (buffer << bitsPerChar) | value;
        bits += bitsPerChar;
        // Write out some bits if the buffer has a byte's worth:
        if (bits >= 8) {
            bits -= 8;
            out[written++] = 0xff & (buffer >> bits);
        }
    }
    // Verify that we have received just enough bits:
    if (bits >= bitsPerChar || (0xff & (buffer << (8 - bits))) !== 0) {
        throw new SyntaxError('Unexpected end of data');
    }
    return out;
}
function encode$7(data, alphabet, bitsPerChar) {
    const pad = alphabet[alphabet.length - 1] === '=';
    const mask = (1 << bitsPerChar) - 1;
    let out = '';
    let bits = 0; // Number of bits currently in the buffer
    let buffer = 0; // Bits waiting to be written out, MSB first
    for (let i = 0; i < data.length; ++i) {
        // Slurp data into the buffer:
        buffer = (buffer << 8) | data[i];
        bits += 8;
        // Write out as much as we can:
        while (bits > bitsPerChar) {
            bits -= bitsPerChar;
            out += alphabet[mask & (buffer >> bits)];
        }
    }
    // Partial character:
    if (bits !== 0) {
        out += alphabet[mask & (buffer << (bitsPerChar - bits))];
    }
    // Add padding characters until we hit a byte boundary:
    if (pad) {
        while (((out.length * bitsPerChar) & 7) !== 0) {
            out += '=';
        }
    }
    return out;
}
function createAlphabetIdx(alphabet) {
    // Build the character lookup table:
    const alphabetIdx = {};
    for (let i = 0; i < alphabet.length; ++i) {
        alphabetIdx[alphabet[i]] = i;
    }
    return alphabetIdx;
}
/**
 * RFC4648 Factory
 */
function rfc4648({ name, prefix, bitsPerChar, alphabet }) {
    const alphabetIdx = createAlphabetIdx(alphabet);
    return from$1({
        prefix,
        name,
        encode(input) {
            return encode$7(input, alphabet, bitsPerChar);
        },
        decode(input) {
            return decode$7(input, alphabetIdx, bitsPerChar, name);
        }
    });
}

const base10 = baseX({
    prefix: '9',
    name: 'base10',
    alphabet: '0123456789'
});

var base10$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base10: base10
});

const base16 = rfc4648({
    prefix: 'f',
    name: 'base16',
    alphabet: '0123456789abcdef',
    bitsPerChar: 4
});
const base16upper = rfc4648({
    prefix: 'F',
    name: 'base16upper',
    alphabet: '0123456789ABCDEF',
    bitsPerChar: 4
});

var base16$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base16: base16,
    base16upper: base16upper
});

const base2 = rfc4648({
    prefix: '0',
    name: 'base2',
    alphabet: '01',
    bitsPerChar: 1
});

var base2$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base2: base2
});

const alphabet = Array.from('🚀🪐☄🛰🌌🌑🌒🌓🌔🌕🌖🌗🌘🌍🌏🌎🐉☀💻🖥💾💿😂❤😍🤣😊🙏💕😭😘👍😅👏😁🔥🥰💔💖💙😢🤔😆🙄💪😉☺👌🤗💜😔😎😇🌹🤦🎉💞✌✨🤷😱😌🌸🙌😋💗💚😏💛🙂💓🤩😄😀🖤😃💯🙈👇🎶😒🤭❣😜💋👀😪😑💥🙋😞😩😡🤪👊🥳😥🤤👉💃😳✋😚😝😴🌟😬🙃🍀🌷😻😓⭐✅🥺🌈😈🤘💦✔😣🏃💐☹🎊💘😠☝😕🌺🎂🌻😐🖕💝🙊😹🗣💫💀👑🎵🤞😛🔴😤🌼😫⚽🤙☕🏆🤫👈😮🙆🍻🍃🐶💁😲🌿🧡🎁⚡🌞🎈❌✊👋😰🤨😶🤝🚶💰🍓💢🤟🙁🚨💨🤬✈🎀🍺🤓😙💟🌱😖👶🥴▶➡❓💎💸⬇😨🌚🦋😷🕺⚠🙅😟😵👎🤲🤠🤧📌🔵💅🧐🐾🍒😗🤑🌊🤯🐷☎💧😯💆👆🎤🙇🍑❄🌴💣🐸💌📍🥀🤢👅💡💩👐📸👻🤐🤮🎼🥵🚩🍎🍊👼💍📣🥂');
const alphabetBytesToChars = (alphabet.reduce((p, c, i) => { p[i] = c; return p; }, ([])));
const alphabetCharsToBytes = (alphabet.reduce((p, c, i) => {
    const codePoint = c.codePointAt(0);
    if (codePoint == null) {
        throw new Error(`Invalid character: ${c}`);
    }
    p[codePoint] = i;
    return p;
}, ([])));
function encode$6(data) {
    return data.reduce((p, c) => {
        p += alphabetBytesToChars[c];
        return p;
    }, '');
}
function decode$6(str) {
    const byts = [];
    for (const char of str) {
        const codePoint = char.codePointAt(0);
        if (codePoint == null) {
            throw new Error(`Invalid character: ${char}`);
        }
        const byt = alphabetCharsToBytes[codePoint];
        if (byt == null) {
            throw new Error(`Non-base256emoji character: ${char}`);
        }
        byts.push(byt);
    }
    return new Uint8Array(byts);
}
const base256emoji = from$1({
    prefix: '🚀',
    name: 'base256emoji',
    encode: encode$6,
    decode: decode$6
});

var base256emoji$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base256emoji: base256emoji
});

const base32$2 = rfc4648({
    prefix: 'b',
    name: 'base32',
    alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
    bitsPerChar: 5
});
const base32upper = rfc4648({
    prefix: 'B',
    name: 'base32upper',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
    bitsPerChar: 5
});
const base32pad = rfc4648({
    prefix: 'c',
    name: 'base32pad',
    alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
    bitsPerChar: 5
});
const base32padupper = rfc4648({
    prefix: 'C',
    name: 'base32padupper',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
    bitsPerChar: 5
});
const base32hex = rfc4648({
    prefix: 'v',
    name: 'base32hex',
    alphabet: '0123456789abcdefghijklmnopqrstuv',
    bitsPerChar: 5
});
const base32hexupper = rfc4648({
    prefix: 'V',
    name: 'base32hexupper',
    alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
    bitsPerChar: 5
});
const base32hexpad = rfc4648({
    prefix: 't',
    name: 'base32hexpad',
    alphabet: '0123456789abcdefghijklmnopqrstuv=',
    bitsPerChar: 5
});
const base32hexpadupper = rfc4648({
    prefix: 'T',
    name: 'base32hexpadupper',
    alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
    bitsPerChar: 5
});
const base32z = rfc4648({
    prefix: 'h',
    name: 'base32z',
    alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
    bitsPerChar: 5
});

var base32$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base32: base32$2,
    base32hex: base32hex,
    base32hexpad: base32hexpad,
    base32hexpadupper: base32hexpadupper,
    base32hexupper: base32hexupper,
    base32pad: base32pad,
    base32padupper: base32padupper,
    base32upper: base32upper,
    base32z: base32z
});

const base36 = baseX({
    prefix: 'k',
    name: 'base36',
    alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'
});
const base36upper = baseX({
    prefix: 'K',
    name: 'base36upper',
    alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
});

var base36$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base36: base36,
    base36upper: base36upper
});

const base58btc = baseX({
    name: 'base58btc',
    prefix: 'z',
    alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});
const base58flickr = baseX({
    name: 'base58flickr',
    prefix: 'Z',
    alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var base58 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base58btc: base58btc,
    base58flickr: base58flickr
});

const base64 = rfc4648({
    prefix: 'm',
    name: 'base64',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
    bitsPerChar: 6
});
const base64pad = rfc4648({
    prefix: 'M',
    name: 'base64pad',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
    bitsPerChar: 6
});
const base64url = rfc4648({
    prefix: 'u',
    name: 'base64url',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
    bitsPerChar: 6
});
const base64urlpad = rfc4648({
    prefix: 'U',
    name: 'base64urlpad',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
    bitsPerChar: 6
});

var base64$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base64: base64,
    base64pad: base64pad,
    base64url: base64url,
    base64urlpad: base64urlpad
});

const base8 = rfc4648({
    prefix: '7',
    name: 'base8',
    alphabet: '01234567',
    bitsPerChar: 3
});

var base8$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base8: base8
});

const identity$1 = from$1({
    prefix: '\x00',
    name: 'identity',
    encode: (buf) => toString$1(buf),
    decode: (str) => fromString$1(str)
});

var identityBase = /*#__PURE__*/Object.freeze({
    __proto__: null,
    identity: identity$1
});

new TextEncoder();
new TextDecoder();

/* eslint-disable */
var encode_1 = encode$5;
var MSB$1 = 0x80, MSBALL = -128, INT = Math.pow(2, 31);
/**
 * @param {number} num
 * @param {number[]} out
 * @param {number} offset
 */
function encode$5(num, out, offset) {
    out = out || [];
    offset = offset || 0;
    var oldOffset = offset;
    while (num >= INT) {
        out[offset++] = (num & 0xFF) | MSB$1;
        num /= 128;
    }
    while (num & MSBALL) {
        out[offset++] = (num & 0xFF) | MSB$1;
        num >>>= 7;
    }
    out[offset] = num | 0;
    // @ts-ignore
    encode$5.bytes = offset - oldOffset + 1;
    return out;
}
var decode$5 = read$1;
var MSB$1$1 = 0x80, REST$1 = 0x7F;
/**
 * @param {string | any[]} buf
 * @param {number} offset
 */
function read$1(buf, offset) {
    var res = 0, offset = offset || 0, shift = 0, counter = offset, b, l = buf.length;
    do {
        if (counter >= l) {
            // @ts-ignore
            read$1.bytes = 0;
            throw new RangeError('Could not decode varint');
        }
        b = buf[counter++];
        res += shift < 28
            ? (b & REST$1) << shift
            : (b & REST$1) * Math.pow(2, shift);
        shift += 7;
    } while (b >= MSB$1$1);
    // @ts-ignore
    read$1.bytes = counter - offset;
    return res;
}
var N1 = Math.pow(2, 7);
var N2 = Math.pow(2, 14);
var N3 = Math.pow(2, 21);
var N4 = Math.pow(2, 28);
var N5 = Math.pow(2, 35);
var N6 = Math.pow(2, 42);
var N7 = Math.pow(2, 49);
var N8 = Math.pow(2, 56);
var N9 = Math.pow(2, 63);
var length = function (/** @type {number} */ value) {
    return (value < N1 ? 1
        : value < N2 ? 2
            : value < N3 ? 3
                : value < N4 ? 4
                    : value < N5 ? 5
                        : value < N6 ? 6
                            : value < N7 ? 7
                                : value < N8 ? 8
                                    : value < N9 ? 9
                                        : 10);
};
var varint = {
    encode: encode_1,
    decode: decode$5,
    encodingLength: length
};
var _brrp_varint = varint;

function decode$4(data, offset = 0) {
    const code = _brrp_varint.decode(data, offset);
    return [code, _brrp_varint.decode.bytes];
}
function encodeTo(int, target, offset = 0) {
    _brrp_varint.encode(int, target, offset);
    return target;
}
function encodingLength(int) {
    return _brrp_varint.encodingLength(int);
}

/**
 * Creates a multihash digest.
 */
function create(code, digest) {
    const size = digest.byteLength;
    const sizeOffset = encodingLength(code);
    const digestOffset = sizeOffset + encodingLength(size);
    const bytes = new Uint8Array(digestOffset + size);
    encodeTo(code, bytes, 0);
    encodeTo(size, bytes, sizeOffset);
    bytes.set(digest, digestOffset);
    return new Digest(code, size, digest, bytes);
}
/**
 * Turns bytes representation of multihash digest into an instance.
 */
function decode$3(multihash) {
    const bytes = coerce(multihash);
    const [code, sizeOffset] = decode$4(bytes);
    const [size, digestOffset] = decode$4(bytes.subarray(sizeOffset));
    const digest = bytes.subarray(sizeOffset + digestOffset);
    if (digest.byteLength !== size) {
        throw new Error('Incorrect length');
    }
    return new Digest(code, size, digest, bytes);
}
function equals$1(a, b) {
    if (a === b) {
        return true;
    }
    else {
        const data = b;
        return (a.code === data.code &&
            a.size === data.size &&
            data.bytes instanceof Uint8Array &&
            equals$2(a.bytes, data.bytes));
    }
}
/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 */
class Digest {
    code;
    size;
    digest;
    bytes;
    /**
     * Creates a multihash digest.
     */
    constructor(code, size, digest, bytes) {
        this.code = code;
        this.size = size;
        this.digest = digest;
        this.bytes = bytes;
    }
}

const code = 0x0;
const name$1 = 'identity';
const encode$4 = coerce;
function digest(input) {
    return create(code, encode$4(input));
}
const identity = { code, name: name$1, encode: encode$4, digest };

function from({ name, code, encode }) {
    return new Hasher(name, code, encode);
}
/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 */
class Hasher {
    name;
    code;
    encode;
    constructor(name, code, encode) {
        this.name = name;
        this.code = code;
        this.encode = encode;
    }
    digest(input) {
        if (input instanceof Uint8Array) {
            const result = this.encode(input);
            return result instanceof Uint8Array
                ? create(this.code, result)
                /* c8 ignore next 1 */
                : result.then(digest => create(this.code, digest));
        }
        else {
            throw Error('Unknown type, must be binary type');
            /* c8 ignore next 1 */
        }
    }
}

/* global crypto */
function sha(name) {
    return async (data) => new Uint8Array(await crypto.subtle.digest(name, data));
}
const sha256$2 = from({
    name: 'sha2-256',
    code: 0x12,
    encode: sha('SHA-256')
});

function format(link, base) {
    const { bytes, version } = link;
    switch (version) {
        case 0:
            return toStringV0(bytes, baseCache(link), base ?? base58btc.encoder);
        default:
            return toStringV1(bytes, baseCache(link), (base ?? base32$2.encoder));
    }
}
const cache$1 = new WeakMap();
function baseCache(cid) {
    const baseCache = cache$1.get(cid);
    if (baseCache == null) {
        const baseCache = new Map();
        cache$1.set(cid, baseCache);
        return baseCache;
    }
    return baseCache;
}
class CID {
    code;
    version;
    multihash;
    bytes;
    '/';
    /**
     * @param version - Version of the CID
     * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
     * @param multihash - (Multi)hash of the of the content.
     */
    constructor(version, code, multihash, bytes) {
        this.code = code;
        this.version = version;
        this.multihash = multihash;
        this.bytes = bytes;
        // flag to serializers that this is a CID and
        // should be treated specially
        this['/'] = bytes;
    }
    /**
     * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
     * please either use `CID.asCID(cid)` or switch to new signalling mechanism
     *
     * @deprecated
     */
    get asCID() {
        return this;
    }
    // ArrayBufferView
    get byteOffset() {
        return this.bytes.byteOffset;
    }
    // ArrayBufferView
    get byteLength() {
        return this.bytes.byteLength;
    }
    toV0() {
        switch (this.version) {
            case 0: {
                return this;
            }
            case 1: {
                const { code, multihash } = this;
                if (code !== DAG_PB_CODE) {
                    throw new Error('Cannot convert a non dag-pb CID to CIDv0');
                }
                // sha2-256
                if (multihash.code !== SHA_256_CODE) {
                    throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0');
                }
                return (CID.createV0(multihash));
            }
            default: {
                throw Error(`Can not convert CID version ${this.version} to version 0. This is a bug please report`);
            }
        }
    }
    toV1() {
        switch (this.version) {
            case 0: {
                const { code, digest } = this.multihash;
                const multihash = create(code, digest);
                return (CID.createV1(this.code, multihash));
            }
            case 1: {
                return this;
            }
            default: {
                throw Error(`Can not convert CID version ${this.version} to version 1. This is a bug please report`);
            }
        }
    }
    equals(other) {
        return CID.equals(this, other);
    }
    static equals(self, other) {
        const unknown = other;
        return (unknown != null &&
            self.code === unknown.code &&
            self.version === unknown.version &&
            equals$1(self.multihash, unknown.multihash));
    }
    toString(base) {
        return format(this, base);
    }
    toJSON() {
        return { '/': format(this) };
    }
    link() {
        return this;
    }
    [Symbol.toStringTag] = 'CID';
    // Legacy
    [Symbol.for('nodejs.util.inspect.custom')]() {
        return `CID(${this.toString()})`;
    }
    /**
     * Takes any input `value` and returns a `CID` instance if it was
     * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
     * it will return value back. If `value` is not instance of this CID
     * class, but is compatible CID it will return new instance of this
     * `CID` class. Otherwise returns null.
     *
     * This allows two different incompatible versions of CID library to
     * co-exist and interop as long as binary interface is compatible.
     */
    static asCID(input) {
        if (input == null) {
            return null;
        }
        const value = input;
        if (value instanceof CID) {
            // If value is instance of CID then we're all set.
            return value;
        }
        else if ((value['/'] != null && value['/'] === value.bytes) || value.asCID === value) {
            // If value isn't instance of this CID class but `this.asCID === this` or
            // `value['/'] === value.bytes` is true it is CID instance coming from a
            // different implementation (diff version or duplicate). In that case we
            // rebase it to this `CID` implementation so caller is guaranteed to get
            // instance with expected API.
            const { version, code, multihash, bytes } = value;
            return new CID(version, code, multihash, bytes ?? encodeCID(version, code, multihash.bytes));
        }
        else if (value[cidSymbol] === true) {
            // If value is a CID from older implementation that used to be tagged via
            // symbol we still rebase it to the this `CID` implementation by
            // delegating that to a constructor.
            const { version, multihash, code } = value;
            const digest = decode$3(multihash);
            return CID.create(version, code, digest);
        }
        else {
            // Otherwise value is not a CID (or an incompatible version of it) in
            // which case we return `null`.
            return null;
        }
    }
    /**
     * @param version - Version of the CID
     * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
     * @param digest - (Multi)hash of the of the content.
     */
    static create(version, code, digest) {
        if (typeof code !== 'number') {
            throw new Error('String codecs are no longer supported');
        }
        if (!(digest.bytes instanceof Uint8Array)) {
            throw new Error('Invalid digest');
        }
        switch (version) {
            case 0: {
                if (code !== DAG_PB_CODE) {
                    throw new Error(`Version 0 CID must use dag-pb (code: ${DAG_PB_CODE}) block encoding`);
                }
                else {
                    return new CID(version, code, digest, digest.bytes);
                }
            }
            case 1: {
                const bytes = encodeCID(version, code, digest.bytes);
                return new CID(version, code, digest, bytes);
            }
            default: {
                throw new Error('Invalid version');
            }
        }
    }
    /**
     * Simplified version of `create` for CIDv0.
     */
    static createV0(digest) {
        return CID.create(0, DAG_PB_CODE, digest);
    }
    /**
     * Simplified version of `create` for CIDv1.
     *
     * @param code - Content encoding format code.
     * @param digest - Multihash of the content.
     */
    static createV1(code, digest) {
        return CID.create(1, code, digest);
    }
    /**
     * Decoded a CID from its binary representation. The byte array must contain
     * only the CID with no additional bytes.
     *
     * An error will be thrown if the bytes provided do not contain a valid
     * binary representation of a CID.
     */
    static decode(bytes) {
        const [cid, remainder] = CID.decodeFirst(bytes);
        if (remainder.length !== 0) {
            throw new Error('Incorrect length');
        }
        return cid;
    }
    /**
     * Decoded a CID from its binary representation at the beginning of a byte
     * array.
     *
     * Returns an array with the first element containing the CID and the second
     * element containing the remainder of the original byte array. The remainder
     * will be a zero-length byte array if the provided bytes only contained a
     * binary CID representation.
     */
    static decodeFirst(bytes) {
        const specs = CID.inspectBytes(bytes);
        const prefixSize = specs.size - specs.multihashSize;
        const multihashBytes = coerce(bytes.subarray(prefixSize, prefixSize + specs.multihashSize));
        if (multihashBytes.byteLength !== specs.multihashSize) {
            throw new Error('Incorrect length');
        }
        const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);
        const digest = new Digest(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);
        const cid = specs.version === 0
            ? CID.createV0(digest)
            : CID.createV1(specs.codec, digest);
        return [cid, bytes.subarray(specs.size)];
    }
    /**
     * Inspect the initial bytes of a CID to determine its properties.
     *
     * Involves decoding up to 4 varints. Typically this will require only 4 to 6
     * bytes but for larger multicodec code values and larger multihash digest
     * lengths these varints can be quite large. It is recommended that at least
     * 10 bytes be made available in the `initialBytes` argument for a complete
     * inspection.
     */
    static inspectBytes(initialBytes) {
        let offset = 0;
        const next = () => {
            const [i, length] = decode$4(initialBytes.subarray(offset));
            offset += length;
            return i;
        };
        let version = next();
        let codec = DAG_PB_CODE;
        if (version === 18) {
            // CIDv0
            version = 0;
            offset = 0;
        }
        else {
            codec = next();
        }
        if (version !== 0 && version !== 1) {
            throw new RangeError(`Invalid CID version ${version}`);
        }
        const prefixSize = offset;
        const multihashCode = next(); // multihash code
        const digestSize = next(); // multihash length
        const size = offset + digestSize;
        const multihashSize = size - prefixSize;
        return { version, codec, multihashCode, digestSize, multihashSize, size };
    }
    /**
     * Takes cid in a string representation and creates an instance. If `base`
     * decoder is not provided will use a default from the configuration. It will
     * throw an error if encoding of the CID is not compatible with supplied (or
     * a default decoder).
     */
    static parse(source, base) {
        const [prefix, bytes] = parseCIDtoBytes(source, base);
        const cid = CID.decode(bytes);
        if (cid.version === 0 && source[0] !== 'Q') {
            throw Error('Version 0 CID string must not include multibase prefix');
        }
        // Cache string representation to avoid computing it on `this.toString()`
        baseCache(cid).set(prefix, source);
        return cid;
    }
}
function parseCIDtoBytes(source, base) {
    switch (source[0]) {
        // CIDv0 is parsed differently
        case 'Q': {
            const decoder = base ?? base58btc;
            return [
                base58btc.prefix,
                decoder.decode(`${base58btc.prefix}${source}`)
            ];
        }
        case base58btc.prefix: {
            const decoder = base ?? base58btc;
            return [base58btc.prefix, decoder.decode(source)];
        }
        case base32$2.prefix: {
            const decoder = base ?? base32$2;
            return [base32$2.prefix, decoder.decode(source)];
        }
        case base36.prefix: {
            const decoder = base ?? base36;
            return [base36.prefix, decoder.decode(source)];
        }
        default: {
            if (base == null) {
                throw Error('To parse non base32, base36 or base58btc encoded CID multibase decoder must be provided');
            }
            return [source[0], base.decode(source)];
        }
    }
}
function toStringV0(bytes, cache, base) {
    const { prefix } = base;
    if (prefix !== base58btc.prefix) {
        throw Error(`Cannot string encode V0 in ${base.name} encoding`);
    }
    const cid = cache.get(prefix);
    if (cid == null) {
        const cid = base.encode(bytes).slice(1);
        cache.set(prefix, cid);
        return cid;
    }
    else {
        return cid;
    }
}
function toStringV1(bytes, cache, base) {
    const { prefix } = base;
    const cid = cache.get(prefix);
    if (cid == null) {
        const cid = base.encode(bytes);
        cache.set(prefix, cid);
        return cid;
    }
    else {
        return cid;
    }
}
const DAG_PB_CODE = 0x70;
const SHA_256_CODE = 0x12;
function encodeCID(version, code, multihash) {
    const codeOffset = encodingLength(version);
    const hashOffset = codeOffset + encodingLength(code);
    const bytes = new Uint8Array(hashOffset + multihash.byteLength);
    encodeTo(version, bytes, 0);
    encodeTo(code, bytes, codeOffset);
    bytes.set(multihash, hashOffset);
    return bytes;
}
const cidSymbol = Symbol.for('@ipld/js-cid/CID');

const bases = { ...identityBase, ...base2$1, ...base8$1, ...base10$1, ...base16$1, ...base32$3, ...base36$1, ...base58, ...base64$1, ...base256emoji$1 };

function createCodec$1(name, prefix, encode, decode) {
    return {
        name,
        prefix,
        encoder: {
            name,
            prefix,
            encode
        },
        decoder: {
            decode
        }
    };
}
const string$1 = createCodec$1('utf8', 'u', (buf) => {
    const decoder = new TextDecoder('utf8');
    return 'u' + decoder.decode(buf);
}, (str) => {
    const encoder = new TextEncoder();
    return encoder.encode(str.substring(1));
});
const ascii = createCodec$1('ascii', 'a', (buf) => {
    let string = 'a';
    for (let i = 0; i < buf.length; i++) {
        string += String.fromCharCode(buf[i]);
    }
    return string;
}, (str) => {
    str = str.substring(1);
    const buf = allocUnsafe(str.length);
    for (let i = 0; i < str.length; i++) {
        buf[i] = str.charCodeAt(i);
    }
    return buf;
});
const BASES = {
    utf8: string$1,
    'utf-8': string$1,
    hex: bases.base16,
    latin1: ascii,
    ascii,
    binary: ascii,
    ...bases
};

/**
 * Create a `Uint8Array` from the passed string
 *
 * Supports `utf8`, `utf-8`, `hex`, and any encoding supported by the multiformats module.
 *
 * Also `ascii` which is similar to node's 'binary' encoding.
 */
function fromString(string, encoding = 'utf8') {
    const base = BASES[encoding];
    if (base == null) {
        throw new Error(`Unsupported encoding "${encoding}"`);
    }
    // add multibase prefix
    return base.decoder.decode(`${base.prefix}${string}`); // eslint-disable-line @typescript-eslint/restrict-template-expressions
}

/**
 * A general purpose buffer pool
 */
function pool(size) {
    const SIZE = 8192;
    const MAX = SIZE >>> 1;
    let slab;
    let offset = SIZE;
    return function poolAlloc(size) {
        if (size < 1 || size > MAX) {
            return allocUnsafe(size);
        }
        if (offset + size > SIZE) {
            slab = allocUnsafe(SIZE);
            offset = 0;
        }
        const buf = slab.subarray(offset, offset += size);
        if ((offset & 7) !== 0) {
            // align to 32 bit
            offset = (offset | 7) + 1;
        }
        return buf;
    };
}

/**
 * Constructs a new writer operation instance.
 *
 * @classdesc Scheduled writer operation
 */
class Op {
    /**
     * Function to call
     */
    fn;
    /**
     * Value byte length
     */
    len;
    /**
     * Next operation
     */
    next;
    /**
     * Value to write
     */
    val;
    constructor(fn, len, val) {
        this.fn = fn;
        this.len = len;
        this.next = undefined;
        this.val = val; // type varies
    }
}
/* istanbul ignore next */
function noop() { } // eslint-disable-line no-empty-function
/**
 * Constructs a new writer state instance
 */
class State {
    /**
     * Current head
     */
    head;
    /**
     * Current tail
     */
    tail;
    /**
     * Current buffer length
     */
    len;
    /**
     * Next state
     */
    next;
    constructor(writer) {
        this.head = writer.head;
        this.tail = writer.tail;
        this.len = writer.len;
        this.next = writer.states;
    }
}
const bufferPool = pool();
/**
 * Allocates a buffer of the specified size
 */
function alloc(size) {
    if (globalThis.Buffer != null) {
        return allocUnsafe(size);
    }
    return bufferPool(size);
}
/**
 * When a value is written, the writer calculates its byte length and puts it into a linked
 * list of operations to perform when finish() is called. This both allows us to allocate
 * buffers of the exact required size and reduces the amount of work we have to do compared
 * to first calculating over objects and then encoding over objects. In our case, the encoding
 * part is just a linked list walk calling operations with already prepared values.
 */
class Uint8ArrayWriter {
    /**
     * Current length
     */
    len;
    /**
     * Operations head
     */
    head;
    /**
     * Operations tail
     */
    tail;
    /**
     * Linked forked states
     */
    states;
    constructor() {
        this.len = 0;
        this.head = new Op(noop, 0, 0);
        this.tail = this.head;
        this.states = null;
    }
    /**
     * Pushes a new operation to the queue
     */
    _push(fn, len, val) {
        this.tail = this.tail.next = new Op(fn, len, val);
        this.len += len;
        return this;
    }
    /**
     * Writes an unsigned 32 bit value as a varint
     */
    uint32(value) {
        // here, the call to this.push has been inlined and a varint specific Op subclass is used.
        // uint32 is by far the most frequently used operation and benefits significantly from this.
        this.len += (this.tail = this.tail.next = new VarintOp((value = value >>> 0) <
            128
            ? 1
            : value < 16384
                ? 2
                : value < 2097152
                    ? 3
                    : value < 268435456
                        ? 4
                        : 5, value)).len;
        return this;
    }
    /**
     * Writes a signed 32 bit value as a varint`
     */
    int32(value) {
        return value < 0
            ? this._push(writeVarint64, 10, LongBits.fromNumber(value)) // 10 bytes per spec
            : this.uint32(value);
    }
    /**
     * Writes a 32 bit value as a varint, zig-zag encoded
     */
    sint32(value) {
        return this.uint32((value << 1 ^ value >> 31) >>> 0);
    }
    /**
     * Writes an unsigned 64 bit value as a varint
     */
    uint64(value) {
        const bits = LongBits.fromBigInt(value);
        return this._push(writeVarint64, bits.length(), bits);
    }
    /**
     * Writes an unsigned 64 bit value as a varint
     */
    uint64Number(value) {
        return this._push(encodeUint8Array, encodingLength$1(value), value);
    }
    /**
     * Writes an unsigned 64 bit value as a varint
     */
    uint64String(value) {
        return this.uint64(BigInt(value));
    }
    /**
     * Writes a signed 64 bit value as a varint
     */
    int64(value) {
        return this.uint64(value);
    }
    /**
     * Writes a signed 64 bit value as a varint
     */
    int64Number(value) {
        return this.uint64Number(value);
    }
    /**
     * Writes a signed 64 bit value as a varint
     */
    int64String(value) {
        return this.uint64String(value);
    }
    /**
     * Writes a signed 64 bit value as a varint, zig-zag encoded
     */
    sint64(value) {
        const bits = LongBits.fromBigInt(value).zzEncode();
        return this._push(writeVarint64, bits.length(), bits);
    }
    /**
     * Writes a signed 64 bit value as a varint, zig-zag encoded
     */
    sint64Number(value) {
        const bits = LongBits.fromNumber(value).zzEncode();
        return this._push(writeVarint64, bits.length(), bits);
    }
    /**
     * Writes a signed 64 bit value as a varint, zig-zag encoded
     */
    sint64String(value) {
        return this.sint64(BigInt(value));
    }
    /**
     * Writes a boolish value as a varint
     */
    bool(value) {
        return this._push(writeByte, 1, value ? 1 : 0);
    }
    /**
     * Writes an unsigned 32 bit value as fixed 32 bits
     */
    fixed32(value) {
        return this._push(writeFixed32, 4, value >>> 0);
    }
    /**
     * Writes a signed 32 bit value as fixed 32 bits
     */
    sfixed32(value) {
        return this.fixed32(value);
    }
    /**
     * Writes an unsigned 64 bit value as fixed 64 bits
     */
    fixed64(value) {
        const bits = LongBits.fromBigInt(value);
        return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);
    }
    /**
     * Writes an unsigned 64 bit value as fixed 64 bits
     */
    fixed64Number(value) {
        const bits = LongBits.fromNumber(value);
        return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);
    }
    /**
     * Writes an unsigned 64 bit value as fixed 64 bits
     */
    fixed64String(value) {
        return this.fixed64(BigInt(value));
    }
    /**
     * Writes a signed 64 bit value as fixed 64 bits
     */
    sfixed64(value) {
        return this.fixed64(value);
    }
    /**
     * Writes a signed 64 bit value as fixed 64 bits
     */
    sfixed64Number(value) {
        return this.fixed64Number(value);
    }
    /**
     * Writes a signed 64 bit value as fixed 64 bits
     */
    sfixed64String(value) {
        return this.fixed64String(value);
    }
    /**
     * Writes a float (32 bit)
     */
    float(value) {
        return this._push(writeFloatLE, 4, value);
    }
    /**
     * Writes a double (64 bit float).
     *
     * @function
     * @param {number} value - Value to write
     * @returns {Writer} `this`
     */
    double(value) {
        return this._push(writeDoubleLE, 8, value);
    }
    /**
     * Writes a sequence of bytes
     */
    bytes(value) {
        const len = value.length >>> 0;
        if (len === 0) {
            return this._push(writeByte, 1, 0);
        }
        return this.uint32(len)._push(writeBytes, len, value);
    }
    /**
     * Writes a string
     */
    string(value) {
        const len = length$1(value);
        return len !== 0
            ? this.uint32(len)._push(write$1, len, value)
            : this._push(writeByte, 1, 0);
    }
    /**
     * Forks this writer's state by pushing it to a stack.
     * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
     */
    fork() {
        this.states = new State(this);
        this.head = this.tail = new Op(noop, 0, 0);
        this.len = 0;
        return this;
    }
    /**
     * Resets this instance to the last state
     */
    reset() {
        if (this.states != null) {
            this.head = this.states.head;
            this.tail = this.states.tail;
            this.len = this.states.len;
            this.states = this.states.next;
        }
        else {
            this.head = this.tail = new Op(noop, 0, 0);
            this.len = 0;
        }
        return this;
    }
    /**
     * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
     */
    ldelim() {
        const head = this.head;
        const tail = this.tail;
        const len = this.len;
        this.reset().uint32(len);
        if (len !== 0) {
            this.tail.next = head.next; // skip noop
            this.tail = tail;
            this.len += len;
        }
        return this;
    }
    /**
     * Finishes the write operation
     */
    finish() {
        let head = this.head.next; // skip noop
        const buf = alloc(this.len);
        let pos = 0;
        while (head != null) {
            head.fn(head.val, buf, pos);
            pos += head.len;
            head = head.next;
        }
        // this.head = this.tail = null;
        return buf;
    }
}
function writeByte(val, buf, pos) {
    buf[pos] = val & 255;
}
function writeVarint32(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}
/**
 * Constructs a new varint writer operation instance.
 *
 * @classdesc Scheduled varint writer operation
 */
class VarintOp extends Op {
    next;
    constructor(len, val) {
        super(writeVarint32, len, val);
        this.next = undefined;
    }
}
function writeVarint64(val, buf, pos) {
    while (val.hi !== 0) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}
function writeFixed32(val, buf, pos) {
    buf[pos] = val & 255;
    buf[pos + 1] = val >>> 8 & 255;
    buf[pos + 2] = val >>> 16 & 255;
    buf[pos + 3] = val >>> 24;
}
function writeBytes(val, buf, pos) {
    buf.set(val, pos);
}
if (globalThis.Buffer != null) {
    Uint8ArrayWriter.prototype.bytes = function (value) {
        const len = value.length >>> 0;
        this.uint32(len);
        if (len > 0) {
            this._push(writeBytesBuffer, len, value);
        }
        return this;
    };
    Uint8ArrayWriter.prototype.string = function (value) {
        const len = globalThis.Buffer.byteLength(value);
        this.uint32(len);
        if (len > 0) {
            this._push(writeStringBuffer, len, value);
        }
        return this;
    };
}
function writeBytesBuffer(val, buf, pos) {
    buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
    // also works for plain array values
}
function writeStringBuffer(val, buf, pos) {
    if (val.length < 40) {
        // plain js is faster for short strings (probably due to redundant assertions)
        write$1(val, buf, pos);
        // @ts-expect-error buf isn't a Uint8Array?
    }
    else if (buf.utf8Write != null) {
        // @ts-expect-error buf isn't a Uint8Array?
        buf.utf8Write(val, pos);
    }
    else {
        buf.set(fromString(val), pos);
    }
}
/**
 * Creates a new writer
 */
function createWriter() {
    return new Uint8ArrayWriter();
}

function encodeMessage(message, codec) {
    const w = createWriter();
    codec.encode(message, w, {
        lengthDelimited: false
    });
    return w.finish();
}

// https://developers.google.com/protocol-buffers/docs/encoding#structure
var CODEC_TYPES;
(function (CODEC_TYPES) {
    CODEC_TYPES[CODEC_TYPES["VARINT"] = 0] = "VARINT";
    CODEC_TYPES[CODEC_TYPES["BIT64"] = 1] = "BIT64";
    CODEC_TYPES[CODEC_TYPES["LENGTH_DELIMITED"] = 2] = "LENGTH_DELIMITED";
    CODEC_TYPES[CODEC_TYPES["START_GROUP"] = 3] = "START_GROUP";
    CODEC_TYPES[CODEC_TYPES["END_GROUP"] = 4] = "END_GROUP";
    CODEC_TYPES[CODEC_TYPES["BIT32"] = 5] = "BIT32";
})(CODEC_TYPES || (CODEC_TYPES = {}));
function createCodec(name, type, encode, decode) {
    return {
        name,
        type,
        encode,
        decode
    };
}

function enumeration(v) {
    function findValue(val) {
        // Use the reverse mapping to look up the enum key for the stored value
        // https://www.typescriptlang.org/docs/handbook/enums.html#reverse-mappings
        if (v[val.toString()] == null) {
            throw new Error('Invalid enum value');
        }
        return v[val];
    }
    const encode = function enumEncode(val, writer) {
        const enumValue = findValue(val);
        writer.int32(enumValue);
    };
    const decode = function enumDecode(reader) {
        const val = reader.int32();
        return findValue(val);
    };
    // @ts-expect-error yeah yeah
    return createCodec('enum', CODEC_TYPES.VARINT, encode, decode);
}

function message$1(encode, decode) {
    return createCodec('message', CODEC_TYPES.LENGTH_DELIMITED, encode, decode);
}

/**
 * @packageDocumentation
 *
 * This module contains serialization/deserialization code used when encoding/decoding protobufs.
 *
 * It should be declared as a dependency of your project:
 *
 * ```console
 * npm i protons-runtime
 * ```
 */
/**
 * Thrown when a repeated field has too many elements
 */
class MaxLengthError extends Error {
    /**
     * This will be removed in a future release
     *
     * @deprecated use the `.name` property instead
     */
    code = 'ERR_MAX_LENGTH';
    name = 'MaxLengthError';
}
/**
 * Thrown when a map has too many elements
 */
class MaxSizeError extends Error {
    /**
     * This will be removed in a future release
     *
     * @deprecated use the `.name` property instead
     */
    code = 'ERR_MAX_SIZE';
    name = 'MaxSizeError';
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
/* eslint-disable import/consistent-type-specifier-style */
/* eslint-disable @typescript-eslint/no-unused-vars */
var RateLimitProof$4;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    proof: alloc$1(0),
                    merkleRoot: alloc$1(0),
                    epoch: alloc$1(0),
                    shareX: alloc$1(0),
                    shareY: alloc$1(0),
                    nullifier: alloc$1(0),
                    rlnIdentifier: alloc$1(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.proof = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.merkleRoot = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.epoch = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.shareX = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.shareY = reader.bytes();
                            break;
                        }
                        case 6: {
                            obj.nullifier = reader.bytes();
                            break;
                        }
                        case 7: {
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf, opts) => {
        return decodeMessage(buf, RateLimitProof.codec(), opts);
    };
})(RateLimitProof$4 || (RateLimitProof$4 = {}));
var WakuMessage$4;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$4.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    payload: alloc$1(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        case 3: {
                            obj.version = reader.uint32();
                            break;
                        }
                        case 10: {
                            obj.timestamp = reader.sint64();
                            break;
                        }
                        case 11: {
                            obj.meta = reader.bytes();
                            break;
                        }
                        case 21: {
                            obj.rateLimitProof = RateLimitProof$4.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.rateLimitProof
                            });
                            break;
                        }
                        case 31: {
                            obj.ephemeral = reader.bool();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessage.codec(), opts);
    };
})(WakuMessage$4 || (WakuMessage$4 = {}));

var message = /*#__PURE__*/Object.freeze({
    __proto__: null,
    get RateLimitProof () { return RateLimitProof$4; },
    get WakuMessage () { return WakuMessage$4; }
});

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
/* eslint-disable import/consistent-type-specifier-style */
/* eslint-disable @typescript-eslint/no-unused-vars */
var FilterRequest;
(function (FilterRequest) {
    (function (ContentFilter) {
        let _codec;
        ContentFilter.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                        w.uint32(10);
                        w.string(obj.contentTopic);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length, opts = {}) => {
                    const obj = {
                        contentTopic: ''
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1: {
                                obj.contentTopic = reader.string();
                                break;
                            }
                            default: {
                                reader.skipType(tag & 7);
                                break;
                            }
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        ContentFilter.encode = (obj) => {
            return encodeMessage(obj, ContentFilter.codec());
        };
        ContentFilter.decode = (buf, opts) => {
            return decodeMessage(buf, ContentFilter.codec(), opts);
        };
    })(FilterRequest.ContentFilter || (FilterRequest.ContentFilter = {}));
    let _codec;
    FilterRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.subscribe != null && obj.subscribe !== false)) {
                    w.uint32(8);
                    w.bool(obj.subscribe);
                }
                if ((obj.topic != null && obj.topic !== '')) {
                    w.uint32(18);
                    w.string(obj.topic);
                }
                if (obj.contentFilters != null) {
                    for (const value of obj.contentFilters) {
                        w.uint32(26);
                        FilterRequest.ContentFilter.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    subscribe: false,
                    topic: '',
                    contentFilters: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.subscribe = reader.bool();
                            break;
                        }
                        case 2: {
                            obj.topic = reader.string();
                            break;
                        }
                        case 3: {
                            if (opts.limits?.contentFilters != null && obj.contentFilters.length === opts.limits.contentFilters) {
                                throw new MaxLengthError('Decode error - map field "contentFilters" had too many elements');
                            }
                            obj.contentFilters.push(FilterRequest.ContentFilter.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.contentFilters$
                            }));
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterRequest.encode = (obj) => {
        return encodeMessage(obj, FilterRequest.codec());
    };
    FilterRequest.decode = (buf, opts) => {
        return decodeMessage(buf, FilterRequest.codec(), opts);
    };
})(FilterRequest || (FilterRequest = {}));
var MessagePush$1;
(function (MessagePush) {
    let _codec;
    MessagePush.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.messages != null) {
                    for (const value of obj.messages) {
                        w.uint32(10);
                        WakuMessage$3.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    messages: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            if (opts.limits?.messages != null && obj.messages.length === opts.limits.messages) {
                                throw new MaxLengthError('Decode error - map field "messages" had too many elements');
                            }
                            obj.messages.push(WakuMessage$3.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.messages$
                            }));
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    MessagePush.encode = (obj) => {
        return encodeMessage(obj, MessagePush.codec());
    };
    MessagePush.decode = (buf, opts) => {
        return decodeMessage(buf, MessagePush.codec(), opts);
    };
})(MessagePush$1 || (MessagePush$1 = {}));
var FilterRpc;
(function (FilterRpc) {
    let _codec;
    FilterRpc.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.request != null) {
                    w.uint32(18);
                    FilterRequest.codec().encode(obj.request, w);
                }
                if (obj.push != null) {
                    w.uint32(26);
                    MessagePush$1.codec().encode(obj.push, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 2: {
                            obj.request = FilterRequest.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.request
                            });
                            break;
                        }
                        case 3: {
                            obj.push = MessagePush$1.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.push
                            });
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterRpc.encode = (obj) => {
        return encodeMessage(obj, FilterRpc.codec());
    };
    FilterRpc.decode = (buf, opts) => {
        return decodeMessage(buf, FilterRpc.codec(), opts);
    };
})(FilterRpc || (FilterRpc = {}));
var RateLimitProof$3;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    proof: alloc$1(0),
                    merkleRoot: alloc$1(0),
                    epoch: alloc$1(0),
                    shareX: alloc$1(0),
                    shareY: alloc$1(0),
                    nullifier: alloc$1(0),
                    rlnIdentifier: alloc$1(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.proof = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.merkleRoot = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.epoch = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.shareX = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.shareY = reader.bytes();
                            break;
                        }
                        case 6: {
                            obj.nullifier = reader.bytes();
                            break;
                        }
                        case 7: {
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf, opts) => {
        return decodeMessage(buf, RateLimitProof.codec(), opts);
    };
})(RateLimitProof$3 || (RateLimitProof$3 = {}));
var WakuMessage$3;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$3.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    payload: alloc$1(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        case 3: {
                            obj.version = reader.uint32();
                            break;
                        }
                        case 10: {
                            obj.timestamp = reader.sint64();
                            break;
                        }
                        case 11: {
                            obj.meta = reader.bytes();
                            break;
                        }
                        case 21: {
                            obj.rateLimitProof = RateLimitProof$3.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.rateLimitProof
                            });
                            break;
                        }
                        case 31: {
                            obj.ephemeral = reader.bool();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessage.codec(), opts);
    };
})(WakuMessage$3 || (WakuMessage$3 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
/* eslint-disable import/consistent-type-specifier-style */
/* eslint-disable @typescript-eslint/no-unused-vars */
var TopicOnlyMessage;
(function (TopicOnlyMessage) {
    let _codec;
    TopicOnlyMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    TopicOnlyMessage.encode = (obj) => {
        return encodeMessage(obj, TopicOnlyMessage.codec());
    };
    TopicOnlyMessage.decode = (buf, opts) => {
        return decodeMessage(buf, TopicOnlyMessage.codec(), opts);
    };
})(TopicOnlyMessage || (TopicOnlyMessage = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
/* eslint-disable import/consistent-type-specifier-style */
/* eslint-disable @typescript-eslint/no-unused-vars */
var FilterSubscribeRequest;
(function (FilterSubscribeRequest) {
    let FilterSubscribeType;
    (function (FilterSubscribeType) {
        FilterSubscribeType["SUBSCRIBER_PING"] = "SUBSCRIBER_PING";
        FilterSubscribeType["SUBSCRIBE"] = "SUBSCRIBE";
        FilterSubscribeType["UNSUBSCRIBE"] = "UNSUBSCRIBE";
        FilterSubscribeType["UNSUBSCRIBE_ALL"] = "UNSUBSCRIBE_ALL";
    })(FilterSubscribeType = FilterSubscribeRequest.FilterSubscribeType || (FilterSubscribeRequest.FilterSubscribeType = {}));
    let __FilterSubscribeTypeValues;
    (function (__FilterSubscribeTypeValues) {
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["SUBSCRIBER_PING"] = 0] = "SUBSCRIBER_PING";
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["SUBSCRIBE"] = 1] = "SUBSCRIBE";
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["UNSUBSCRIBE"] = 2] = "UNSUBSCRIBE";
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["UNSUBSCRIBE_ALL"] = 3] = "UNSUBSCRIBE_ALL";
    })(__FilterSubscribeTypeValues || (__FilterSubscribeTypeValues = {}));
    (function (FilterSubscribeType) {
        FilterSubscribeType.codec = () => {
            return enumeration(__FilterSubscribeTypeValues);
        };
    })(FilterSubscribeType = FilterSubscribeRequest.FilterSubscribeType || (FilterSubscribeRequest.FilterSubscribeType = {}));
    let _codec;
    FilterSubscribeRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.filterSubscribeType != null && __FilterSubscribeTypeValues[obj.filterSubscribeType] !== 0) {
                    w.uint32(16);
                    FilterSubscribeRequest.FilterSubscribeType.codec().encode(obj.filterSubscribeType, w);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(82);
                    w.string(obj.pubsubTopic);
                }
                if (obj.contentTopics != null) {
                    for (const value of obj.contentTopics) {
                        w.uint32(90);
                        w.string(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: '',
                    filterSubscribeType: FilterSubscribeType.SUBSCRIBER_PING,
                    contentTopics: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 2: {
                            obj.filterSubscribeType = FilterSubscribeRequest.FilterSubscribeType.codec().decode(reader);
                            break;
                        }
                        case 10: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        case 11: {
                            if (opts.limits?.contentTopics != null && obj.contentTopics.length === opts.limits.contentTopics) {
                                throw new MaxLengthError('Decode error - map field "contentTopics" had too many elements');
                            }
                            obj.contentTopics.push(reader.string());
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterSubscribeRequest.encode = (obj) => {
        return encodeMessage(obj, FilterSubscribeRequest.codec());
    };
    FilterSubscribeRequest.decode = (buf, opts) => {
        return decodeMessage(buf, FilterSubscribeRequest.codec(), opts);
    };
})(FilterSubscribeRequest || (FilterSubscribeRequest = {}));
var FilterSubscribeResponse$1;
(function (FilterSubscribeResponse) {
    let _codec;
    FilterSubscribeResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if ((obj.statusCode != null && obj.statusCode !== 0)) {
                    w.uint32(80);
                    w.uint32(obj.statusCode);
                }
                if (obj.statusDesc != null) {
                    w.uint32(90);
                    w.string(obj.statusDesc);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: '',
                    statusCode: 0
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 10: {
                            obj.statusCode = reader.uint32();
                            break;
                        }
                        case 11: {
                            obj.statusDesc = reader.string();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterSubscribeResponse.encode = (obj) => {
        return encodeMessage(obj, FilterSubscribeResponse.codec());
    };
    FilterSubscribeResponse.decode = (buf, opts) => {
        return decodeMessage(buf, FilterSubscribeResponse.codec(), opts);
    };
})(FilterSubscribeResponse$1 || (FilterSubscribeResponse$1 = {}));
var MessagePush;
(function (MessagePush) {
    let _codec;
    MessagePush.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.wakuMessage != null) {
                    w.uint32(10);
                    WakuMessage$2.codec().encode(obj.wakuMessage, w);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(18);
                    w.string(obj.pubsubTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.wakuMessage = WakuMessage$2.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.wakuMessage
                            });
                            break;
                        }
                        case 2: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    MessagePush.encode = (obj) => {
        return encodeMessage(obj, MessagePush.codec());
    };
    MessagePush.decode = (buf, opts) => {
        return decodeMessage(buf, MessagePush.codec(), opts);
    };
})(MessagePush || (MessagePush = {}));
var RateLimitProof$2;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    proof: alloc$1(0),
                    merkleRoot: alloc$1(0),
                    epoch: alloc$1(0),
                    shareX: alloc$1(0),
                    shareY: alloc$1(0),
                    nullifier: alloc$1(0),
                    rlnIdentifier: alloc$1(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.proof = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.merkleRoot = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.epoch = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.shareX = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.shareY = reader.bytes();
                            break;
                        }
                        case 6: {
                            obj.nullifier = reader.bytes();
                            break;
                        }
                        case 7: {
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf, opts) => {
        return decodeMessage(buf, RateLimitProof.codec(), opts);
    };
})(RateLimitProof$2 || (RateLimitProof$2 = {}));
var WakuMessage$2;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$2.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    payload: alloc$1(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        case 3: {
                            obj.version = reader.uint32();
                            break;
                        }
                        case 10: {
                            obj.timestamp = reader.sint64();
                            break;
                        }
                        case 11: {
                            obj.meta = reader.bytes();
                            break;
                        }
                        case 21: {
                            obj.rateLimitProof = RateLimitProof$2.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.rateLimitProof
                            });
                            break;
                        }
                        case 31: {
                            obj.ephemeral = reader.bool();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessage.codec(), opts);
    };
})(WakuMessage$2 || (WakuMessage$2 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
/* eslint-disable import/consistent-type-specifier-style */
/* eslint-disable @typescript-eslint/no-unused-vars */
var PushRequest;
(function (PushRequest) {
    let _codec;
    PushRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.pubsubTopic != null && obj.pubsubTopic !== '')) {
                    w.uint32(10);
                    w.string(obj.pubsubTopic);
                }
                if (obj.message != null) {
                    w.uint32(18);
                    WakuMessage$1.codec().encode(obj.message, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    pubsubTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        case 2: {
                            obj.message = WakuMessage$1.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.message
                            });
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushRequest.encode = (obj) => {
        return encodeMessage(obj, PushRequest.codec());
    };
    PushRequest.decode = (buf, opts) => {
        return decodeMessage(buf, PushRequest.codec(), opts);
    };
})(PushRequest || (PushRequest = {}));
var PushResponse;
(function (PushResponse) {
    let _codec;
    PushResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.isSuccess != null && obj.isSuccess !== false)) {
                    w.uint32(8);
                    w.bool(obj.isSuccess);
                }
                if (obj.info != null) {
                    w.uint32(18);
                    w.string(obj.info);
                }
                if (obj.statusCode != null) {
                    w.uint32(80);
                    w.uint32(obj.statusCode);
                }
                if (obj.statusDesc != null) {
                    w.uint32(90);
                    w.string(obj.statusDesc);
                }
                if (obj.relayPeerCount != null) {
                    w.uint32(96);
                    w.uint32(obj.relayPeerCount);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    isSuccess: false
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.isSuccess = reader.bool();
                            break;
                        }
                        case 2: {
                            obj.info = reader.string();
                            break;
                        }
                        case 10: {
                            obj.statusCode = reader.uint32();
                            break;
                        }
                        case 11: {
                            obj.statusDesc = reader.string();
                            break;
                        }
                        case 12: {
                            obj.relayPeerCount = reader.uint32();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushResponse.encode = (obj) => {
        return encodeMessage(obj, PushResponse.codec());
    };
    PushResponse.decode = (buf, opts) => {
        return decodeMessage(buf, PushResponse.codec(), opts);
    };
})(PushResponse || (PushResponse = {}));
var PushRpc$1;
(function (PushRpc) {
    let _codec;
    PushRpc.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.request != null) {
                    w.uint32(18);
                    PushRequest.codec().encode(obj.request, w);
                }
                if (obj.response != null) {
                    w.uint32(26);
                    PushResponse.codec().encode(obj.response, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 2: {
                            obj.request = PushRequest.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.request
                            });
                            break;
                        }
                        case 3: {
                            obj.response = PushResponse.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.response
                            });
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushRpc.encode = (obj) => {
        return encodeMessage(obj, PushRpc.codec());
    };
    PushRpc.decode = (buf, opts) => {
        return decodeMessage(buf, PushRpc.codec(), opts);
    };
})(PushRpc$1 || (PushRpc$1 = {}));
var LightPushRequestV3;
(function (LightPushRequestV3) {
    let _codec;
    LightPushRequestV3.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(162);
                    w.string(obj.pubsubTopic);
                }
                if (obj.message != null) {
                    w.uint32(170);
                    WakuMessage$1.codec().encode(obj.message, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 20: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        case 21: {
                            obj.message = WakuMessage$1.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.message
                            });
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    LightPushRequestV3.encode = (obj) => {
        return encodeMessage(obj, LightPushRequestV3.codec());
    };
    LightPushRequestV3.decode = (buf, opts) => {
        return decodeMessage(buf, LightPushRequestV3.codec(), opts);
    };
})(LightPushRequestV3 || (LightPushRequestV3 = {}));
var LightPushResponseV3;
(function (LightPushResponseV3) {
    let _codec;
    LightPushResponseV3.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if ((obj.statusCode != null && obj.statusCode !== 0)) {
                    w.uint32(80);
                    w.uint32(obj.statusCode);
                }
                if (obj.statusDesc != null) {
                    w.uint32(90);
                    w.string(obj.statusDesc);
                }
                if (obj.relayPeerCount != null) {
                    w.uint32(96);
                    w.uint32(obj.relayPeerCount);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: '',
                    statusCode: 0
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 10: {
                            obj.statusCode = reader.uint32();
                            break;
                        }
                        case 11: {
                            obj.statusDesc = reader.string();
                            break;
                        }
                        case 12: {
                            obj.relayPeerCount = reader.uint32();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    LightPushResponseV3.encode = (obj) => {
        return encodeMessage(obj, LightPushResponseV3.codec());
    };
    LightPushResponseV3.decode = (buf, opts) => {
        return decodeMessage(buf, LightPushResponseV3.codec(), opts);
    };
})(LightPushResponseV3 || (LightPushResponseV3 = {}));
var RateLimitProof$1;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    proof: alloc$1(0),
                    merkleRoot: alloc$1(0),
                    epoch: alloc$1(0),
                    shareX: alloc$1(0),
                    shareY: alloc$1(0),
                    nullifier: alloc$1(0),
                    rlnIdentifier: alloc$1(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.proof = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.merkleRoot = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.epoch = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.shareX = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.shareY = reader.bytes();
                            break;
                        }
                        case 6: {
                            obj.nullifier = reader.bytes();
                            break;
                        }
                        case 7: {
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf, opts) => {
        return decodeMessage(buf, RateLimitProof.codec(), opts);
    };
})(RateLimitProof$1 || (RateLimitProof$1 = {}));
var WakuMessage$1;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$1.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    payload: alloc$1(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        case 3: {
                            obj.version = reader.uint32();
                            break;
                        }
                        case 10: {
                            obj.timestamp = reader.sint64();
                            break;
                        }
                        case 11: {
                            obj.meta = reader.bytes();
                            break;
                        }
                        case 21: {
                            obj.rateLimitProof = RateLimitProof$1.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.rateLimitProof
                            });
                            break;
                        }
                        case 31: {
                            obj.ephemeral = reader.bool();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessage.codec(), opts);
    };
})(WakuMessage$1 || (WakuMessage$1 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
/* eslint-disable import/consistent-type-specifier-style */
/* eslint-disable @typescript-eslint/no-unused-vars */
var WakuMessageKeyValue;
(function (WakuMessageKeyValue) {
    let _codec;
    WakuMessageKeyValue.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.messageHash != null) {
                    w.uint32(10);
                    w.bytes(obj.messageHash);
                }
                if (obj.message != null) {
                    w.uint32(18);
                    WakuMessage.codec().encode(obj.message, w);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(26);
                    w.string(obj.pubsubTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.messageHash = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.message = WakuMessage.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.message
                            });
                            break;
                        }
                        case 3: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessageKeyValue.encode = (obj) => {
        return encodeMessage(obj, WakuMessageKeyValue.codec());
    };
    WakuMessageKeyValue.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessageKeyValue.codec(), opts);
    };
})(WakuMessageKeyValue || (WakuMessageKeyValue = {}));
var StoreQueryRequest$1;
(function (StoreQueryRequest) {
    let _codec;
    StoreQueryRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if ((obj.includeData != null && obj.includeData !== false)) {
                    w.uint32(16);
                    w.bool(obj.includeData);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(82);
                    w.string(obj.pubsubTopic);
                }
                if (obj.contentTopics != null) {
                    for (const value of obj.contentTopics) {
                        w.uint32(90);
                        w.string(value);
                    }
                }
                if (obj.timeStart != null) {
                    w.uint32(96);
                    w.sint64(obj.timeStart);
                }
                if (obj.timeEnd != null) {
                    w.uint32(104);
                    w.sint64(obj.timeEnd);
                }
                if (obj.messageHashes != null) {
                    for (const value of obj.messageHashes) {
                        w.uint32(162);
                        w.bytes(value);
                    }
                }
                if (obj.paginationCursor != null) {
                    w.uint32(410);
                    w.bytes(obj.paginationCursor);
                }
                if ((obj.paginationForward != null && obj.paginationForward !== false)) {
                    w.uint32(416);
                    w.bool(obj.paginationForward);
                }
                if (obj.paginationLimit != null) {
                    w.uint32(424);
                    w.uint64(obj.paginationLimit);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: '',
                    includeData: false,
                    contentTopics: [],
                    messageHashes: [],
                    paginationForward: false
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 2: {
                            obj.includeData = reader.bool();
                            break;
                        }
                        case 10: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        case 11: {
                            if (opts.limits?.contentTopics != null && obj.contentTopics.length === opts.limits.contentTopics) {
                                throw new MaxLengthError('Decode error - map field "contentTopics" had too many elements');
                            }
                            obj.contentTopics.push(reader.string());
                            break;
                        }
                        case 12: {
                            obj.timeStart = reader.sint64();
                            break;
                        }
                        case 13: {
                            obj.timeEnd = reader.sint64();
                            break;
                        }
                        case 20: {
                            if (opts.limits?.messageHashes != null && obj.messageHashes.length === opts.limits.messageHashes) {
                                throw new MaxLengthError('Decode error - map field "messageHashes" had too many elements');
                            }
                            obj.messageHashes.push(reader.bytes());
                            break;
                        }
                        case 51: {
                            obj.paginationCursor = reader.bytes();
                            break;
                        }
                        case 52: {
                            obj.paginationForward = reader.bool();
                            break;
                        }
                        case 53: {
                            obj.paginationLimit = reader.uint64();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    StoreQueryRequest.encode = (obj) => {
        return encodeMessage(obj, StoreQueryRequest.codec());
    };
    StoreQueryRequest.decode = (buf, opts) => {
        return decodeMessage(buf, StoreQueryRequest.codec(), opts);
    };
})(StoreQueryRequest$1 || (StoreQueryRequest$1 = {}));
var StoreQueryResponse$1;
(function (StoreQueryResponse) {
    let _codec;
    StoreQueryResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.statusCode != null) {
                    w.uint32(80);
                    w.uint32(obj.statusCode);
                }
                if (obj.statusDesc != null) {
                    w.uint32(90);
                    w.string(obj.statusDesc);
                }
                if (obj.messages != null) {
                    for (const value of obj.messages) {
                        w.uint32(162);
                        WakuMessageKeyValue.codec().encode(value, w);
                    }
                }
                if (obj.paginationCursor != null) {
                    w.uint32(410);
                    w.bytes(obj.paginationCursor);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: '',
                    messages: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 10: {
                            obj.statusCode = reader.uint32();
                            break;
                        }
                        case 11: {
                            obj.statusDesc = reader.string();
                            break;
                        }
                        case 20: {
                            if (opts.limits?.messages != null && obj.messages.length === opts.limits.messages) {
                                throw new MaxLengthError('Decode error - map field "messages" had too many elements');
                            }
                            obj.messages.push(WakuMessageKeyValue.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.messages$
                            }));
                            break;
                        }
                        case 51: {
                            obj.paginationCursor = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    StoreQueryResponse.encode = (obj) => {
        return encodeMessage(obj, StoreQueryResponse.codec());
    };
    StoreQueryResponse.decode = (buf, opts) => {
        return decodeMessage(buf, StoreQueryResponse.codec(), opts);
    };
})(StoreQueryResponse$1 || (StoreQueryResponse$1 = {}));
var RateLimitProof;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    proof: alloc$1(0),
                    merkleRoot: alloc$1(0),
                    epoch: alloc$1(0),
                    shareX: alloc$1(0),
                    shareY: alloc$1(0),
                    nullifier: alloc$1(0),
                    rlnIdentifier: alloc$1(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.proof = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.merkleRoot = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.epoch = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.shareX = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.shareY = reader.bytes();
                            break;
                        }
                        case 6: {
                            obj.nullifier = reader.bytes();
                            break;
                        }
                        case 7: {
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf, opts) => {
        return decodeMessage(buf, RateLimitProof.codec(), opts);
    };
})(RateLimitProof || (RateLimitProof = {}));
var WakuMessage;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    payload: alloc$1(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        case 3: {
                            obj.version = reader.uint32();
                            break;
                        }
                        case 10: {
                            obj.timestamp = reader.sint64();
                            break;
                        }
                        case 11: {
                            obj.meta = reader.bytes();
                            break;
                        }
                        case 21: {
                            obj.rateLimitProof = RateLimitProof.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.rateLimitProof
                            });
                            break;
                        }
                        case 31: {
                            obj.ephemeral = reader.bool();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessage.codec(), opts);
    };
})(WakuMessage || (WakuMessage = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
/* eslint-disable import/consistent-type-specifier-style */
/* eslint-disable @typescript-eslint/no-unused-vars */
var PeerInfo;
(function (PeerInfo) {
    let _codec;
    PeerInfo.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.enr != null) {
                    w.uint32(10);
                    w.bytes(obj.enr);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.enr = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerInfo.encode = (obj) => {
        return encodeMessage(obj, PeerInfo.codec());
    };
    PeerInfo.decode = (buf, opts) => {
        return decodeMessage(buf, PeerInfo.codec(), opts);
    };
})(PeerInfo || (PeerInfo = {}));
var PeerExchangeQuery;
(function (PeerExchangeQuery) {
    let _codec;
    PeerExchangeQuery.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.numPeers != null) {
                    w.uint32(8);
                    w.uint64(obj.numPeers);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.numPeers = reader.uint64();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeQuery.encode = (obj) => {
        return encodeMessage(obj, PeerExchangeQuery.codec());
    };
    PeerExchangeQuery.decode = (buf, opts) => {
        return decodeMessage(buf, PeerExchangeQuery.codec(), opts);
    };
})(PeerExchangeQuery || (PeerExchangeQuery = {}));
var PeerExchangeResponse;
(function (PeerExchangeResponse) {
    let _codec;
    PeerExchangeResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.peerInfos != null) {
                    for (const value of obj.peerInfos) {
                        w.uint32(10);
                        PeerInfo.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    peerInfos: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            if (opts.limits?.peerInfos != null && obj.peerInfos.length === opts.limits.peerInfos) {
                                throw new MaxLengthError('Decode error - map field "peerInfos" had too many elements');
                            }
                            obj.peerInfos.push(PeerInfo.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.peerInfos$
                            }));
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeResponse.encode = (obj) => {
        return encodeMessage(obj, PeerExchangeResponse.codec());
    };
    PeerExchangeResponse.decode = (buf, opts) => {
        return decodeMessage(buf, PeerExchangeResponse.codec(), opts);
    };
})(PeerExchangeResponse || (PeerExchangeResponse = {}));
var PeerExchangeRPC$1;
(function (PeerExchangeRPC) {
    let _codec;
    PeerExchangeRPC.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.query != null) {
                    w.uint32(10);
                    PeerExchangeQuery.codec().encode(obj.query, w);
                }
                if (obj.response != null) {
                    w.uint32(18);
                    PeerExchangeResponse.codec().encode(obj.response, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.query = PeerExchangeQuery.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.query
                            });
                            break;
                        }
                        case 2: {
                            obj.response = PeerExchangeResponse.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.response
                            });
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeRPC.encode = (obj) => {
        return encodeMessage(obj, PeerExchangeRPC.codec());
    };
    PeerExchangeRPC.decode = (buf, opts) => {
        return decodeMessage(buf, PeerExchangeRPC.codec(), opts);
    };
})(PeerExchangeRPC$1 || (PeerExchangeRPC$1 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
/* eslint-disable import/consistent-type-specifier-style */
/* eslint-disable @typescript-eslint/no-unused-vars */
var WakuMetadataRequest;
(function (WakuMetadataRequest) {
    let _codec;
    WakuMetadataRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.clusterId != null) {
                    w.uint32(8);
                    w.uint32(obj.clusterId);
                }
                if (obj.shards != null) {
                    for (const value of obj.shards) {
                        w.uint32(16);
                        w.uint32(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    shards: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.clusterId = reader.uint32();
                            break;
                        }
                        case 2: {
                            if (opts.limits?.shards != null && obj.shards.length === opts.limits.shards) {
                                throw new MaxLengthError('Decode error - map field "shards" had too many elements');
                            }
                            obj.shards.push(reader.uint32());
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMetadataRequest.encode = (obj) => {
        return encodeMessage(obj, WakuMetadataRequest.codec());
    };
    WakuMetadataRequest.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMetadataRequest.codec(), opts);
    };
})(WakuMetadataRequest || (WakuMetadataRequest = {}));
var WakuMetadataResponse;
(function (WakuMetadataResponse) {
    let _codec;
    WakuMetadataResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.clusterId != null) {
                    w.uint32(8);
                    w.uint32(obj.clusterId);
                }
                if (obj.shards != null) {
                    for (const value of obj.shards) {
                        w.uint32(16);
                        w.uint32(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    shards: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.clusterId = reader.uint32();
                            break;
                        }
                        case 2: {
                            if (opts.limits?.shards != null && obj.shards.length === opts.limits.shards) {
                                throw new MaxLengthError('Decode error - map field "shards" had too many elements');
                            }
                            obj.shards.push(reader.uint32());
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMetadataResponse.encode = (obj) => {
        return encodeMessage(obj, WakuMetadataResponse.codec());
    };
    WakuMetadataResponse.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMetadataResponse.codec(), opts);
    };
})(WakuMetadataResponse || (WakuMetadataResponse = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
/* eslint-disable import/consistent-type-specifier-style */
/* eslint-disable @typescript-eslint/no-unused-vars */
var HistoryEntry;
(function (HistoryEntry) {
    let _codec;
    HistoryEntry.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.messageId != null && obj.messageId !== '')) {
                    w.uint32(10);
                    w.string(obj.messageId);
                }
                if (obj.retrievalHint != null) {
                    w.uint32(18);
                    w.bytes(obj.retrievalHint);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    messageId: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.messageId = reader.string();
                            break;
                        }
                        case 2: {
                            obj.retrievalHint = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    HistoryEntry.encode = (obj) => {
        return encodeMessage(obj, HistoryEntry.codec());
    };
    HistoryEntry.decode = (buf, opts) => {
        return decodeMessage(buf, HistoryEntry.codec(), opts);
    };
})(HistoryEntry || (HistoryEntry = {}));
var SdsMessage;
(function (SdsMessage) {
    let _codec;
    SdsMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.messageId != null && obj.messageId !== '')) {
                    w.uint32(18);
                    w.string(obj.messageId);
                }
                if ((obj.channelId != null && obj.channelId !== '')) {
                    w.uint32(26);
                    w.string(obj.channelId);
                }
                if (obj.lamportTimestamp != null) {
                    w.uint32(80);
                    w.int32(obj.lamportTimestamp);
                }
                if (obj.causalHistory != null) {
                    for (const value of obj.causalHistory) {
                        w.uint32(90);
                        HistoryEntry.codec().encode(value, w);
                    }
                }
                if (obj.bloomFilter != null) {
                    w.uint32(98);
                    w.bytes(obj.bloomFilter);
                }
                if (obj.content != null) {
                    w.uint32(162);
                    w.bytes(obj.content);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    messageId: '',
                    channelId: '',
                    causalHistory: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 2: {
                            obj.messageId = reader.string();
                            break;
                        }
                        case 3: {
                            obj.channelId = reader.string();
                            break;
                        }
                        case 10: {
                            obj.lamportTimestamp = reader.int32();
                            break;
                        }
                        case 11: {
                            if (opts.limits?.causalHistory != null && obj.causalHistory.length === opts.limits.causalHistory) {
                                throw new MaxLengthError('Decode error - map field "causalHistory" had too many elements');
                            }
                            obj.causalHistory.push(HistoryEntry.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.causalHistory$
                            }));
                            break;
                        }
                        case 12: {
                            obj.bloomFilter = reader.bytes();
                            break;
                        }
                        case 20: {
                            obj.content = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    SdsMessage.encode = (obj) => {
        return encodeMessage(obj, SdsMessage.codec());
    };
    SdsMessage.decode = (buf, opts) => {
        return decodeMessage(buf, SdsMessage.codec(), opts);
    };
})(SdsMessage || (SdsMessage = {}));

function isDefined(value) {
    return Boolean(value);
}

/**
 * Return pseudo random subset of the input.
 */
function getPseudoRandomSubset(values, wantedNumber) {
    if (values.length <= wantedNumber || values.length <= 1) {
        return values;
    }
    return shuffle(values).slice(0, wantedNumber);
}
function shuffle(arr) {
    if (arr.length <= 1) {
        return arr;
    }
    const randInt = () => {
        return Math.floor(Math.random() * Math.floor(arr.length));
    };
    for (let i = 0; i < arr.length; i++) {
        const j = randInt();
        const tmp = arr[i];
        arr[i] = arr[j];
        arr[j] = tmp;
    }
    return arr;
}

function groupByContentTopic(values) {
    const groupedDecoders = new Map();
    values.forEach((value) => {
        let decs = groupedDecoders.get(value.contentTopic);
        if (!decs) {
            groupedDecoders.set(value.contentTopic, []);
            decs = groupedDecoders.get(value.contentTopic);
        }
        decs.push(value);
    });
    return groupedDecoders;
}

const FRAME_RATE = 60;
/**
 * Function that transforms IReceiver subscription to iterable stream of data.
 * @param receiver - object that allows to be subscribed to;
 * @param decoder - parameter to be passed to receiver for subscription;
 * @param options - options for receiver for subscription;
 * @param iteratorOptions - optional configuration for iterator;
 * @returns iterator and stop function to terminate it.
 */
async function toAsyncIterator(receiver, decoder, iteratorOptions) {
    const iteratorDelay = iteratorOptions?.iteratorDelay ?? FRAME_RATE;
    const messages = [];
    let unsubscribe;
    unsubscribe = await receiver.subscribeWithUnsubscribe(decoder, (message) => {
        messages.push(message);
    });
    const isWithTimeout = Number.isInteger(iteratorOptions?.timeoutMs);
    const timeoutMs = iteratorOptions?.timeoutMs ?? 0;
    const startTime = Date.now();
    async function* iterator() {
        while (true) {
            if (isWithTimeout && Date.now() - startTime >= timeoutMs) {
                return;
            }
            await wait(iteratorDelay);
            const message = messages.shift();
            if (!unsubscribe && messages.length === 0) {
                return message;
            }
            if (!message && unsubscribe) {
                continue;
            }
            yield message;
        }
    }
    return {
        iterator: iterator(),
        async stop() {
            if (unsubscribe) {
                await unsubscribe();
                unsubscribe = undefined;
            }
        }
    };
}
function wait(ms) {
    return new Promise((resolve) => {
        setTimeout(resolve, ms);
    });
}

const MB = 1024 ** 2;
const SIZE_CAP_IN_MB = 1;
/**
 * Return whether the size of the message is under the upper limit for the network.
 * This performs a protobuf encoding! If you have access to the fully encoded message,
 * use {@link isSizeUnderCapBuf} instead.
 * @param message
 * @param encoder
 */
async function isMessageSizeUnderCap(encoder, message) {
    const buf = await encoder.toWire(message);
    if (!buf)
        return false;
    return isWireSizeUnderCap(buf);
}
const isWireSizeUnderCap = (buf) => buf.length / MB <= SIZE_CAP_IN_MB;

const crypto$2 = typeof globalThis === 'object' && 'crypto' in globalThis ? globalThis.crypto : undefined;

/**
 * Utilities for hex, bytes, CSPRNG.
 * @module
 */
/*! noble-hashes - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// We use WebCrypto aka globalThis.crypto, which exists in browsers and node.js 16+.
// node.js versions earlier than v19 don't declare it in global scope.
// For node.js, package.json#exports field mapping rewrites import
// from `crypto` to `cryptoNode`, which imports native module.
// Makes the utils un-importable in browsers without a bundler.
// Once node.js 18 is deprecated (2025-04-30), we can just drop the import.
/** Checks if something is Uint8Array. Be careful: nodejs Buffer will return true. */
function isBytes$3(a) {
    return a instanceof Uint8Array || (ArrayBuffer.isView(a) && a.constructor.name === 'Uint8Array');
}
/** Asserts something is positive integer. */
function anumber$1(n) {
    if (!Number.isSafeInteger(n) || n < 0)
        throw new Error('positive integer expected, got ' + n);
}
/** Asserts something is Uint8Array. */
function abytes$2(b, ...lengths) {
    if (!isBytes$3(b))
        throw new Error('Uint8Array expected');
    if (lengths.length > 0 && !lengths.includes(b.length))
        throw new Error('Uint8Array expected of length ' + lengths + ', got length=' + b.length);
}
/** Asserts something is hash */
function ahash(h) {
    if (typeof h !== 'function' || typeof h.create !== 'function')
        throw new Error('Hash should be wrapped by utils.createHasher');
    anumber$1(h.outputLen);
    anumber$1(h.blockLen);
}
/** Asserts a hash instance has not been destroyed / finished */
function aexists$1(instance, checkFinished = true) {
    if (instance.destroyed)
        throw new Error('Hash instance has been destroyed');
    if (checkFinished && instance.finished)
        throw new Error('Hash#digest() has already been called');
}
/** Asserts output is properly-sized byte array */
function aoutput$1(out, instance) {
    abytes$2(out);
    const min = instance.outputLen;
    if (out.length < min) {
        throw new Error('digestInto() expects output buffer of length at least ' + min);
    }
}
/** Zeroize a byte array. Warning: JS provides no guarantees. */
function clean$1(...arrays) {
    for (let i = 0; i < arrays.length; i++) {
        arrays[i].fill(0);
    }
}
/** Create DataView of an array for easy byte-level manipulation. */
function createView$1(arr) {
    return new DataView(arr.buffer, arr.byteOffset, arr.byteLength);
}
/** The rotate right (circular right shift) operation for uint32 */
function rotr(word, shift) {
    return (word << (32 - shift)) | (word >>> shift);
}
// Built-in hex conversion https://caniuse.com/mdn-javascript_builtins_uint8array_fromhex
const hasHexBuiltin = /* @__PURE__ */ (() => 
// @ts-ignore
typeof Uint8Array.from([]).toHex === 'function' && typeof Uint8Array.fromHex === 'function')();
// Array where index 0xf0 (240) is mapped to string 'f0'
const hexes$1 = /* @__PURE__ */ Array.from({ length: 256 }, (_, i) => i.toString(16).padStart(2, '0'));
/**
 * Convert byte array to hex string. Uses built-in function, when available.
 * @example bytesToHex(Uint8Array.from([0xca, 0xfe, 0x01, 0x23])) // 'cafe0123'
 */
function bytesToHex$2(bytes) {
    abytes$2(bytes);
    // @ts-ignore
    if (hasHexBuiltin)
        return bytes.toHex();
    // pre-caching improves the speed 6x
    let hex = '';
    for (let i = 0; i < bytes.length; i++) {
        hex += hexes$1[bytes[i]];
    }
    return hex;
}
// We use optimized technique to convert hex string to byte array
const asciis$1 = { _0: 48, _9: 57, A: 65, F: 70, a: 97, f: 102 };
function asciiToBase16$1(ch) {
    if (ch >= asciis$1._0 && ch <= asciis$1._9)
        return ch - asciis$1._0; // '2' => 50-48
    if (ch >= asciis$1.A && ch <= asciis$1.F)
        return ch - (asciis$1.A - 10); // 'B' => 66-(65-10)
    if (ch >= asciis$1.a && ch <= asciis$1.f)
        return ch - (asciis$1.a - 10); // 'b' => 98-(97-10)
    return;
}
/**
 * Convert hex string to byte array. Uses built-in function, when available.
 * @example hexToBytes('cafe0123') // Uint8Array.from([0xca, 0xfe, 0x01, 0x23])
 */
function hexToBytes$2(hex) {
    if (typeof hex !== 'string')
        throw new Error('hex string expected, got ' + typeof hex);
    // @ts-ignore
    if (hasHexBuiltin)
        return Uint8Array.fromHex(hex);
    const hl = hex.length;
    const al = hl / 2;
    if (hl % 2)
        throw new Error('hex string expected, got unpadded hex of length ' + hl);
    const array = new Uint8Array(al);
    for (let ai = 0, hi = 0; ai < al; ai++, hi += 2) {
        const n1 = asciiToBase16$1(hex.charCodeAt(hi));
        const n2 = asciiToBase16$1(hex.charCodeAt(hi + 1));
        if (n1 === undefined || n2 === undefined) {
            const char = hex[hi] + hex[hi + 1];
            throw new Error('hex string expected, got non-hex character "' + char + '" at index ' + hi);
        }
        array[ai] = n1 * 16 + n2; // multiply first octet, e.g. 'a3' => 10*16+3 => 160 + 3 => 163
    }
    return array;
}
/**
 * Converts string to bytes using UTF8 encoding.
 * @example utf8ToBytes('abc') // Uint8Array.from([97, 98, 99])
 */
function utf8ToBytes$2(str) {
    if (typeof str !== 'string')
        throw new Error('string expected');
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
/**
 * Normalizes (non-hex) string or Uint8Array to Uint8Array.
 * Warning: when Uint8Array is passed, it would NOT get copied.
 * Keep in mind for future mutable operations.
 */
function toBytes$1(data) {
    if (typeof data === 'string')
        data = utf8ToBytes$2(data);
    abytes$2(data);
    return data;
}
/** Copies several Uint8Arrays into one. */
function concatBytes$1(...arrays) {
    let sum = 0;
    for (let i = 0; i < arrays.length; i++) {
        const a = arrays[i];
        abytes$2(a);
        sum += a.length;
    }
    const res = new Uint8Array(sum);
    for (let i = 0, pad = 0; i < arrays.length; i++) {
        const a = arrays[i];
        res.set(a, pad);
        pad += a.length;
    }
    return res;
}
/** For runtime check if class implements interface */
class Hash {
}
/** Wraps hash function, creating an interface on top of it */
function createHasher(hashCons) {
    const hashC = (msg) => hashCons().update(toBytes$1(msg)).digest();
    const tmp = hashCons();
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = () => hashCons();
    return hashC;
}
/** Cryptographically secure PRNG. Uses internal OS-level `crypto.getRandomValues`. */
function randomBytes$1(bytesLength = 32) {
    if (crypto$2 && typeof crypto$2.getRandomValues === 'function') {
        return crypto$2.getRandomValues(new Uint8Array(bytesLength));
    }
    // Legacy Node.js compatibility
    if (crypto$2 && typeof crypto$2.randomBytes === 'function') {
        return Uint8Array.from(crypto$2.randomBytes(bytesLength));
    }
    throw new Error('crypto.getRandomValues must be defined');
}

/**
 * Internal Merkle-Damgard hash utils.
 * @module
 */
/** Polyfill for Safari 14. https://caniuse.com/mdn-javascript_builtins_dataview_setbiguint64 */
function setBigUint64$1(view, byteOffset, value, isLE) {
    if (typeof view.setBigUint64 === 'function')
        return view.setBigUint64(byteOffset, value, isLE);
    const _32n = BigInt(32);
    const _u32_max = BigInt(0xffffffff);
    const wh = Number((value >> _32n) & _u32_max);
    const wl = Number(value & _u32_max);
    const h = isLE ? 4 : 0;
    const l = isLE ? 0 : 4;
    view.setUint32(byteOffset + h, wh, isLE);
    view.setUint32(byteOffset + l, wl, isLE);
}
/** Choice: a ? b : c */
function Chi(a, b, c) {
    return (a & b) ^ (~a & c);
}
/** Majority function, true if any two inputs is true. */
function Maj(a, b, c) {
    return (a & b) ^ (a & c) ^ (b & c);
}
/**
 * Merkle-Damgard hash construction base class.
 * Could be used to create MD5, RIPEMD, SHA1, SHA2.
 */
class HashMD extends Hash {
    constructor(blockLen, outputLen, padOffset, isLE) {
        super();
        this.finished = false;
        this.length = 0;
        this.pos = 0;
        this.destroyed = false;
        this.blockLen = blockLen;
        this.outputLen = outputLen;
        this.padOffset = padOffset;
        this.isLE = isLE;
        this.buffer = new Uint8Array(blockLen);
        this.view = createView$1(this.buffer);
    }
    update(data) {
        aexists$1(this);
        data = toBytes$1(data);
        abytes$2(data);
        const { view, buffer, blockLen } = this;
        const len = data.length;
        for (let pos = 0; pos < len;) {
            const take = Math.min(blockLen - this.pos, len - pos);
            // Fast path: we have at least one block in input, cast it to view and process
            if (take === blockLen) {
                const dataView = createView$1(data);
                for (; blockLen <= len - pos; pos += blockLen)
                    this.process(dataView, pos);
                continue;
            }
            buffer.set(data.subarray(pos, pos + take), this.pos);
            this.pos += take;
            pos += take;
            if (this.pos === blockLen) {
                this.process(view, 0);
                this.pos = 0;
            }
        }
        this.length += data.length;
        this.roundClean();
        return this;
    }
    digestInto(out) {
        aexists$1(this);
        aoutput$1(out, this);
        this.finished = true;
        // Padding
        // We can avoid allocation of buffer for padding completely if it
        // was previously not allocated here. But it won't change performance.
        const { buffer, view, blockLen, isLE } = this;
        let { pos } = this;
        // append the bit '1' to the message
        buffer[pos++] = 0b10000000;
        clean$1(this.buffer.subarray(pos));
        // we have less than padOffset left in buffer, so we cannot put length in
        // current block, need process it and pad again
        if (this.padOffset > blockLen - pos) {
            this.process(view, 0);
            pos = 0;
        }
        // Pad until full block byte with zeros
        for (let i = pos; i < blockLen; i++)
            buffer[i] = 0;
        // Note: sha512 requires length to be 128bit integer, but length in JS will overflow before that
        // You need to write around 2 exabytes (u64_max / 8 / (1024**6)) for this to happen.
        // So we just write lowest 64 bits of that value.
        setBigUint64$1(view, blockLen - 8, BigInt(this.length * 8), isLE);
        this.process(view, 0);
        const oview = createView$1(out);
        const len = this.outputLen;
        // NOTE: we do division by 4 later, which should be fused in single op with modulo by JIT
        if (len % 4)
            throw new Error('_sha2: outputLen should be aligned to 32bit');
        const outLen = len / 4;
        const state = this.get();
        if (outLen > state.length)
            throw new Error('_sha2: outputLen bigger than state');
        for (let i = 0; i < outLen; i++)
            oview.setUint32(4 * i, state[i], isLE);
    }
    digest() {
        const { buffer, outputLen } = this;
        this.digestInto(buffer);
        const res = buffer.slice(0, outputLen);
        this.destroy();
        return res;
    }
    _cloneInto(to) {
        to || (to = new this.constructor());
        to.set(...this.get());
        const { blockLen, buffer, length, finished, destroyed, pos } = this;
        to.destroyed = destroyed;
        to.finished = finished;
        to.length = length;
        to.pos = pos;
        if (length % blockLen)
            to.buffer.set(buffer);
        return to;
    }
    clone() {
        return this._cloneInto();
    }
}
/**
 * Initial SHA-2 state: fractional parts of square roots of first 16 primes 2..53.
 * Check out `test/misc/sha2-gen-iv.js` for recomputation guide.
 */
/** Initial SHA256 state. Bits 0..32 of frac part of sqrt of primes 2..19 */
const SHA256_IV = /* @__PURE__ */ Uint32Array.from([
    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19,
]);
/** Initial SHA512 state. Bits 0..64 of frac part of sqrt of primes 2..19 */
const SHA512_IV = /* @__PURE__ */ Uint32Array.from([
    0x6a09e667, 0xf3bcc908, 0xbb67ae85, 0x84caa73b, 0x3c6ef372, 0xfe94f82b, 0xa54ff53a, 0x5f1d36f1,
    0x510e527f, 0xade682d1, 0x9b05688c, 0x2b3e6c1f, 0x1f83d9ab, 0xfb41bd6b, 0x5be0cd19, 0x137e2179,
]);

/**
 * Internal helpers for u64. BigUint64Array is too slow as per 2025, so we implement it using Uint32Array.
 * @todo re-check https://issues.chromium.org/issues/42212588
 * @module
 */
const U32_MASK64 = /* @__PURE__ */ BigInt(2 ** 32 - 1);
const _32n = /* @__PURE__ */ BigInt(32);
function fromBig(n, le = false) {
    if (le)
        return { h: Number(n & U32_MASK64), l: Number((n >> _32n) & U32_MASK64) };
    return { h: Number((n >> _32n) & U32_MASK64) | 0, l: Number(n & U32_MASK64) | 0 };
}
function split(lst, le = false) {
    const len = lst.length;
    let Ah = new Uint32Array(len);
    let Al = new Uint32Array(len);
    for (let i = 0; i < len; i++) {
        const { h, l } = fromBig(lst[i], le);
        [Ah[i], Al[i]] = [h, l];
    }
    return [Ah, Al];
}
// for Shift in [0, 32)
const shrSH = (h, _l, s) => h >>> s;
const shrSL = (h, l, s) => (h << (32 - s)) | (l >>> s);
// Right rotate for Shift in [1, 32)
const rotrSH = (h, l, s) => (h >>> s) | (l << (32 - s));
const rotrSL = (h, l, s) => (h << (32 - s)) | (l >>> s);
// Right rotate for Shift in (32, 64), NOTE: 32 is special case.
const rotrBH = (h, l, s) => (h << (64 - s)) | (l >>> (s - 32));
const rotrBL = (h, l, s) => (h >>> (s - 32)) | (l << (64 - s));
// JS uses 32-bit signed integers for bitwise operations which means we cannot
// simple take carry out of low bit sum by shift, we need to use division.
function add(Ah, Al, Bh, Bl) {
    const l = (Al >>> 0) + (Bl >>> 0);
    return { h: (Ah + Bh + ((l / 2 ** 32) | 0)) | 0, l: l | 0 };
}
// Addition with more than 2 elements
const add3L = (Al, Bl, Cl) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0);
const add3H = (low, Ah, Bh, Ch) => (Ah + Bh + Ch + ((low / 2 ** 32) | 0)) | 0;
const add4L = (Al, Bl, Cl, Dl) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0);
const add4H = (low, Ah, Bh, Ch, Dh) => (Ah + Bh + Ch + Dh + ((low / 2 ** 32) | 0)) | 0;
const add5L = (Al, Bl, Cl, Dl, El) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0) + (El >>> 0);
const add5H = (low, Ah, Bh, Ch, Dh, Eh) => (Ah + Bh + Ch + Dh + Eh + ((low / 2 ** 32) | 0)) | 0;

/**
 * SHA2 hash function. A.k.a. sha256, sha384, sha512, sha512_224, sha512_256.
 * SHA256 is the fastest hash implementable in JS, even faster than Blake3.
 * Check out [RFC 4634](https://datatracker.ietf.org/doc/html/rfc4634) and
 * [FIPS 180-4](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf).
 * @module
 */
/**
 * Round constants:
 * First 32 bits of fractional parts of the cube roots of the first 64 primes 2..311)
 */
// prettier-ignore
const SHA256_K = /* @__PURE__ */ Uint32Array.from([
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
]);
/** Reusable temporary buffer. "W" comes straight from spec. */
const SHA256_W = /* @__PURE__ */ new Uint32Array(64);
class SHA256 extends HashMD {
    constructor(outputLen = 32) {
        super(64, outputLen, 8, false);
        // We cannot use array here since array allows indexing by variable
        // which means optimizer/compiler cannot use registers.
        this.A = SHA256_IV[0] | 0;
        this.B = SHA256_IV[1] | 0;
        this.C = SHA256_IV[2] | 0;
        this.D = SHA256_IV[3] | 0;
        this.E = SHA256_IV[4] | 0;
        this.F = SHA256_IV[5] | 0;
        this.G = SHA256_IV[6] | 0;
        this.H = SHA256_IV[7] | 0;
    }
    get() {
        const { A, B, C, D, E, F, G, H } = this;
        return [A, B, C, D, E, F, G, H];
    }
    // prettier-ignore
    set(A, B, C, D, E, F, G, H) {
        this.A = A | 0;
        this.B = B | 0;
        this.C = C | 0;
        this.D = D | 0;
        this.E = E | 0;
        this.F = F | 0;
        this.G = G | 0;
        this.H = H | 0;
    }
    process(view, offset) {
        // Extend the first 16 words into the remaining 48 words w[16..63] of the message schedule array
        for (let i = 0; i < 16; i++, offset += 4)
            SHA256_W[i] = view.getUint32(offset, false);
        for (let i = 16; i < 64; i++) {
            const W15 = SHA256_W[i - 15];
            const W2 = SHA256_W[i - 2];
            const s0 = rotr(W15, 7) ^ rotr(W15, 18) ^ (W15 >>> 3);
            const s1 = rotr(W2, 17) ^ rotr(W2, 19) ^ (W2 >>> 10);
            SHA256_W[i] = (s1 + SHA256_W[i - 7] + s0 + SHA256_W[i - 16]) | 0;
        }
        // Compression function main loop, 64 rounds
        let { A, B, C, D, E, F, G, H } = this;
        for (let i = 0; i < 64; i++) {
            const sigma1 = rotr(E, 6) ^ rotr(E, 11) ^ rotr(E, 25);
            const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;
            const sigma0 = rotr(A, 2) ^ rotr(A, 13) ^ rotr(A, 22);
            const T2 = (sigma0 + Maj(A, B, C)) | 0;
            H = G;
            G = F;
            F = E;
            E = (D + T1) | 0;
            D = C;
            C = B;
            B = A;
            A = (T1 + T2) | 0;
        }
        // Add the compressed chunk to the current hash value
        A = (A + this.A) | 0;
        B = (B + this.B) | 0;
        C = (C + this.C) | 0;
        D = (D + this.D) | 0;
        E = (E + this.E) | 0;
        F = (F + this.F) | 0;
        G = (G + this.G) | 0;
        H = (H + this.H) | 0;
        this.set(A, B, C, D, E, F, G, H);
    }
    roundClean() {
        clean$1(SHA256_W);
    }
    destroy() {
        this.set(0, 0, 0, 0, 0, 0, 0, 0);
        clean$1(this.buffer);
    }
}
// SHA2-512 is slower than sha256 in js because u64 operations are slow.
// Round contants
// First 32 bits of the fractional parts of the cube roots of the first 80 primes 2..409
// prettier-ignore
const K512 = /* @__PURE__ */ (() => split([
    '0x428a2f98d728ae22', '0x7137449123ef65cd', '0xb5c0fbcfec4d3b2f', '0xe9b5dba58189dbbc',
    '0x3956c25bf348b538', '0x59f111f1b605d019', '0x923f82a4af194f9b', '0xab1c5ed5da6d8118',
    '0xd807aa98a3030242', '0x12835b0145706fbe', '0x243185be4ee4b28c', '0x550c7dc3d5ffb4e2',
    '0x72be5d74f27b896f', '0x80deb1fe3b1696b1', '0x9bdc06a725c71235', '0xc19bf174cf692694',
    '0xe49b69c19ef14ad2', '0xefbe4786384f25e3', '0x0fc19dc68b8cd5b5', '0x240ca1cc77ac9c65',
    '0x2de92c6f592b0275', '0x4a7484aa6ea6e483', '0x5cb0a9dcbd41fbd4', '0x76f988da831153b5',
    '0x983e5152ee66dfab', '0xa831c66d2db43210', '0xb00327c898fb213f', '0xbf597fc7beef0ee4',
    '0xc6e00bf33da88fc2', '0xd5a79147930aa725', '0x06ca6351e003826f', '0x142929670a0e6e70',
    '0x27b70a8546d22ffc', '0x2e1b21385c26c926', '0x4d2c6dfc5ac42aed', '0x53380d139d95b3df',
    '0x650a73548baf63de', '0x766a0abb3c77b2a8', '0x81c2c92e47edaee6', '0x92722c851482353b',
    '0xa2bfe8a14cf10364', '0xa81a664bbc423001', '0xc24b8b70d0f89791', '0xc76c51a30654be30',
    '0xd192e819d6ef5218', '0xd69906245565a910', '0xf40e35855771202a', '0x106aa07032bbd1b8',
    '0x19a4c116b8d2d0c8', '0x1e376c085141ab53', '0x2748774cdf8eeb99', '0x34b0bcb5e19b48a8',
    '0x391c0cb3c5c95a63', '0x4ed8aa4ae3418acb', '0x5b9cca4f7763e373', '0x682e6ff3d6b2b8a3',
    '0x748f82ee5defb2fc', '0x78a5636f43172f60', '0x84c87814a1f0ab72', '0x8cc702081a6439ec',
    '0x90befffa23631e28', '0xa4506cebde82bde9', '0xbef9a3f7b2c67915', '0xc67178f2e372532b',
    '0xca273eceea26619c', '0xd186b8c721c0c207', '0xeada7dd6cde0eb1e', '0xf57d4f7fee6ed178',
    '0x06f067aa72176fba', '0x0a637dc5a2c898a6', '0x113f9804bef90dae', '0x1b710b35131c471b',
    '0x28db77f523047d84', '0x32caab7b40c72493', '0x3c9ebe0a15c9bebc', '0x431d67c49c100d4c',
    '0x4cc5d4becb3e42b6', '0x597f299cfc657e2a', '0x5fcb6fab3ad6faec', '0x6c44198c4a475817'
].map(n => BigInt(n))))();
const SHA512_Kh = /* @__PURE__ */ (() => K512[0])();
const SHA512_Kl = /* @__PURE__ */ (() => K512[1])();
// Reusable temporary buffers
const SHA512_W_H = /* @__PURE__ */ new Uint32Array(80);
const SHA512_W_L = /* @__PURE__ */ new Uint32Array(80);
class SHA512 extends HashMD {
    constructor(outputLen = 64) {
        super(128, outputLen, 16, false);
        // We cannot use array here since array allows indexing by variable
        // which means optimizer/compiler cannot use registers.
        // h -- high 32 bits, l -- low 32 bits
        this.Ah = SHA512_IV[0] | 0;
        this.Al = SHA512_IV[1] | 0;
        this.Bh = SHA512_IV[2] | 0;
        this.Bl = SHA512_IV[3] | 0;
        this.Ch = SHA512_IV[4] | 0;
        this.Cl = SHA512_IV[5] | 0;
        this.Dh = SHA512_IV[6] | 0;
        this.Dl = SHA512_IV[7] | 0;
        this.Eh = SHA512_IV[8] | 0;
        this.El = SHA512_IV[9] | 0;
        this.Fh = SHA512_IV[10] | 0;
        this.Fl = SHA512_IV[11] | 0;
        this.Gh = SHA512_IV[12] | 0;
        this.Gl = SHA512_IV[13] | 0;
        this.Hh = SHA512_IV[14] | 0;
        this.Hl = SHA512_IV[15] | 0;
    }
    // prettier-ignore
    get() {
        const { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;
        return [Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl];
    }
    // prettier-ignore
    set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl) {
        this.Ah = Ah | 0;
        this.Al = Al | 0;
        this.Bh = Bh | 0;
        this.Bl = Bl | 0;
        this.Ch = Ch | 0;
        this.Cl = Cl | 0;
        this.Dh = Dh | 0;
        this.Dl = Dl | 0;
        this.Eh = Eh | 0;
        this.El = El | 0;
        this.Fh = Fh | 0;
        this.Fl = Fl | 0;
        this.Gh = Gh | 0;
        this.Gl = Gl | 0;
        this.Hh = Hh | 0;
        this.Hl = Hl | 0;
    }
    process(view, offset) {
        // Extend the first 16 words into the remaining 64 words w[16..79] of the message schedule array
        for (let i = 0; i < 16; i++, offset += 4) {
            SHA512_W_H[i] = view.getUint32(offset);
            SHA512_W_L[i] = view.getUint32((offset += 4));
        }
        for (let i = 16; i < 80; i++) {
            // s0 := (w[i-15] rightrotate 1) xor (w[i-15] rightrotate 8) xor (w[i-15] rightshift 7)
            const W15h = SHA512_W_H[i - 15] | 0;
            const W15l = SHA512_W_L[i - 15] | 0;
            const s0h = rotrSH(W15h, W15l, 1) ^ rotrSH(W15h, W15l, 8) ^ shrSH(W15h, W15l, 7);
            const s0l = rotrSL(W15h, W15l, 1) ^ rotrSL(W15h, W15l, 8) ^ shrSL(W15h, W15l, 7);
            // s1 := (w[i-2] rightrotate 19) xor (w[i-2] rightrotate 61) xor (w[i-2] rightshift 6)
            const W2h = SHA512_W_H[i - 2] | 0;
            const W2l = SHA512_W_L[i - 2] | 0;
            const s1h = rotrSH(W2h, W2l, 19) ^ rotrBH(W2h, W2l, 61) ^ shrSH(W2h, W2l, 6);
            const s1l = rotrSL(W2h, W2l, 19) ^ rotrBL(W2h, W2l, 61) ^ shrSL(W2h, W2l, 6);
            // SHA256_W[i] = s0 + s1 + SHA256_W[i - 7] + SHA256_W[i - 16];
            const SUMl = add4L(s0l, s1l, SHA512_W_L[i - 7], SHA512_W_L[i - 16]);
            const SUMh = add4H(SUMl, s0h, s1h, SHA512_W_H[i - 7], SHA512_W_H[i - 16]);
            SHA512_W_H[i] = SUMh | 0;
            SHA512_W_L[i] = SUMl | 0;
        }
        let { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;
        // Compression function main loop, 80 rounds
        for (let i = 0; i < 80; i++) {
            // S1 := (e rightrotate 14) xor (e rightrotate 18) xor (e rightrotate 41)
            const sigma1h = rotrSH(Eh, El, 14) ^ rotrSH(Eh, El, 18) ^ rotrBH(Eh, El, 41);
            const sigma1l = rotrSL(Eh, El, 14) ^ rotrSL(Eh, El, 18) ^ rotrBL(Eh, El, 41);
            //const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;
            const CHIh = (Eh & Fh) ^ (~Eh & Gh);
            const CHIl = (El & Fl) ^ (~El & Gl);
            // T1 = H + sigma1 + Chi(E, F, G) + SHA512_K[i] + SHA512_W[i]
            // prettier-ignore
            const T1ll = add5L(Hl, sigma1l, CHIl, SHA512_Kl[i], SHA512_W_L[i]);
            const T1h = add5H(T1ll, Hh, sigma1h, CHIh, SHA512_Kh[i], SHA512_W_H[i]);
            const T1l = T1ll | 0;
            // S0 := (a rightrotate 28) xor (a rightrotate 34) xor (a rightrotate 39)
            const sigma0h = rotrSH(Ah, Al, 28) ^ rotrBH(Ah, Al, 34) ^ rotrBH(Ah, Al, 39);
            const sigma0l = rotrSL(Ah, Al, 28) ^ rotrBL(Ah, Al, 34) ^ rotrBL(Ah, Al, 39);
            const MAJh = (Ah & Bh) ^ (Ah & Ch) ^ (Bh & Ch);
            const MAJl = (Al & Bl) ^ (Al & Cl) ^ (Bl & Cl);
            Hh = Gh | 0;
            Hl = Gl | 0;
            Gh = Fh | 0;
            Gl = Fl | 0;
            Fh = Eh | 0;
            Fl = El | 0;
            ({ h: Eh, l: El } = add(Dh | 0, Dl | 0, T1h | 0, T1l | 0));
            Dh = Ch | 0;
            Dl = Cl | 0;
            Ch = Bh | 0;
            Cl = Bl | 0;
            Bh = Ah | 0;
            Bl = Al | 0;
            const All = add3L(T1l, sigma0l, MAJl);
            Ah = add3H(All, T1h, sigma0h, MAJh);
            Al = All | 0;
        }
        // Add the compressed chunk to the current hash value
        ({ h: Ah, l: Al } = add(this.Ah | 0, this.Al | 0, Ah | 0, Al | 0));
        ({ h: Bh, l: Bl } = add(this.Bh | 0, this.Bl | 0, Bh | 0, Bl | 0));
        ({ h: Ch, l: Cl } = add(this.Ch | 0, this.Cl | 0, Ch | 0, Cl | 0));
        ({ h: Dh, l: Dl } = add(this.Dh | 0, this.Dl | 0, Dh | 0, Dl | 0));
        ({ h: Eh, l: El } = add(this.Eh | 0, this.El | 0, Eh | 0, El | 0));
        ({ h: Fh, l: Fl } = add(this.Fh | 0, this.Fl | 0, Fh | 0, Fl | 0));
        ({ h: Gh, l: Gl } = add(this.Gh | 0, this.Gl | 0, Gh | 0, Gl | 0));
        ({ h: Hh, l: Hl } = add(this.Hh | 0, this.Hl | 0, Hh | 0, Hl | 0));
        this.set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl);
    }
    roundClean() {
        clean$1(SHA512_W_H, SHA512_W_L);
    }
    destroy() {
        clean$1(this.buffer);
        this.set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);
    }
}
/**
 * SHA2-256 hash function from RFC 4634.
 *
 * It is the fastest JS hash, even faster than Blake3.
 * To break sha256 using birthday attack, attackers need to try 2^128 hashes.
 * BTC network is doing 2^70 hashes/sec (2^95 hashes/year) as per 2025.
 */
const sha256$1 = /* @__PURE__ */ createHasher(() => new SHA256());
/** SHA2-512 hash function from RFC 4634. */
const sha512 = /* @__PURE__ */ createHasher(() => new SHA512());

/**
 * SHA2-256 a.k.a. sha256. In JS, it is the fastest hash, even faster than Blake3.
 *
 * To break sha256 using birthday attack, attackers need to try 2^128 hashes.
 * BTC network is doing 2^70 hashes/sec (2^95 hashes/year) as per 2025.
 *
 * Check out [FIPS 180-4](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf).
 * @module
 * @deprecated
 */
/** @deprecated Use import from `noble/hashes/sha2` module */
const sha256 = sha256$1;

var Protocols;
(function (Protocols) {
    Protocols["Relay"] = "relay";
    Protocols["Store"] = "store";
    Protocols["LightPush"] = "lightpush";
    Protocols["Filter"] = "filter";
})(Protocols || (Protocols = {}));
var ProtocolError$1;
(function (ProtocolError) {
    //
    // GENERAL ERRORS SECTION
    //
    /**
     * Could not determine the origin of the fault. Best to check connectivity and try again
     * */
    ProtocolError["GENERIC_FAIL"] = "Generic error";
    /**
     * The remote peer rejected the message. Information provided by the remote peer
     * is logged. Review message validity, or mitigation for `NO_PEER_AVAILABLE`
     * or `DECODE_FAILED` can be used.
     */
    ProtocolError["REMOTE_PEER_REJECTED"] = "Remote peer rejected";
    /**
     * Failure to protobuf decode the message. May be due to a remote peer issue,
     * ensuring that messages are sent via several peer enable mitigation of this error.
     */
    ProtocolError["DECODE_FAILED"] = "Failed to decode";
    /**
     * Failure to find a peer with suitable protocols. This may due to a connection issue.
     * Mitigation can be: retrying after a given time period, display connectivity issue
     * to user or listening for `peer:connected:bootstrap` or `peer:connected:peer-exchange`
     * on the connection manager before retrying.
     */
    ProtocolError["NO_PEER_AVAILABLE"] = "No peer available";
    /**
     * Failure to find a stream to the peer. This may be because the connection with the peer is not still alive.
     * Mitigation can be: retrying after a given time period, or mitigation for `NO_PEER_AVAILABLE` can be used.
     */
    ProtocolError["NO_STREAM_AVAILABLE"] = "No stream available";
    /**
     * The remote peer did not behave as expected. Mitigation for `NO_PEER_AVAILABLE`
     * or `DECODE_FAILED` can be used.
     */
    ProtocolError["NO_RESPONSE"] = "No response received";
    //
    // SEND ERRORS SECTION
    //
    /**
     * Failure to protobuf encode the message. This is not recoverable and needs
     * further investigation.
     */
    ProtocolError["ENCODE_FAILED"] = "Failed to encode";
    /**
     * The message payload is empty, making the message invalid. Ensure that a non-empty
     * payload is set on the outgoing message.
     */
    ProtocolError["EMPTY_PAYLOAD"] = "Payload is empty";
    /**
     * The message size is above the maximum message size allowed on the Waku Network.
     * Compressing the message or using an alternative strategy for large messages is recommended.
     */
    ProtocolError["SIZE_TOO_BIG"] = "Size is too big";
    /**
     * The PubsubTopic passed to the send function is not configured on the Waku node.
     * Please ensure that the PubsubTopic is used when initializing the Waku node.
     */
    ProtocolError["TOPIC_NOT_CONFIGURED"] = "Topic not configured";
    /**
     * Fails when
     */
    ProtocolError["STREAM_ABORTED"] = "Stream aborted";
    /**
     * General proof generation error message.
     * nwaku: https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/group_manager/group_manager_base.nim#L201C19-L201C42
     */
    ProtocolError["RLN_PROOF_GENERATION"] = "Proof generation failed";
    //
    // RECEIVE ERRORS SECTION
    //
    /**
     * The pubsub topic configured on the decoder does not match the pubsub topic setup on the protocol.
     * Ensure that the pubsub topic used for decoder creation is the same as the one used for protocol.
     */
    ProtocolError["TOPIC_DECODER_MISMATCH"] = "Topic decoder mismatch";
    /**
     * The topics passed in the decoders do not match each other, or don't exist at all.
     * Ensure that all the pubsub topics used in the decoders are valid and match each other.
     */
    ProtocolError["INVALID_DECODER_TOPICS"] = "Invalid decoder topics";
})(ProtocolError$1 || (ProtocolError$1 = {}));

// Peer tags
var Tags;
(function (Tags) {
    Tags["BOOTSTRAP"] = "bootstrap";
    Tags["PEER_EXCHANGE"] = "peer-exchange";
    Tags["LOCAL"] = "local-peer-cache";
})(Tags || (Tags = {}));
// Connection tag
const CONNECTION_LOCKED_TAG = "locked";

const DNS_DISCOVERY_TAG = "@waku/bootstrap";

/**
 * The default cluster ID for The Waku Network
 */
const DEFAULT_CLUSTER_ID = 1;
/**
 * The default number of shards under a cluster.
 */
const DEFAULT_NUM_SHARDS = 8;
/**
 * DefaultShardInfo is default configuration for The Waku Network.
 */
const DefaultShardInfo = {
    clusterId: DEFAULT_CLUSTER_ID,
    shards: [0, 1, 2, 3, 4, 5, 6, 7, 8]
};
const DefaultNetworkConfig = DefaultShardInfo;

var HealthStatus;
(function (HealthStatus) {
    /**
     * No peer connections
     */
    HealthStatus["Unhealthy"] = "Unhealthy";
    /**
     * At least 1 peer supporting both Filter and LightPush protocols
     */
    HealthStatus["MinimallyHealthy"] = "MinimallyHealthy";
    /**
     * At least 2 peers supporting both Filter and LightPush protocols
     */
    HealthStatus["SufficientlyHealthy"] = "SufficientlyHealthy";
})(HealthStatus || (HealthStatus = {}));

/**
 * Turns a `Uint8Array` into a string.
 *
 * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.
 *
 * Also `ascii` which is similar to node's 'binary' encoding.
 */
function toString(array, encoding = 'utf8') {
    const base = BASES[encoding];
    if (base == null) {
        throw new Error(`Unsupported encoding "${encoding}"`);
    }
    // strip multibase prefix
    return base.encoder.encode(array).substring(1);
}

/**
 * Convert input to a byte array.
 *
 * Handles both `0x` prefixed and non-prefixed strings.
 */
function hexToBytes$1(hex) {
    if (typeof hex === "string") {
        const _hex = hex.replace(/^0x/i, "");
        return fromString(_hex.toLowerCase(), "base16");
    }
    return hex;
}
function numberToBytes(value) {
    const buffer = new ArrayBuffer(8);
    const view = new DataView(buffer);
    if (typeof value === "number") {
        view.setFloat64(0, value, false);
    }
    else {
        view.setBigInt64(0, value, false);
    }
    return new Uint8Array(buffer);
}
/**
 * Convert byte array to hex string (no `0x` prefix).
 */
const bytesToHex$1 = (bytes) => toString(bytes, "base16");
/**
 * Decode byte array to utf-8 string.
 */
const bytesToUtf8 = (b) => toString(b, "utf8");
/**
 * Encode utf-8 string to byte array.
 */
const utf8ToBytes$1 = (s) => fromString(s, "utf8");
/**
 * Concatenate using Uint8Arrays as `Buffer` has a different behavior with `DataView`
 */
function concat$1(byteArrays, totalLength) {
    const len = byteArrays.reduce((acc, curr) => acc + curr.length, 0);
    const res = new Uint8Array(len);
    let offset = 0;
    for (const bytes of byteArrays) {
        res.set(bytes, offset);
        offset += bytes.length;
    }
    return res;
}

function isStaticSharding(config) {
    return ("clusterId" in config && "shards" in config && !("contentTopics" in config));
}
function isAutoSharding(config) {
    return "contentTopics" in config;
}

function derivePubsubTopicsFromNetworkConfig(networkConfig) {
    if (isStaticSharding(networkConfig)) {
        if (networkConfig.shards.length === 0) {
            throw new Error("Invalid shards configuration: please provide at least one shard");
        }
        return shardInfoToPubsubTopics(networkConfig);
    }
    else if (isAutoSharding(networkConfig)) {
        if (networkConfig.contentTopics.length === 0) {
            throw new Error("Invalid content topics configuration: please provide at least one content topic");
        }
        return networkConfig.contentTopics.map((contentTopic) => contentTopicToPubsubTopic(contentTopic, networkConfig.clusterId));
    }
    else {
        throw new Error("Unknown shard config. Please use ShardInfo or ContentTopicInfo");
    }
}
const singleShardInfoToPubsubTopic = (shardInfo) => {
    if (shardInfo.shard === undefined)
        throw new Error("Invalid shard");
    return `/waku/2/rs/${shardInfo.clusterId ?? DEFAULT_CLUSTER_ID}/${shardInfo.shard}`;
};
const singleShardInfosToShardInfo = (singleShardInfos) => {
    if (singleShardInfos.length === 0)
        throw new Error("Invalid shard");
    const clusterIds = singleShardInfos.map((shardInfo) => shardInfo.clusterId);
    if (new Set(clusterIds).size !== 1) {
        throw new Error("Passed shard infos have different clusterIds");
    }
    const shards = singleShardInfos
        .map((shardInfo) => shardInfo.shard)
        .filter((shard) => shard !== undefined);
    return {
        clusterId: singleShardInfos[0].clusterId,
        shards
    };
};
/**
 * @deprecated will be removed, use cluster and shard comparison directly
 */
const shardInfoToPubsubTopics = (shardInfo) => {
    if ("contentTopics" in shardInfo && shardInfo.contentTopics) {
        // Autosharding: explicitly defined content topics
        return Array.from(new Set(shardInfo.contentTopics.map((contentTopic) => contentTopicToPubsubTopic(contentTopic, shardInfo.clusterId))));
    }
    else if ("shards" in shardInfo) {
        // Static sharding
        if (shardInfo.shards === undefined)
            throw new Error("Invalid shard");
        return Array.from(new Set(shardInfo.shards.map((index) => `/waku/2/rs/${shardInfo.clusterId ?? DEFAULT_CLUSTER_ID}/${index}`)));
    }
    else if ("application" in shardInfo && "version" in shardInfo) {
        // Autosharding: single shard from application and version
        return [
            contentTopicToPubsubTopic(`/${shardInfo.application}/${shardInfo.version}/default/default`, shardInfo.clusterId)
        ];
    }
    else {
        throw new Error("Missing required configuration in shard parameters");
    }
};
/**
 * @deprecated will be removed
 */
const pubsubTopicToSingleShardInfo = (pubsubTopics) => {
    const parts = pubsubTopics.split("/");
    if (parts.length != 6 ||
        parts[1] !== "waku" ||
        parts[2] !== "2" ||
        parts[3] !== "rs")
        throw new Error("Invalid pubsub topic");
    const clusterId = parseInt(parts[4]);
    const shard = parseInt(parts[5]);
    if (isNaN(clusterId) || isNaN(shard))
        throw new Error("Invalid clusterId or shard");
    return {
        clusterId,
        shard
    };
};
const pubsubTopicsToShardInfo = (pubsubTopics) => {
    const shardInfoSet = new Set();
    const clusterIds = new Set();
    for (const topic of pubsubTopics) {
        const { clusterId, shard } = pubsubTopicToSingleShardInfo(topic);
        shardInfoSet.add(`${clusterId}:${shard}`);
        clusterIds.add(clusterId);
    }
    if (shardInfoSet.size === 0) {
        throw new Error("No valid pubsub topics provided");
    }
    if (clusterIds.size > 1) {
        throw new Error("Pubsub topics from multiple cluster IDs are not supported");
    }
    const clusterId = clusterIds.values().next().value;
    const shards = Array.from(shardInfoSet).map((info) => parseInt(info.split(":")[1]));
    return {
        clusterId,
        shards
    };
};
/**
 * Given a string, will throw an error if it is not formatted as a valid content topic for autosharding based on https://rfc.vac.dev/spec/51/
 * @param contentTopic String to validate
 * @returns Object with each content topic field as an attribute
 */
function ensureValidContentTopic(contentTopic) {
    const parts = contentTopic.split("/");
    if (parts.length < 5 || parts.length > 6) {
        throw Error("Content topic format is invalid");
    }
    // Validate generation field if present
    let generation = 0;
    if (parts.length == 6) {
        generation = parseInt(parts[1]);
        if (isNaN(generation)) {
            throw new Error("Invalid generation field in content topic");
        }
        if (generation > 0) {
            throw new Error("Generation greater than 0 is not supported");
        }
    }
    // Validate remaining fields
    const fields = parts.splice(-4);
    // Validate application field
    if (fields[0].length == 0) {
        throw new Error("Application field cannot be empty");
    }
    // Validate version field
    if (fields[1].length == 0) {
        throw new Error("Version field cannot be empty");
    }
    // Validate topic name field
    if (fields[2].length == 0) {
        throw new Error("Topic name field cannot be empty");
    }
    // Validate encoding field
    if (fields[3].length == 0) {
        throw new Error("Encoding field cannot be empty");
    }
    return {
        generation,
        application: fields[0],
        version: fields[1],
        topicName: fields[2],
        encoding: fields[3]
    };
}
/**
 * Given a string, determines which autoshard index to use for its pubsub topic.
 * Based on the algorithm described in the RFC: https://rfc.vac.dev/spec/51//#algorithm
 */
function contentTopicToShardIndex(contentTopic, networkShards = 8) {
    const { application, version } = ensureValidContentTopic(contentTopic);
    const digest = sha256(concat$1([utf8ToBytes$1(application), utf8ToBytes$1(version)]));
    const dataview = new DataView(digest.buffer.slice(-8));
    return Number(dataview.getBigUint64(0, false) % BigInt(networkShards));
}
function contentTopicToPubsubTopic(contentTopic, clusterId = DEFAULT_CLUSTER_ID, networkShards = 8) {
    if (!contentTopic) {
        throw Error("Content topic must be specified");
    }
    const shardIndex = contentTopicToShardIndex(contentTopic, networkShards);
    return `/waku/2/rs/${clusterId}/${shardIndex}`;
}
/**
 * Given an array of content topics, groups them together by their Pubsub topic as derived using the algorithm for autosharding.
 * If any of the content topics are not properly formatted, the function will throw an error.
 */
function contentTopicsByPubsubTopic(contentTopics, clusterId = DEFAULT_CLUSTER_ID, networkShards = 8) {
    const groupedContentTopics = new Map();
    for (const contentTopic of contentTopics) {
        const pubsubTopic = contentTopicToPubsubTopic(contentTopic, clusterId, networkShards);
        let topics = groupedContentTopics.get(pubsubTopic);
        if (!topics) {
            groupedContentTopics.set(pubsubTopic, []);
            topics = groupedContentTopics.get(pubsubTopic);
        }
        topics.push(contentTopic);
    }
    return groupedContentTopics;
}
/**
 * Used when creating encoders/decoders to determine which pubsub topic to use
 */
function determinePubsubTopic(contentTopic, 
// TODO: make it accept ShardInfo https://github.com/waku-org/js-waku/issues/2086
pubsubTopicShardInfo) {
    if (typeof pubsubTopicShardInfo == "string") {
        return pubsubTopicShardInfo;
    }
    return pubsubTopicShardInfo?.shard !== undefined
        ? singleShardInfoToPubsubTopic(pubsubTopicShardInfo)
        : contentTopicToPubsubTopic(contentTopic, pubsubTopicShardInfo?.clusterId ?? DEFAULT_CLUSTER_ID);
}
/**
 * Validates sharding configuration and sets defaults where possible.
 * @returns Validated sharding parameters, with any missing values set to defaults
 */
const ensureShardingConfigured = (networkConfig) => {
    const clusterId = networkConfig.clusterId ?? DEFAULT_CLUSTER_ID;
    const shards = "shards" in networkConfig ? networkConfig.shards : [];
    const contentTopics = "contentTopics" in networkConfig ? networkConfig.contentTopics : [];
    const isShardsConfigured = shards && shards.length > 0;
    const isContentTopicsConfigured = contentTopics && contentTopics.length > 0;
    if (isShardsConfigured) {
        return {
            shardInfo: { clusterId, shards },
            pubsubTopics: shardInfoToPubsubTopics({ clusterId, shards })
        };
    }
    if (isContentTopicsConfigured) {
        const pubsubTopics = Array.from(new Set(contentTopics.map((topic) => contentTopicToPubsubTopic(topic, clusterId))));
        const shards = Array.from(new Set(contentTopics.map((topic) => contentTopicToShardIndex(topic))));
        return {
            shardInfo: { clusterId, shards },
            pubsubTopics
        };
    }
    throw new Error("Missing minimum required configuration options for static sharding or autosharding.");
};

function pushOrInitMapSet(map, key, newValue) {
    let arr = map.get(key);
    if (typeof arr === "undefined") {
        map.set(key, new Set());
        arr = map.get(key);
    }
    arr.add(newValue);
}

const decodeRelayShard = (bytes) => {
    // explicitly converting to Uint8Array to avoid Buffer
    // https://github.com/libp2p/js-libp2p/issues/2146
    bytes = new Uint8Array(bytes);
    if (bytes.length < 3)
        throw new Error("Insufficient data");
    const view = new DataView(bytes.buffer);
    const clusterId = view.getUint16(0);
    const shards = [];
    if (bytes.length === 130) {
        // rsv format (Bit Vector)
        for (let i = 0; i < 1024; i++) {
            const byteIndex = Math.floor(i / 8) + 2; // Adjusted for the 2-byte cluster field
            const bitIndex = 7 - (i % 8);
            if (view.getUint8(byteIndex) & (1 << bitIndex)) {
                shards.push(i);
            }
        }
    }
    else {
        // rs format (Index List)
        const numIndices = view.getUint8(2);
        for (let i = 0, offset = 3; i < numIndices; i++, offset += 2) {
            if (offset + 1 >= bytes.length)
                throw new Error("Unexpected end of data");
            shards.push(view.getUint16(offset));
        }
    }
    return { clusterId, shards };
};
const encodeRelayShard = (shardInfo) => {
    const { clusterId, shards } = shardInfo;
    const totalLength = shards.length >= 64 ? 130 : 3 + 2 * shards.length;
    const buffer = new ArrayBuffer(totalLength);
    const view = new DataView(buffer);
    view.setUint16(0, clusterId);
    if (shards.length >= 64) {
        // rsv format (Bit Vector)
        for (const index of shards) {
            const byteIndex = Math.floor(index / 8) + 2; // Adjusted for the 2-byte cluster field
            const bitIndex = 7 - (index % 8);
            view.setUint8(byteIndex, view.getUint8(byteIndex) | (1 << bitIndex));
        }
    }
    else {
        // rs format (Index List)
        view.setUint8(2, shards.length);
        for (let i = 0, offset = 3; i < shards.length; i++, offset += 2) {
            view.setUint16(offset, shards[i]);
        }
    }
    return new Uint8Array(buffer);
};

async function delay$1(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
}

function removeItemFromArray(arr, value) {
    const index = arr.indexOf(value);
    if (index > -1) {
        arr.splice(index, 1);
    }
    return arr;
}
function getWsMultiaddrFromMultiaddrs(addresses) {
    const wsMultiaddr = addresses.find((addr) => addr.toString().includes("ws") || addr.toString().includes("wss"));
    if (!wsMultiaddr) {
        throw new Error("No ws multiaddr found in the given addresses");
    }
    return wsMultiaddr;
}

var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

function getDefaultExportFromCjs (x) {
	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
}

var browser = {exports: {}};

/**
 * Helpers.
 */

var ms$1;
var hasRequiredMs;

function requireMs () {
	if (hasRequiredMs) return ms$1;
	hasRequiredMs = 1;
	var s = 1000;
	var m = s * 60;
	var h = m * 60;
	var d = h * 24;
	var w = d * 7;
	var y = d * 365.25;

	/**
	 * Parse or format the given `val`.
	 *
	 * Options:
	 *
	 *  - `long` verbose formatting [false]
	 *
	 * @param {String|Number} val
	 * @param {Object} [options]
	 * @throws {Error} throw an error if val is not a non-empty string or a number
	 * @return {String|Number}
	 * @api public
	 */

	ms$1 = function (val, options) {
	  options = options || {};
	  var type = typeof val;
	  if (type === 'string' && val.length > 0) {
	    return parse(val);
	  } else if (type === 'number' && isFinite(val)) {
	    return options.long ? fmtLong(val) : fmtShort(val);
	  }
	  throw new Error(
	    'val is not a non-empty string or a valid number. val=' +
	      JSON.stringify(val)
	  );
	};

	/**
	 * Parse the given `str` and return milliseconds.
	 *
	 * @param {String} str
	 * @return {Number}
	 * @api private
	 */

	function parse(str) {
	  str = String(str);
	  if (str.length > 100) {
	    return;
	  }
	  var match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(
	    str
	  );
	  if (!match) {
	    return;
	  }
	  var n = parseFloat(match[1]);
	  var type = (match[2] || 'ms').toLowerCase();
	  switch (type) {
	    case 'years':
	    case 'year':
	    case 'yrs':
	    case 'yr':
	    case 'y':
	      return n * y;
	    case 'weeks':
	    case 'week':
	    case 'w':
	      return n * w;
	    case 'days':
	    case 'day':
	    case 'd':
	      return n * d;
	    case 'hours':
	    case 'hour':
	    case 'hrs':
	    case 'hr':
	    case 'h':
	      return n * h;
	    case 'minutes':
	    case 'minute':
	    case 'mins':
	    case 'min':
	    case 'm':
	      return n * m;
	    case 'seconds':
	    case 'second':
	    case 'secs':
	    case 'sec':
	    case 's':
	      return n * s;
	    case 'milliseconds':
	    case 'millisecond':
	    case 'msecs':
	    case 'msec':
	    case 'ms':
	      return n;
	    default:
	      return undefined;
	  }
	}

	/**
	 * Short format for `ms`.
	 *
	 * @param {Number} ms
	 * @return {String}
	 * @api private
	 */

	function fmtShort(ms) {
	  var msAbs = Math.abs(ms);
	  if (msAbs >= d) {
	    return Math.round(ms / d) + 'd';
	  }
	  if (msAbs >= h) {
	    return Math.round(ms / h) + 'h';
	  }
	  if (msAbs >= m) {
	    return Math.round(ms / m) + 'm';
	  }
	  if (msAbs >= s) {
	    return Math.round(ms / s) + 's';
	  }
	  return ms + 'ms';
	}

	/**
	 * Long format for `ms`.
	 *
	 * @param {Number} ms
	 * @return {String}
	 * @api private
	 */

	function fmtLong(ms) {
	  var msAbs = Math.abs(ms);
	  if (msAbs >= d) {
	    return plural(ms, msAbs, d, 'day');
	  }
	  if (msAbs >= h) {
	    return plural(ms, msAbs, h, 'hour');
	  }
	  if (msAbs >= m) {
	    return plural(ms, msAbs, m, 'minute');
	  }
	  if (msAbs >= s) {
	    return plural(ms, msAbs, s, 'second');
	  }
	  return ms + ' ms';
	}

	/**
	 * Pluralization helper.
	 */

	function plural(ms, msAbs, n, name) {
	  var isPlural = msAbs >= n * 1.5;
	  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');
	}
	return ms$1;
}

/**
 * This is the common logic for both the Node.js and web browser
 * implementations of `debug()`.
 */

function setup$1(env) {
	createDebug.debug = createDebug;
	createDebug.default = createDebug;
	createDebug.coerce = coerce;
	createDebug.disable = disable;
	createDebug.enable = enable;
	createDebug.enabled = enabled;
	createDebug.humanize = requireMs();
	createDebug.destroy = destroy;

	Object.keys(env).forEach(key => {
		createDebug[key] = env[key];
	});

	/**
	* The currently active debug mode names, and names to skip.
	*/

	createDebug.names = [];
	createDebug.skips = [];

	/**
	* Map of special "%n" handling functions, for the debug "format" argument.
	*
	* Valid key names are a single, lower or upper-case letter, i.e. "n" and "N".
	*/
	createDebug.formatters = {};

	/**
	* Selects a color for a debug namespace
	* @param {String} namespace The namespace string for the debug instance to be colored
	* @return {Number|String} An ANSI color code for the given namespace
	* @api private
	*/
	function selectColor(namespace) {
		let hash = 0;

		for (let i = 0; i < namespace.length; i++) {
			hash = ((hash << 5) - hash) + namespace.charCodeAt(i);
			hash |= 0; // Convert to 32bit integer
		}

		return createDebug.colors[Math.abs(hash) % createDebug.colors.length];
	}
	createDebug.selectColor = selectColor;

	/**
	* Create a debugger with the given `namespace`.
	*
	* @param {String} namespace
	* @return {Function}
	* @api public
	*/
	function createDebug(namespace) {
		let prevTime;
		let enableOverride = null;
		let namespacesCache;
		let enabledCache;

		function debug(...args) {
			// Disabled?
			if (!debug.enabled) {
				return;
			}

			const self = debug;

			// Set `diff` timestamp
			const curr = Number(new Date());
			const ms = curr - (prevTime || curr);
			self.diff = ms;
			self.prev = prevTime;
			self.curr = curr;
			prevTime = curr;

			args[0] = createDebug.coerce(args[0]);

			if (typeof args[0] !== 'string') {
				// Anything else let's inspect with %O
				args.unshift('%O');
			}

			// Apply any `formatters` transformations
			let index = 0;
			args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {
				// If we encounter an escaped % then don't increase the array index
				if (match === '%%') {
					return '%';
				}
				index++;
				const formatter = createDebug.formatters[format];
				if (typeof formatter === 'function') {
					const val = args[index];
					match = formatter.call(self, val);

					// Now we need to remove `args[index]` since it's inlined in the `format`
					args.splice(index, 1);
					index--;
				}
				return match;
			});

			// Apply env-specific formatting (colors, etc.)
			createDebug.formatArgs.call(self, args);

			const logFn = self.log || createDebug.log;
			logFn.apply(self, args);
		}

		debug.namespace = namespace;
		debug.useColors = createDebug.useColors();
		debug.color = createDebug.selectColor(namespace);
		debug.extend = extend;
		debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.

		Object.defineProperty(debug, 'enabled', {
			enumerable: true,
			configurable: false,
			get: () => {
				if (enableOverride !== null) {
					return enableOverride;
				}
				if (namespacesCache !== createDebug.namespaces) {
					namespacesCache = createDebug.namespaces;
					enabledCache = createDebug.enabled(namespace);
				}

				return enabledCache;
			},
			set: v => {
				enableOverride = v;
			}
		});

		// Env-specific initialization logic for debug instances
		if (typeof createDebug.init === 'function') {
			createDebug.init(debug);
		}

		return debug;
	}

	function extend(namespace, delimiter) {
		const newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);
		newDebug.log = this.log;
		return newDebug;
	}

	/**
	* Enables a debug mode by namespaces. This can include modes
	* separated by a colon and wildcards.
	*
	* @param {String} namespaces
	* @api public
	*/
	function enable(namespaces) {
		createDebug.save(namespaces);
		createDebug.namespaces = namespaces;

		createDebug.names = [];
		createDebug.skips = [];

		const split = (typeof namespaces === 'string' ? namespaces : '')
			.trim()
			.replace(/\s+/g, ',')
			.split(',')
			.filter(Boolean);

		for (const ns of split) {
			if (ns[0] === '-') {
				createDebug.skips.push(ns.slice(1));
			} else {
				createDebug.names.push(ns);
			}
		}
	}

	/**
	 * Checks if the given string matches a namespace template, honoring
	 * asterisks as wildcards.
	 *
	 * @param {String} search
	 * @param {String} template
	 * @return {Boolean}
	 */
	function matchesTemplate(search, template) {
		let searchIndex = 0;
		let templateIndex = 0;
		let starIndex = -1;
		let matchIndex = 0;

		while (searchIndex < search.length) {
			if (templateIndex < template.length && (template[templateIndex] === search[searchIndex] || template[templateIndex] === '*')) {
				// Match character or proceed with wildcard
				if (template[templateIndex] === '*') {
					starIndex = templateIndex;
					matchIndex = searchIndex;
					templateIndex++; // Skip the '*'
				} else {
					searchIndex++;
					templateIndex++;
				}
			} else if (starIndex !== -1) { // eslint-disable-line no-negated-condition
				// Backtrack to the last '*' and try to match more characters
				templateIndex = starIndex + 1;
				matchIndex++;
				searchIndex = matchIndex;
			} else {
				return false; // No match
			}
		}

		// Handle trailing '*' in template
		while (templateIndex < template.length && template[templateIndex] === '*') {
			templateIndex++;
		}

		return templateIndex === template.length;
	}

	/**
	* Disable debug output.
	*
	* @return {String} namespaces
	* @api public
	*/
	function disable() {
		const namespaces = [
			...createDebug.names,
			...createDebug.skips.map(namespace => '-' + namespace)
		].join(',');
		createDebug.enable('');
		return namespaces;
	}

	/**
	* Returns true if the given mode name is enabled, false otherwise.
	*
	* @param {String} name
	* @return {Boolean}
	* @api public
	*/
	function enabled(name) {
		for (const skip of createDebug.skips) {
			if (matchesTemplate(name, skip)) {
				return false;
			}
		}

		for (const ns of createDebug.names) {
			if (matchesTemplate(name, ns)) {
				return true;
			}
		}

		return false;
	}

	/**
	* Coerce `val`.
	*
	* @param {Mixed} val
	* @return {Mixed}
	* @api private
	*/
	function coerce(val) {
		if (val instanceof Error) {
			return val.stack || val.message;
		}
		return val;
	}

	/**
	* XXX DO NOT USE. This is a temporary stub function.
	* XXX It WILL be removed in the next major release.
	*/
	function destroy() {
		console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
	}

	createDebug.enable(createDebug.load());

	return createDebug;
}

var common = setup$1;

/* eslint-env browser */

(function (module, exports) {
	/**
	 * This is the web browser implementation of `debug()`.
	 */

	exports.formatArgs = formatArgs;
	exports.save = save;
	exports.load = load;
	exports.useColors = useColors;
	exports.storage = localstorage();
	exports.destroy = (() => {
		let warned = false;

		return () => {
			if (!warned) {
				warned = true;
				console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
			}
		};
	})();

	/**
	 * Colors.
	 */

	exports.colors = [
		'#0000CC',
		'#0000FF',
		'#0033CC',
		'#0033FF',
		'#0066CC',
		'#0066FF',
		'#0099CC',
		'#0099FF',
		'#00CC00',
		'#00CC33',
		'#00CC66',
		'#00CC99',
		'#00CCCC',
		'#00CCFF',
		'#3300CC',
		'#3300FF',
		'#3333CC',
		'#3333FF',
		'#3366CC',
		'#3366FF',
		'#3399CC',
		'#3399FF',
		'#33CC00',
		'#33CC33',
		'#33CC66',
		'#33CC99',
		'#33CCCC',
		'#33CCFF',
		'#6600CC',
		'#6600FF',
		'#6633CC',
		'#6633FF',
		'#66CC00',
		'#66CC33',
		'#9900CC',
		'#9900FF',
		'#9933CC',
		'#9933FF',
		'#99CC00',
		'#99CC33',
		'#CC0000',
		'#CC0033',
		'#CC0066',
		'#CC0099',
		'#CC00CC',
		'#CC00FF',
		'#CC3300',
		'#CC3333',
		'#CC3366',
		'#CC3399',
		'#CC33CC',
		'#CC33FF',
		'#CC6600',
		'#CC6633',
		'#CC9900',
		'#CC9933',
		'#CCCC00',
		'#CCCC33',
		'#FF0000',
		'#FF0033',
		'#FF0066',
		'#FF0099',
		'#FF00CC',
		'#FF00FF',
		'#FF3300',
		'#FF3333',
		'#FF3366',
		'#FF3399',
		'#FF33CC',
		'#FF33FF',
		'#FF6600',
		'#FF6633',
		'#FF9900',
		'#FF9933',
		'#FFCC00',
		'#FFCC33'
	];

	/**
	 * Currently only WebKit-based Web Inspectors, Firefox >= v31,
	 * and the Firebug extension (any Firefox version) are known
	 * to support "%c" CSS customizations.
	 *
	 * TODO: add a `localStorage` variable to explicitly enable/disable colors
	 */

	// eslint-disable-next-line complexity
	function useColors() {
		// NB: In an Electron preload script, document will be defined but not fully
		// initialized. Since we know we're in Chrome, we'll just detect this case
		// explicitly
		if (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {
			return true;
		}

		// Internet Explorer and Edge do not support colors.
		if (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\/(\d+)/)) {
			return false;
		}

		let m;

		// Is webkit? http://stackoverflow.com/a/16459606/376773
		// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632
		// eslint-disable-next-line no-return-assign
		return (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||
			// Is firebug? http://stackoverflow.com/a/398120/376773
			(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||
			// Is firefox >= v31?
			// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages
			(typeof navigator !== 'undefined' && navigator.userAgent && (m = navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/)) && parseInt(m[1], 10) >= 31) ||
			// Double check webkit in userAgent just in case we are in a worker
			(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/));
	}

	/**
	 * Colorize log arguments if enabled.
	 *
	 * @api public
	 */

	function formatArgs(args) {
		args[0] = (this.useColors ? '%c' : '') +
			this.namespace +
			(this.useColors ? ' %c' : ' ') +
			args[0] +
			(this.useColors ? '%c ' : ' ') +
			'+' + module.exports.humanize(this.diff);

		if (!this.useColors) {
			return;
		}

		const c = 'color: ' + this.color;
		args.splice(1, 0, c, 'color: inherit');

		// The final "%c" is somewhat tricky, because there could be other
		// arguments passed either before or after the %c, so we need to
		// figure out the correct index to insert the CSS into
		let index = 0;
		let lastC = 0;
		args[0].replace(/%[a-zA-Z%]/g, match => {
			if (match === '%%') {
				return;
			}
			index++;
			if (match === '%c') {
				// We only are interested in the *last* %c
				// (the user may have provided their own)
				lastC = index;
			}
		});

		args.splice(lastC, 0, c);
	}

	/**
	 * Invokes `console.debug()` when available.
	 * No-op when `console.debug` is not a "function".
	 * If `console.debug` is not available, falls back
	 * to `console.log`.
	 *
	 * @api public
	 */
	exports.log = console.debug || console.log || (() => {});

	/**
	 * Save `namespaces`.
	 *
	 * @param {String} namespaces
	 * @api private
	 */
	function save(namespaces) {
		try {
			if (namespaces) {
				exports.storage.setItem('debug', namespaces);
			} else {
				exports.storage.removeItem('debug');
			}
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}
	}

	/**
	 * Load `namespaces`.
	 *
	 * @return {String} returns the previously persisted debug modes
	 * @api private
	 */
	function load() {
		let r;
		try {
			r = exports.storage.getItem('debug') || exports.storage.getItem('DEBUG') ;
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}

		// If debug isn't set in LS, and we're in Electron, try to load $DEBUG
		if (!r && typeof process !== 'undefined' && 'env' in process) {
			r = process.env.DEBUG;
		}

		return r;
	}

	/**
	 * Localstorage attempts to return the localstorage.
	 *
	 * This is necessary because safari throws
	 * when a user disables cookies/localstorage
	 * and you attempt to access it.
	 *
	 * @return {LocalStorage}
	 * @api private
	 */

	function localstorage() {
		try {
			// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context
			// The Browser also has localStorage in the global context.
			return localStorage;
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}
	}

	module.exports = common(exports);

	const {formatters} = module.exports;

	/**
	 * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.
	 */

	formatters.j = function (v) {
		try {
			return JSON.stringify(v);
		} catch (error) {
			return '[UnexpectedJSONParseError]: ' + error.message;
		}
	}; 
} (browser, browser.exports));

var browserExports = browser.exports;
var debug = /*@__PURE__*/getDefaultExportFromCjs(browserExports);

const APP_NAME = "waku";
let Logger$1 = class Logger {
    _info;
    _warn;
    _error;
    static createDebugNamespace(level, prefix) {
        return prefix ? `${APP_NAME}:${prefix}:${level}` : `${APP_NAME}:${level}`;
    }
    constructor(prefix) {
        this._info = debug(Logger.createDebugNamespace("info", prefix));
        this._warn = debug(Logger.createDebugNamespace("warn", prefix));
        this._error = debug(Logger.createDebugNamespace("error", prefix));
    }
    get info() {
        return this._info;
    }
    get warn() {
        return this._warn;
    }
    get error() {
        return this._error;
    }
    log(level, ...args) {
        const logger = this[level] || this.log;
        logger(...args);
    }
};

var index$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Logger: Logger$1,
    contentTopicToPubsubTopic: contentTopicToPubsubTopic,
    contentTopicToShardIndex: contentTopicToShardIndex,
    contentTopicsByPubsubTopic: contentTopicsByPubsubTopic,
    decodeRelayShard: decodeRelayShard,
    delay: delay$1,
    derivePubsubTopicsFromNetworkConfig: derivePubsubTopicsFromNetworkConfig,
    determinePubsubTopic: determinePubsubTopic,
    encodeRelayShard: encodeRelayShard,
    ensureShardingConfigured: ensureShardingConfigured,
    ensureValidContentTopic: ensureValidContentTopic,
    getPseudoRandomSubset: getPseudoRandomSubset,
    getWsMultiaddrFromMultiaddrs: getWsMultiaddrFromMultiaddrs,
    groupByContentTopic: groupByContentTopic,
    isAutoSharding: isAutoSharding,
    isDefined: isDefined,
    isMessageSizeUnderCap: isMessageSizeUnderCap,
    isStaticSharding: isStaticSharding,
    isWireSizeUnderCap: isWireSizeUnderCap,
    pubsubTopicToSingleShardInfo: pubsubTopicToSingleShardInfo,
    pubsubTopicsToShardInfo: pubsubTopicsToShardInfo,
    pushOrInitMapSet: pushOrInitMapSet,
    removeItemFromArray: removeItemFromArray,
    shardInfoToPubsubTopics: shardInfoToPubsubTopics,
    singleShardInfoToPubsubTopic: singleShardInfoToPubsubTopic,
    singleShardInfosToShardInfo: singleShardInfosToShardInfo,
    toAsyncIterator: toAsyncIterator
});

const log$v = new Logger$1("message:version-0");
const OneMillion = BigInt(1_000_000);
const Version = 0;
class DecodedMessage {
    pubsubTopic;
    proto;
    constructor(pubsubTopic, proto) {
        this.pubsubTopic = pubsubTopic;
        this.proto = proto;
    }
    get ephemeral() {
        return Boolean(this.proto.ephemeral);
    }
    get payload() {
        return this.proto.payload;
    }
    get contentTopic() {
        return this.proto.contentTopic;
    }
    get timestamp() {
        // In the case we receive a value that is bigger than JS's max number,
        // we catch the error and return undefined.
        try {
            if (this.proto.timestamp) {
                // nanoseconds 10^-9 to milliseconds 10^-3
                const timestamp = this.proto.timestamp / OneMillion;
                return new Date(Number(timestamp));
            }
            return;
        }
        catch (e) {
            return;
        }
    }
    get meta() {
        return this.proto.meta;
    }
    get version() {
        // https://rfc.vac.dev/spec/14/
        // > If omitted, the value SHOULD be interpreted as version 0.
        return this.proto.version ?? Version;
    }
    get rateLimitProof() {
        return this.proto.rateLimitProof;
    }
}
let Encoder$1 = class Encoder {
    contentTopic;
    ephemeral;
    pubsubTopic;
    metaSetter;
    constructor(contentTopic, ephemeral = false, pubsubTopic, metaSetter) {
        this.contentTopic = contentTopic;
        this.ephemeral = ephemeral;
        this.pubsubTopic = pubsubTopic;
        this.metaSetter = metaSetter;
        if (!contentTopic || contentTopic === "") {
            throw new Error("Content topic must be specified");
        }
    }
    async toWire(message$1) {
        return WakuMessage$4.encode(await this.toProtoObj(message$1));
    }
    async toProtoObj(message) {
        const timestamp = message.timestamp ?? new Date();
        const protoMessage = {
            payload: message.payload,
            version: Version,
            contentTopic: this.contentTopic,
            timestamp: BigInt(timestamp.valueOf()) * OneMillion,
            meta: undefined,
            rateLimitProof: message.rateLimitProof,
            ephemeral: this.ephemeral
        };
        if (this.metaSetter) {
            const meta = this.metaSetter(protoMessage);
            return { ...protoMessage, meta };
        }
        return protoMessage;
    }
};
/**
 * Creates an encoder that encode messages without Waku level encryption or signature.
 *
 * An encoder is used to encode messages in the [14/WAKU2-MESSAGE](https://rfc.vac.dev/spec/14/)
 * format to be sent over the Waku network. The resulting encoder can then be
 * pass to { @link @waku/interfaces!ISender.send } to automatically encode outgoing
 * messages.
 */
function createEncoder({ pubsubTopic, pubsubTopicShardInfo, contentTopic, ephemeral, metaSetter }) {
    return new Encoder$1(contentTopic, ephemeral, determinePubsubTopic(contentTopic, pubsubTopic ?? pubsubTopicShardInfo), metaSetter);
}
let Decoder$1 = class Decoder {
    pubsubTopic;
    contentTopic;
    constructor(pubsubTopic, contentTopic) {
        this.pubsubTopic = pubsubTopic;
        this.contentTopic = contentTopic;
        if (!contentTopic || contentTopic === "") {
            throw new Error("Content topic must be specified");
        }
    }
    fromWireToProtoObj(bytes) {
        const protoMessage = WakuMessage$4.decode(bytes);
        return Promise.resolve({
            payload: protoMessage.payload,
            contentTopic: protoMessage.contentTopic,
            version: protoMessage.version ?? undefined,
            timestamp: protoMessage.timestamp ?? undefined,
            meta: protoMessage.meta ?? undefined,
            rateLimitProof: protoMessage.rateLimitProof ?? undefined,
            ephemeral: protoMessage.ephemeral ?? false
        });
    }
    async fromProtoObj(pubsubTopic, proto) {
        // https://rfc.vac.dev/spec/14/
        // > If omitted, the value SHOULD be interpreted as version 0.
        if (proto.version ?? 0 !== Version) {
            log$v.error("Failed to decode due to incorrect version, expected:", Version, ", actual:", proto.version);
            return Promise.resolve(undefined);
        }
        return new DecodedMessage(pubsubTopic, proto);
    }
};
/**
 * Creates a decoder that decode messages without Waku level encryption.
 *
 * A decoder is used to decode messages from the [14/WAKU2-MESSAGE](https://rfc.vac.dev/spec/14/)
 * format when received from the Waku network. The resulting decoder can then be
 * pass to { @link @waku/interfaces!IReceiver.subscribe } to automatically decode incoming
 * messages.
 *
 * @param contentTopic The resulting decoder will only decode messages with this content topic.
 */
function createDecoder(contentTopic, pubsubTopicShardInfo) {
    return new Decoder$1(determinePubsubTopic(contentTopic, pubsubTopicShardInfo), contentTopic);
}

var version_0 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    DecodedMessage: DecodedMessage,
    Decoder: Decoder$1,
    Encoder: Encoder$1,
    Version: Version,
    createDecoder: createDecoder,
    createEncoder: createEncoder,
    proto: message
});

var index$4 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    version_0: version_0
});

/**
 * @packageDocumentation
 *
 * For when you need a one-liner to collect iterable values.
 *
 * @example
 *
 * ```javascript
 * import all from 'it-all'
 *
 * // This can also be an iterator, etc
 * const values = function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const arr = all(values)
 *
 * console.info(arr) // 0, 1, 2, 3, 4
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const arr = await all(values())
 *
 * console.info(arr) // 0, 1, 2, 3, 4
 * ```
 */
function isAsyncIterable$9(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function all$1(source) {
    if (isAsyncIterable$9(source)) {
        return (async () => {
            const arr = [];
            for await (const entry of source) {
                arr.push(entry);
            }
            return arr;
        })();
    }
    const arr = [];
    for (const entry of source) {
        arr.push(entry);
    }
    return arr;
}

/**
 * To guarantee Uint8Array semantics, convert nodejs Buffers
 * into vanilla Uint8Arrays
 */
function asUint8Array(buf) {
    return buf;
}

/**
 * Returns a new Uint8Array created by concatenating the passed Uint8Arrays
 */
function concat(arrays, length) {
    if (length == null) {
        length = arrays.reduce((acc, curr) => acc + curr.length, 0);
    }
    const output = allocUnsafe(length);
    let offset = 0;
    for (const arr of arrays) {
        output.set(arr, offset);
        offset += arr.length;
    }
    return asUint8Array(output);
}

/**
 * Returns true if the two passed Uint8Arrays have the same content
 */
function equals(a, b) {
    if (a === b) {
        return true;
    }
    if (a.byteLength !== b.byteLength) {
        return false;
    }
    for (let i = 0; i < a.byteLength; i++) {
        if (a[i] !== b[i]) {
            return false;
        }
    }
    return true;
}

/**
 * @packageDocumentation
 *
 * A class that lets you do operations over a list of Uint8Arrays without
 * copying them.
 *
 * ```js
 * import { Uint8ArrayList } from 'uint8arraylist'
 *
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.subarray()
 * // -> Uint8Array([0, 1, 2, 3, 4, 5])
 *
 * list.consume(3)
 * list.subarray()
 * // -> Uint8Array([3, 4, 5])
 *
 * // you can also iterate over the list
 * for (const buf of list) {
 *   // ..do something with `buf`
 * }
 *
 * list.subarray(0, 1)
 * // -> Uint8Array([0])
 * ```
 *
 * ## Converting Uint8ArrayLists to Uint8Arrays
 *
 * There are two ways to turn a `Uint8ArrayList` into a `Uint8Array` - `.slice` and `.subarray` and one way to turn a `Uint8ArrayList` into a `Uint8ArrayList` with different contents - `.sublist`.
 *
 * ### slice
 *
 * Slice follows the same semantics as [Uint8Array.slice](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/slice) in that it creates a new `Uint8Array` and copies bytes into it using an optional offset & length.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.slice(0, 1)
 * // -> Uint8Array([0])
 * ```
 *
 * ### subarray
 *
 * Subarray attempts to follow the same semantics as [Uint8Array.subarray](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/subarray) with one important different - this is a no-copy operation, unless the requested bytes span two internal buffers in which case it is a copy operation.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.subarray(0, 1)
 * // -> Uint8Array([0]) - no-copy
 *
 * list.subarray(2, 5)
 * // -> Uint8Array([2, 3, 4]) - copy
 * ```
 *
 * ### sublist
 *
 * Sublist creates and returns a new `Uint8ArrayList` that shares the underlying buffers with the original so is always a no-copy operation.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.sublist(0, 1)
 * // -> Uint8ArrayList([0]) - no-copy
 *
 * list.sublist(2, 5)
 * // -> Uint8ArrayList([2], [3, 4]) - no-copy
 * ```
 *
 * ## Inspiration
 *
 * Borrows liberally from [bl](https://www.npmjs.com/package/bl) but only uses native JS types.
 */
const symbol$1 = Symbol.for('@achingbrain/uint8arraylist');
function findBufAndOffset(bufs, index) {
    if (index == null || index < 0) {
        throw new RangeError('index is out of bounds');
    }
    let offset = 0;
    for (const buf of bufs) {
        const bufEnd = offset + buf.byteLength;
        if (index < bufEnd) {
            return {
                buf,
                index: index - offset
            };
        }
        offset = bufEnd;
    }
    throw new RangeError('index is out of bounds');
}
/**
 * Check if object is a CID instance
 *
 * @example
 *
 * ```js
 * import { isUint8ArrayList, Uint8ArrayList } from 'uint8arraylist'
 *
 * isUint8ArrayList(true) // false
 * isUint8ArrayList([]) // false
 * isUint8ArrayList(new Uint8ArrayList()) // true
 * ```
 */
function isUint8ArrayList(value) {
    return Boolean(value?.[symbol$1]);
}
class Uint8ArrayList {
    bufs;
    length;
    [symbol$1] = true;
    constructor(...data) {
        this.bufs = [];
        this.length = 0;
        if (data.length > 0) {
            this.appendAll(data);
        }
    }
    *[Symbol.iterator]() {
        yield* this.bufs;
    }
    get byteLength() {
        return this.length;
    }
    /**
     * Add one or more `bufs` to the end of this Uint8ArrayList
     */
    append(...bufs) {
        this.appendAll(bufs);
    }
    /**
     * Add all `bufs` to the end of this Uint8ArrayList
     */
    appendAll(bufs) {
        let length = 0;
        for (const buf of bufs) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.push(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.push(...buf.bufs);
            }
            else {
                throw new Error('Could not append value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Add one or more `bufs` to the start of this Uint8ArrayList
     */
    prepend(...bufs) {
        this.prependAll(bufs);
    }
    /**
     * Add all `bufs` to the start of this Uint8ArrayList
     */
    prependAll(bufs) {
        let length = 0;
        for (const buf of bufs.reverse()) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.unshift(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.unshift(...buf.bufs);
            }
            else {
                throw new Error('Could not prepend value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Read the value at `index`
     */
    get(index) {
        const res = findBufAndOffset(this.bufs, index);
        return res.buf[res.index];
    }
    /**
     * Set the value at `index` to `value`
     */
    set(index, value) {
        const res = findBufAndOffset(this.bufs, index);
        res.buf[res.index] = value;
    }
    /**
     * Copy bytes from `buf` to the index specified by `offset`
     */
    write(buf, offset = 0) {
        if (buf instanceof Uint8Array) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf[i]);
            }
        }
        else if (isUint8ArrayList(buf)) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf.get(i));
            }
        }
        else {
            throw new Error('Could not write value, must be an Uint8Array or a Uint8ArrayList');
        }
    }
    /**
     * Remove bytes from the front of the pool
     */
    consume(bytes) {
        // first, normalize the argument, in accordance with how Buffer does it
        bytes = Math.trunc(bytes);
        // do nothing if not a positive number
        if (Number.isNaN(bytes) || bytes <= 0) {
            return;
        }
        // if consuming all bytes, skip iterating
        if (bytes === this.byteLength) {
            this.bufs = [];
            this.length = 0;
            return;
        }
        while (this.bufs.length > 0) {
            if (bytes >= this.bufs[0].byteLength) {
                bytes -= this.bufs[0].byteLength;
                this.length -= this.bufs[0].byteLength;
                this.bufs.shift();
            }
            else {
                this.bufs[0] = this.bufs[0].subarray(bytes);
                this.length -= bytes;
                break;
            }
        }
    }
    /**
     * Extracts a section of an array and returns a new array.
     *
     * This is a copy operation as it is with Uint8Arrays and Arrays
     * - note this is different to the behaviour of Node Buffers.
     */
    slice(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        return concat(bufs, length);
    }
    /**
     * Returns a alloc from the given start and end element index.
     *
     * In the best case where the data extracted comes from a single Uint8Array
     * internally this is a no-copy operation otherwise it is a copy operation.
     */
    subarray(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        if (bufs.length === 1) {
            return bufs[0];
        }
        return concat(bufs, length);
    }
    /**
     * Returns a allocList from the given start and end element index.
     *
     * This is a no-copy operation.
     */
    sublist(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        const list = new Uint8ArrayList();
        list.length = length;
        // don't loop, just set the bufs
        list.bufs = [...bufs];
        return list;
    }
    _subList(beginInclusive, endExclusive) {
        beginInclusive = beginInclusive ?? 0;
        endExclusive = endExclusive ?? this.length;
        if (beginInclusive < 0) {
            beginInclusive = this.length + beginInclusive;
        }
        if (endExclusive < 0) {
            endExclusive = this.length + endExclusive;
        }
        if (beginInclusive < 0 || endExclusive > this.length) {
            throw new RangeError('index is out of bounds');
        }
        if (beginInclusive === endExclusive) {
            return { bufs: [], length: 0 };
        }
        if (beginInclusive === 0 && endExclusive === this.length) {
            return { bufs: this.bufs, length: this.length };
        }
        const bufs = [];
        let offset = 0;
        for (let i = 0; i < this.bufs.length; i++) {
            const buf = this.bufs[i];
            const bufStart = offset;
            const bufEnd = bufStart + buf.byteLength;
            // for next loop
            offset = bufEnd;
            if (beginInclusive >= bufEnd) {
                // start after this buf
                continue;
            }
            const sliceStartInBuf = beginInclusive >= bufStart && beginInclusive < bufEnd;
            const sliceEndsInBuf = endExclusive > bufStart && endExclusive <= bufEnd;
            if (sliceStartInBuf && sliceEndsInBuf) {
                // slice is wholly contained within this buffer
                if (beginInclusive === bufStart && endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                const start = beginInclusive - bufStart;
                bufs.push(buf.subarray(start, start + (endExclusive - beginInclusive)));
                break;
            }
            if (sliceStartInBuf) {
                // slice starts in this buffer
                if (beginInclusive === 0) {
                    // requested whole buffer
                    bufs.push(buf);
                    continue;
                }
                // requested part of buffer
                bufs.push(buf.subarray(beginInclusive - bufStart));
                continue;
            }
            if (sliceEndsInBuf) {
                if (endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                bufs.push(buf.subarray(0, endExclusive - bufStart));
                break;
            }
            // slice started before this buffer and ends after it
            bufs.push(buf);
        }
        return { bufs, length: endExclusive - beginInclusive };
    }
    indexOf(search, offset = 0) {
        if (!isUint8ArrayList(search) && !(search instanceof Uint8Array)) {
            throw new TypeError('The "value" argument must be a Uint8ArrayList or Uint8Array');
        }
        const needle = search instanceof Uint8Array ? search : search.subarray();
        offset = Number(offset ?? 0);
        if (isNaN(offset)) {
            offset = 0;
        }
        if (offset < 0) {
            offset = this.length + offset;
        }
        if (offset < 0) {
            offset = 0;
        }
        if (search.length === 0) {
            return offset > this.length ? this.length : offset;
        }
        // https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string-search_algorithm
        const M = needle.byteLength;
        if (M === 0) {
            throw new TypeError('search must be at least 1 byte long');
        }
        // radix
        const radix = 256;
        const rightmostPositions = new Int32Array(radix);
        // position of the rightmost occurrence of the byte c in the pattern
        for (let c = 0; c < radix; c++) {
            // -1 for bytes not in pattern
            rightmostPositions[c] = -1;
        }
        for (let j = 0; j < M; j++) {
            // rightmost position for bytes in pattern
            rightmostPositions[needle[j]] = j;
        }
        // Return offset of first match, -1 if no match
        const right = rightmostPositions;
        const lastIndex = this.byteLength - needle.byteLength;
        const lastPatIndex = needle.byteLength - 1;
        let skip;
        for (let i = offset; i <= lastIndex; i += skip) {
            skip = 0;
            for (let j = lastPatIndex; j >= 0; j--) {
                const char = this.get(i + j);
                if (needle[j] !== char) {
                    skip = Math.max(1, j - right[char]);
                    break;
                }
            }
            if (skip === 0) {
                return i;
            }
        }
        return -1;
    }
    getInt8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt8(0);
    }
    setInt8(byteOffset, value) {
        const buf = allocUnsafe(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt8(0, value);
        this.write(buf, byteOffset);
    }
    getInt16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt16(0, littleEndian);
    }
    setInt16(byteOffset, value, littleEndian) {
        const buf = alloc$1(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getInt32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt32(0, littleEndian);
    }
    setInt32(byteOffset, value, littleEndian) {
        const buf = alloc$1(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigInt64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigInt64(0, littleEndian);
    }
    setBigInt64(byteOffset, value, littleEndian) {
        const buf = alloc$1(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigInt64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint8(0);
    }
    setUint8(byteOffset, value) {
        const buf = allocUnsafe(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint8(0, value);
        this.write(buf, byteOffset);
    }
    getUint16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint16(0, littleEndian);
    }
    setUint16(byteOffset, value, littleEndian) {
        const buf = alloc$1(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint32(0, littleEndian);
    }
    setUint32(byteOffset, value, littleEndian) {
        const buf = alloc$1(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigUint64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigUint64(0, littleEndian);
    }
    setBigUint64(byteOffset, value, littleEndian) {
        const buf = alloc$1(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigUint64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat32(0, littleEndian);
    }
    setFloat32(byteOffset, value, littleEndian) {
        const buf = alloc$1(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat64(0, littleEndian);
    }
    setFloat64(byteOffset, value, littleEndian) {
        const buf = alloc$1(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    equals(other) {
        if (other == null) {
            return false;
        }
        if (!(other instanceof Uint8ArrayList)) {
            return false;
        }
        if (other.bufs.length !== this.bufs.length) {
            return false;
        }
        for (let i = 0; i < this.bufs.length; i++) {
            if (!equals(this.bufs[i], other.bufs[i])) {
                return false;
            }
        }
        return true;
    }
    /**
     * Create a Uint8ArrayList from a pre-existing list of Uint8Arrays.  Use this
     * method if you know the total size of all the Uint8Arrays ahead of time.
     */
    static fromUint8Arrays(bufs, length) {
        const list = new Uint8ArrayList();
        list.bufs = bufs;
        if (length == null) {
            length = bufs.reduce((acc, curr) => acc + curr.byteLength, 0);
        }
        list.length = length;
        return list;
    }
}
/*
function indexOf (needle: Uint8Array, haystack: Uint8Array, offset = 0) {
  for (let i = offset; i < haystack.byteLength; i++) {
    for (let j = 0; j < needle.length; j++) {
      if (haystack[i + j] !== needle[j]) {
        break
      }

      if (j === needle.byteLength -1) {
        return i
      }
    }

    if (haystack.byteLength - i < needle.byteLength) {
      break
    }
  }

  return -1
}
*/

function isAsyncIterable$8(thing) {
    return thing[Symbol.asyncIterator] != null;
}

const defaultEncoder$1 = (length) => {
    const lengthLength = encodingLength$1(length);
    const lengthBuf = allocUnsafe(lengthLength);
    encode$8(length, lengthBuf);
    defaultEncoder$1.bytes = lengthLength;
    return lengthBuf;
};
defaultEncoder$1.bytes = 0;
function encode$3(source, options) {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder$1;
    function* maybeYield(chunk) {
        // length + data
        const length = encodeLength(chunk.byteLength);
        // yield only Uint8Arrays
        if (length instanceof Uint8Array) {
            yield length;
        }
        else {
            yield* length;
        }
        // yield only Uint8Arrays
        if (chunk instanceof Uint8Array) {
            yield chunk;
        }
        else {
            yield* chunk;
        }
    }
    if (isAsyncIterable$8(source)) {
        return (async function* () {
            for await (const chunk of source) {
                yield* maybeYield(chunk);
            }
        })();
    }
    return (function* () {
        for (const chunk of source) {
            yield* maybeYield(chunk);
        }
    })();
}
encode$3.single = (chunk, options) => {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder$1;
    return new Uint8ArrayList(encodeLength(chunk.byteLength), chunk);
};

/**
 * The reported length of the next data message was not a positive integer
 */
let InvalidMessageLengthError$2 = class InvalidMessageLengthError extends Error {
    name = 'InvalidMessageLengthError';
    code = 'ERR_INVALID_MSG_LENGTH';
};
/**
 * The reported length of the next data message was larger than the configured
 * max allowable value
 */
let InvalidDataLengthError$3 = class InvalidDataLengthError extends Error {
    name = 'InvalidDataLengthError';
    code = 'ERR_MSG_DATA_TOO_LONG';
};
/**
 * The varint used to specify the length of the next data message contained more
 * bytes than the configured max allowable value
 */
let InvalidDataLengthLengthError$2 = class InvalidDataLengthLengthError extends Error {
    name = 'InvalidDataLengthLengthError';
    code = 'ERR_MSG_LENGTH_TOO_LONG';
};
/**
 * The incoming stream ended before the expected number of bytes were read
 */
let UnexpectedEOFError$2 = class UnexpectedEOFError extends Error {
    name = 'UnexpectedEOFError';
    code = 'ERR_UNEXPECTED_EOF';
};

/* eslint max-depth: ["error", 6] */
// Maximum length of the length section of the message
const MAX_LENGTH_LENGTH$1 = 8; // Varint.encode(Number.MAX_SAFE_INTEGER).length
// Maximum length of the data section of the message
const MAX_DATA_LENGTH$2 = 1024 * 1024 * 4;
var ReadMode$2;
(function (ReadMode) {
    ReadMode[ReadMode["LENGTH"] = 0] = "LENGTH";
    ReadMode[ReadMode["DATA"] = 1] = "DATA";
})(ReadMode$2 || (ReadMode$2 = {}));
const defaultDecoder$1 = (buf) => {
    const length = decode$8(buf);
    defaultDecoder$1.bytes = encodingLength$1(length);
    return length;
};
defaultDecoder$1.bytes = 0;
function decode$2(source, options) {
    const buffer = new Uint8ArrayList();
    let mode = ReadMode$2.LENGTH;
    let dataLength = -1;
    const lengthDecoder = options?.lengthDecoder ?? defaultDecoder$1;
    const maxLengthLength = options?.maxLengthLength ?? MAX_LENGTH_LENGTH$1;
    const maxDataLength = options?.maxDataLength ?? MAX_DATA_LENGTH$2;
    function* maybeYield() {
        while (buffer.byteLength > 0) {
            if (mode === ReadMode$2.LENGTH) {
                // read length, ignore errors for short reads
                try {
                    dataLength = lengthDecoder(buffer);
                    if (dataLength < 0) {
                        throw new InvalidMessageLengthError$2('Invalid message length');
                    }
                    if (dataLength > maxDataLength) {
                        throw new InvalidDataLengthError$3('Message length too long');
                    }
                    const dataLengthLength = lengthDecoder.bytes;
                    buffer.consume(dataLengthLength);
                    if (options?.onLength != null) {
                        options.onLength(dataLength);
                    }
                    mode = ReadMode$2.DATA;
                }
                catch (err) {
                    if (err instanceof RangeError) {
                        if (buffer.byteLength > maxLengthLength) {
                            throw new InvalidDataLengthLengthError$2('Message length length too long');
                        }
                        break;
                    }
                    throw err;
                }
            }
            if (mode === ReadMode$2.DATA) {
                if (buffer.byteLength < dataLength) {
                    // not enough data, wait for more
                    break;
                }
                const data = buffer.sublist(0, dataLength);
                buffer.consume(dataLength);
                if (options?.onData != null) {
                    options.onData(data);
                }
                yield data;
                mode = ReadMode$2.LENGTH;
            }
        }
    }
    if (isAsyncIterable$8(source)) {
        return (async function* () {
            for await (const buf of source) {
                buffer.append(buf);
                yield* maybeYield();
            }
            if (buffer.byteLength > 0) {
                throw new UnexpectedEOFError$2('Unexpected end of input');
            }
        })();
    }
    return (function* () {
        for (const buf of source) {
            buffer.append(buf);
            yield* maybeYield();
        }
        if (buffer.byteLength > 0) {
            throw new UnexpectedEOFError$2('Unexpected end of input');
        }
    })();
}
decode$2.fromReader = (reader, options) => {
    let byteLength = 1; // Read single byte chunks until the length is known
    const varByteSource = (async function* () {
        while (true) {
            try {
                const { done, value } = await reader.next(byteLength);
                if (done === true) {
                    return;
                }
                if (value != null) {
                    yield value;
                }
            }
            catch (err) {
                if (err.code === 'ERR_UNDER_READ') {
                    return { done: true, value: null };
                }
                throw err;
            }
            finally {
                // Reset the byteLength so we continue to check for varints
                byteLength = 1;
            }
        }
    }());
    /**
     * Once the length has been parsed, read chunk for that length
     */
    const onLength = (l) => { byteLength = l; };
    return decode$2(varByteSource, {
        ...(options ?? {}),
        onLength
    });
};

function pDefer() {
	const deferred = {};

	deferred.promise = new Promise((resolve, reject) => {
		deferred.resolve = resolve;
		deferred.reject = reject;
	});

	return deferred;
}

// ported from https://www.npmjs.com/package/fast-fifo
class FixedFIFO {
    buffer;
    mask;
    top;
    btm;
    next;
    constructor(hwm) {
        if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) {
            throw new Error('Max size for a FixedFIFO should be a power of two');
        }
        this.buffer = new Array(hwm);
        this.mask = hwm - 1;
        this.top = 0;
        this.btm = 0;
        this.next = null;
    }
    push(data) {
        if (this.buffer[this.top] !== undefined) {
            return false;
        }
        this.buffer[this.top] = data;
        this.top = (this.top + 1) & this.mask;
        return true;
    }
    shift() {
        const last = this.buffer[this.btm];
        if (last === undefined) {
            return undefined;
        }
        this.buffer[this.btm] = undefined;
        this.btm = (this.btm + 1) & this.mask;
        return last;
    }
    isEmpty() {
        return this.buffer[this.btm] === undefined;
    }
}
class FIFO {
    size;
    hwm;
    head;
    tail;
    constructor(options = {}) {
        this.hwm = options.splitLimit ?? 16;
        this.head = new FixedFIFO(this.hwm);
        this.tail = this.head;
        this.size = 0;
    }
    calculateSize(obj) {
        if (obj?.byteLength != null) {
            return obj.byteLength;
        }
        return 1;
    }
    push(val) {
        if (val?.value != null) {
            this.size += this.calculateSize(val.value);
        }
        if (!this.head.push(val)) {
            const prev = this.head;
            this.head = prev.next = new FixedFIFO(2 * this.head.buffer.length);
            this.head.push(val);
        }
    }
    shift() {
        let val = this.tail.shift();
        if (val === undefined && (this.tail.next != null)) {
            const next = this.tail.next;
            this.tail.next = null;
            this.tail = next;
            val = this.tail.shift();
        }
        if (val?.value != null) {
            this.size -= this.calculateSize(val.value);
        }
        return val;
    }
    isEmpty() {
        return this.head.isEmpty();
    }
}

/**
 * @packageDocumentation
 *
 * An iterable that you can push values into.
 *
 * @example
 *
 * ```js
 * import { pushable } from 'it-pushable'
 *
 * const source = pushable()
 *
 * setTimeout(() => source.push('hello'), 100)
 * setTimeout(() => source.push('world'), 200)
 * setTimeout(() => source.end(), 300)
 *
 * const start = Date.now()
 *
 * for await (const value of source) {
 *   console.log(`got "${value}" after ${Date.now() - start}ms`)
 * }
 * console.log(`done after ${Date.now() - start}ms`)
 *
 * // Output:
 * // got "hello" after 105ms
 * // got "world" after 207ms
 * // done after 309ms
 * ```
 *
 * @example
 *
 * ```js
 * import { pushableV } from 'it-pushable'
 * import all from 'it-all'
 *
 * const source = pushableV()
 *
 * source.push(1)
 * source.push(2)
 * source.push(3)
 * source.end()
 *
 * console.info(await all(source))
 *
 * // Output:
 * // [ [1, 2, 3] ]
 * ```
 */
let AbortError$6 = class AbortError extends Error {
    type;
    code;
    constructor(message, code) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.code = code ?? 'ABORT_ERR';
    }
};
function pushable(options = {}) {
    const getNext = (buffer) => {
        const next = buffer.shift();
        if (next == null) {
            return { done: true };
        }
        if (next.error != null) {
            throw next.error;
        }
        return {
            done: next.done === true,
            // @ts-expect-error if done is false, value will be present
            value: next.value
        };
    };
    return _pushable(getNext, options);
}
function _pushable(getNext, options) {
    options = options ?? {};
    let onEnd = options.onEnd;
    let buffer = new FIFO();
    let pushable;
    let onNext;
    let ended;
    let drain = pDefer();
    const waitNext = async () => {
        try {
            if (!buffer.isEmpty()) {
                return getNext(buffer);
            }
            if (ended) {
                return { done: true };
            }
            return await new Promise((resolve, reject) => {
                onNext = (next) => {
                    onNext = null;
                    buffer.push(next);
                    try {
                        resolve(getNext(buffer));
                    }
                    catch (err) {
                        reject(err);
                    }
                    return pushable;
                };
            });
        }
        finally {
            if (buffer.isEmpty()) {
                // settle promise in the microtask queue to give consumers a chance to
                // await after calling .push
                queueMicrotask(() => {
                    drain.resolve();
                    drain = pDefer();
                });
            }
        }
    };
    const bufferNext = (next) => {
        if (onNext != null) {
            return onNext(next);
        }
        buffer.push(next);
        return pushable;
    };
    const bufferError = (err) => {
        buffer = new FIFO();
        if (onNext != null) {
            return onNext({ error: err });
        }
        buffer.push({ error: err });
        return pushable;
    };
    const push = (value) => {
        if (ended) {
            return pushable;
        }
        // @ts-expect-error `byteLength` is not declared on PushType
        if (options?.objectMode !== true && value?.byteLength == null) {
            throw new Error('objectMode was not true but tried to push non-Uint8Array value');
        }
        return bufferNext({ done: false, value });
    };
    const end = (err) => {
        if (ended)
            return pushable;
        ended = true;
        return (err != null) ? bufferError(err) : bufferNext({ done: true });
    };
    const _return = () => {
        buffer = new FIFO();
        end();
        return { done: true };
    };
    const _throw = (err) => {
        end(err);
        return { done: true };
    };
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next: waitNext,
        return: _return,
        throw: _throw,
        push,
        end,
        get readableLength() {
            return buffer.size;
        },
        onEmpty: async (options) => {
            const signal = options?.signal;
            signal?.throwIfAborted();
            if (buffer.isEmpty()) {
                return;
            }
            let cancel;
            let listener;
            if (signal != null) {
                cancel = new Promise((resolve, reject) => {
                    listener = () => {
                        reject(new AbortError$6());
                    };
                    signal.addEventListener('abort', listener);
                });
            }
            try {
                await Promise.race([
                    drain.promise,
                    cancel
                ]);
            }
            finally {
                if (listener != null && signal != null) {
                    signal?.removeEventListener('abort', listener);
                }
            }
        }
    };
    if (onEnd == null) {
        return pushable;
    }
    const _pushable = pushable;
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next() {
            return _pushable.next();
        },
        throw(err) {
            _pushable.throw(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return { done: true };
        },
        return() {
            _pushable.return();
            if (onEnd != null) {
                onEnd();
                onEnd = undefined;
            }
            return { done: true };
        },
        push,
        end(err) {
            _pushable.end(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return pushable;
        },
        get readableLength() {
            return _pushable.readableLength;
        },
        onEmpty: (opts) => {
            return _pushable.onEmpty(opts);
        }
    };
    return pushable;
}

/**
 * An abort error class that extends error
 */
let AbortError$5 = class AbortError extends Error {
    type;
    code;
    constructor(message, code, name) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.name = name ?? 'AbortError';
        this.code = code ?? 'ABORT_ERR';
    }
};
/**
 * Race a promise against an abort signal
 */
async function raceSignal(promise, signal, opts) {
    if (signal == null) {
        return promise;
    }
    if (signal.aborted) {
        // the passed promise may yet resolve or reject but the use has signalled
        // they are no longer interested so smother the error
        promise.catch(() => { });
        return Promise.reject(new AbortError$5(opts?.errorMessage, opts?.errorCode, opts?.errorName));
    }
    let listener;
    // create the error here so we have more context in the stack trace
    const error = new AbortError$5(opts?.errorMessage, opts?.errorCode, opts?.errorName);
    try {
        return await Promise.race([
            promise,
            new Promise((resolve, reject) => {
                listener = () => {
                    reject(error);
                };
                signal.addEventListener('abort', listener);
            })
        ]);
    }
    finally {
        if (listener != null) {
            signal.removeEventListener('abort', listener);
        }
    }
}

/**
 * @packageDocumentation
 *
 * A pushable async generator that waits until the current value is consumed
 * before allowing a new value to be pushed.
 *
 * Useful for when you don't want to keep memory usage under control and/or
 * allow a downstream consumer to dictate how fast data flows through a pipe,
 * but you want to be able to apply a transform to that data.
 *
 * @example
 *
 * ```typescript
 * import { queuelessPushable } from 'it-queueless-pushable'
 *
 * const pushable = queuelessPushable<string>()
 *
 * // run asynchronously
 * Promise.resolve().then(async () => {
 *   // push a value - the returned promise will not resolve until the value is
 *   // read from the pushable
 *   await pushable.push('hello')
 * })
 *
 * // read a value
 * const result = await pushable.next()
 * console.info(result) // { done: false, value: 'hello' }
 * ```
 */
class QueuelessPushable {
    readNext;
    haveNext;
    ended;
    nextResult;
    error;
    constructor() {
        this.ended = false;
        this.readNext = pDefer();
        this.haveNext = pDefer();
    }
    [Symbol.asyncIterator]() {
        return this;
    }
    async next() {
        if (this.nextResult == null) {
            // wait for the supplier to push a value
            await this.haveNext.promise;
        }
        if (this.nextResult == null) {
            throw new Error('HaveNext promise resolved but nextResult was undefined');
        }
        const nextResult = this.nextResult;
        this.nextResult = undefined;
        // signal to the supplier that we read the value
        this.readNext.resolve();
        this.readNext = pDefer();
        return nextResult;
    }
    async throw(err) {
        this.ended = true;
        this.error = err;
        if (err != null) {
            // this can cause unhandled promise rejections if nothing is awaiting the
            // next value so attach a dummy catch listener to the promise
            this.haveNext.promise.catch(() => { });
            this.haveNext.reject(err);
        }
        const result = {
            done: true,
            value: undefined
        };
        return result;
    }
    async return() {
        const result = {
            done: true,
            value: undefined
        };
        this.ended = true;
        this.nextResult = result;
        // let the consumer know we have a new value
        this.haveNext.resolve();
        return result;
    }
    async push(value, options) {
        await this._push(value, options);
    }
    async end(err, options) {
        if (err != null) {
            await this.throw(err);
        }
        else {
            // abortable return
            await this._push(undefined, options);
        }
    }
    async _push(value, options) {
        if (value != null && this.ended) {
            throw this.error ?? new Error('Cannot push value onto an ended pushable');
        }
        // wait for all values to be read
        while (this.nextResult != null) {
            await this.readNext.promise;
        }
        if (value != null) {
            this.nextResult = { done: false, value };
        }
        else {
            this.ended = true;
            this.nextResult = { done: true, value: undefined };
        }
        // let the consumer know we have a new value
        this.haveNext.resolve();
        this.haveNext = pDefer();
        // wait for the consumer to have finished processing the value and requested
        // the next one or for the passed signal to abort the waiting
        await raceSignal(this.readNext.promise, options?.signal, options);
    }
}
function queuelessPushable() {
    return new QueuelessPushable();
}

/**
 * @packageDocumentation
 *
 * Merge several (async)iterables into one, yield values as they arrive.
 *
 * Nb. sources are iterated over in parallel so the order of emitted items is not guaranteed.
 *
 * @example
 *
 * ```javascript
 * import merge from 'it-merge'
 * import all from 'it-all'
 *
 * // This can also be an iterator, generator, etc
 * const values1 = [0, 1, 2, 3, 4]
 * const values2 = [5, 6, 7, 8, 9]
 *
 * const arr = all(merge(values1, values2))
 *
 * console.info(arr) // 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import merge from 'it-merge'
 * import all from 'it-all'
 *
 * // This can also be an iterator, async iterator, generator, etc
 * const values1 = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 * const values2 = async function * () {
 *   yield * [5, 6, 7, 8, 9]
 * }
 *
 * const arr = await all(merge(values1(), values2()))
 *
 * console.info(arr) // 0, 1, 5, 6, 2, 3, 4, 7, 8, 9  <- nb. order is not guaranteed
 * ```
 */
function isAsyncIterable$7(thing) {
    return thing[Symbol.asyncIterator] != null;
}
async function addAllToPushable(sources, output, signal) {
    try {
        await Promise.all(sources.map(async (source) => {
            for await (const item of source) {
                await output.push(item, {
                    signal
                });
                signal.throwIfAborted();
            }
        }));
        await output.end(undefined, {
            signal
        });
    }
    catch (err) {
        await output.end(err, {
            signal
        })
            .catch(() => { });
    }
}
async function* mergeSources(sources) {
    const controller = new AbortController();
    const output = queuelessPushable();
    addAllToPushable(sources, output, controller.signal)
        .catch(() => { });
    try {
        yield* output;
    }
    finally {
        controller.abort();
    }
}
function* mergeSyncSources(syncSources) {
    for (const source of syncSources) {
        yield* source;
    }
}
function merge$1(...sources) {
    const syncSources = [];
    for (const source of sources) {
        if (!isAsyncIterable$7(source)) {
            syncSources.push(source);
        }
    }
    if (syncSources.length === sources.length) {
        // all sources are synchronous
        return mergeSyncSources(syncSources);
    }
    return mergeSources(sources);
}

function pipe(first, ...rest) {
    if (first == null) {
        throw new Error('Empty pipeline');
    }
    // Duplex at start: wrap in function and return duplex source
    if (isDuplex(first)) {
        const duplex = first;
        first = () => duplex.source;
        // Iterable at start: wrap in function
    }
    else if (isIterable(first) || isAsyncIterable$6(first)) {
        const source = first;
        first = () => source;
    }
    const fns = [first, ...rest];
    if (fns.length > 1) {
        // Duplex at end: use duplex sink
        if (isDuplex(fns[fns.length - 1])) {
            fns[fns.length - 1] = fns[fns.length - 1].sink;
        }
    }
    if (fns.length > 2) {
        // Duplex in the middle, consume source with duplex sink and return duplex source
        for (let i = 1; i < fns.length - 1; i++) {
            if (isDuplex(fns[i])) {
                fns[i] = duplexPipelineFn(fns[i]);
            }
        }
    }
    return rawPipe(...fns);
}
const rawPipe = (...fns) => {
    let res;
    while (fns.length > 0) {
        res = fns.shift()(res);
    }
    return res;
};
const isAsyncIterable$6 = (obj) => {
    return obj?.[Symbol.asyncIterator] != null;
};
const isIterable = (obj) => {
    return obj?.[Symbol.iterator] != null;
};
const isDuplex = (obj) => {
    if (obj == null) {
        return false;
    }
    return obj.sink != null && obj.source != null;
};
const duplexPipelineFn = (duplex) => {
    return (source) => {
        const p = duplex.sink(source);
        if (p?.then != null) {
            const stream = pushable({
                objectMode: true
            });
            p.then(() => {
                stream.end();
            }, (err) => {
                stream.end(err);
            });
            let sourceWrap;
            const source = duplex.source;
            if (isAsyncIterable$6(source)) {
                sourceWrap = async function* () {
                    yield* source;
                    stream.end();
                };
            }
            else if (isIterable(source)) {
                sourceWrap = function* () {
                    yield* source;
                    stream.end();
                };
            }
            else {
                throw new Error('Unknown duplex source type - must be Iterable or AsyncIterable');
            }
            return merge$1(stream, sourceWrap());
        }
        return duplex.source;
    };
};

function selectOpenConnection(connections) {
    return connections
        .filter((c) => c.status === "open")
        .sort((left, right) => right.timeline.open - left.timeline.open)
        .at(0);
}

const STREAM_LOCK_KEY = "consumed";
class StreamManager {
    multicodec;
    libp2p;
    log;
    ongoingCreation = new Set();
    streamPool = new Map();
    constructor(multicodec, libp2p) {
        this.multicodec = multicodec;
        this.libp2p = libp2p;
        this.log = new Logger$1(`stream-manager:${multicodec}`);
        this.libp2p.events.addEventListener("peer:update", this.handlePeerUpdateStreamPool);
    }
    async getStream(peerId) {
        const peerIdStr = peerId.toString();
        const scheduledStream = this.streamPool.get(peerIdStr);
        if (scheduledStream) {
            this.streamPool.delete(peerIdStr);
            await scheduledStream;
        }
        let stream = this.getOpenStreamForCodec(peerId);
        if (stream) {
            this.log.info(`Found existing stream peerId=${peerIdStr} multicodec=${this.multicodec}`);
            this.lockStream(peerIdStr, stream);
            return stream;
        }
        stream = await this.createStream(peerId);
        this.lockStream(peerIdStr, stream);
        return stream;
    }
    async createStream(peerId, retries = 0) {
        const connections = this.libp2p.connectionManager.getConnections(peerId);
        const connection = selectOpenConnection(connections);
        if (!connection) {
            throw new Error(`Failed to get a connection to the peer peerId=${peerId.toString()} multicodec=${this.multicodec}`);
        }
        let lastError;
        let stream;
        for (let i = 0; i < retries + 1; i++) {
            try {
                this.log.info(`Attempting to create a stream for peerId=${peerId.toString()} multicodec=${this.multicodec}`);
                stream = await connection.newStream(this.multicodec);
                this.log.info(`Created stream for peerId=${peerId.toString()} multicodec=${this.multicodec}`);
                break;
            }
            catch (error) {
                lastError = error;
            }
        }
        if (!stream) {
            throw new Error(`Failed to create a new stream for ${peerId.toString()} -- ` + lastError);
        }
        return stream;
    }
    async createStreamWithLock(peer) {
        const peerId = peer.id.toString();
        if (this.ongoingCreation.has(peerId)) {
            this.log.info(`Skipping creation of a stream due to lock for peerId=${peerId} multicodec=${this.multicodec}`);
            return;
        }
        try {
            this.ongoingCreation.add(peerId);
            await this.createStream(peer.id);
        }
        catch (error) {
            this.log.error(`Failed to createStreamWithLock:`, error);
        }
        finally {
            this.ongoingCreation.delete(peerId);
        }
        return;
    }
    handlePeerUpdateStreamPool = (evt) => {
        const { peer } = evt.detail;
        if (!peer.protocols.includes(this.multicodec)) {
            return;
        }
        const stream = this.getOpenStreamForCodec(peer.id);
        if (stream) {
            return;
        }
        this.scheduleNewStream(peer);
    };
    scheduleNewStream(peer) {
        this.log.info(`Scheduling creation of a stream for peerId=${peer.id.toString()} multicodec=${this.multicodec}`);
        // abandon previous attempt
        if (this.streamPool.has(peer.id.toString())) {
            this.streamPool.delete(peer.id.toString());
        }
        this.streamPool.set(peer.id.toString(), this.createStreamWithLock(peer));
    }
    getOpenStreamForCodec(peerId) {
        const connections = this.libp2p.connectionManager.getConnections(peerId);
        const connection = selectOpenConnection(connections);
        if (!connection) {
            return;
        }
        const stream = connection.streams.find((s) => s.protocol === this.multicodec);
        if (!stream) {
            return;
        }
        const isStreamUnusable = ["done", "closed", "closing"].includes(stream.writeStatus || "");
        if (isStreamUnusable || this.isStreamLocked(stream)) {
            return;
        }
        return stream;
    }
    lockStream(peerId, stream) {
        this.log.info(`Locking stream for peerId:${peerId}\tstreamId:${stream.id}`);
        stream.metadata[STREAM_LOCK_KEY] = true;
    }
    isStreamLocked(stream) {
        return !!stream.metadata[STREAM_LOCK_KEY];
    }
}

// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
let getRandomValues;
const rnds8 = new Uint8Array(16);
function rng() {
  // lazy load so that environments that need to polyfill have a chance to do so
  if (!getRandomValues) {
    // getRandomValues needs to be invoked in a context where "this" is a Crypto implementation.
    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);

    if (!getRandomValues) {
      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
    }
  }

  return getRandomValues(rnds8);
}

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */

const byteToHex = [];

for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).slice(1));
}

function unsafeStringify(arr, offset = 0) {
  // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434
  return byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]];
}

const randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);
var native = {
  randomUUID
};

function v4(options, buf, offset) {
  if (native.randomUUID && true && !options) {
    return native.randomUUID();
  }

  options = options || {};
  const rnds = options.random || (options.rng || rng)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`

  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  return unsafeStringify(rnds);
}

/**
 * FilterPushRPC represents a message conforming to the Waku FilterPush protocol.
 * Protocol documentation: https://rfc.vac.dev/spec/12/
 */
class FilterPushRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = MessagePush.decode(bytes);
        return new FilterPushRpc(res);
    }
    encode() {
        return MessagePush.encode(this.proto);
    }
    get wakuMessage() {
        return this.proto.wakuMessage;
    }
    /**
     * Get the pubsub topic from the FilterPushRpc object.
     * @returns string
     */
    get pubsubTopic() {
        return this.proto.pubsubTopic;
    }
}
class FilterSubscribeRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createSubscribeRequest(pubsubTopic, contentTopics) {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.SUBSCRIBE,
            pubsubTopic,
            contentTopics
        });
    }
    static createUnsubscribeRequest(pubsubTopic, contentTopics) {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.UNSUBSCRIBE,
            pubsubTopic,
            contentTopics
        });
    }
    static createUnsubscribeAllRequest(pubsubTopic) {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.UNSUBSCRIBE_ALL,
            pubsubTopic,
            contentTopics: []
        });
    }
    static createSubscriberPingRequest() {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.SUBSCRIBER_PING,
            pubsubTopic: "",
            contentTopics: []
        });
    }
    static decode(bytes) {
        const res = FilterSubscribeRequest.decode(bytes);
        return new FilterSubscribeRpc(res);
    }
    encode() {
        return FilterSubscribeRequest.encode(this.proto);
    }
    get filterSubscribeType() {
        return this.proto.filterSubscribeType;
    }
    get requestId() {
        return this.proto.requestId;
    }
    get pubsubTopic() {
        return this.proto.pubsubTopic;
    }
    get contentTopics() {
        return this.proto.contentTopics;
    }
}
class FilterSubscribeResponse {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = FilterSubscribeResponse$1.decode(bytes);
        return new FilterSubscribeResponse(res);
    }
    encode() {
        return FilterSubscribeResponse$1.encode(this.proto);
    }
    get statusCode() {
        return this.proto.statusCode;
    }
    get statusDesc() {
        return this.proto.statusDesc;
    }
    get requestId() {
        return this.proto.requestId;
    }
}

const log$u = new Logger$1("filter-core");
const FilterCodecs = {
    SUBSCRIBE: "/vac/waku/filter-subscribe/2.0.0-beta1",
    PUSH: "/vac/waku/filter-push/2.0.0-beta1"
};
class FilterCore {
    handleIncomingMessage;
    streamManager;
    multicodec = FilterCodecs.SUBSCRIBE;
    constructor(handleIncomingMessage, libp2p) {
        this.handleIncomingMessage = handleIncomingMessage;
        this.streamManager = new StreamManager(FilterCodecs.SUBSCRIBE, libp2p.components);
        libp2p
            .handle(FilterCodecs.PUSH, this.onRequest.bind(this), {
            maxInboundStreams: 100
        })
            .catch((e) => {
            log$u.error("Failed to register ", FilterCodecs.PUSH, e);
        });
    }
    async subscribe(pubsubTopic, peerId, contentTopics) {
        const stream = await this.streamManager.getStream(peerId);
        const request = FilterSubscribeRpc.createSubscribeRequest(pubsubTopic, contentTopics);
        let res;
        try {
            res = await pipe([request.encode()], encode$3, stream, decode$2, async (source) => await all$1(source));
            if (!res?.length) {
                throw Error("Received no response from subscription request.");
            }
        }
        catch (error) {
            log$u.error("Failed to send subscribe request", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.GENERIC_FAIL,
                    peerId: peerId
                }
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$u.error(`Filter subscribe request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                failure: {
                    error: ProtocolError$1.REMOTE_PEER_REJECTED,
                    peerId: peerId
                },
                success: null
            };
        }
        return {
            failure: null,
            success: peerId
        };
    }
    async unsubscribe(pubsubTopic, peerId, contentTopics) {
        let stream;
        try {
            stream = await this.streamManager.getStream(peerId);
        }
        catch (error) {
            log$u.error(`Failed to get a stream for remote peer${peerId.toString()}`, error);
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.NO_STREAM_AVAILABLE,
                    peerId: peerId
                }
            };
        }
        const unsubscribeRequest = FilterSubscribeRpc.createUnsubscribeRequest(pubsubTopic, contentTopics);
        try {
            await pipe([unsubscribeRequest.encode()], encode$3, stream.sink);
        }
        catch (error) {
            log$u.error("Failed to send unsubscribe request", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.GENERIC_FAIL,
                    peerId: peerId
                }
            };
        }
        return {
            success: peerId,
            failure: null
        };
    }
    async unsubscribeAll(pubsubTopic, peerId) {
        const stream = await this.streamManager.getStream(peerId);
        const request = FilterSubscribeRpc.createUnsubscribeAllRequest(pubsubTopic);
        const res = await pipe([request.encode()], encode$3, stream, decode$2, async (source) => await all$1(source));
        if (!res || !res.length) {
            return {
                failure: {
                    error: ProtocolError$1.NO_RESPONSE,
                    peerId: peerId
                },
                success: null
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$u.error(`Filter unsubscribe all request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                failure: {
                    error: ProtocolError$1.REMOTE_PEER_REJECTED,
                    peerId: peerId
                },
                success: null
            };
        }
        return {
            failure: null,
            success: peerId
        };
    }
    async ping(peerId) {
        let stream;
        try {
            stream = await this.streamManager.getStream(peerId);
        }
        catch (error) {
            log$u.error(`Failed to get a stream for remote peer${peerId.toString()}`, error);
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.NO_STREAM_AVAILABLE,
                    peerId: peerId
                }
            };
        }
        const request = FilterSubscribeRpc.createSubscriberPingRequest();
        let res;
        try {
            res = await pipe([request.encode()], encode$3, stream, decode$2, async (source) => await all$1(source));
        }
        catch (error) {
            log$u.error("Failed to send ping request", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.GENERIC_FAIL,
                    peerId: peerId
                }
            };
        }
        if (!res || !res.length) {
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.NO_RESPONSE,
                    peerId: peerId
                }
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$u.error(`Filter ping request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.REMOTE_PEER_REJECTED,
                    peerId: peerId
                }
            };
        }
        return {
            success: peerId,
            failure: null
        };
    }
    onRequest(streamData) {
        const { connection, stream } = streamData;
        const { remotePeer } = connection;
        log$u.info(`Received message from ${remotePeer.toString()}`);
        try {
            pipe(stream, decode$2, async (source) => {
                for await (const bytes of source) {
                    const response = FilterPushRpc.decode(bytes.slice());
                    const { pubsubTopic, wakuMessage } = response;
                    if (!wakuMessage) {
                        log$u.error("Received empty message");
                        return;
                    }
                    if (!pubsubTopic) {
                        log$u.error("Pubsub topic missing from push message");
                        return;
                    }
                    await this.handleIncomingMessage(pubsubTopic, wakuMessage, connection.remotePeer.toString());
                }
            }).then(() => {
                log$u.info("Receiving pipe closed.");
            }, async (e) => {
                log$u.error(`Error with receiving pipe on peer:${connection.remotePeer.toString()} -- stream:${stream.id} -- protocol:${stream.protocol}: `, e);
            });
        }
        catch (e) {
            log$u.error("Error decoding message", e);
        }
    }
}

var index$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    FilterCodecs: FilterCodecs,
    FilterCore: FilterCore
});

class PushRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createRequest(message, pubsubTopic) {
        return new PushRpc({
            requestId: v4(),
            request: {
                message: message,
                pubsubTopic: pubsubTopic
            },
            response: undefined
        });
    }
    static decode(bytes) {
        const res = PushRpc$1.decode(bytes);
        return new PushRpc(res);
    }
    encode() {
        return PushRpc$1.encode(this.proto);
    }
    get query() {
        return this.proto.request;
    }
    get response() {
        return this.proto.response;
    }
}

// should match nwaku
// https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/rln_relay.nim#L309
// https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/tests/waku_rln_relay/rln/waku_rln_relay_utils.nim#L20
const RLN_GENERATION_PREFIX_ERROR = "could not generate rln proof";
const RLN_MESSAGE_ID_PREFIX_ERROR = "could not get new message id to generate an rln proof";
// rare case on nwaku side
// https://github.com/waku-org/nwaku/blob/a4e92a3d02448fd708857b7b6cac2a7faa7eb4f9/waku/waku_lightpush/callbacks.nim#L49
// https://github.com/waku-org/nwaku/blob/a4e92a3d02448fd708857b7b6cac2a7faa7eb4f9/waku/node/waku_node.nim#L1117
const RLN_REMOTE_VALIDATION = "RLN validation failed";
const isRLNResponseError = (info) => {
    if (!info) {
        return false;
    }
    return (info.includes(RLN_GENERATION_PREFIX_ERROR) ||
        info.includes(RLN_MESSAGE_ID_PREFIX_ERROR) ||
        info.includes(RLN_REMOTE_VALIDATION));
};

const log$t = new Logger$1("light-push");
const LightPushCodec = "/vac/waku/lightpush/2.0.0-beta1";
/**
 * Implements the [Waku v2 Light Push protocol](https://rfc.vac.dev/spec/19/).
 */
class LightPushCore {
    streamManager;
    multicodec = LightPushCodec;
    constructor(libp2p) {
        this.streamManager = new StreamManager(LightPushCodec, libp2p.components);
    }
    async preparePushMessage(encoder, message) {
        try {
            if (!message.payload || message.payload.length === 0) {
                log$t.error("Failed to send waku light push: payload is empty");
                return { query: null, error: ProtocolError$1.EMPTY_PAYLOAD };
            }
            if (!(await isMessageSizeUnderCap(encoder, message))) {
                log$t.error("Failed to send waku light push: message is bigger than 1MB");
                return { query: null, error: ProtocolError$1.SIZE_TOO_BIG };
            }
            const protoMessage = await encoder.toProtoObj(message);
            if (!protoMessage) {
                log$t.error("Failed to encode to protoMessage, aborting push");
                return {
                    query: null,
                    error: ProtocolError$1.ENCODE_FAILED
                };
            }
            const query = PushRpc.createRequest(protoMessage, encoder.pubsubTopic);
            return { query, error: null };
        }
        catch (error) {
            log$t.error("Failed to prepare push message", error);
            return {
                query: null,
                error: ProtocolError$1.GENERIC_FAIL
            };
        }
    }
    async send(encoder, message, peerId) {
        const { query, error: preparationError } = await this.preparePushMessage(encoder, message);
        if (preparationError || !query) {
            return {
                success: null,
                failure: {
                    error: preparationError,
                    peerId
                }
            };
        }
        let stream;
        try {
            stream = await this.streamManager.getStream(peerId);
        }
        catch (error) {
            log$t.error("Failed to get stream", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.NO_STREAM_AVAILABLE,
                    peerId: peerId
                }
            };
        }
        let res;
        try {
            res = await pipe([query.encode()], encode$3, stream, decode$2, async (source) => await all$1(source));
        }
        catch (err) {
            // can fail only because of `stream` abortion
            log$t.error("Failed to send waku light push request", err);
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.STREAM_ABORTED,
                    peerId: peerId
                }
            };
        }
        const bytes = new Uint8ArrayList();
        res.forEach((chunk) => {
            bytes.append(chunk);
        });
        let response;
        try {
            response = PushRpc.decode(bytes).response;
        }
        catch (err) {
            log$t.error("Failed to decode push reply", err);
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.DECODE_FAILED,
                    peerId: peerId
                }
            };
        }
        if (!response) {
            log$t.error("Remote peer fault: No response in PushRPC");
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.NO_RESPONSE,
                    peerId: peerId
                }
            };
        }
        if (isRLNResponseError(response.info)) {
            log$t.error("Remote peer fault: RLN generation");
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.RLN_PROOF_GENERATION,
                    peerId: peerId
                }
            };
        }
        if (!response.isSuccess) {
            log$t.error("Remote peer rejected the message: ", response.info);
            return {
                success: null,
                failure: {
                    error: ProtocolError$1.REMOTE_PEER_REJECTED,
                    peerId: peerId
                }
            };
        }
        return { success: peerId, failure: null };
    }
}

var index$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    LightPushCodec: LightPushCodec,
    LightPushCore: LightPushCore,
    get PushResponse () { return PushResponse; }
});

const EmptyMessage = {
    payload: new Uint8Array(),
    contentTopic: "",
    version: undefined,
    timestamp: undefined,
    meta: undefined,
    rateLimitProof: undefined,
    ephemeral: undefined
};
function toProtoMessage(wire) {
    return { ...EmptyMessage, ...wire };
}

// https://github.com/waku-org/nwaku/blob/7205f95cff9f49ca0bb762e8fd0bf56a6a7f3b3b/waku/waku_store/common.nim#L12
const DEFAULT_PAGE_SIZE = 20;
const MAX_PAGE_SIZE = 100;
const MAX_TIME_RANGE = 24 * 60 * 60 * 1000;
const ONE_MILLION = 1_000000;
class StoreQueryRequest {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static create(params) {
        const request = new StoreQueryRequest({
            ...params,
            contentTopics: params.contentTopics || [],
            requestId: v4(),
            timeStart: params.timeStart
                ? BigInt(params.timeStart.getTime() * ONE_MILLION)
                : undefined,
            timeEnd: params.timeEnd
                ? BigInt(params.timeEnd.getTime() * ONE_MILLION)
                : undefined,
            messageHashes: params.messageHashes || [],
            paginationLimit: params.paginationLimit
                ? BigInt(params.paginationLimit)
                : undefined
        });
        const isHashQuery = params.messageHashes && params.messageHashes.length > 0;
        const hasContentTopics = params.contentTopics && params.contentTopics.length > 0;
        const hasTimeFilter = params.timeStart || params.timeEnd;
        if (isHashQuery) {
            if (hasContentTopics || hasTimeFilter) {
                throw new Error("Message hash lookup queries cannot include content filter criteria (contentTopics, timeStart, or timeEnd)");
            }
        }
        else {
            if ((params.pubsubTopic &&
                (!params.contentTopics || params.contentTopics.length === 0)) ||
                (!params.pubsubTopic &&
                    params.contentTopics &&
                    params.contentTopics.length > 0)) {
                throw new Error("Both pubsubTopic and contentTopics must be set together for content-filtered queries");
            }
        }
        return request;
    }
    static decode(bytes) {
        const res = StoreQueryRequest$1.decode(bytes);
        return new StoreQueryRequest(res);
    }
    encode() {
        return StoreQueryRequest$1.encode(this.proto);
    }
}
class StoreQueryResponse {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = StoreQueryResponse$1.decode(bytes);
        return new StoreQueryResponse(res);
    }
    encode() {
        return StoreQueryResponse$1.encode(this.proto);
    }
    get statusCode() {
        return this.proto.statusCode;
    }
    get statusDesc() {
        return this.proto.statusDesc;
    }
    get messages() {
        return this.proto.messages;
    }
    get paginationCursor() {
        return this.proto.paginationCursor;
    }
}

const log$s = new Logger$1("store");
const StoreCodec = "/vac/waku/store-query/3.0.0";
class StoreCore {
    streamManager;
    multicodec = StoreCodec;
    constructor(libp2p) {
        this.streamManager = new StreamManager(StoreCodec, libp2p.components);
    }
    get maxTimeLimit() {
        return MAX_TIME_RANGE;
    }
    async *queryPerPage(queryOpts, decoders, peerId) {
        if (queryOpts.timeStart && queryOpts.timeEnd) {
            const timeDiff = queryOpts.timeEnd.getTime() - queryOpts.timeStart.getTime();
            if (timeDiff > MAX_TIME_RANGE) {
                throw new Error("Time range bigger than 24h");
            }
        }
        // Only validate decoder content topics for content-filtered queries
        const isHashQuery = queryOpts.messageHashes && queryOpts.messageHashes.length > 0;
        if (!isHashQuery &&
            queryOpts.contentTopics &&
            queryOpts.contentTopics.toString() !==
                Array.from(decoders.keys()).toString()) {
            throw new Error("Internal error, the decoders should match the query's content topics");
        }
        let currentCursor = queryOpts.paginationCursor;
        while (true) {
            const storeQueryRequest = StoreQueryRequest.create({
                ...queryOpts,
                paginationCursor: currentCursor
            });
            log$s.info("Sending store query request:", {
                hasMessageHashes: !!queryOpts.messageHashes?.length,
                messageHashCount: queryOpts.messageHashes?.length,
                pubsubTopic: queryOpts.pubsubTopic,
                contentTopics: queryOpts.contentTopics
            });
            let stream;
            try {
                stream = await this.streamManager.getStream(peerId);
            }
            catch (e) {
                log$s.error("Failed to get stream", e);
                break;
            }
            const res = await pipe([storeQueryRequest.encode()], encode$3, stream, decode$2, async (source) => await all$1(source));
            const bytes = new Uint8ArrayList();
            res.forEach((chunk) => {
                bytes.append(chunk);
            });
            const storeQueryResponse = StoreQueryResponse.decode(bytes);
            if (!storeQueryResponse.statusCode ||
                storeQueryResponse.statusCode >= 300) {
                const errorMessage = `Store query failed with status code: ${storeQueryResponse.statusCode}, description: ${storeQueryResponse.statusDesc}`;
                log$s.error(errorMessage);
                throw new Error(errorMessage);
            }
            if (!storeQueryResponse.messages || !storeQueryResponse.messages.length) {
                log$s.warn("Stopping pagination due to empty messages in response");
                break;
            }
            log$s.info(`${storeQueryResponse.messages.length} messages retrieved from store`);
            const decodedMessages = storeQueryResponse.messages.map((protoMsg) => {
                if (!protoMsg.message) {
                    return Promise.resolve(undefined);
                }
                const contentTopic = protoMsg.message.contentTopic;
                if (contentTopic) {
                    const decoder = decoders.get(contentTopic);
                    if (decoder) {
                        return decoder.fromProtoObj(protoMsg.pubsubTopic || "", toProtoMessage(protoMsg.message));
                    }
                }
                return Promise.resolve(undefined);
            });
            yield decodedMessages;
            if (queryOpts.paginationForward) {
                currentCursor =
                    storeQueryResponse.messages[storeQueryResponse.messages.length - 1]
                        .messageHash;
            }
            else {
                currentCursor = storeQueryResponse.messages[0].messageHash;
            }
            if (storeQueryResponse.messages.length > MAX_PAGE_SIZE &&
                storeQueryResponse.messages.length <
                    (queryOpts.paginationLimit || DEFAULT_PAGE_SIZE)) {
                break;
            }
        }
    }
}

var index$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    StoreCodec: StoreCodec,
    StoreCore: StoreCore
});

const log$r = new Logger$1("connection-limiter");
const DEFAULT_CONNECTION_MONITOR_INTERVAL = 5 * 1_000;
/**
 * This class is responsible for limiting the number of connections to peers.
 * It also dials all known peers because libp2p might have emitted `peer:discovery` before initialization
 * and listen to `peer:connect` and `peer:disconnect` events to manage connections.
 */
class ConnectionLimiter {
    libp2p;
    events;
    networkMonitor;
    dialer;
    connectionMonitorInterval = null;
    options;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.events = options.events;
        this.networkMonitor = options.networkMonitor;
        this.dialer = options.dialer;
        this.options = options.options;
        this.onWakuConnectionEvent = this.onWakuConnectionEvent.bind(this);
        this.onDisconnectedEvent = this.onDisconnectedEvent.bind(this);
    }
    start() {
        // dial all known peers because libp2p might have emitted `peer:discovery` before initialization
        void this.dialPeersFromStore();
        if (this.options.enableAutoRecovery &&
            this.connectionMonitorInterval === null) {
            this.connectionMonitorInterval = setInterval(() => void this.maintainConnections(), DEFAULT_CONNECTION_MONITOR_INTERVAL);
        }
        this.events.addEventListener("waku:connection", this.onWakuConnectionEvent);
        /**
         * NOTE: Event is not being emitted on closing nor losing a connection.
         * @see https://github.com/libp2p/js-libp2p/issues/939
         * @see https://github.com/status-im/js-waku/issues/252
         *
         * >This event will be triggered anytime we are disconnected from another peer,
         * >regardless of the circumstances of that disconnection.
         * >If we happen to have multiple connections to a peer,
         * >this event will **only** be triggered when the last connection is closed.
         * @see https://github.com/libp2p/js-libp2p/blob/bad9e8c0ff58d60a78314077720c82ae331cc55b/doc/API.md?plain=1#L2100
         */
        this.libp2p.addEventListener("peer:disconnect", this.onDisconnectedEvent);
    }
    stop() {
        this.events.removeEventListener("waku:connection", this.onWakuConnectionEvent);
        this.libp2p.removeEventListener("peer:disconnect", this.onDisconnectedEvent);
        if (this.connectionMonitorInterval) {
            clearInterval(this.connectionMonitorInterval);
            this.connectionMonitorInterval = null;
        }
    }
    onWakuConnectionEvent() {
        if (!this.options.enableAutoRecovery) {
            log$r.info(`Auto recovery is disabled, skipping`);
            return;
        }
        if (this.networkMonitor.isBrowserConnected()) {
            void this.dialPeersFromStore();
        }
    }
    async maintainConnections() {
        await this.maintainConnectionsCount();
        await this.maintainBootstrapConnections();
    }
    async onDisconnectedEvent() {
        if (this.libp2p.getConnections().length === 0) {
            log$r.info(`No connections, dialing peers from store`);
            await this.dialPeersFromStore();
        }
    }
    async maintainConnectionsCount() {
        log$r.info(`Maintaining connections count`);
        const connections = this.libp2p.getConnections();
        if (connections.length <= this.options.maxConnections) {
            log$r.info(`Node has less than max connections ${this.options.maxConnections}, trying to dial more peers`);
            const peers = await this.getPrioritizedPeers();
            if (peers.length === 0) {
                log$r.info(`No peers to dial, node is utilizing all known peers`);
                return;
            }
            const promises = peers
                .slice(0, this.options.maxConnections - connections.length)
                .map((p) => this.dialer.dial(p.id));
            await Promise.all(promises);
            return;
        }
        log$r.info(`Node has more than max connections ${this.options.maxConnections}, dropping connections`);
        try {
            const connectionsToDrop = connections
                .filter((c) => !c.tags.includes(CONNECTION_LOCKED_TAG))
                .slice(this.options.maxConnections);
            if (connectionsToDrop.length === 0) {
                log$r.info(`No connections to drop, skipping`);
                return;
            }
            const promises = connectionsToDrop.map((c) => this.libp2p.hangUp(c.remotePeer));
            await Promise.all(promises);
            log$r.info(`Dropped ${connectionsToDrop.length} connections`);
        }
        catch (error) {
            log$r.error(`Unexpected error while maintaining connections`, error);
        }
    }
    async maintainBootstrapConnections() {
        log$r.info(`Maintaining bootstrap connections`);
        const bootstrapPeers = await this.getBootstrapPeers();
        if (bootstrapPeers.length <= this.options.maxBootstrapPeers) {
            return;
        }
        try {
            const peersToDrop = bootstrapPeers.slice(this.options.maxBootstrapPeers);
            log$r.info(`Dropping ${peersToDrop.length} bootstrap connections because node has more than max bootstrap connections ${this.options.maxBootstrapPeers}`);
            const promises = peersToDrop.map((p) => this.libp2p.hangUp(p.id));
            await Promise.all(promises);
            log$r.info(`Dropped ${peersToDrop.length} bootstrap connections`);
        }
        catch (error) {
            log$r.error(`Unexpected error while maintaining bootstrap connections`, error);
        }
    }
    async dialPeersFromStore() {
        log$r.info(`Dialing peers from store`);
        try {
            const peers = await this.getPrioritizedPeers();
            if (peers.length === 0) {
                log$r.info(`No peers to dial, skipping`);
                return;
            }
            const promises = peers.map((p) => this.dialer.dial(p.id));
            log$r.info(`Dialing ${peers.length} peers from store`);
            await Promise.all(promises);
            log$r.info(`Dialed ${promises.length} peers from store`);
        }
        catch (error) {
            log$r.error(`Unexpected error while dialing peer store peers`, error);
        }
    }
    /**
     * Returns a list of peers ordered by priority:
     * - bootstrap peers
     * - peers from peer exchange
     * - peers from local store (last because we are not sure that locally stored information is up to date)
     */
    async getPrioritizedPeers() {
        const allPeers = await this.libp2p.peerStore.all();
        const allConnections = this.libp2p.getConnections();
        log$r.info(`Found ${allPeers.length} peers in store, and found ${allConnections.length} connections`);
        const notConnectedPeers = allPeers.filter((p) => !allConnections.some((c) => c.remotePeer.equals(p.id)) &&
            p.addresses.some((a) => a.multiaddr.toString().includes("wss") ||
                a.multiaddr.toString().includes("ws")));
        const bootstrapPeers = notConnectedPeers.filter((p) => p.tags.has(Tags.BOOTSTRAP));
        const peerExchangePeers = notConnectedPeers.filter((p) => p.tags.has(Tags.PEER_EXCHANGE));
        const localStorePeers = notConnectedPeers.filter((p) => p.tags.has(Tags.LOCAL));
        return [...bootstrapPeers, ...peerExchangePeers, ...localStorePeers];
    }
    async getBootstrapPeers() {
        const peers = await Promise.all(this.libp2p
            .getConnections()
            .map((conn) => conn.remotePeer)
            .map((id) => this.getPeer(id)));
        const bootstrapPeers = peers.filter((peer) => peer && peer.tags.has(Tags.BOOTSTRAP));
        return bootstrapPeers;
    }
    async getPeer(peerId) {
        try {
            return await this.libp2p.peerStore.get(peerId);
        }
        catch (error) {
            log$r.error(`Failed to get peer ${peerId}, error: ${error}`);
            return null;
        }
    }
}

const log$q = new Logger$1("dialer");
class Dialer {
    libp2p;
    shardReader;
    options;
    dialingQueue = [];
    dialHistory = new Map();
    failedDials = new Map();
    dialingInterval = null;
    isProcessing = false;
    isImmediateDialing = false;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.shardReader = options.shardReader;
        this.options = options.options;
    }
    start() {
        log$q.info("Starting dialer");
        if (!this.dialingInterval) {
            this.dialingInterval = setInterval(() => {
                void this.processQueue();
            }, 500);
        }
        this.dialHistory.clear();
        this.failedDials.clear();
    }
    stop() {
        log$q.info("Stopping dialer");
        if (this.dialingInterval) {
            clearInterval(this.dialingInterval);
            this.dialingInterval = null;
        }
        this.dialHistory.clear();
        this.failedDials.clear();
    }
    async dial(peerId) {
        const shouldSkip = await this.shouldSkipPeer(peerId);
        if (shouldSkip) {
            log$q.info(`Skipping peer: ${peerId}`);
            return;
        }
        const isEmptyQueue = this.dialingQueue.length === 0;
        const isNotDialing = !this.isProcessing && !this.isImmediateDialing;
        // If queue is empty and we're not currently processing, dial immediately
        if (isEmptyQueue && isNotDialing) {
            this.isImmediateDialing = true;
            log$q.info("Dialed peer immediately");
            await this.dialPeer(peerId);
            this.isImmediateDialing = false;
            log$q.info("Released immediate dial lock");
        }
        else {
            this.dialingQueue.push(peerId);
            log$q.info(`Added peer to dialing queue, queue size: ${this.dialingQueue.length}`);
        }
    }
    async processQueue() {
        if (this.dialingQueue.length === 0 || this.isProcessing) {
            return;
        }
        this.isProcessing = true;
        try {
            const peersToDial = this.dialingQueue.slice(0, this.options.maxDialingPeers);
            this.dialingQueue = this.dialingQueue.slice(peersToDial.length);
            log$q.info(`Processing dial queue: dialing ${peersToDial.length} peers, ${this.dialingQueue.length} remaining in queue`);
            await Promise.all(peersToDial.map((peerId) => this.dialPeer(peerId)));
        }
        finally {
            this.isProcessing = false;
        }
    }
    async dialPeer(peerId) {
        try {
            log$q.info(`Dialing peer from queue: ${peerId}`);
            await this.libp2p.dial(peerId);
            this.dialHistory.set(peerId.toString(), Date.now());
            this.failedDials.delete(peerId.toString());
            log$q.info(`Successfully dialed peer from queue: ${peerId}`);
        }
        catch (error) {
            log$q.error(`Error dialing peer ${peerId}`, error);
            this.failedDials.set(peerId.toString(), Date.now());
        }
    }
    async shouldSkipPeer(peerId) {
        const hasConnection = this.libp2p.getPeers().some((p) => p.equals(peerId));
        if (hasConnection) {
            log$q.info(`Skipping peer ${peerId} - already connected`);
            return true;
        }
        if (this.isRecentlyDialed(peerId)) {
            log$q.info(`Skipping peer ${peerId} - already dialed in the last 10 seconds`);
            return true;
        }
        if (this.isRecentlyFailed(peerId)) {
            log$q.info(`Skipping peer ${peerId} - recently failed to dial`);
            return true;
        }
        try {
            const hasShardInfo = await this.shardReader.hasShardInfo(peerId);
            if (!hasShardInfo) {
                log$q.info(`Skipping peer ${peerId} - no shard info`);
                return false;
            }
            const isOnSameShard = await this.shardReader.isPeerOnNetwork(peerId);
            if (!isOnSameShard) {
                log$q.info(`Skipping peer ${peerId} - not on same shard`);
                return true;
            }
            return false;
        }
        catch (error) {
            log$q.error(`Error checking shard info for peer ${peerId}`, error);
            return true; // Skip peer when there's an error
        }
    }
    isRecentlyDialed(peerId) {
        const lastDialed = this.dialHistory.get(peerId.toString());
        if (lastDialed &&
            Date.now() - lastDialed < this.options.dialCooldown * 1000) {
            return true;
        }
        return false;
    }
    isRecentlyFailed(peerId) {
        const lastFailed = this.failedDials.get(peerId.toString());
        if (lastFailed &&
            Date.now() - lastFailed < this.options.failedDialCooldown * 1000) {
            return true;
        }
        return false;
    }
}

const log$p = new Logger$1("discovery-dialer");
/**
 * This class is responsible for dialing peers that are discovered by the libp2p node.
 * Managing limits for the peers is out of scope for this class.
 * Dialing after discovery is needed to identify the peer and get all other information: metadata, protocols, etc.
 */
class DiscoveryDialer {
    libp2p;
    dialer;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.dialer = options.dialer;
        this.onPeerDiscovery = this.onPeerDiscovery.bind(this);
    }
    start() {
        this.libp2p.addEventListener("peer:discovery", this.onPeerDiscovery);
    }
    stop() {
        this.libp2p.removeEventListener("peer:discovery", this.onPeerDiscovery);
    }
    async onPeerDiscovery(event) {
        const peerId = event.detail.id;
        log$p.info(`Discovered new peer: ${peerId}`);
        try {
            await this.updatePeerStore(peerId, event.detail.multiaddrs);
            await this.dialer.dial(peerId);
        }
        catch (error) {
            log$p.error(`Error dialing peer ${peerId}`, error);
        }
    }
    async updatePeerStore(peerId, multiaddrs) {
        try {
            log$p.info(`Updating peer store for ${peerId}`);
            const peer = await this.getPeer(peerId);
            if (!peer) {
                log$p.info(`Peer ${peerId} not found in store, saving`);
                await this.libp2p.peerStore.save(peerId, {
                    multiaddrs: multiaddrs
                });
                return;
            }
            const hasSameAddr = multiaddrs.every((addr) => peer.addresses.some((a) => a.multiaddr.equals(addr)));
            if (hasSameAddr) {
                log$p.info(`Peer ${peerId} has same addresses in peer store, skipping`);
                return;
            }
            log$p.info(`Merging peer ${peerId} addresses in peer store`);
            await this.libp2p.peerStore.merge(peerId, {
                multiaddrs: multiaddrs
            });
        }
        catch (error) {
            log$p.error(`Error updating peer store for ${peerId}`, error);
        }
    }
    async getPeer(peerId) {
        try {
            return await this.libp2p.peerStore.get(peerId);
        }
        catch (error) {
            log$p.error(`Error getting peer info for ${peerId}`, error);
            return undefined;
        }
    }
}

const RelayPingContentTopic = "/relay-ping/1/ping/null";
const log$o = new Logger$1("keep-alive");
class KeepAliveManager {
    relay;
    libp2p;
    options;
    pingKeepAliveTimers = new Map();
    relayKeepAliveTimers = new Map();
    constructor({ options, relay, libp2p }) {
        this.options = options;
        this.relay = relay;
        this.libp2p = libp2p;
        this.onPeerConnect = this.onPeerConnect.bind(this);
        this.onPeerDisconnect = this.onPeerDisconnect.bind(this);
    }
    start() {
        this.libp2p.addEventListener("peer:connect", this.onPeerConnect);
        this.libp2p.addEventListener("peer:disconnect", this.onPeerDisconnect);
    }
    stop() {
        this.libp2p.removeEventListener("peer:connect", this.onPeerConnect);
        this.libp2p.removeEventListener("peer:disconnect", this.onPeerDisconnect);
        for (const timer of this.pingKeepAliveTimers.values()) {
            clearInterval(timer);
        }
        for (const timerArray of this.relayKeepAliveTimers.values()) {
            for (const timer of timerArray) {
                clearInterval(timer);
            }
        }
        this.pingKeepAliveTimers.clear();
        this.relayKeepAliveTimers.clear();
    }
    onPeerConnect(evt) {
        const peerId = evt.detail;
        this.startPingForPeer(peerId);
    }
    onPeerDisconnect(evt) {
        const peerId = evt.detail;
        this.stopPingForPeer(peerId);
    }
    startPingForPeer(peerId) {
        // Just in case a timer already exists for this peer
        this.stopPingForPeer(peerId);
        this.startLibp2pPing(peerId);
        this.startRelayPing(peerId);
    }
    stopPingForPeer(peerId) {
        this.stopLibp2pPing(peerId);
        this.stopRelayPing(peerId);
    }
    startLibp2pPing(peerId) {
        if (this.options.pingKeepAlive === 0) {
            log$o.warn(`Ping keep alive is disabled pingKeepAlive:${this.options.pingKeepAlive}, skipping start for libp2p ping`);
            return;
        }
        const peerIdStr = peerId.toString();
        if (this.pingKeepAliveTimers.has(peerIdStr)) {
            log$o.warn(`Ping already started for peer: ${peerIdStr}, skipping start for libp2p ping`);
            return;
        }
        const interval = setInterval(() => {
            void this.pingLibp2p(peerId);
        }, this.options.pingKeepAlive * 1000);
        this.pingKeepAliveTimers.set(peerIdStr, interval);
    }
    stopLibp2pPing(peerId) {
        const peerIdStr = peerId.toString();
        if (!this.pingKeepAliveTimers.has(peerIdStr)) {
            log$o.warn(`Ping not started for peer: ${peerIdStr}, skipping stop for ping`);
            return;
        }
        clearInterval(this.pingKeepAliveTimers.get(peerIdStr));
        this.pingKeepAliveTimers.delete(peerIdStr);
    }
    startRelayPing(peerId) {
        if (!this.relay) {
            return;
        }
        if (this.options.relayKeepAlive === 0) {
            log$o.warn(`Relay keep alive is disabled relayKeepAlive:${this.options.relayKeepAlive}, skipping start for relay ping`);
            return;
        }
        if (this.relayKeepAliveTimers.has(peerId.toString())) {
            log$o.warn(`Relay ping already started for peer: ${peerId.toString()}, skipping start for relay ping`);
            return;
        }
        const intervals = [];
        for (const topic of this.relay.pubsubTopics) {
            const meshPeers = this.relay.getMeshPeers(topic);
            if (!meshPeers.includes(peerId.toString())) {
                log$o.warn(`Peer: ${peerId.toString()} is not in the mesh for topic: ${topic}, skipping start for relay ping`);
                continue;
            }
            const encoder = createEncoder({
                pubsubTopicShardInfo: pubsubTopicToSingleShardInfo(topic),
                contentTopic: RelayPingContentTopic,
                ephemeral: true
            });
            const interval = setInterval(() => {
                void this.pingRelay(encoder);
            }, this.options.relayKeepAlive * 1000);
            intervals.push(interval);
        }
        this.relayKeepAliveTimers.set(peerId.toString(), intervals);
    }
    stopRelayPing(peerId) {
        if (!this.relay) {
            return;
        }
        const peerIdStr = peerId.toString();
        if (!this.relayKeepAliveTimers.has(peerIdStr)) {
            log$o.warn(`Relay ping not started for peer: ${peerIdStr}, skipping stop for relay ping`);
            return;
        }
        this.relayKeepAliveTimers.get(peerIdStr)?.map(clearInterval);
        this.relayKeepAliveTimers.delete(peerIdStr);
    }
    async pingRelay(encoder) {
        try {
            log$o.info("Sending Waku Relay ping message");
            await this.relay.send(encoder, { payload: new Uint8Array([1]) });
        }
        catch (e) {
            log$o.error("Failed to send relay ping", e);
        }
    }
    async pingLibp2p(peerId) {
        try {
            log$o.info(`Pinging libp2p peer (${peerId.toString()})`);
            const ping = await this.libp2p.services.ping.ping(peerId);
            log$o.info(`Ping succeeded (${peerId.toString()})`, ping);
            await this.libp2p.peerStore.merge(peerId, {
                metadata: {
                    ping: utf8ToBytes$1(ping.toString())
                }
            });
            log$o.info(`Ping updated for peer (${peerId.toString()})`);
        }
        catch (e) {
            log$o.error(`Ping failed for peer (${peerId.toString()})`, e);
        }
    }
}

class NetworkMonitor {
    libp2p;
    events;
    isNetworkConnected = false;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.events = options.events;
        this.onConnectedEvent = this.onConnectedEvent.bind(this);
        this.onDisconnectedEvent = this.onDisconnectedEvent.bind(this);
        this.dispatchNetworkEvent = this.dispatchNetworkEvent.bind(this);
    }
    start() {
        this.libp2p.addEventListener("peer:connect", this.onConnectedEvent);
        this.libp2p.addEventListener("peer:disconnect", this.onDisconnectedEvent);
        try {
            globalThis.addEventListener("online", this.dispatchNetworkEvent);
            globalThis.addEventListener("offline", this.dispatchNetworkEvent);
        }
        catch (err) {
            // ignore
        }
    }
    stop() {
        this.libp2p.removeEventListener("peer:connect", this.onConnectedEvent);
        this.libp2p.removeEventListener("peer:disconnect", this.onDisconnectedEvent);
        try {
            globalThis.removeEventListener("online", this.dispatchNetworkEvent);
            globalThis.removeEventListener("offline", this.dispatchNetworkEvent);
        }
        catch (err) {
            // ignore
        }
    }
    /**
     * Returns true if the node is connected to the network via libp2p and browser.
     */
    isConnected() {
        if (!this.isBrowserConnected()) {
            return false;
        }
        return this.isP2PConnected();
    }
    /**
     * Returns true if the node is connected to the network via libp2p.
     */
    isP2PConnected() {
        return this.isNetworkConnected;
    }
    /**
     * Returns true if the node is connected to the network via browser.
     */
    isBrowserConnected() {
        try {
            if (globalThis?.navigator && !globalThis?.navigator?.onLine) {
                return false;
            }
        }
        catch (err) {
            // ignore
        }
        return true;
    }
    onConnectedEvent() {
        if (!this.isNetworkConnected) {
            this.isNetworkConnected = true;
            this.dispatchNetworkEvent();
        }
    }
    onDisconnectedEvent() {
        if (this.isNetworkConnected && this.libp2p.getConnections().length === 0) {
            this.isNetworkConnected = false;
            this.dispatchNetworkEvent();
        }
    }
    dispatchNetworkEvent() {
        this.events.dispatchEvent(new CustomEvent("waku:connection", {
            detail: this.isConnected()
        }));
    }
}

const log$n = new Logger$1("shard-reader");
/**
 * This class is responsible for reading the shard info from the libp2p peer store or from the current node's network config.
 */
class ShardReader {
    libp2p;
    staticShard;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.staticShard = this.getStaticShardFromNetworkConfig(options.networkConfig);
    }
    async isPeerOnNetwork(id) {
        const shardInfo = await this.getShardInfo(id);
        if (!shardInfo) {
            return false;
        }
        const clusterMatch = shardInfo.clusterId === this.staticShard.clusterId;
        const shardOverlap = this.staticShard.shards.some((s) => shardInfo.shards.includes(s));
        return clusterMatch && shardOverlap;
    }
    async hasShardInfo(id) {
        const shardInfo = await this.getShardInfo(id);
        return !!shardInfo;
    }
    async isPeerOnTopic(id, pubsubTopic) {
        try {
            const shardInfo = pubsubTopicToSingleShardInfo(pubsubTopic);
            return await this.isPeerOnShard(id, shardInfo);
        }
        catch (error) {
            log$n.error(`Error comparing pubsub topic ${pubsubTopic} with shard info for ${id}`, error);
            return false;
        }
    }
    async isPeerOnShard(id, shard) {
        const peerShardInfo = await this.getShardInfo(id);
        if (!peerShardInfo || shard.shard === undefined) {
            return false;
        }
        return (peerShardInfo.clusterId === shard.clusterId &&
            peerShardInfo.shards.includes(shard.shard));
    }
    async getShardInfo(id) {
        try {
            const peer = await this.libp2p.peerStore.get(id);
            const shardInfoBytes = peer.metadata.get("shardInfo");
            if (!shardInfoBytes) {
                return undefined;
            }
            const decodedShardInfo = decodeRelayShard(shardInfoBytes);
            return decodedShardInfo;
        }
        catch (error) {
            log$n.error(`Error getting shard info for ${id}`, error);
            return undefined;
        }
    }
    getStaticShardFromNetworkConfig(networkConfig) {
        if ("shards" in networkConfig) {
            return networkConfig;
        }
        const shards = networkConfig.contentTopics.map((topic) => contentTopicToShardIndex(topic));
        return {
            clusterId: networkConfig.clusterId,
            shards
        };
    }
}

const connectionSymbol = Symbol.for('@libp2p/connection');

/**
 * Any object that implements this Symbol as a property should return a
 * Partial<ContentRouting> instance as the property value, similar to how
 * `Symbol.Iterable` can be used to return an `Iterable` from an `Iterator`.
 *
 * @example
 *
 * ```TypeScript
 * import { contentRoutingSymbol, ContentRouting } from '@libp2p/content-routing'
 *
 * class MyContentRouter implements ContentRouting {
 *   get [contentRoutingSymbol] () {
 *     return this
 *   }
 *
 *   // ...other methods
 * }
 * ```
 */
const contentRoutingSymbol = Symbol.for('@libp2p/content-routing');

/**
 * Any object that implements this Symbol as a property should return a
 * PeerDiscovery instance as the property value, similar to how
 * `Symbol.Iterable` can be used to return an `Iterable` from an `Iterator`.
 *
 * @example
 *
 * ```TypeScript
 * import { peerDiscovery, PeerDiscovery } from '@libp2p/peer-discovery'
 *
 * class MyPeerDiscoverer implements PeerDiscovery {
 *   get [peerDiscovery] () {
 *     return this
 *   }
 *
 *   // ...other methods
 * }
 * ```
 */
const peerDiscoverySymbol = Symbol.for('@libp2p/peer-discovery');

/**
 * All PeerId implementations must use this symbol as the name of a property
 * with a boolean `true` value
 */
const peerIdSymbol = Symbol.for('@libp2p/peer-id');
/**
 * Returns true if the passed argument is a PeerId implementation
 */
function isPeerId(other) {
    return Boolean(other?.[peerIdSymbol]);
}

/**
 * Any object that implements this Symbol as a property should return a
 * PeerRouting instance as the property value, similar to how `Symbol.Iterable`
 * can be used to return an `Iterable` from an `Iterator`.
 *
 * @example
 *
 * ```TypeScript
 * import { peerRouting, PeerRouting } from '@libp2p/peer-routing'
 *
 * class MyPeerRouter implements PeerRouting {
 *   get [peerRouting] () {
 *     return this
 *   }
 *
 *   // ...other methods
 * }
 * ```
 */
const peerRoutingSymbol = Symbol.for('@libp2p/peer-routing');

/**
 * When a peer that is tagged with this prefix disconnects, we will attempt to
 * redial it, up to a limit.
 *
 * To allow multiple components to add/remove their own keep-alive tags without
 * accidentally overwriting those of other components, attach a unique suffix to
 * the tag, e.g. `keep-alive-circuit-relay` or `keep-alive-kad-dht`, etc.
 */
const KEEP_ALIVE = 'keep-alive';

const transportSymbol = Symbol.for('@libp2p/transport');
/**
 * Enum Transport Manager Fault Tolerance values
 */
var FaultTolerance;
(function (FaultTolerance) {
    /**
     * should be used for failing in any listen circumstance
     */
    FaultTolerance[FaultTolerance["FATAL_ALL"] = 0] = "FATAL_ALL";
    /**
     * should be used for not failing when not listening
     */
    FaultTolerance[FaultTolerance["NO_FATAL"] = 1] = "NO_FATAL";
})(FaultTolerance || (FaultTolerance = {}));

/**
 * When this error is thrown it means an operation was aborted,
 * usually in response to the `abort` event being emitted by an
 * AbortSignal.
 */
let AbortError$4 = class AbortError extends Error {
    static name = 'AbortError';
    constructor(message = 'The operation was aborted') {
        super(message);
        this.name = 'AbortError';
    }
};
/**
 * Thrown when a remote Peer ID does not match the expected one
 */
class UnexpectedPeerError extends Error {
    static name = 'UnexpectedPeerError';
    constructor(message = 'Unexpected Peer') {
        super(message);
        this.name = 'UnexpectedPeerError';
    }
}
/**
 * Thrown when a crypto exchange fails
 */
let InvalidCryptoExchangeError$1 = class InvalidCryptoExchangeError extends Error {
    static name = 'InvalidCryptoExchangeError';
    constructor(message = 'Invalid crypto exchange') {
        super(message);
        this.name = 'InvalidCryptoExchangeError';
    }
};
/**
 * Thrown when invalid parameters are passed to a function or method call
 */
let InvalidParametersError$1 = class InvalidParametersError extends Error {
    static name = 'InvalidParametersError';
    constructor(message = 'Invalid parameters') {
        super(message);
        this.name = 'InvalidParametersError';
    }
};
/**
 * Thrown when a public key is invalid
 */
class InvalidPublicKeyError extends Error {
    static name = 'InvalidPublicKeyError';
    constructor(message = 'Invalid public key') {
        super(message);
        this.name = 'InvalidPublicKeyError';
    }
}
/**
 * Thrown when a connection is closing
 */
class ConnectionClosingError extends Error {
    static name = 'ConnectionClosingError';
    constructor(message = 'The connection is closing') {
        super(message);
        this.name = 'ConnectionClosingError';
    }
}
/**
 * Thrown when a connection is closed
 */
class ConnectionClosedError extends Error {
    static name = 'ConnectionClosedError';
    constructor(message = 'The connection is closed') {
        super(message);
        this.name = 'ConnectionClosedError';
    }
}
/**
 * Thrown when a connection fails
 */
class ConnectionFailedError extends Error {
    static name = 'ConnectionFailedError';
    constructor(message = 'Connection failed') {
        super(message);
        this.name = 'ConnectionFailedError';
    }
}
/**
 * Thrown when the muxer is closed and an attempt to open a stream occurs
 */
class MuxerClosedError extends Error {
    static name = 'MuxerClosedError';
    constructor(message = 'The muxer is closed') {
        super(message);
        this.name = 'MuxerClosedError';
    }
}
/**
 * Thrown when a protocol stream is reset by the remote muxer
 */
class StreamResetError extends Error {
    static name = 'StreamResetError';
    constructor(message = 'The stream has been reset') {
        super(message);
        this.name = 'StreamResetError';
    }
}
/**
 * Thrown when a stream is in an invalid state
 */
class StreamStateError extends Error {
    static name = 'StreamStateError';
    constructor(message = 'The stream is in an invalid state') {
        super(message);
        this.name = 'StreamStateError';
    }
}
/**
 * Thrown when a value could not be found
 */
let NotFoundError$1 = class NotFoundError extends Error {
    static name = 'NotFoundError';
    constructor(message = 'Not found') {
        super(message);
        this.name = 'NotFoundError';
    }
};
/**
 * Thrown when an invalid peer ID is encountered
 */
class InvalidPeerIdError extends Error {
    static name = 'InvalidPeerIdError';
    constructor(message = 'Invalid PeerID') {
        super(message);
        this.name = 'InvalidPeerIdError';
    }
}
/**
 * Thrown when an invalid multiaddr is encountered
 */
let InvalidMultiaddrError$1 = class InvalidMultiaddrError extends Error {
    static name = 'InvalidMultiaddrError';
    constructor(message = 'Invalid multiaddr') {
        super(message);
        this.name = 'InvalidMultiaddrError';
    }
};
/**
 * Thrown when an invalid CID is encountered
 */
class InvalidCIDError extends Error {
    static name = 'InvalidCIDError';
    constructor(message = 'Invalid CID') {
        super(message);
        this.name = 'InvalidCIDError';
    }
}
/**
 * Thrown when an invalid multihash is encountered
 */
class InvalidMultihashError extends Error {
    static name = 'InvalidMultihashError';
    constructor(message = 'Invalid Multihash') {
        super(message);
        this.name = 'InvalidMultihashError';
    }
}
/**
 * Thrown when a protocol is not supported
 */
class UnsupportedProtocolError extends Error {
    static name = 'UnsupportedProtocolError';
    constructor(message = 'Unsupported protocol error') {
        super(message);
        this.name = 'UnsupportedProtocolError';
    }
}
/**
 * An invalid or malformed message was encountered during a protocol exchange
 */
class InvalidMessageError extends Error {
    static name = 'InvalidMessageError';
    constructor(message = 'Invalid message') {
        super(message);
        this.name = 'InvalidMessageError';
    }
}
/**
 * Thrown when a remote peer sends a structurally valid message that does not
 * comply with the protocol
 */
class ProtocolError extends Error {
    static name = 'ProtocolError';
    constructor(message = 'Protocol error') {
        super(message);
        this.name = 'ProtocolError';
    }
}
/**
 * Throw when an operation times out
 */
let TimeoutError$1 = class TimeoutError extends Error {
    static name = 'TimeoutError';
    constructor(message = 'Timed out') {
        super(message);
        this.name = 'TimeoutError';
    }
};
/**
 * Thrown when a startable component is interacted with but it has not been
 * started yet
 */
class NotStartedError extends Error {
    static name = 'NotStartedError';
    constructor(message = 'Not started') {
        super(message);
        this.name = 'NotStartedError';
    }
}
/**
 * Thrown when dialing an address failed
 */
class DialError extends Error {
    static name = 'DialError';
    constructor(message = 'Dial error') {
        super(message);
        this.name = 'DialError';
    }
}
/**
 * This error is thrown when a limited connection is encountered, i.e. if the
 * user tried to open a stream on a connection for a protocol that is not
 * configured to run over limited connections.
 */
class LimitedConnectionError extends Error {
    static name = 'LimitedConnectionError';
    constructor(message = 'Limited connection') {
        super(message);
        this.name = 'LimitedConnectionError';
    }
}
/**
 * This error is thrown where there are too many inbound protocols streams open
 */
class TooManyInboundProtocolStreamsError extends Error {
    static name = 'TooManyInboundProtocolStreamsError';
    constructor(message = 'Too many inbound protocol streams') {
        super(message);
        this.name = 'TooManyInboundProtocolStreamsError';
    }
}
/**
 * This error is thrown where there are too many outbound protocols streams open
 */
class TooManyOutboundProtocolStreamsError extends Error {
    static name = 'TooManyOutboundProtocolStreamsError';
    constructor(message = 'Too many outbound protocol streams') {
        super(message);
        this.name = 'TooManyOutboundProtocolStreamsError';
    }
}
/**
 * Thrown when an attempt to operate on an unsupported key was made
 */
class UnsupportedKeyTypeError extends Error {
    static name = 'UnsupportedKeyTypeError';
    constructor(message = 'Unsupported key type') {
        super(message);
        this.name = 'UnsupportedKeyTypeError';
    }
}

/**
 * Noop for browser compatibility
 */
function setMaxListeners() { }

/**
 * @packageDocumentation
 *
 * Adds types to the EventTarget class.
 *
 * Hopefully this won't be necessary
 * forever:
 *
 * - https://github.com/microsoft/TypeScript/issues/28357
 * - https://github.com/microsoft/TypeScript/issues/43477
 * - https://github.com/microsoft/TypeScript/issues/299
 * - https://www.npmjs.com/package/typed-events
 * - https://www.npmjs.com/package/typed-event-emitter
 * - https://www.npmjs.com/package/typed-event-target
 * - etc
 *
 * In addition to types, a `safeDispatchEvent` method is available which
 * prevents dispatching events that aren't in the event map, and a
 * `listenerCount` method which reports the number of listeners that are
 * currently registered for a given event.
 *
 * @example
 *
 * ```ts
 * import { TypedEventEmitter } from 'main-event'
 * import type { TypedEventTarget } from 'main-event'
 *
 * interface EventTypes {
 *   'test': CustomEvent<string>
 * }
 *
 * const target = new TypedEventEmitter<EventTypes>()
 *
 * // it's a regular EventTarget
 * console.info(target instanceof EventTarget) // true
 *
 * // register listeners normally
 * target.addEventListener('test', (evt) => {
 *   // evt is CustomEvent<string>
 * })
 *
 * // @ts-expect-error 'derp' is not in the event map
 * target.addEventListener('derp', () => {})
 *
 * // use normal dispatchEvent method
 * target.dispatchEvent(new CustomEvent('test', {
 *   detail: 'hello'
 * }))
 *
 * // use type safe dispatch method
 * target.safeDispatchEvent('test', {
 *   detail: 'world'
 * })
 *
 * // report listener count
 * console.info(target.listenerCount('test')) // 0
 *
 * // event emitters can be used purely as interfaces too
 * function acceptTarget (target: TypedEventTarget<EventTypes>) {
 *   // ...
 * }
 * ```
 */
/**
 * An implementation of a typed event target
 */
class TypedEventEmitter extends EventTarget {
    #listeners = new Map();
    constructor() {
        super();
    }
    listenerCount(type) {
        const listeners = this.#listeners.get(type);
        if (listeners == null) {
            return 0;
        }
        return listeners.length;
    }
    addEventListener(type, listener, options) {
        super.addEventListener(type, listener, options);
        let list = this.#listeners.get(type);
        if (list == null) {
            list = [];
            this.#listeners.set(type, list);
        }
        list.push({
            callback: listener,
            once: (options !== true && options !== false && options?.once) ?? false
        });
    }
    removeEventListener(type, listener, options) {
        super.removeEventListener(type.toString(), listener ?? null, options);
        let list = this.#listeners.get(type);
        if (list == null) {
            return;
        }
        list = list.filter(({ callback }) => callback !== listener);
        this.#listeners.set(type, list);
    }
    dispatchEvent(event) {
        const result = super.dispatchEvent(event);
        let list = this.#listeners.get(event.type);
        if (list == null) {
            return result;
        }
        list = list.filter(({ once }) => !once);
        this.#listeners.set(event.type, list);
        return result;
    }
    safeDispatchEvent(type, detail = {}) {
        return this.dispatchEvent(new CustomEvent(type, detail));
    }
}

/**
 * Returns `true` if the object has type overlap with `Startable`
 */
function isStartable(obj) {
    return obj != null && typeof obj.start === 'function' && typeof obj.stop === 'function';
}
/**
 * A function that can be used to start and objects passed to it. This checks
 * that an object is startable before invoking its lifecycle methods so it is
 * safe to pass non-`Startable`s in.
 *
 * @example
 *
 * ```TypeScript
 * import { start } from '@libp2p/interface'
 * import type { Startable } from '@libp2p/interface'
 *
 * const startable: Startable = {
 *   start: () => {},
 *   stop: () => {}
 * }
 *
 * const notStartable = 5
 *
 * await start(
 *   startable,
 *   notStartable
 * )
 * ```
 */
async function start(...objs) {
    const startables = [];
    for (const obj of objs) {
        if (isStartable(obj)) {
            startables.push(obj);
        }
    }
    await Promise.all(startables.map(async (s) => {
        if (s.beforeStart != null) {
            await s.beforeStart();
        }
    }));
    await Promise.all(startables.map(async (s) => {
        await s.start();
    }));
    await Promise.all(startables.map(async (s) => {
        if (s.afterStart != null) {
            await s.afterStart();
        }
    }));
}
/**
 * A function that can be used to stop and objects passed to it. This checks
 * that an object is startable before invoking its lifecycle methods so it is
 * safe to pass non-`Startable`s in.
 *
 * @example
 *
 * ```TypeScript
 * import { stop } from '@libp2p/interface'
 * import type { Startable } from '@libp2p/interface'
 *
 * const startable: Startable = {
 *   start: () => {},
 *   stop: () => {}
 * }
 *
 * const notStartable = 5
 *
 * await stop(
 *   startable,
 *   notStartable
 * )
 * ```
 */
async function stop(...objs) {
    const startables = [];
    for (const obj of objs) {
        if (isStartable(obj)) {
            startables.push(obj);
        }
    }
    await Promise.all(startables.map(async (s) => {
        if (s.beforeStop != null) {
            await s.beforeStop();
        }
    }));
    await Promise.all(startables.map(async (s) => {
        await s.stop();
    }));
    await Promise.all(startables.map(async (s) => {
        if (s.afterStop != null) {
            await s.afterStop();
        }
    }));
}

/**
 * @packageDocumentation
 *
 * Exports a `Libp2p` type for modules to use as a type argument.
 *
 * @example
 *
 * ```typescript
 * import type { Libp2p } from '@libp2p/interface'
 *
 * function doSomethingWithLibp2p (node: Libp2p) {
 *   // ...
 * }
 * ```
 */
/**
 * This symbol is used by libp2p services to define the capabilities they can
 * provide to other libp2p services.
 *
 * The service should define a property with this symbol as the key and the
 * value should be a string array of provided capabilities.
 */
const serviceCapabilities = Symbol.for('@libp2p/service-capabilities');
/**
 * This symbol is used by libp2p services to define the capabilities they
 * require from other libp2p services.
 *
 * The service should define a property with this symbol as the key and the
 * value should be a string array of required capabilities.
 */
const serviceDependencies = Symbol.for('@libp2p/service-dependencies');

const TAG_MASK = parseInt('11111', 2);
const LONG_LENGTH_MASK = parseInt('10000000', 2);
const LONG_LENGTH_BYTES_MASK = parseInt('01111111', 2);
const decoders$1 = {
    0x0: readSequence,
    0x1: readSequence,
    0x2: readInteger,
    0x3: readBitString,
    0x4: readOctetString,
    0x5: readNull,
    0x6: readObjectIdentifier,
    0x10: readSequence,
    0x16: readSequence,
    0x30: readSequence
};
function decodeDer(buf, context = { offset: 0 }) {
    const tag = buf[context.offset] & TAG_MASK;
    context.offset++;
    if (decoders$1[tag] != null) {
        return decoders$1[tag](buf, context);
    }
    throw new Error('No decoder for tag ' + tag);
}
function readLength(buf, context) {
    let length = 0;
    if ((buf[context.offset] & LONG_LENGTH_MASK) === LONG_LENGTH_MASK) {
        // long length
        const count = buf[context.offset] & LONG_LENGTH_BYTES_MASK;
        let str = '0x';
        context.offset++;
        for (let i = 0; i < count; i++, context.offset++) {
            str += buf[context.offset].toString(16).padStart(2, '0');
        }
        length = parseInt(str, 16);
    }
    else {
        length = buf[context.offset];
        context.offset++;
    }
    return length;
}
function readSequence(buf, context) {
    readLength(buf, context);
    const entries = [];
    while (true) {
        if (context.offset >= buf.byteLength) {
            break;
        }
        const result = decodeDer(buf, context);
        if (result === null) {
            break;
        }
        entries.push(result);
    }
    return entries;
}
function readInteger(buf, context) {
    const length = readLength(buf, context);
    const start = context.offset;
    const end = context.offset + length;
    const vals = [];
    for (let i = start; i < end; i++) {
        if (i === start && buf[i] === 0) {
            continue;
        }
        vals.push(buf[i]);
    }
    context.offset += length;
    return Uint8Array.from(vals);
}
function readObjectIdentifier(buf, context) {
    const count = readLength(buf, context);
    const finalOffset = context.offset + count;
    const byte = buf[context.offset];
    context.offset++;
    let val1 = 0;
    let val2 = 0;
    if (byte < 40) {
        val1 = 0;
        val2 = byte;
    }
    else if (byte < 80) {
        val1 = 1;
        val2 = byte - 40;
    }
    else {
        val1 = 2;
        val2 = byte - 80;
    }
    let oid = `${val1}.${val2}`;
    let num = [];
    while (context.offset < finalOffset) {
        const byte = buf[context.offset];
        context.offset++;
        // remove msb
        num.push(byte & 0b01111111);
        if (byte < 128) {
            num.reverse();
            // reached the end of the encoding
            let val = 0;
            for (let i = 0; i < num.length; i++) {
                val += num[i] << (i * 7);
            }
            oid += `.${val}`;
            num = [];
        }
    }
    return oid;
}
function readNull(buf, context) {
    context.offset++;
    return null;
}
function readBitString(buf, context) {
    const length = readLength(buf, context);
    const unusedBits = buf[context.offset];
    context.offset++;
    const bytes = buf.subarray(context.offset, context.offset + length - 1);
    context.offset += length;
    if (unusedBits !== 0) {
        // need to shift all bytes along by this many bits
        throw new Error('Unused bits in bit string is unimplemented');
    }
    return bytes;
}
function readOctetString(buf, context) {
    const length = readLength(buf, context);
    const bytes = buf.subarray(context.offset, context.offset + length);
    context.offset += length;
    return bytes;
}
function encodeNumber(value) {
    let number = value.toString(16);
    if (number.length % 2 === 1) {
        number = '0' + number;
    }
    const array = new Uint8ArrayList();
    for (let i = 0; i < number.length; i += 2) {
        array.append(Uint8Array.from([parseInt(`${number[i]}${number[i + 1]}`, 16)]));
    }
    return array;
}
function encodeLength(bytes) {
    if (bytes.byteLength < 128) {
        return Uint8Array.from([bytes.byteLength]);
    }
    // long length
    const length = encodeNumber(bytes.byteLength);
    return new Uint8ArrayList(Uint8Array.from([
        length.byteLength | LONG_LENGTH_MASK
    ]), length);
}
function encodeInteger(value) {
    const contents = new Uint8ArrayList();
    const mask = 0b10000000;
    const positive = (value.subarray()[0] & mask) === mask;
    if (positive) {
        contents.append(Uint8Array.from([0]));
    }
    contents.append(value);
    return new Uint8ArrayList(Uint8Array.from([0x02]), encodeLength(contents), contents);
}
function encodeBitString(value) {
    // unused bits is always 0 with full-byte-only values
    const unusedBits = Uint8Array.from([0]);
    const contents = new Uint8ArrayList(unusedBits, value);
    return new Uint8ArrayList(Uint8Array.from([0x03]), encodeLength(contents), contents);
}
function encodeSequence(values, tag = 0x30) {
    const output = new Uint8ArrayList();
    for (const buf of values) {
        output.append(buf);
    }
    return new Uint8ArrayList(Uint8Array.from([tag]), encodeLength(output), output);
}

const ECDSA_P_256_OID = '1.2.840.10045.3.1.7';
const ECDSA_P_384_OID = '1.3.132.0.34';
const ECDSA_P_521_OID = '1.3.132.0.35';
async function hashAndVerify$3(key, sig, msg, options) {
    const publicKey = await crypto.subtle.importKey('jwk', key, {
        name: 'ECDSA',
        namedCurve: key.crv ?? 'P-256'
    }, false, ['verify']);
    options?.signal?.throwIfAborted();
    const result = await crypto.subtle.verify({
        name: 'ECDSA',
        hash: {
            name: 'SHA-256'
        }
    }, publicKey, sig, msg.subarray());
    options?.signal?.throwIfAborted();
    return result;
}

// 1.2.840.10045.3.1.7 prime256v1 (ANSI X9.62 named elliptic curve)
const OID_256 = Uint8Array.from([0x06, 0x08, 0x2A, 0x86, 0x48, 0xCE, 0x3D, 0x03, 0x01, 0x07]);
// 1.3.132.0.34 secp384r1 (SECG (Certicom) named elliptic curve)
const OID_384 = Uint8Array.from([0x06, 0x05, 0x2B, 0x81, 0x04, 0x00, 0x22]);
// 1.3.132.0.35 secp521r1 (SECG (Certicom) named elliptic curve)
const OID_521 = Uint8Array.from([0x06, 0x05, 0x2B, 0x81, 0x04, 0x00, 0x23]);
const P_256_KEY_JWK = {
    ext: true,
    kty: 'EC',
    crv: 'P-256'
};
const P_384_KEY_JWK = {
    ext: true,
    kty: 'EC',
    crv: 'P-384'
};
const P_521_KEY_JWK = {
    ext: true,
    kty: 'EC',
    crv: 'P-521'
};
const P_256_KEY_LENGTH = 32;
const P_384_KEY_LENGTH = 48;
const P_521_KEY_LENGTH = 66;
function unmarshalECDSAPublicKey(bytes) {
    const message = decodeDer(bytes);
    return pkiMessageToECDSAPublicKey(message);
}
function pkiMessageToECDSAPublicKey(message) {
    const coordinates = message[1][1][0];
    const offset = 1;
    let x;
    let y;
    if (coordinates.byteLength === ((P_256_KEY_LENGTH * 2) + 1)) {
        x = toString(coordinates.subarray(offset, offset + P_256_KEY_LENGTH), 'base64url');
        y = toString(coordinates.subarray(offset + P_256_KEY_LENGTH), 'base64url');
        return new ECDSAPublicKey({
            ...P_256_KEY_JWK,
            key_ops: ['verify'],
            x,
            y
        });
    }
    if (coordinates.byteLength === ((P_384_KEY_LENGTH * 2) + 1)) {
        x = toString(coordinates.subarray(offset, offset + P_384_KEY_LENGTH), 'base64url');
        y = toString(coordinates.subarray(offset + P_384_KEY_LENGTH), 'base64url');
        return new ECDSAPublicKey({
            ...P_384_KEY_JWK,
            key_ops: ['verify'],
            x,
            y
        });
    }
    if (coordinates.byteLength === ((P_521_KEY_LENGTH * 2) + 1)) {
        x = toString(coordinates.subarray(offset, offset + P_521_KEY_LENGTH), 'base64url');
        y = toString(coordinates.subarray(offset + P_521_KEY_LENGTH), 'base64url');
        return new ECDSAPublicKey({
            ...P_521_KEY_JWK,
            key_ops: ['verify'],
            x,
            y
        });
    }
    throw new InvalidParametersError$1(`coordinates were wrong length, got ${coordinates.byteLength}, expected 65, 97 or 133`);
}
function publicKeyToPKIMessage(publicKey) {
    return encodeSequence([
        encodeInteger(Uint8Array.from([1])), // header
        encodeSequence([
            getOID(publicKey.crv)
        ], 0xA0),
        encodeSequence([
            encodeBitString(new Uint8ArrayList(Uint8Array.from([0x04]), fromString(publicKey.x ?? '', 'base64url'), fromString(publicKey.y ?? '', 'base64url')))
        ], 0xA1)
    ]).subarray();
}
function getOID(curve) {
    if (curve === 'P-256') {
        return OID_256;
    }
    if (curve === 'P-384') {
        return OID_384;
    }
    if (curve === 'P-521') {
        return OID_521;
    }
    throw new InvalidParametersError$1(`Invalid curve ${curve}`);
}

class ECDSAPublicKey {
    type = 'ECDSA';
    jwk;
    _raw;
    constructor(jwk) {
        this.jwk = jwk;
    }
    get raw() {
        if (this._raw == null) {
            this._raw = publicKeyToPKIMessage(this.jwk);
        }
        return this._raw;
    }
    toMultihash() {
        return identity.digest(publicKeyToProtobuf(this));
    }
    toCID() {
        return CID.createV1(114, this.toMultihash());
    }
    toString() {
        return base58btc.encode(this.toMultihash().bytes).substring(1);
    }
    equals(key) {
        if (key == null || !(key.raw instanceof Uint8Array)) {
            return false;
        }
        return equals(this.raw, key.raw);
    }
    async verify(data, sig, options) {
        return hashAndVerify$3(this.jwk, sig, data, options);
    }
}

/**
 * Hex, bytes and number utilities.
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
const _0n$6 = /* @__PURE__ */ BigInt(0);
const _1n$8 = /* @__PURE__ */ BigInt(1);
function abool$1(title, value) {
    if (typeof value !== 'boolean')
        throw new Error(title + ' boolean expected, got ' + value);
}
// Used in weierstrass, der
function numberToHexUnpadded$1(num) {
    const hex = num.toString(16);
    return hex.length & 1 ? '0' + hex : hex;
}
function hexToNumber$1(hex) {
    if (typeof hex !== 'string')
        throw new Error('hex string expected, got ' + typeof hex);
    return hex === '' ? _0n$6 : BigInt('0x' + hex); // Big Endian
}
// BE: Big Endian, LE: Little Endian
function bytesToNumberBE(bytes) {
    return hexToNumber$1(bytesToHex$2(bytes));
}
function bytesToNumberLE(bytes) {
    abytes$2(bytes);
    return hexToNumber$1(bytesToHex$2(Uint8Array.from(bytes).reverse()));
}
function numberToBytesBE(n, len) {
    return hexToBytes$2(n.toString(16).padStart(len * 2, '0'));
}
function numberToBytesLE(n, len) {
    return numberToBytesBE(n, len).reverse();
}
/**
 * Takes hex string or Uint8Array, converts to Uint8Array.
 * Validates output length.
 * Will throw error for other types.
 * @param title descriptive title for an error e.g. 'private key'
 * @param hex hex string or Uint8Array
 * @param expectedLength optional, will compare to result array's length
 * @returns
 */
function ensureBytes$1(title, hex, expectedLength) {
    let res;
    if (typeof hex === 'string') {
        try {
            res = hexToBytes$2(hex);
        }
        catch (e) {
            throw new Error(title + ' must be hex string or Uint8Array, cause: ' + e);
        }
    }
    else if (isBytes$3(hex)) {
        // Uint8Array.from() instead of hash.slice() because node.js Buffer
        // is instance of Uint8Array, and its slice() creates **mutable** copy
        res = Uint8Array.from(hex);
    }
    else {
        throw new Error(title + ' must be hex string or Uint8Array');
    }
    const len = res.length;
    if (typeof expectedLength === 'number' && len !== expectedLength)
        throw new Error(title + ' of length ' + expectedLength + ' expected, got ' + len);
    return res;
}
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
// export const utf8ToBytes: typeof utf8ToBytes_ = utf8ToBytes_;
/**
 * Converts bytes to string using UTF8 encoding.
 * @example bytesToUtf8(Uint8Array.from([97, 98, 99])) // 'abc'
 */
// export const bytesToUtf8: typeof bytesToUtf8_ = bytesToUtf8_;
// Is positive bigint
const isPosBig = (n) => typeof n === 'bigint' && _0n$6 <= n;
function inRange(n, min, max) {
    return isPosBig(n) && isPosBig(min) && isPosBig(max) && min <= n && n < max;
}
/**
 * Asserts min <= n < max. NOTE: It's < max and not <= max.
 * @example
 * aInRange('x', x, 1n, 256n); // would assume x is in (1n..255n)
 */
function aInRange(title, n, min, max) {
    // Why min <= n < max and not a (min < n < max) OR b (min <= n <= max)?
    // consider P=256n, min=0n, max=P
    // - a for min=0 would require -1:          `inRange('x', x, -1n, P)`
    // - b would commonly require subtraction:  `inRange('x', x, 0n, P - 1n)`
    // - our way is the cleanest:               `inRange('x', x, 0n, P)
    if (!inRange(n, min, max))
        throw new Error('expected valid ' + title + ': ' + min + ' <= n < ' + max + ', got ' + n);
}
// Bit operations
/**
 * Calculates amount of bits in a bigint.
 * Same as `n.toString(2).length`
 * TODO: merge with nLength in modular
 */
function bitLen(n) {
    let len;
    for (len = 0; n > _0n$6; n >>= _1n$8, len += 1)
        ;
    return len;
}
/**
 * Calculate mask for N bits. Not using ** operator with bigints because of old engines.
 * Same as BigInt(`0b${Array(i).fill('1').join('')}`)
 */
const bitMask = (n) => (_1n$8 << BigInt(n)) - _1n$8;
/**
 * Minimal HMAC-DRBG from NIST 800-90 for RFC6979 sigs.
 * @returns function that will call DRBG until 2nd arg returns something meaningful
 * @example
 *   const drbg = createHmacDRBG<Key>(32, 32, hmac);
 *   drbg(seed, bytesToKey); // bytesToKey must return Key or undefined
 */
function createHmacDrbg(hashLen, qByteLen, hmacFn) {
    if (typeof hashLen !== 'number' || hashLen < 2)
        throw new Error('hashLen must be a number');
    if (typeof qByteLen !== 'number' || qByteLen < 2)
        throw new Error('qByteLen must be a number');
    if (typeof hmacFn !== 'function')
        throw new Error('hmacFn must be a function');
    // Step B, Step C: set hashLen to 8*ceil(hlen/8)
    const u8n = (len) => new Uint8Array(len); // creates Uint8Array
    const u8of = (byte) => Uint8Array.of(byte); // another shortcut
    let v = u8n(hashLen); // Minimal non-full-spec HMAC-DRBG from NIST 800-90 for RFC6979 sigs.
    let k = u8n(hashLen); // Steps B and C of RFC6979 3.2: set hashLen, in our case always same
    let i = 0; // Iterations counter, will throw when over 1000
    const reset = () => {
        v.fill(1);
        k.fill(0);
        i = 0;
    };
    const h = (...b) => hmacFn(k, v, ...b); // hmac(k)(v, ...values)
    const reseed = (seed = u8n(0)) => {
        // HMAC-DRBG reseed() function. Steps D-G
        k = h(u8of(0x00), seed); // k = hmac(k || v || 0x00 || seed)
        v = h(); // v = hmac(k || v)
        if (seed.length === 0)
            return;
        k = h(u8of(0x01), seed); // k = hmac(k || v || 0x01 || seed)
        v = h(); // v = hmac(k || v)
    };
    const gen = () => {
        // HMAC-DRBG generate() function
        if (i++ >= 1000)
            throw new Error('drbg: tried 1000 values');
        let len = 0;
        const out = [];
        while (len < qByteLen) {
            v = h();
            const sl = v.slice();
            out.push(sl);
            len += v.length;
        }
        return concatBytes$1(...out);
    };
    const genUntil = (seed, pred) => {
        reset();
        reseed(seed); // Steps D-G
        let res = undefined; // Step H: grind until k is in [1..n-1]
        while (!(res = pred(gen())))
            reseed();
        reset();
        return res;
    };
    return genUntil;
}
function _validateObject(object, fields, optFields = {}) {
    if (!object || typeof object !== 'object')
        throw new Error('expected valid options object');
    function checkField(fieldName, expectedType, isOpt) {
        const val = object[fieldName];
        if (isOpt && val === undefined)
            return;
        const current = typeof val;
        if (current !== expectedType || val === null)
            throw new Error(`param "${fieldName}" is invalid: expected ${expectedType}, got ${current}`);
    }
    Object.entries(fields).forEach(([k, v]) => checkField(k, v, false));
    Object.entries(optFields).forEach(([k, v]) => checkField(k, v, true));
}
/**
 * Memoizes (caches) computation result.
 * Uses WeakMap: the value is going auto-cleaned by GC after last reference is removed.
 */
function memoized(fn) {
    const map = new WeakMap();
    return (arg, ...args) => {
        const val = map.get(arg);
        if (val !== undefined)
            return val;
        const computed = fn(arg, ...args);
        map.set(arg, computed);
        return computed;
    };
}

/**
 * Utils for modular division and fields.
 * Field over 11 is a finite (Galois) field is integer number operations `mod 11`.
 * There is no division: it is replaced by modular multiplicative inverse.
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// prettier-ignore
const _0n$5 = BigInt(0), _1n$7 = BigInt(1), _2n$6 = /* @__PURE__ */ BigInt(2), _3n$3 = /* @__PURE__ */ BigInt(3);
// prettier-ignore
const _4n$1 = /* @__PURE__ */ BigInt(4), _5n$1 = /* @__PURE__ */ BigInt(5);
const _8n$3 = /* @__PURE__ */ BigInt(8);
// Calculates a modulo b
function mod$1(a, b) {
    const result = a % b;
    return result >= _0n$5 ? result : b + result;
}
/** Does `x^(2^power)` mod p. `pow2(30, 4)` == `30^(2^4)` */
function pow2$1(x, power, modulo) {
    let res = x;
    while (power-- > _0n$5) {
        res *= res;
        res %= modulo;
    }
    return res;
}
/**
 * Inverses number over modulo.
 * Implemented using [Euclidean GCD](https://brilliant.org/wiki/extended-euclidean-algorithm/).
 */
function invert$1(number, modulo) {
    if (number === _0n$5)
        throw new Error('invert: expected non-zero number');
    if (modulo <= _0n$5)
        throw new Error('invert: expected positive modulus, got ' + modulo);
    // Fermat's little theorem "CT-like" version inv(n) = n^(m-2) mod m is 30x slower.
    let a = mod$1(number, modulo);
    let b = modulo;
    // prettier-ignore
    let x = _0n$5, u = _1n$7;
    while (a !== _0n$5) {
        // JIT applies optimization if those two lines follow each other
        const q = b / a;
        const r = b % a;
        const m = x - u * q;
        // prettier-ignore
        b = a, a = r, x = u, u = m;
    }
    const gcd = b;
    if (gcd !== _1n$7)
        throw new Error('invert: does not exist');
    return mod$1(x, modulo);
}
// Not all roots are possible! Example which will throw:
// const NUM =
// n = 72057594037927816n;
// Fp = Field(BigInt('0x1a0111ea397fe69a4b1ba7b6434bacd764774b84f38512bf6730d2a0f6b0f6241eabfffeb153ffffb9feffffffffaaab'));
function sqrt3mod4(Fp, n) {
    const p1div4 = (Fp.ORDER + _1n$7) / _4n$1;
    const root = Fp.pow(n, p1div4);
    // Throw if root^2 != n
    if (!Fp.eql(Fp.sqr(root), n))
        throw new Error('Cannot find square root');
    return root;
}
function sqrt5mod8(Fp, n) {
    const p5div8 = (Fp.ORDER - _5n$1) / _8n$3;
    const n2 = Fp.mul(n, _2n$6);
    const v = Fp.pow(n2, p5div8);
    const nv = Fp.mul(n, v);
    const i = Fp.mul(Fp.mul(nv, _2n$6), v);
    const root = Fp.mul(nv, Fp.sub(i, Fp.ONE));
    if (!Fp.eql(Fp.sqr(root), n))
        throw new Error('Cannot find square root');
    return root;
}
// TODO: Commented-out for now. Provide test vectors.
// Tonelli is too slow for extension fields Fp2.
// That means we can't use sqrt (c1, c2...) even for initialization constants.
// if (P % _16n === _9n) return sqrt9mod16;
// // prettier-ignore
// function sqrt9mod16<T>(Fp: IField<T>, n: T, p7div16?: bigint) {
//   if (p7div16 === undefined) p7div16 = (Fp.ORDER + BigInt(7)) / _16n;
//   const c1 = Fp.sqrt(Fp.neg(Fp.ONE)); //  1. c1 = sqrt(-1) in F, i.e., (c1^2) == -1 in F
//   const c2 = Fp.sqrt(c1);             //  2. c2 = sqrt(c1) in F, i.e., (c2^2) == c1 in F
//   const c3 = Fp.sqrt(Fp.neg(c1));     //  3. c3 = sqrt(-c1) in F, i.e., (c3^2) == -c1 in F
//   const c4 = p7div16;                 //  4. c4 = (q + 7) / 16        # Integer arithmetic
//   let tv1 = Fp.pow(n, c4);            //  1. tv1 = x^c4
//   let tv2 = Fp.mul(c1, tv1);          //  2. tv2 = c1 * tv1
//   const tv3 = Fp.mul(c2, tv1);        //  3. tv3 = c2 * tv1
//   let tv4 = Fp.mul(c3, tv1);          //  4. tv4 = c3 * tv1
//   const e1 = Fp.eql(Fp.sqr(tv2), n);  //  5.  e1 = (tv2^2) == x
//   const e2 = Fp.eql(Fp.sqr(tv3), n);  //  6.  e2 = (tv3^2) == x
//   tv1 = Fp.cmov(tv1, tv2, e1); //  7. tv1 = CMOV(tv1, tv2, e1)  # Select tv2 if (tv2^2) == x
//   tv2 = Fp.cmov(tv4, tv3, e2); //  8. tv2 = CMOV(tv4, tv3, e2)  # Select tv3 if (tv3^2) == x
//   const e3 = Fp.eql(Fp.sqr(tv2), n);  //  9.  e3 = (tv2^2) == x
//   return Fp.cmov(tv1, tv2, e3); // 10.  z = CMOV(tv1, tv2, e3) # Select the sqrt from tv1 and tv2
// }
/**
 * Tonelli-Shanks square root search algorithm.
 * 1. https://eprint.iacr.org/2012/685.pdf (page 12)
 * 2. Square Roots from 1; 24, 51, 10 to Dan Shanks
 * @param P field order
 * @returns function that takes field Fp (created from P) and number n
 */
function tonelliShanks(P) {
    // Initialization (precomputation).
    // Caching initialization could boost perf by 7%.
    if (P < BigInt(3))
        throw new Error('sqrt is not defined for small field');
    // Factor P - 1 = Q * 2^S, where Q is odd
    let Q = P - _1n$7;
    let S = 0;
    while (Q % _2n$6 === _0n$5) {
        Q /= _2n$6;
        S++;
    }
    // Find the first quadratic non-residue Z >= 2
    let Z = _2n$6;
    const _Fp = Field(P);
    while (FpLegendre(_Fp, Z) === 1) {
        // Basic primality test for P. After x iterations, chance of
        // not finding quadratic non-residue is 2^x, so 2^1000.
        if (Z++ > 1000)
            throw new Error('Cannot find square root: probably non-prime P');
    }
    // Fast-path; usually done before Z, but we do "primality test".
    if (S === 1)
        return sqrt3mod4;
    // Slow-path
    // TODO: test on Fp2 and others
    let cc = _Fp.pow(Z, Q); // c = z^Q
    const Q1div2 = (Q + _1n$7) / _2n$6;
    return function tonelliSlow(Fp, n) {
        if (Fp.is0(n))
            return n;
        // Check if n is a quadratic residue using Legendre symbol
        if (FpLegendre(Fp, n) !== 1)
            throw new Error('Cannot find square root');
        // Initialize variables for the main loop
        let M = S;
        let c = Fp.mul(Fp.ONE, cc); // c = z^Q, move cc from field _Fp into field Fp
        let t = Fp.pow(n, Q); // t = n^Q, first guess at the fudge factor
        let R = Fp.pow(n, Q1div2); // R = n^((Q+1)/2), first guess at the square root
        // Main loop
        // while t != 1
        while (!Fp.eql(t, Fp.ONE)) {
            if (Fp.is0(t))
                return Fp.ZERO; // if t=0 return R=0
            let i = 1;
            // Find the smallest i >= 1 such that t^(2^i) ≡ 1 (mod P)
            let t_tmp = Fp.sqr(t); // t^(2^1)
            while (!Fp.eql(t_tmp, Fp.ONE)) {
                i++;
                t_tmp = Fp.sqr(t_tmp); // t^(2^2)...
                if (i === M)
                    throw new Error('Cannot find square root');
            }
            // Calculate the exponent for b: 2^(M - i - 1)
            const exponent = _1n$7 << BigInt(M - i - 1); // bigint is important
            const b = Fp.pow(c, exponent); // b = 2^(M - i - 1)
            // Update variables
            M = i;
            c = Fp.sqr(b); // c = b^2
            t = Fp.mul(t, c); // t = (t * b^2)
            R = Fp.mul(R, b); // R = R*b
        }
        return R;
    };
}
/**
 * Square root for a finite field. Will try optimized versions first:
 *
 * 1. P ≡ 3 (mod 4)
 * 2. P ≡ 5 (mod 8)
 * 3. Tonelli-Shanks algorithm
 *
 * Different algorithms can give different roots, it is up to user to decide which one they want.
 * For example there is FpSqrtOdd/FpSqrtEven to choice root based on oddness (used for hash-to-curve).
 */
function FpSqrt(P) {
    // P ≡ 3 (mod 4) => √n = n^((P+1)/4)
    if (P % _4n$1 === _3n$3)
        return sqrt3mod4;
    // P ≡ 5 (mod 8) => Atkin algorithm, page 10 of https://eprint.iacr.org/2012/685.pdf
    if (P % _8n$3 === _5n$1)
        return sqrt5mod8;
    // P ≡ 9 (mod 16) not implemented, see above
    // Tonelli-Shanks algorithm
    return tonelliShanks(P);
}
// Little-endian check for first LE bit (last BE bit);
const isNegativeLE = (num, modulo) => (mod$1(num, modulo) & _1n$7) === _1n$7;
// prettier-ignore
const FIELD_FIELDS = [
    'create', 'isValid', 'is0', 'neg', 'inv', 'sqrt', 'sqr',
    'eql', 'add', 'sub', 'mul', 'pow', 'div',
    'addN', 'subN', 'mulN', 'sqrN'
];
function validateField(field) {
    const initial = {
        ORDER: 'bigint',
        MASK: 'bigint',
        BYTES: 'number',
        BITS: 'number',
    };
    const opts = FIELD_FIELDS.reduce((map, val) => {
        map[val] = 'function';
        return map;
    }, initial);
    _validateObject(field, opts);
    // const max = 16384;
    // if (field.BYTES < 1 || field.BYTES > max) throw new Error('invalid field');
    // if (field.BITS < 1 || field.BITS > 8 * max) throw new Error('invalid field');
    return field;
}
// Generic field functions
/**
 * Same as `pow` but for Fp: non-constant-time.
 * Unsafe in some contexts: uses ladder, so can expose bigint bits.
 */
function FpPow(Fp, num, power) {
    if (power < _0n$5)
        throw new Error('invalid exponent, negatives unsupported');
    if (power === _0n$5)
        return Fp.ONE;
    if (power === _1n$7)
        return num;
    let p = Fp.ONE;
    let d = num;
    while (power > _0n$5) {
        if (power & _1n$7)
            p = Fp.mul(p, d);
        d = Fp.sqr(d);
        power >>= _1n$7;
    }
    return p;
}
/**
 * Efficiently invert an array of Field elements.
 * Exception-free. Will return `undefined` for 0 elements.
 * @param passZero map 0 to 0 (instead of undefined)
 */
function FpInvertBatch(Fp, nums, passZero = false) {
    const inverted = new Array(nums.length).fill(passZero ? Fp.ZERO : undefined);
    // Walk from first to last, multiply them by each other MOD p
    const multipliedAcc = nums.reduce((acc, num, i) => {
        if (Fp.is0(num))
            return acc;
        inverted[i] = acc;
        return Fp.mul(acc, num);
    }, Fp.ONE);
    // Invert last element
    const invertedAcc = Fp.inv(multipliedAcc);
    // Walk from last to first, multiply them by inverted each other MOD p
    nums.reduceRight((acc, num, i) => {
        if (Fp.is0(num))
            return acc;
        inverted[i] = Fp.mul(acc, inverted[i]);
        return Fp.mul(acc, num);
    }, invertedAcc);
    return inverted;
}
/**
 * Legendre symbol.
 * Legendre constant is used to calculate Legendre symbol (a | p)
 * which denotes the value of a^((p-1)/2) (mod p).
 *
 * * (a | p) ≡ 1    if a is a square (mod p), quadratic residue
 * * (a | p) ≡ -1   if a is not a square (mod p), quadratic non residue
 * * (a | p) ≡ 0    if a ≡ 0 (mod p)
 */
function FpLegendre(Fp, n) {
    // We can use 3rd argument as optional cache of this value
    // but seems unneeded for now. The operation is very fast.
    const p1mod2 = (Fp.ORDER - _1n$7) / _2n$6;
    const powered = Fp.pow(n, p1mod2);
    const yes = Fp.eql(powered, Fp.ONE);
    const zero = Fp.eql(powered, Fp.ZERO);
    const no = Fp.eql(powered, Fp.neg(Fp.ONE));
    if (!yes && !zero && !no)
        throw new Error('invalid Legendre symbol result');
    return yes ? 1 : zero ? 0 : -1;
}
// CURVE.n lengths
function nLength(n, nBitLength) {
    // Bit size, byte size of CURVE.n
    if (nBitLength !== undefined)
        anumber$1(nBitLength);
    const _nBitLength = nBitLength !== undefined ? nBitLength : n.toString(2).length;
    const nByteLength = Math.ceil(_nBitLength / 8);
    return { nBitLength: _nBitLength, nByteLength };
}
/**
 * Creates a finite field. Major performance optimizations:
 * * 1. Denormalized operations like mulN instead of mul.
 * * 2. Identical object shape: never add or remove keys.
 * * 3. `Object.freeze`.
 * Fragile: always run a benchmark on a change.
 * Security note: operations don't check 'isValid' for all elements for performance reasons,
 * it is caller responsibility to check this.
 * This is low-level code, please make sure you know what you're doing.
 *
 * Note about field properties:
 * * CHARACTERISTIC p = prime number, number of elements in main subgroup.
 * * ORDER q = similar to cofactor in curves, may be composite `q = p^m`.
 *
 * @param ORDER field order, probably prime, or could be composite
 * @param bitLen how many bits the field consumes
 * @param isLE (default: false) if encoding / decoding should be in little-endian
 * @param redef optional faster redefinitions of sqrt and other methods
 */
function Field(ORDER, bitLenOrOpts, isLE = false, opts = {}) {
    if (ORDER <= _0n$5)
        throw new Error('invalid field: expected ORDER > 0, got ' + ORDER);
    let _nbitLength = undefined;
    let _sqrt = undefined;
    if (typeof bitLenOrOpts === 'object' && bitLenOrOpts != null) {
        if (opts.sqrt || isLE)
            throw new Error('cannot specify opts in two arguments');
        const _opts = bitLenOrOpts;
        if (_opts.BITS)
            _nbitLength = _opts.BITS;
        if (_opts.sqrt)
            _sqrt = _opts.sqrt;
        if (typeof _opts.isLE === 'boolean')
            isLE = _opts.isLE;
    }
    else {
        if (typeof bitLenOrOpts === 'number')
            _nbitLength = bitLenOrOpts;
        if (opts.sqrt)
            _sqrt = opts.sqrt;
    }
    const { nBitLength: BITS, nByteLength: BYTES } = nLength(ORDER, _nbitLength);
    if (BYTES > 2048)
        throw new Error('invalid field: expected ORDER of <= 2048 bytes');
    let sqrtP; // cached sqrtP
    const f = Object.freeze({
        ORDER,
        isLE,
        BITS,
        BYTES,
        MASK: bitMask(BITS),
        ZERO: _0n$5,
        ONE: _1n$7,
        create: (num) => mod$1(num, ORDER),
        isValid: (num) => {
            if (typeof num !== 'bigint')
                throw new Error('invalid field element: expected bigint, got ' + typeof num);
            return _0n$5 <= num && num < ORDER; // 0 is valid element, but it's not invertible
        },
        is0: (num) => num === _0n$5,
        // is valid and invertible
        isValidNot0: (num) => !f.is0(num) && f.isValid(num),
        isOdd: (num) => (num & _1n$7) === _1n$7,
        neg: (num) => mod$1(-num, ORDER),
        eql: (lhs, rhs) => lhs === rhs,
        sqr: (num) => mod$1(num * num, ORDER),
        add: (lhs, rhs) => mod$1(lhs + rhs, ORDER),
        sub: (lhs, rhs) => mod$1(lhs - rhs, ORDER),
        mul: (lhs, rhs) => mod$1(lhs * rhs, ORDER),
        pow: (num, power) => FpPow(f, num, power),
        div: (lhs, rhs) => mod$1(lhs * invert$1(rhs, ORDER), ORDER),
        // Same as above, but doesn't normalize
        sqrN: (num) => num * num,
        addN: (lhs, rhs) => lhs + rhs,
        subN: (lhs, rhs) => lhs - rhs,
        mulN: (lhs, rhs) => lhs * rhs,
        inv: (num) => invert$1(num, ORDER),
        sqrt: _sqrt ||
            ((n) => {
                if (!sqrtP)
                    sqrtP = FpSqrt(ORDER);
                return sqrtP(f, n);
            }),
        toBytes: (num) => (isLE ? numberToBytesLE(num, BYTES) : numberToBytesBE(num, BYTES)),
        fromBytes: (bytes) => {
            if (bytes.length !== BYTES)
                throw new Error('Field.fromBytes: expected ' + BYTES + ' bytes, got ' + bytes.length);
            return isLE ? bytesToNumberLE(bytes) : bytesToNumberBE(bytes);
        },
        // TODO: we don't need it here, move out to separate fn
        invertBatch: (lst) => FpInvertBatch(f, lst),
        // We can't move this out because Fp6, Fp12 implement it
        // and it's unclear what to return in there.
        cmov: (a, b, c) => (c ? b : a),
    });
    return Object.freeze(f);
}
/**
 * Returns total number of bytes consumed by the field element.
 * For example, 32 bytes for usual 256-bit weierstrass curve.
 * @param fieldOrder number of field elements, usually CURVE.n
 * @returns byte length of field
 */
function getFieldBytesLength(fieldOrder) {
    if (typeof fieldOrder !== 'bigint')
        throw new Error('field order must be bigint');
    const bitLength = fieldOrder.toString(2).length;
    return Math.ceil(bitLength / 8);
}
/**
 * Returns minimal amount of bytes that can be safely reduced
 * by field order.
 * Should be 2^-128 for 128-bit curve such as P256.
 * @param fieldOrder number of field elements, usually CURVE.n
 * @returns byte length of target hash
 */
function getMinHashLength(fieldOrder) {
    const length = getFieldBytesLength(fieldOrder);
    return length + Math.ceil(length / 2);
}
/**
 * "Constant-time" private key generation utility.
 * Can take (n + n/2) or more bytes of uniform input e.g. from CSPRNG or KDF
 * and convert them into private scalar, with the modulo bias being negligible.
 * Needs at least 48 bytes of input for 32-byte private key.
 * https://research.kudelskisecurity.com/2020/07/28/the-definitive-guide-to-modulo-bias-and-how-to-avoid-it/
 * FIPS 186-5, A.2 https://csrc.nist.gov/publications/detail/fips/186/5/final
 * RFC 9380, https://www.rfc-editor.org/rfc/rfc9380#section-5
 * @param hash hash output from SHA3 or a similar function
 * @param groupOrder size of subgroup - (e.g. secp256k1.CURVE.n)
 * @param isLE interpret hash bytes as LE num
 * @returns valid private scalar
 */
function mapHashToField(key, fieldOrder, isLE = false) {
    const len = key.length;
    const fieldLen = getFieldBytesLength(fieldOrder);
    const minLen = getMinHashLength(fieldOrder);
    // No small numbers: need to understand bias story. No huge numbers: easier to detect JS timings.
    if (len < 16 || len < minLen || len > 1024)
        throw new Error('expected ' + minLen + '-1024 bytes of input, got ' + len);
    const num = isLE ? bytesToNumberLE(key) : bytesToNumberBE(key);
    // `mod(x, 11)` can sometimes produce 0. `mod(x, 10) + 1` is the same, but no 0
    const reduced = mod$1(num, fieldOrder - _1n$7) + _1n$7;
    return isLE ? numberToBytesLE(reduced, fieldLen) : numberToBytesBE(reduced, fieldLen);
}

/**
 * Methods for elliptic curve multiplication by scalars.
 * Contains wNAF, pippenger
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
const _0n$4 = BigInt(0);
const _1n$6 = BigInt(1);
function negateCt(condition, item) {
    const neg = item.negate();
    return condition ? neg : item;
}
/**
 * Takes a bunch of Projective Points but executes only one
 * inversion on all of them. Inversion is very slow operation,
 * so this improves performance massively.
 * Optimization: converts a list of projective points to a list of identical points with Z=1.
 */
function normalizeZ(c, property, points) {
    const getz = property === 'pz' ? (p) => p.pz : (p) => p.ez;
    const toInv = FpInvertBatch(c.Fp, points.map(getz));
    // @ts-ignore
    const affined = points.map((p, i) => p.toAffine(toInv[i]));
    return affined.map(c.fromAffine);
}
function validateW(W, bits) {
    if (!Number.isSafeInteger(W) || W <= 0 || W > bits)
        throw new Error('invalid window size, expected [1..' + bits + '], got W=' + W);
}
function calcWOpts(W, scalarBits) {
    validateW(W, scalarBits);
    const windows = Math.ceil(scalarBits / W) + 1; // W=8 33. Not 32, because we skip zero
    const windowSize = 2 ** (W - 1); // W=8 128. Not 256, because we skip zero
    const maxNumber = 2 ** W; // W=8 256
    const mask = bitMask(W); // W=8 255 == mask 0b11111111
    const shiftBy = BigInt(W); // W=8 8
    return { windows, windowSize, mask, maxNumber, shiftBy };
}
function calcOffsets(n, window, wOpts) {
    const { windowSize, mask, maxNumber, shiftBy } = wOpts;
    let wbits = Number(n & mask); // extract W bits.
    let nextN = n >> shiftBy; // shift number by W bits.
    // What actually happens here:
    // const highestBit = Number(mask ^ (mask >> 1n));
    // let wbits2 = wbits - 1; // skip zero
    // if (wbits2 & highestBit) { wbits2 ^= Number(mask); // (~);
    // split if bits > max: +224 => 256-32
    if (wbits > windowSize) {
        // we skip zero, which means instead of `>= size-1`, we do `> size`
        wbits -= maxNumber; // -32, can be maxNumber - wbits, but then we need to set isNeg here.
        nextN += _1n$6; // +256 (carry)
    }
    const offsetStart = window * windowSize;
    const offset = offsetStart + Math.abs(wbits) - 1; // -1 because we skip zero
    const isZero = wbits === 0; // is current window slice a 0?
    const isNeg = wbits < 0; // is current window slice negative?
    const isNegF = window % 2 !== 0; // fake random statement for noise
    const offsetF = offsetStart; // fake offset for noise
    return { nextN, offset, isZero, isNeg, isNegF, offsetF };
}
function validateMSMPoints(points, c) {
    if (!Array.isArray(points))
        throw new Error('array expected');
    points.forEach((p, i) => {
        if (!(p instanceof c))
            throw new Error('invalid point at index ' + i);
    });
}
function validateMSMScalars(scalars, field) {
    if (!Array.isArray(scalars))
        throw new Error('array of scalars expected');
    scalars.forEach((s, i) => {
        if (!field.isValid(s))
            throw new Error('invalid scalar at index ' + i);
    });
}
// Since points in different groups cannot be equal (different object constructor),
// we can have single place to store precomputes.
// Allows to make points frozen / immutable.
const pointPrecomputes$1 = new WeakMap();
const pointWindowSizes = new WeakMap();
function getW(P) {
    return pointWindowSizes.get(P) || 1;
}
function assert0(n) {
    if (n !== _0n$4)
        throw new Error('invalid wNAF');
}
/**
 * Elliptic curve multiplication of Point by scalar. Fragile.
 * Scalars should always be less than curve order: this should be checked inside of a curve itself.
 * Creates precomputation tables for fast multiplication:
 * - private scalar is split by fixed size windows of W bits
 * - every window point is collected from window's table & added to accumulator
 * - since windows are different, same point inside tables won't be accessed more than once per calc
 * - each multiplication is 'Math.ceil(CURVE_ORDER / 𝑊) + 1' point additions (fixed for any scalar)
 * - +1 window is neccessary for wNAF
 * - wNAF reduces table size: 2x less memory + 2x faster generation, but 10% slower multiplication
 *
 * @todo Research returning 2d JS array of windows, instead of a single window.
 * This would allow windows to be in different memory locations
 */
function wNAF(c, bits) {
    return {
        constTimeNegate: negateCt,
        hasPrecomputes(elm) {
            return getW(elm) !== 1;
        },
        // non-const time multiplication ladder
        unsafeLadder(elm, n, p = c.ZERO) {
            let d = elm;
            while (n > _0n$4) {
                if (n & _1n$6)
                    p = p.add(d);
                d = d.double();
                n >>= _1n$6;
            }
            return p;
        },
        /**
         * Creates a wNAF precomputation window. Used for caching.
         * Default window size is set by `utils.precompute()` and is equal to 8.
         * Number of precomputed points depends on the curve size:
         * 2^(𝑊−1) * (Math.ceil(𝑛 / 𝑊) + 1), where:
         * - 𝑊 is the window size
         * - 𝑛 is the bitlength of the curve order.
         * For a 256-bit curve and window size 8, the number of precomputed points is 128 * 33 = 4224.
         * @param elm Point instance
         * @param W window size
         * @returns precomputed point tables flattened to a single array
         */
        precomputeWindow(elm, W) {
            const { windows, windowSize } = calcWOpts(W, bits);
            const points = [];
            let p = elm;
            let base = p;
            for (let window = 0; window < windows; window++) {
                base = p;
                points.push(base);
                // i=1, bc we skip 0
                for (let i = 1; i < windowSize; i++) {
                    base = base.add(p);
                    points.push(base);
                }
                p = base.double();
            }
            return points;
        },
        /**
         * Implements ec multiplication using precomputed tables and w-ary non-adjacent form.
         * @param W window size
         * @param precomputes precomputed tables
         * @param n scalar (we don't check here, but should be less than curve order)
         * @returns real and fake (for const-time) points
         */
        wNAF(W, precomputes, n) {
            // Smaller version:
            // https://github.com/paulmillr/noble-secp256k1/blob/47cb1669b6e506ad66b35fe7d76132ae97465da2/index.ts#L502-L541
            // TODO: check the scalar is less than group order?
            // wNAF behavior is undefined otherwise. But have to carefully remove
            // other checks before wNAF. ORDER == bits here.
            // Accumulators
            let p = c.ZERO;
            let f = c.BASE;
            // This code was first written with assumption that 'f' and 'p' will never be infinity point:
            // since each addition is multiplied by 2 ** W, it cannot cancel each other. However,
            // there is negate now: it is possible that negated element from low value
            // would be the same as high element, which will create carry into next window.
            // It's not obvious how this can fail, but still worth investigating later.
            const wo = calcWOpts(W, bits);
            for (let window = 0; window < wo.windows; window++) {
                // (n === _0n) is handled and not early-exited. isEven and offsetF are used for noise
                const { nextN, offset, isZero, isNeg, isNegF, offsetF } = calcOffsets(n, window, wo);
                n = nextN;
                if (isZero) {
                    // bits are 0: add garbage to fake point
                    // Important part for const-time getPublicKey: add random "noise" point to f.
                    f = f.add(negateCt(isNegF, precomputes[offsetF]));
                }
                else {
                    // bits are 1: add to result point
                    p = p.add(negateCt(isNeg, precomputes[offset]));
                }
            }
            assert0(n);
            // Return both real and fake points: JIT won't eliminate f.
            // At this point there is a way to F be infinity-point even if p is not,
            // which makes it less const-time: around 1 bigint multiply.
            return { p, f };
        },
        /**
         * Implements ec unsafe (non const-time) multiplication using precomputed tables and w-ary non-adjacent form.
         * @param W window size
         * @param precomputes precomputed tables
         * @param n scalar (we don't check here, but should be less than curve order)
         * @param acc accumulator point to add result of multiplication
         * @returns point
         */
        wNAFUnsafe(W, precomputes, n, acc = c.ZERO) {
            const wo = calcWOpts(W, bits);
            for (let window = 0; window < wo.windows; window++) {
                if (n === _0n$4)
                    break; // Early-exit, skip 0 value
                const { nextN, offset, isZero, isNeg } = calcOffsets(n, window, wo);
                n = nextN;
                if (isZero) {
                    // Window bits are 0: skip processing.
                    // Move to next window.
                    continue;
                }
                else {
                    const item = precomputes[offset];
                    acc = acc.add(isNeg ? item.negate() : item); // Re-using acc allows to save adds in MSM
                }
            }
            assert0(n);
            return acc;
        },
        getPrecomputes(W, P, transform) {
            // Calculate precomputes on a first run, reuse them after
            let comp = pointPrecomputes$1.get(P);
            if (!comp) {
                comp = this.precomputeWindow(P, W);
                if (W !== 1) {
                    // Doing transform outside of if brings 15% perf hit
                    if (typeof transform === 'function')
                        comp = transform(comp);
                    pointPrecomputes$1.set(P, comp);
                }
            }
            return comp;
        },
        wNAFCached(P, n, transform) {
            const W = getW(P);
            return this.wNAF(W, this.getPrecomputes(W, P, transform), n);
        },
        wNAFCachedUnsafe(P, n, transform, prev) {
            const W = getW(P);
            if (W === 1)
                return this.unsafeLadder(P, n, prev); // For W=1 ladder is ~x2 faster
            return this.wNAFUnsafe(W, this.getPrecomputes(W, P, transform), n, prev);
        },
        // We calculate precomputes for elliptic curve point multiplication
        // using windowed method. This specifies window size and
        // stores precomputed values. Usually only base point would be precomputed.
        setWindowSize(P, W) {
            validateW(W, bits);
            pointWindowSizes.set(P, W);
            pointPrecomputes$1.delete(P);
        },
    };
}
/**
 * Endomorphism-specific multiplication for Koblitz curves.
 * Cost: 128 dbl, 0-256 adds.
 */
function mulEndoUnsafe(c, point, k1, k2) {
    let acc = point;
    let p1 = c.ZERO;
    let p2 = c.ZERO;
    while (k1 > _0n$4 || k2 > _0n$4) {
        if (k1 & _1n$6)
            p1 = p1.add(acc);
        if (k2 & _1n$6)
            p2 = p2.add(acc);
        acc = acc.double();
        k1 >>= _1n$6;
        k2 >>= _1n$6;
    }
    return { p1, p2 };
}
/**
 * Pippenger algorithm for multi-scalar multiplication (MSM, Pa + Qb + Rc + ...).
 * 30x faster vs naive addition on L=4096, 10x faster than precomputes.
 * For N=254bit, L=1, it does: 1024 ADD + 254 DBL. For L=5: 1536 ADD + 254 DBL.
 * Algorithmically constant-time (for same L), even when 1 point + scalar, or when scalar = 0.
 * @param c Curve Point constructor
 * @param fieldN field over CURVE.N - important that it's not over CURVE.P
 * @param points array of L curve points
 * @param scalars array of L scalars (aka private keys / bigints)
 */
function pippenger(c, fieldN, points, scalars) {
    // If we split scalars by some window (let's say 8 bits), every chunk will only
    // take 256 buckets even if there are 4096 scalars, also re-uses double.
    // TODO:
    // - https://eprint.iacr.org/2024/750.pdf
    // - https://tches.iacr.org/index.php/TCHES/article/view/10287
    // 0 is accepted in scalars
    validateMSMPoints(points, c);
    validateMSMScalars(scalars, fieldN);
    const plength = points.length;
    const slength = scalars.length;
    if (plength !== slength)
        throw new Error('arrays of points and scalars must have equal length');
    // if (plength === 0) throw new Error('array must be of length >= 2');
    const zero = c.ZERO;
    const wbits = bitLen(BigInt(plength));
    let windowSize = 1; // bits
    if (wbits > 12)
        windowSize = wbits - 3;
    else if (wbits > 4)
        windowSize = wbits - 2;
    else if (wbits > 0)
        windowSize = 2;
    const MASK = bitMask(windowSize);
    const buckets = new Array(Number(MASK) + 1).fill(zero); // +1 for zero array
    const lastBits = Math.floor((fieldN.BITS - 1) / windowSize) * windowSize;
    let sum = zero;
    for (let i = lastBits; i >= 0; i -= windowSize) {
        buckets.fill(zero);
        for (let j = 0; j < slength; j++) {
            const scalar = scalars[j];
            const wbits = Number((scalar >> BigInt(i)) & MASK);
            buckets[wbits] = buckets[wbits].add(points[j]);
        }
        let resI = zero; // not using this will do small speed-up, but will lose ct
        // Skip first bucket, because it is zero
        for (let j = buckets.length - 1, sumI = zero; j > 0; j--) {
            sumI = sumI.add(buckets[j]);
            resI = resI.add(sumI);
        }
        sum = sum.add(resI);
        if (i !== 0)
            for (let j = 0; j < windowSize; j++)
                sum = sum.double();
    }
    return sum;
}
function createField(order, field) {
    if (field) {
        if (field.ORDER !== order)
            throw new Error('Field.ORDER must match order: Fp == p, Fn == n');
        validateField(field);
        return field;
    }
    else {
        return Field(order);
    }
}
/** Validates CURVE opts and creates fields */
function _createCurveFields(type, CURVE, curveOpts = {}) {
    if (!CURVE || typeof CURVE !== 'object')
        throw new Error(`expected valid ${type} CURVE object`);
    for (const p of ['p', 'n', 'h']) {
        const val = CURVE[p];
        if (!(typeof val === 'bigint' && val > _0n$4))
            throw new Error(`CURVE.${p} must be positive bigint`);
    }
    const Fp = createField(CURVE.p, curveOpts.Fp);
    const Fn = createField(CURVE.n, curveOpts.Fn);
    const _b = type === 'weierstrass' ? 'b' : 'd';
    const params = ['Gx', 'Gy', 'a', _b];
    for (const p of params) {
        // @ts-ignore
        if (!Fp.isValid(CURVE[p]))
            throw new Error(`CURVE.${p} must be valid field element of CURVE.Fp`);
    }
    return { Fp, Fn };
}

/**
 * Twisted Edwards curve. The formula is: ax² + y² = 1 + dx²y².
 * For design rationale of types / exports, see weierstrass module documentation.
 * Untwisted Edwards curves exist, but they aren't used in real-world protocols.
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Be friendly to bad ECMAScript parsers by not using bigint literals
// prettier-ignore
const _0n$3 = BigInt(0), _1n$5 = BigInt(1), _2n$5 = BigInt(2), _8n$2 = BigInt(8);
// verification rule is either zip215 or rfc8032 / nist186-5. Consult fromHex:
const VERIFY_DEFAULT = { zip215: true };
function isEdValidXY(Fp, CURVE, x, y) {
    const x2 = Fp.sqr(x);
    const y2 = Fp.sqr(y);
    const left = Fp.add(Fp.mul(CURVE.a, x2), y2);
    const right = Fp.add(Fp.ONE, Fp.mul(CURVE.d, Fp.mul(x2, y2)));
    return Fp.eql(left, right);
}
function edwards(CURVE, curveOpts = {}) {
    const { Fp, Fn } = _createCurveFields('edwards', CURVE, curveOpts);
    const { h: cofactor, n: CURVE_ORDER } = CURVE;
    _validateObject(curveOpts, {}, { uvRatio: 'function' });
    // Important:
    // There are some places where Fp.BYTES is used instead of nByteLength.
    // So far, everything has been tested with curves of Fp.BYTES == nByteLength.
    // TODO: test and find curves which behave otherwise.
    const MASK = _2n$5 << (BigInt(Fn.BYTES * 8) - _1n$5);
    const modP = (n) => Fp.create(n); // Function overrides
    // sqrt(u/v)
    const uvRatio = curveOpts.uvRatio ||
        ((u, v) => {
            try {
                return { isValid: true, value: Fp.sqrt(Fp.div(u, v)) };
            }
            catch (e) {
                return { isValid: false, value: _0n$3 };
            }
        });
    // Validate whether the passed curve params are valid.
    // equation ax² + y² = 1 + dx²y² should work for generator point.
    if (!isEdValidXY(Fp, CURVE, CURVE.Gx, CURVE.Gy))
        throw new Error('bad curve params: generator point');
    /**
     * Asserts coordinate is valid: 0 <= n < MASK.
     * Coordinates >= Fp.ORDER are allowed for zip215.
     */
    function acoord(title, n, banZero = false) {
        const min = banZero ? _1n$5 : _0n$3;
        aInRange('coordinate ' + title, n, min, MASK);
        return n;
    }
    function aextpoint(other) {
        if (!(other instanceof Point))
            throw new Error('ExtendedPoint expected');
    }
    // Converts Extended point to default (x, y) coordinates.
    // Can accept precomputed Z^-1 - for example, from invertBatch.
    const toAffineMemo = memoized((p, iz) => {
        const { ex: x, ey: y, ez: z } = p;
        const is0 = p.is0();
        if (iz == null)
            iz = is0 ? _8n$2 : Fp.inv(z); // 8 was chosen arbitrarily
        const ax = modP(x * iz);
        const ay = modP(y * iz);
        const zz = modP(z * iz);
        if (is0)
            return { x: _0n$3, y: _1n$5 };
        if (zz !== _1n$5)
            throw new Error('invZ was invalid');
        return { x: ax, y: ay };
    });
    const assertValidMemo = memoized((p) => {
        const { a, d } = CURVE;
        if (p.is0())
            throw new Error('bad point: ZERO'); // TODO: optimize, with vars below?
        // Equation in affine coordinates: ax² + y² = 1 + dx²y²
        // Equation in projective coordinates (X/Z, Y/Z, Z):  (aX² + Y²)Z² = Z⁴ + dX²Y²
        const { ex: X, ey: Y, ez: Z, et: T } = p;
        const X2 = modP(X * X); // X²
        const Y2 = modP(Y * Y); // Y²
        const Z2 = modP(Z * Z); // Z²
        const Z4 = modP(Z2 * Z2); // Z⁴
        const aX2 = modP(X2 * a); // aX²
        const left = modP(Z2 * modP(aX2 + Y2)); // (aX² + Y²)Z²
        const right = modP(Z4 + modP(d * modP(X2 * Y2))); // Z⁴ + dX²Y²
        if (left !== right)
            throw new Error('bad point: equation left != right (1)');
        // In Extended coordinates we also have T, which is x*y=T/Z: check X*Y == Z*T
        const XY = modP(X * Y);
        const ZT = modP(Z * T);
        if (XY !== ZT)
            throw new Error('bad point: equation left != right (2)');
        return true;
    });
    // Extended Point works in extended coordinates: (X, Y, Z, T) ∋ (x=X/Z, y=Y/Z, T=xy).
    // https://en.wikipedia.org/wiki/Twisted_Edwards_curve#Extended_coordinates
    class Point {
        constructor(ex, ey, ez, et) {
            this.ex = acoord('x', ex);
            this.ey = acoord('y', ey);
            this.ez = acoord('z', ez, true);
            this.et = acoord('t', et);
            Object.freeze(this);
        }
        get x() {
            return this.toAffine().x;
        }
        get y() {
            return this.toAffine().y;
        }
        static fromAffine(p) {
            if (p instanceof Point)
                throw new Error('extended point not allowed');
            const { x, y } = p || {};
            acoord('x', x);
            acoord('y', y);
            return new Point(x, y, _1n$5, modP(x * y));
        }
        static normalizeZ(points) {
            return normalizeZ(Point, 'ez', points);
        }
        // Multiscalar Multiplication
        static msm(points, scalars) {
            return pippenger(Point, Fn, points, scalars);
        }
        // "Private method", don't use it directly
        _setWindowSize(windowSize) {
            this.precompute(windowSize);
        }
        precompute(windowSize = 8, isLazy = true) {
            wnaf.setWindowSize(this, windowSize);
            if (!isLazy)
                this.multiply(_2n$5); // random number
            return this;
        }
        // Not required for fromHex(), which always creates valid points.
        // Could be useful for fromAffine().
        assertValidity() {
            assertValidMemo(this);
        }
        // Compare one point to another.
        equals(other) {
            aextpoint(other);
            const { ex: X1, ey: Y1, ez: Z1 } = this;
            const { ex: X2, ey: Y2, ez: Z2 } = other;
            const X1Z2 = modP(X1 * Z2);
            const X2Z1 = modP(X2 * Z1);
            const Y1Z2 = modP(Y1 * Z2);
            const Y2Z1 = modP(Y2 * Z1);
            return X1Z2 === X2Z1 && Y1Z2 === Y2Z1;
        }
        is0() {
            return this.equals(Point.ZERO);
        }
        negate() {
            // Flips point sign to a negative one (-x, y in affine coords)
            return new Point(modP(-this.ex), this.ey, this.ez, modP(-this.et));
        }
        // Fast algo for doubling Extended Point.
        // https://hyperelliptic.org/EFD/g1p/auto-twisted-extended.html#doubling-dbl-2008-hwcd
        // Cost: 4M + 4S + 1*a + 6add + 1*2.
        double() {
            const { a } = CURVE;
            const { ex: X1, ey: Y1, ez: Z1 } = this;
            const A = modP(X1 * X1); // A = X12
            const B = modP(Y1 * Y1); // B = Y12
            const C = modP(_2n$5 * modP(Z1 * Z1)); // C = 2*Z12
            const D = modP(a * A); // D = a*A
            const x1y1 = X1 + Y1;
            const E = modP(modP(x1y1 * x1y1) - A - B); // E = (X1+Y1)2-A-B
            const G = D + B; // G = D+B
            const F = G - C; // F = G-C
            const H = D - B; // H = D-B
            const X3 = modP(E * F); // X3 = E*F
            const Y3 = modP(G * H); // Y3 = G*H
            const T3 = modP(E * H); // T3 = E*H
            const Z3 = modP(F * G); // Z3 = F*G
            return new Point(X3, Y3, Z3, T3);
        }
        // Fast algo for adding 2 Extended Points.
        // https://hyperelliptic.org/EFD/g1p/auto-twisted-extended.html#addition-add-2008-hwcd
        // Cost: 9M + 1*a + 1*d + 7add.
        add(other) {
            aextpoint(other);
            const { a, d } = CURVE;
            const { ex: X1, ey: Y1, ez: Z1, et: T1 } = this;
            const { ex: X2, ey: Y2, ez: Z2, et: T2 } = other;
            const A = modP(X1 * X2); // A = X1*X2
            const B = modP(Y1 * Y2); // B = Y1*Y2
            const C = modP(T1 * d * T2); // C = T1*d*T2
            const D = modP(Z1 * Z2); // D = Z1*Z2
            const E = modP((X1 + Y1) * (X2 + Y2) - A - B); // E = (X1+Y1)*(X2+Y2)-A-B
            const F = D - C; // F = D-C
            const G = D + C; // G = D+C
            const H = modP(B - a * A); // H = B-a*A
            const X3 = modP(E * F); // X3 = E*F
            const Y3 = modP(G * H); // Y3 = G*H
            const T3 = modP(E * H); // T3 = E*H
            const Z3 = modP(F * G); // Z3 = F*G
            return new Point(X3, Y3, Z3, T3);
        }
        subtract(other) {
            return this.add(other.negate());
        }
        // Constant-time multiplication.
        multiply(scalar) {
            const n = scalar;
            aInRange('scalar', n, _1n$5, CURVE_ORDER); // 1 <= scalar < L
            const { p, f } = wnaf.wNAFCached(this, n, Point.normalizeZ);
            return Point.normalizeZ([p, f])[0];
        }
        // Non-constant-time multiplication. Uses double-and-add algorithm.
        // It's faster, but should only be used when you don't care about
        // an exposed private key e.g. sig verification.
        // Does NOT allow scalars higher than CURVE.n.
        // Accepts optional accumulator to merge with multiply (important for sparse scalars)
        multiplyUnsafe(scalar, acc = Point.ZERO) {
            const n = scalar;
            aInRange('scalar', n, _0n$3, CURVE_ORDER); // 0 <= scalar < L
            if (n === _0n$3)
                return Point.ZERO;
            if (this.is0() || n === _1n$5)
                return this;
            return wnaf.wNAFCachedUnsafe(this, n, Point.normalizeZ, acc);
        }
        // Checks if point is of small order.
        // If you add something to small order point, you will have "dirty"
        // point with torsion component.
        // Multiplies point by cofactor and checks if the result is 0.
        isSmallOrder() {
            return this.multiplyUnsafe(cofactor).is0();
        }
        // Multiplies point by curve order and checks if the result is 0.
        // Returns `false` is the point is dirty.
        isTorsionFree() {
            return wnaf.wNAFCachedUnsafe(this, CURVE_ORDER).is0();
        }
        // Converts Extended point to default (x, y) coordinates.
        // Can accept precomputed Z^-1 - for example, from invertBatch.
        toAffine(invertedZ) {
            return toAffineMemo(this, invertedZ);
        }
        clearCofactor() {
            if (cofactor === _1n$5)
                return this;
            return this.multiplyUnsafe(cofactor);
        }
        static fromBytes(bytes, zip215 = false) {
            abytes$2(bytes);
            return this.fromHex(bytes, zip215);
        }
        // Converts hash string or Uint8Array to Point.
        // Uses algo from RFC8032 5.1.3.
        static fromHex(hex, zip215 = false) {
            const { d, a } = CURVE;
            const len = Fp.BYTES;
            hex = ensureBytes$1('pointHex', hex, len); // copy hex to a new array
            abool$1('zip215', zip215);
            const normed = hex.slice(); // copy again, we'll manipulate it
            const lastByte = hex[len - 1]; // select last byte
            normed[len - 1] = lastByte & -129; // clear last bit
            const y = bytesToNumberLE(normed);
            // zip215=true is good for consensus-critical apps. =false follows RFC8032 / NIST186-5.
            // RFC8032 prohibits >= p, but ZIP215 doesn't
            // zip215=true:  0 <= y < MASK (2^256 for ed25519)
            // zip215=false: 0 <= y < P (2^255-19 for ed25519)
            const max = zip215 ? MASK : Fp.ORDER;
            aInRange('pointHex.y', y, _0n$3, max);
            // Ed25519: x² = (y²-1)/(dy²+1) mod p. Ed448: x² = (y²-1)/(dy²-1) mod p. Generic case:
            // ax²+y²=1+dx²y² => y²-1=dx²y²-ax² => y²-1=x²(dy²-a) => x²=(y²-1)/(dy²-a)
            const y2 = modP(y * y); // denominator is always non-0 mod p.
            const u = modP(y2 - _1n$5); // u = y² - 1
            const v = modP(d * y2 - a); // v = d y² + 1.
            let { isValid, value: x } = uvRatio(u, v); // √(u/v)
            if (!isValid)
                throw new Error('Point.fromHex: invalid y coordinate');
            const isXOdd = (x & _1n$5) === _1n$5; // There are 2 square roots. Use x_0 bit to select proper
            const isLastByteOdd = (lastByte & 0x80) !== 0; // x_0, last bit
            if (!zip215 && x === _0n$3 && isLastByteOdd)
                // if x=0 and x_0 = 1, fail
                throw new Error('Point.fromHex: x=0 and x_0=1');
            if (isLastByteOdd !== isXOdd)
                x = modP(-x); // if x_0 != x mod 2, set x = p-x
            return Point.fromAffine({ x, y });
        }
        static fromPrivateScalar(scalar) {
            return Point.BASE.multiply(scalar);
        }
        toBytes() {
            const { x, y } = this.toAffine();
            const bytes = numberToBytesLE(y, Fp.BYTES); // each y has 2 x values (x, -y)
            bytes[bytes.length - 1] |= x & _1n$5 ? 0x80 : 0; // when compressing, it's enough to store y
            return bytes; // and use the last byte to encode sign of x
        }
        /** @deprecated use `toBytes` */
        toRawBytes() {
            return this.toBytes();
        }
        toHex() {
            return bytesToHex$2(this.toBytes());
        }
        toString() {
            return `<Point ${this.is0() ? 'ZERO' : this.toHex()}>`;
        }
    }
    // base / generator point
    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, _1n$5, modP(CURVE.Gx * CURVE.Gy));
    // zero / infinity / identity point
    Point.ZERO = new Point(_0n$3, _1n$5, _1n$5, _0n$3); // 0, 1, 1, 0
    // fields
    Point.Fp = Fp;
    Point.Fn = Fn;
    const wnaf = wNAF(Point, Fn.BYTES * 8); // Fn.BITS?
    return Point;
}
/**
 * Initializes EdDSA signatures over given Edwards curve.
 */
function eddsa(Point, eddsaOpts) {
    _validateObject(eddsaOpts, {
        hash: 'function',
    }, {
        adjustScalarBytes: 'function',
        randomBytes: 'function',
        domain: 'function',
        prehash: 'function',
        mapToCurve: 'function',
    });
    const { prehash, hash: cHash } = eddsaOpts;
    const { BASE: G, Fp, Fn } = Point;
    const CURVE_ORDER = Fn.ORDER;
    const randomBytes_ = eddsaOpts.randomBytes || randomBytes$1;
    const adjustScalarBytes = eddsaOpts.adjustScalarBytes || ((bytes) => bytes); // NOOP
    const domain = eddsaOpts.domain ||
        ((data, ctx, phflag) => {
            abool$1('phflag', phflag);
            if (ctx.length || phflag)
                throw new Error('Contexts/pre-hash are not supported');
            return data;
        }); // NOOP
    function modN(a) {
        return Fn.create(a);
    }
    // Little-endian SHA512 with modulo n
    function modN_LE(hash) {
        // Not using Fn.fromBytes: hash can be 2*Fn.BYTES
        return modN(bytesToNumberLE(hash));
    }
    // Get the hashed private scalar per RFC8032 5.1.5
    function getPrivateScalar(key) {
        const len = Fp.BYTES;
        key = ensureBytes$1('private key', key, len);
        // Hash private key with curve's hash function to produce uniformingly random input
        // Check byte lengths: ensure(64, h(ensure(32, key)))
        const hashed = ensureBytes$1('hashed private key', cHash(key), 2 * len);
        const head = adjustScalarBytes(hashed.slice(0, len)); // clear first half bits, produce FE
        const prefix = hashed.slice(len, 2 * len); // second half is called key prefix (5.1.6)
        const scalar = modN_LE(head); // The actual private scalar
        return { head, prefix, scalar };
    }
    // Convenience method that creates public key from scalar. RFC8032 5.1.5
    function getExtendedPublicKey(key) {
        const { head, prefix, scalar } = getPrivateScalar(key);
        const point = G.multiply(scalar); // Point on Edwards curve aka public key
        const pointBytes = point.toBytes();
        return { head, prefix, scalar, point, pointBytes };
    }
    // Calculates EdDSA pub key. RFC8032 5.1.5. Privkey is hashed. Use first half with 3 bits cleared
    function getPublicKey(privKey) {
        return getExtendedPublicKey(privKey).pointBytes;
    }
    // int('LE', SHA512(dom2(F, C) || msgs)) mod N
    function hashDomainToScalar(context = Uint8Array.of(), ...msgs) {
        const msg = concatBytes$1(...msgs);
        return modN_LE(cHash(domain(msg, ensureBytes$1('context', context), !!prehash)));
    }
    /** Signs message with privateKey. RFC8032 5.1.6 */
    function sign(msg, privKey, options = {}) {
        msg = ensureBytes$1('message', msg);
        if (prehash)
            msg = prehash(msg); // for ed25519ph etc.
        const { prefix, scalar, pointBytes } = getExtendedPublicKey(privKey);
        const r = hashDomainToScalar(options.context, prefix, msg); // r = dom2(F, C) || prefix || PH(M)
        const R = G.multiply(r).toBytes(); // R = rG
        const k = hashDomainToScalar(options.context, R, pointBytes, msg); // R || A || PH(M)
        const s = modN(r + k * scalar); // S = (r + k * s) mod L
        aInRange('signature.s', s, _0n$3, CURVE_ORDER); // 0 <= s < l
        const L = Fp.BYTES;
        const res = concatBytes$1(R, numberToBytesLE(s, L));
        return ensureBytes$1('result', res, L * 2); // 64-byte signature
    }
    const verifyOpts = VERIFY_DEFAULT;
    /**
     * Verifies EdDSA signature against message and public key. RFC8032 5.1.7.
     * An extended group equation is checked.
     */
    function verify(sig, msg, publicKey, options = verifyOpts) {
        const { context, zip215 } = options;
        const len = Fp.BYTES; // Verifies EdDSA signature against message and public key. RFC8032 5.1.7.
        sig = ensureBytes$1('signature', sig, 2 * len); // An extended group equation is checked.
        msg = ensureBytes$1('message', msg);
        publicKey = ensureBytes$1('publicKey', publicKey, len);
        if (zip215 !== undefined)
            abool$1('zip215', zip215);
        if (prehash)
            msg = prehash(msg); // for ed25519ph, etc
        const s = bytesToNumberLE(sig.slice(len, 2 * len));
        let A, R, SB;
        try {
            // zip215=true is good for consensus-critical apps. =false follows RFC8032 / NIST186-5.
            // zip215=true:  0 <= y < MASK (2^256 for ed25519)
            // zip215=false: 0 <= y < P (2^255-19 for ed25519)
            A = Point.fromHex(publicKey, zip215);
            R = Point.fromHex(sig.slice(0, len), zip215);
            SB = G.multiplyUnsafe(s); // 0 <= s < l is done inside
        }
        catch (error) {
            return false;
        }
        if (!zip215 && A.isSmallOrder())
            return false;
        const k = hashDomainToScalar(context, R.toBytes(), A.toBytes(), msg);
        const RkA = R.add(A.multiplyUnsafe(k));
        // Extended group equation
        // [8][S]B = [8]R + [8][k]A'
        return RkA.subtract(SB).clearCofactor().is0();
    }
    G.precompute(8); // Enable precomputes. Slows down first publicKey computation by 20ms.
    const utils = {
        getExtendedPublicKey,
        /** ed25519 priv keys are uniform 32b. No need to check for modulo bias, like in secp256k1. */
        randomPrivateKey: () => randomBytes_(Fp.BYTES),
        /**
         * We're doing scalar multiplication (used in getPublicKey etc) with precomputed BASE_POINT
         * values. This slows down first getPublicKey() by milliseconds (see Speed section),
         * but allows to speed-up subsequent getPublicKey() calls up to 20x.
         * @param windowSize 2, 4, 8, 16
         */
        precompute(windowSize = 8, point = Point.BASE) {
            return point.precompute(windowSize, false);
        },
    };
    return { getPublicKey, sign, verify, utils, Point };
}
function _eddsa_legacy_opts_to_new(c) {
    const CURVE = {
        a: c.a,
        d: c.d,
        p: c.Fp.ORDER,
        n: c.n,
        h: c.h,
        Gx: c.Gx,
        Gy: c.Gy,
    };
    const Fp = c.Fp;
    const Fn = Field(CURVE.n, c.nBitLength, true);
    const curveOpts = { Fp, Fn, uvRatio: c.uvRatio };
    const eddsaOpts = {
        hash: c.hash,
        randomBytes: c.randomBytes,
        adjustScalarBytes: c.adjustScalarBytes,
        domain: c.domain,
        prehash: c.prehash,
        mapToCurve: c.mapToCurve,
    };
    return { CURVE, curveOpts, eddsaOpts };
}
function _eddsa_new_output_to_legacy(c, eddsa) {
    const legacy = Object.assign({}, eddsa, { ExtendedPoint: eddsa.Point, CURVE: c });
    return legacy;
}
// TODO: remove. Use eddsa
function twistedEdwards(c) {
    const { CURVE, curveOpts, eddsaOpts } = _eddsa_legacy_opts_to_new(c);
    const Point = edwards(CURVE, curveOpts);
    const EDDSA = eddsa(Point, eddsaOpts);
    return _eddsa_new_output_to_legacy(c, EDDSA);
}

/**
 * Montgomery curve methods. It's not really whole montgomery curve,
 * just bunch of very specific methods for X25519 / X448 from
 * [RFC 7748](https://www.rfc-editor.org/rfc/rfc7748)
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
const _0n$2 = BigInt(0);
const _1n$4 = BigInt(1);
const _2n$4 = BigInt(2);
function validateOpts(curve) {
    _validateObject(curve, {
        adjustScalarBytes: 'function',
        powPminus2: 'function',
    });
    return Object.freeze({ ...curve });
}
function montgomery(curveDef) {
    const CURVE = validateOpts(curveDef);
    const { P, type, adjustScalarBytes, powPminus2, randomBytes: rand } = CURVE;
    const is25519 = type === 'x25519';
    if (!is25519 && type !== 'x448')
        throw new Error('invalid type');
    const randomBytes_ = rand || randomBytes$1;
    const montgomeryBits = is25519 ? 255 : 448;
    const fieldLen = is25519 ? 32 : 56;
    const Gu = is25519 ? BigInt(9) : BigInt(5);
    // RFC 7748 #5:
    // The constant a24 is (486662 - 2) / 4 = 121665 for curve25519/X25519 and
    // (156326 - 2) / 4 = 39081 for curve448/X448
    // const a = is25519 ? 156326n : 486662n;
    const a24 = is25519 ? BigInt(121665) : BigInt(39081);
    // RFC: x25519 "the resulting integer is of the form 2^254 plus
    // eight times a value between 0 and 2^251 - 1 (inclusive)"
    // x448: "2^447 plus four times a value between 0 and 2^445 - 1 (inclusive)"
    const minScalar = is25519 ? _2n$4 ** BigInt(254) : _2n$4 ** BigInt(447);
    const maxAdded = is25519
        ? BigInt(8) * _2n$4 ** BigInt(251) - _1n$4
        : BigInt(4) * _2n$4 ** BigInt(445) - _1n$4;
    const maxScalar = minScalar + maxAdded + _1n$4; // (inclusive)
    const modP = (n) => mod$1(n, P);
    const GuBytes = encodeU(Gu);
    function encodeU(u) {
        return numberToBytesLE(modP(u), fieldLen);
    }
    function decodeU(u) {
        const _u = ensureBytes$1('u coordinate', u, fieldLen);
        // RFC: When receiving such an array, implementations of X25519
        // (but not X448) MUST mask the most significant bit in the final byte.
        if (is25519)
            _u[31] &= 127; // 0b0111_1111
        // RFC: Implementations MUST accept non-canonical values and process them as
        // if they had been reduced modulo the field prime.  The non-canonical
        // values are 2^255 - 19 through 2^255 - 1 for X25519 and 2^448 - 2^224
        // - 1 through 2^448 - 1 for X448.
        return modP(bytesToNumberLE(_u));
    }
    function decodeScalar(scalar) {
        return bytesToNumberLE(adjustScalarBytes(ensureBytes$1('scalar', scalar, fieldLen)));
    }
    function scalarMult(scalar, u) {
        const pu = montgomeryLadder(decodeU(u), decodeScalar(scalar));
        // Some public keys are useless, of low-order. Curve author doesn't think
        // it needs to be validated, but we do it nonetheless.
        // https://cr.yp.to/ecdh.html#validate
        if (pu === _0n$2)
            throw new Error('invalid private or public key received');
        return encodeU(pu);
    }
    // Computes public key from private. By doing scalar multiplication of base point.
    function scalarMultBase(scalar) {
        return scalarMult(scalar, GuBytes);
    }
    // cswap from RFC7748 "example code"
    function cswap(swap, x_2, x_3) {
        // dummy = mask(swap) AND (x_2 XOR x_3)
        // Where mask(swap) is the all-1 or all-0 word of the same length as x_2
        // and x_3, computed, e.g., as mask(swap) = 0 - swap.
        const dummy = modP(swap * (x_2 - x_3));
        x_2 = modP(x_2 - dummy); // x_2 = x_2 XOR dummy
        x_3 = modP(x_3 + dummy); // x_3 = x_3 XOR dummy
        return { x_2, x_3 };
    }
    /**
     * Montgomery x-only multiplication ladder.
     * @param pointU u coordinate (x) on Montgomery Curve 25519
     * @param scalar by which the point would be multiplied
     * @returns new Point on Montgomery curve
     */
    function montgomeryLadder(u, scalar) {
        aInRange('u', u, _0n$2, P);
        aInRange('scalar', scalar, minScalar, maxScalar);
        const k = scalar;
        const x_1 = u;
        let x_2 = _1n$4;
        let z_2 = _0n$2;
        let x_3 = u;
        let z_3 = _1n$4;
        let swap = _0n$2;
        for (let t = BigInt(montgomeryBits - 1); t >= _0n$2; t--) {
            const k_t = (k >> t) & _1n$4;
            swap ^= k_t;
            ({ x_2, x_3 } = cswap(swap, x_2, x_3));
            ({ x_2: z_2, x_3: z_3 } = cswap(swap, z_2, z_3));
            swap = k_t;
            const A = x_2 + z_2;
            const AA = modP(A * A);
            const B = x_2 - z_2;
            const BB = modP(B * B);
            const E = AA - BB;
            const C = x_3 + z_3;
            const D = x_3 - z_3;
            const DA = modP(D * A);
            const CB = modP(C * B);
            const dacb = DA + CB;
            const da_cb = DA - CB;
            x_3 = modP(dacb * dacb);
            z_3 = modP(x_1 * modP(da_cb * da_cb));
            x_2 = modP(AA * BB);
            z_2 = modP(E * (AA + modP(a24 * E)));
        }
        ({ x_2, x_3 } = cswap(swap, x_2, x_3));
        ({ x_2: z_2, x_3: z_3 } = cswap(swap, z_2, z_3));
        const z2 = powPminus2(z_2); // `Fp.pow(x, P - _2n)` is much slower equivalent
        return modP(x_2 * z2); // Return x_2 * (z_2^(p - 2))
    }
    return {
        scalarMult,
        scalarMultBase,
        getSharedSecret: (privateKey, publicKey) => scalarMult(privateKey, publicKey),
        getPublicKey: (privateKey) => scalarMultBase(privateKey),
        utils: { randomPrivateKey: () => randomBytes_(fieldLen) },
        GuBytes: GuBytes.slice(),
    };
}

/**
 * ed25519 Twisted Edwards curve with following addons:
 * - X25519 ECDH
 * - Ristretto cofactor elimination
 * - Elligator hash-to-group / point indistinguishability
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// prettier-ignore
BigInt(0); const _1n$3 = BigInt(1), _2n$3 = BigInt(2), _3n$2 = BigInt(3);
// prettier-ignore
const _5n = BigInt(5), _8n$1 = BigInt(8);
// 2n**255n - 19n
// Removing Fp.create() will still work, and is 10% faster on sign
//     a: Fp.create(BigInt(-1)),
// d is -121665/121666 a.k.a. Fp.neg(121665 * Fp.inv(121666))
// Finite field 2n**255n - 19n
// Subgroup order 2n**252n + 27742317777372353535851937790883648493n;
const ed25519_CURVE = {
    p: BigInt('0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffed'),
    n: BigInt('0x1000000000000000000000000000000014def9dea2f79cd65812631a5cf5d3ed'),
    h: _8n$1,
    a: BigInt('0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffec'),
    d: BigInt('0x52036cee2b6ffe738cc740797779e89800700a4d4141d8ab75eb4dca135978a3'),
    Gx: BigInt('0x216936d3cd6e53fec0a4e231fdd6dc5c692cc7609525a7b2c9562d608f25d51a'),
    Gy: BigInt('0x6666666666666666666666666666666666666666666666666666666666666658'),
};
function ed25519_pow_2_252_3(x) {
    // prettier-ignore
    const _10n = BigInt(10), _20n = BigInt(20), _40n = BigInt(40), _80n = BigInt(80);
    const P = ed25519_CURVE.p;
    const x2 = (x * x) % P;
    const b2 = (x2 * x) % P; // x^3, 11
    const b4 = (pow2$1(b2, _2n$3, P) * b2) % P; // x^15, 1111
    const b5 = (pow2$1(b4, _1n$3, P) * x) % P; // x^31
    const b10 = (pow2$1(b5, _5n, P) * b5) % P;
    const b20 = (pow2$1(b10, _10n, P) * b10) % P;
    const b40 = (pow2$1(b20, _20n, P) * b20) % P;
    const b80 = (pow2$1(b40, _40n, P) * b40) % P;
    const b160 = (pow2$1(b80, _80n, P) * b80) % P;
    const b240 = (pow2$1(b160, _80n, P) * b80) % P;
    const b250 = (pow2$1(b240, _10n, P) * b10) % P;
    const pow_p_5_8 = (pow2$1(b250, _2n$3, P) * x) % P;
    // ^ To pow to (p+3)/8, multiply it by x.
    return { pow_p_5_8, b2 };
}
function adjustScalarBytes(bytes) {
    // Section 5: For X25519, in order to decode 32 random bytes as an integer scalar,
    // set the three least significant bits of the first byte
    bytes[0] &= 248; // 0b1111_1000
    // and the most significant bit of the last to zero,
    bytes[31] &= 127; // 0b0111_1111
    // set the second most significant bit of the last byte to 1
    bytes[31] |= 64; // 0b0100_0000
    return bytes;
}
// √(-1) aka √(a) aka 2^((p-1)/4)
// Fp.sqrt(Fp.neg(1))
const ED25519_SQRT_M1 = /* @__PURE__ */ BigInt('19681161376707505956807079304988542015446066515923890162744021073123829784752');
// sqrt(u/v)
function uvRatio(u, v) {
    const P = ed25519_CURVE.p;
    const v3 = mod$1(v * v * v, P); // v³
    const v7 = mod$1(v3 * v3 * v, P); // v⁷
    // (p+3)/8 and (p-5)/8
    const pow = ed25519_pow_2_252_3(u * v7).pow_p_5_8;
    let x = mod$1(u * v3 * pow, P); // (uv³)(uv⁷)^(p-5)/8
    const vx2 = mod$1(v * x * x, P); // vx²
    const root1 = x; // First root candidate
    const root2 = mod$1(x * ED25519_SQRT_M1, P); // Second root candidate
    const useRoot1 = vx2 === u; // If vx² = u (mod p), x is a square root
    const useRoot2 = vx2 === mod$1(-u, P); // If vx² = -u, set x <-- x * 2^((p-1)/4)
    const noRoot = vx2 === mod$1(-u * ED25519_SQRT_M1, P); // There is no valid root, vx² = -u√(-1)
    if (useRoot1)
        x = root1;
    if (useRoot2 || noRoot)
        x = root2; // We return root2 anyway, for const-time
    if (isNegativeLE(x, P))
        x = mod$1(-x, P);
    return { isValid: useRoot1 || useRoot2, value: x };
}
const Fp = /* @__PURE__ */ (() => Field(ed25519_CURVE.p, undefined, true))();
const ed25519Defaults = /* @__PURE__ */ (() => ({
    ...ed25519_CURVE,
    Fp,
    hash: sha512,
    adjustScalarBytes,
    // dom2
    // Ratio of u to v. Allows us to combine inversion and square root. Uses algo from RFC8032 5.1.3.
    // Constant-time, u/√v
    uvRatio,
}))();
/**
 * ed25519 curve with EdDSA signatures.
 * @example
 * import { ed25519 } from '@noble/curves/ed25519';
 * const priv = ed25519.utils.randomPrivateKey();
 * const pub = ed25519.getPublicKey(priv);
 * const msg = new TextEncoder().encode('hello');
 * const sig = ed25519.sign(msg, priv);
 * ed25519.verify(sig, msg, pub); // Default mode: follows ZIP215
 * ed25519.verify(sig, msg, pub, { zip215: false }); // RFC8032 / FIPS 186-5
 */
const ed25519 = /* @__PURE__ */ (() => twistedEdwards(ed25519Defaults))();
/**
 * ECDH using curve25519 aka x25519.
 * @example
 * import { x25519 } from '@noble/curves/ed25519';
 * const priv = 'a546e36bf0527c9d3b16154b82465edd62144c0ac1fc5a18506a2244ba449ac4';
 * const pub = 'e6db6867583030db3594c1a424b15f7c726624ec26b3353b10a903a6d0ab1c4c';
 * x25519.getSharedSecret(priv, pub) === x25519.scalarMult(priv, pub); // aliases
 * x25519.getPublicKey(priv) === x25519.scalarMultBase(priv);
 * x25519.getPublicKey(x25519.utils.randomPrivateKey());
 */
const x25519 = /* @__PURE__ */ (() => {
    const P = ed25519_CURVE.p;
    return montgomery({
        P,
        type: 'x25519',
        powPminus2: (x) => {
            // x^(p-2) aka x^(2^255-21)
            const { pow_p_5_8, b2 } = ed25519_pow_2_252_3(x);
            return mod$1(pow2$1(pow_p_5_8, _3n$2, P) * b2, P);
        },
        adjustScalarBytes,
    });
})();

/**
 * Signing a message failed
 */
/**
 * Verifying a message signature failed
 */
class VerificationError extends Error {
    constructor(message = 'An error occurred while verifying a message') {
        super(message);
        this.name = 'VerificationError';
    }
}
/**
 * WebCrypto was not available in the current context
 */
class WebCryptoMissingError extends Error {
    constructor(message = 'Missing Web Crypto API') {
        super(message);
        this.name = 'WebCryptoMissingError';
    }
}

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto?.subtle == null) {
            throw new WebCryptoMissingError('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p/blob/main/packages/crypto/README.md#web-crypto-api');
        }
        return nativeCrypto;
    }
};

const PUBLIC_KEY_BYTE_LENGTH$1 = 32;
const PRIVATE_KEY_BYTE_LENGTH = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys
const KEYS_BYTE_LENGTH = 32;
// memoize support result to skip additional awaits every time we use an ed key
let ed25519Supported;
const webCryptoEd25519SupportedPromise = (async () => {
    try {
        await webcrypto.get().subtle.generateKey({ name: 'Ed25519' }, true, ['sign', 'verify']);
        return true;
    }
    catch {
        return false;
    }
})();
function generateKey() {
    // the actual private key (32 bytes)
    const privateKeyRaw = ed25519.utils.randomPrivateKey();
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    // concatenated the public key to the private key
    const privateKey = concatKeys(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
async function hashAndSignWebCrypto(privateKey, msg) {
    let privateKeyRaw;
    if (privateKey.length === PRIVATE_KEY_BYTE_LENGTH) {
        privateKeyRaw = privateKey.subarray(0, 32);
    }
    else {
        privateKeyRaw = privateKey;
    }
    const jwk = {
        crv: 'Ed25519',
        kty: 'OKP',
        x: toString(privateKey.subarray(32), 'base64url'),
        d: toString(privateKeyRaw, 'base64url'),
        ext: true,
        key_ops: ['sign']
    };
    const key = await webcrypto.get().subtle.importKey('jwk', jwk, { name: 'Ed25519' }, true, ['sign']);
    const sig = await webcrypto.get().subtle.sign({ name: 'Ed25519' }, key, msg instanceof Uint8Array ? msg : msg.subarray());
    return new Uint8Array(sig, 0, sig.byteLength);
}
function hashAndSignNoble(privateKey, msg) {
    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH);
    return ed25519.sign(msg instanceof Uint8Array ? msg : msg.subarray(), privateKeyRaw);
}
async function hashAndSign(privateKey, msg) {
    if (ed25519Supported == null) {
        ed25519Supported = await webCryptoEd25519SupportedPromise;
    }
    if (ed25519Supported) {
        return hashAndSignWebCrypto(privateKey, msg);
    }
    return hashAndSignNoble(privateKey, msg);
}
async function hashAndVerifyWebCrypto(publicKey, sig, msg) {
    if (publicKey.buffer instanceof ArrayBuffer) {
        const key = await webcrypto.get().subtle.importKey('raw', publicKey.buffer, { name: 'Ed25519' }, false, ['verify']);
        const isValid = await webcrypto.get().subtle.verify({ name: 'Ed25519' }, key, sig, msg instanceof Uint8Array ? msg : msg.subarray());
        return isValid;
    }
    throw new TypeError('WebCrypto does not support SharedArrayBuffer for Ed25519 keys');
}
function hashAndVerifyNoble(publicKey, sig, msg) {
    return ed25519.verify(sig, msg instanceof Uint8Array ? msg : msg.subarray(), publicKey);
}
async function hashAndVerify$2(publicKey, sig, msg) {
    if (ed25519Supported == null) {
        ed25519Supported = await webCryptoEd25519SupportedPromise;
    }
    if (ed25519Supported) {
        return hashAndVerifyWebCrypto(publicKey, sig, msg);
    }
    return hashAndVerifyNoble(publicKey, sig, msg);
}
function concatKeys(privateKeyRaw, publicKey) {
    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH);
    for (let i = 0; i < KEYS_BYTE_LENGTH; i++) {
        privateKey[i] = privateKeyRaw[i];
        privateKey[KEYS_BYTE_LENGTH + i] = publicKey[i];
    }
    return privateKey;
}

function isPromise$2(thing) {
    if (thing == null) {
        return false;
    }
    return typeof thing.then === 'function' &&
        typeof thing.catch === 'function' &&
        typeof thing.finally === 'function';
}

class Ed25519PublicKey {
    type = 'Ed25519';
    raw;
    constructor(key) {
        this.raw = ensureEd25519Key(key, PUBLIC_KEY_BYTE_LENGTH$1);
    }
    toMultihash() {
        return identity.digest(publicKeyToProtobuf(this));
    }
    toCID() {
        return CID.createV1(114, this.toMultihash());
    }
    toString() {
        return base58btc.encode(this.toMultihash().bytes).substring(1);
    }
    equals(key) {
        if (key == null || !(key.raw instanceof Uint8Array)) {
            return false;
        }
        return equals(this.raw, key.raw);
    }
    verify(data, sig, options) {
        options?.signal?.throwIfAborted();
        const result = hashAndVerify$2(this.raw, sig, data);
        if (isPromise$2(result)) {
            return result.then(res => {
                options?.signal?.throwIfAborted();
                return res;
            });
        }
        return result;
    }
}
class Ed25519PrivateKey {
    type = 'Ed25519';
    raw;
    publicKey;
    // key       - 64 byte Uint8Array containing private key
    // publicKey - 32 byte Uint8Array containing public key
    constructor(key, publicKey) {
        this.raw = ensureEd25519Key(key, PRIVATE_KEY_BYTE_LENGTH);
        this.publicKey = new Ed25519PublicKey(publicKey);
    }
    equals(key) {
        if (key == null || !(key.raw instanceof Uint8Array)) {
            return false;
        }
        return equals(this.raw, key.raw);
    }
    sign(message, options) {
        options?.signal?.throwIfAborted();
        const sig = hashAndSign(this.raw, message);
        if (isPromise$2(sig)) {
            return sig.then(res => {
                options?.signal?.throwIfAborted();
                return res;
            });
        }
        options?.signal?.throwIfAborted();
        return sig;
    }
}

function unmarshalEd25519PublicKey(bytes) {
    bytes = ensureEd25519Key(bytes, PUBLIC_KEY_BYTE_LENGTH$1);
    return new Ed25519PublicKey(bytes);
}
async function generateEd25519KeyPair() {
    const { privateKey, publicKey } = generateKey();
    return new Ed25519PrivateKey(privateKey, publicKey);
}
function ensureEd25519Key(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new InvalidParametersError$1(`Key must be a Uint8Array of length ${length}, got ${key.length}`);
    }
    return key;
}

var KeyType;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["secp256k1"] = "secp256k1";
    KeyType["ECDSA"] = "ECDSA";
})(KeyType || (KeyType = {}));
var __KeyTypeValues;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["secp256k1"] = 2] = "secp256k1";
    __KeyTypeValues[__KeyTypeValues["ECDSA"] = 3] = "ECDSA";
})(__KeyTypeValues || (__KeyTypeValues = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues);
    };
})(KeyType || (KeyType = {}));
var PublicKey;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.Type = KeyType.codec().decode(reader);
                            break;
                        }
                        case 2: {
                            obj.Data = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf, opts) => {
        return decodeMessage(buf, PublicKey.codec(), opts);
    };
})(PublicKey || (PublicKey = {}));
var PrivateKey;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.Type = KeyType.codec().decode(reader);
                            break;
                        }
                        case 2: {
                            obj.Data = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf, opts) => {
        return decodeMessage(buf, PrivateKey.codec(), opts);
    };
})(PrivateKey || (PrivateKey = {}));

/**
 * Generates a Uint8Array with length `number` populated by random bytes
 */
function randomBytes(length) {
    if (isNaN(length) || length <= 0) {
        throw new InvalidParametersError$1('random bytes length must be a Number bigger than 0');
    }
    return randomBytes$1(length);
}

class RSAPublicKey {
    type = 'RSA';
    jwk;
    _raw;
    _multihash;
    constructor(jwk, digest) {
        this.jwk = jwk;
        this._multihash = digest;
    }
    get raw() {
        if (this._raw == null) {
            this._raw = jwkToPkix(this.jwk);
        }
        return this._raw;
    }
    toMultihash() {
        return this._multihash;
    }
    toCID() {
        return CID.createV1(114, this._multihash);
    }
    toString() {
        return base58btc.encode(this.toMultihash().bytes).substring(1);
    }
    equals(key) {
        if (key == null || !(key.raw instanceof Uint8Array)) {
            return false;
        }
        return equals(this.raw, key.raw);
    }
    verify(data, sig, options) {
        return hashAndVerify$1(this.jwk, sig, data, options);
    }
}

const SHA2_256_CODE = 0x12;
const MAX_RSA_JWK_SIZE = 1062;
const RSA_ALGORITHM_IDENTIFIER = Uint8Array.from([
    0x30, 0x0D, 0x06, 0x09, 0x2A, 0x86, 0x48, 0x86, 0xF7, 0x0D, 0x01, 0x01, 0x01, 0x05, 0x00
]);
function pkixMessageToJwk(message) {
    const keys = decodeDer(message[1], {
        offset: 0
    });
    // this looks fragile but DER is a canonical format so we are safe to have
    // deeply property chains like this
    return {
        kty: 'RSA',
        n: toString(keys[0], 'base64url'),
        e: toString(keys[1], 'base64url')
    };
}
/**
 * Convert a JWK public key to PKIX in ASN1 DER format
 */
function jwkToPkix(jwk) {
    if (jwk.n == null || jwk.e == null) {
        throw new InvalidParametersError$1('JWK was missing components');
    }
    const subjectPublicKeyInfo = encodeSequence([
        RSA_ALGORITHM_IDENTIFIER,
        encodeBitString(encodeSequence([
            encodeInteger(fromString(jwk.n, 'base64url')),
            encodeInteger(fromString(jwk.e, 'base64url'))
        ]))
    ]);
    return subjectPublicKeyInfo.subarray();
}
/**
 * Turn a PKIX message into a PublicKey
 */
function pkixToRSAPublicKey(bytes, digest) {
    if (bytes.byteLength >= MAX_RSA_JWK_SIZE) {
        throw new InvalidPublicKeyError('Key size is too large');
    }
    const message = decodeDer(bytes, {
        offset: 0
    });
    return pkixMessageToRSAPublicKey(message, bytes, digest);
}
function pkixMessageToRSAPublicKey(message, bytes, digest) {
    const jwk = pkixMessageToJwk(message);
    if (digest == null) {
        const hash = sha256(PublicKey.encode({
            Type: KeyType.RSA,
            Data: bytes
        }));
        digest = create(SHA2_256_CODE, hash);
    }
    return new RSAPublicKey(jwk, digest);
}

const RSAES_PKCS1_V1_5_OID = '1.2.840.113549.1.1.1';
async function hashAndVerify$1(key, sig, msg, options) {
    const publicKey = await webcrypto.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['verify']);
    options?.signal?.throwIfAborted();
    const result = await webcrypto.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg instanceof Uint8Array ? msg : msg.subarray());
    options?.signal?.throwIfAborted();
    return result;
}

/**
 * HMAC: RFC2104 message authentication code.
 * @module
 */
class HMAC extends Hash {
    constructor(hash, _key) {
        super();
        this.finished = false;
        this.destroyed = false;
        ahash(hash);
        const key = toBytes$1(_key);
        this.iHash = hash.create();
        if (typeof this.iHash.update !== 'function')
            throw new Error('Expected instance of class which extends utils.Hash');
        this.blockLen = this.iHash.blockLen;
        this.outputLen = this.iHash.outputLen;
        const blockLen = this.blockLen;
        const pad = new Uint8Array(blockLen);
        // blockLen can be bigger than outputLen
        pad.set(key.length > blockLen ? hash.create().update(key).digest() : key);
        for (let i = 0; i < pad.length; i++)
            pad[i] ^= 0x36;
        this.iHash.update(pad);
        // By doing update (processing of first block) of outer hash here we can re-use it between multiple calls via clone
        this.oHash = hash.create();
        // Undo internal XOR && apply outer XOR
        for (let i = 0; i < pad.length; i++)
            pad[i] ^= 0x36 ^ 0x5c;
        this.oHash.update(pad);
        clean$1(pad);
    }
    update(buf) {
        aexists$1(this);
        this.iHash.update(buf);
        return this;
    }
    digestInto(out) {
        aexists$1(this);
        abytes$2(out, this.outputLen);
        this.finished = true;
        this.iHash.digestInto(out);
        this.oHash.update(out);
        this.oHash.digestInto(out);
        this.destroy();
    }
    digest() {
        const out = new Uint8Array(this.oHash.outputLen);
        this.digestInto(out);
        return out;
    }
    _cloneInto(to) {
        // Create new instance without calling constructor since key already in state and we don't know it.
        to || (to = Object.create(Object.getPrototypeOf(this), {}));
        const { oHash, iHash, finished, destroyed, blockLen, outputLen } = this;
        to = to;
        to.finished = finished;
        to.destroyed = destroyed;
        to.blockLen = blockLen;
        to.outputLen = outputLen;
        to.oHash = oHash._cloneInto(to.oHash);
        to.iHash = iHash._cloneInto(to.iHash);
        return to;
    }
    clone() {
        return this._cloneInto();
    }
    destroy() {
        this.destroyed = true;
        this.oHash.destroy();
        this.iHash.destroy();
    }
}
/**
 * HMAC: RFC2104 message authentication code.
 * @param hash - function that would be used e.g. sha256
 * @param key - message key
 * @param message - message data
 * @example
 * import { hmac } from '@noble/hashes/hmac';
 * import { sha256 } from '@noble/hashes/sha2';
 * const mac1 = hmac(sha256, 'key', 'message');
 */
const hmac = (hash, key, message) => new HMAC(hash, key).update(message).digest();
hmac.create = (hash, key) => new HMAC(hash, key);

/**
 * Short Weierstrass curve methods. The formula is: y² = x³ + ax + b.
 *
 * ### Design rationale for types
 *
 * * Interaction between classes from different curves should fail:
 *   `k256.Point.BASE.add(p256.Point.BASE)`
 * * For this purpose we want to use `instanceof` operator, which is fast and works during runtime
 * * Different calls of `curve()` would return different classes -
 *   `curve(params) !== curve(params)`: if somebody decided to monkey-patch their curve,
 *   it won't affect others
 *
 * TypeScript can't infer types for classes created inside a function. Classes is one instance
 * of nominative types in TypeScript and interfaces only check for shape, so it's hard to create
 * unique type for every function call.
 *
 * We can use generic types via some param, like curve opts, but that would:
 *     1. Enable interaction between `curve(params)` and `curve(params)` (curves of same params)
 *     which is hard to debug.
 *     2. Params can be generic and we can't enforce them to be constant value:
 *     if somebody creates curve from non-constant params,
 *     it would be allowed to interact with other curves with non-constant params
 *
 * @todo https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-7.html#unique-symbol
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
function validateSigVerOpts(opts) {
    if (opts.lowS !== undefined)
        abool$1('lowS', opts.lowS);
    if (opts.prehash !== undefined)
        abool$1('prehash', opts.prehash);
}
class DERErr extends Error {
    constructor(m = '') {
        super(m);
    }
}
/**
 * ASN.1 DER encoding utilities. ASN is very complex & fragile. Format:
 *
 *     [0x30 (SEQUENCE), bytelength, 0x02 (INTEGER), intLength, R, 0x02 (INTEGER), intLength, S]
 *
 * Docs: https://letsencrypt.org/docs/a-warm-welcome-to-asn1-and-der/, https://luca.ntop.org/Teaching/Appunti/asn1.html
 */
const DER = {
    // asn.1 DER encoding utils
    Err: DERErr,
    // Basic building block is TLV (Tag-Length-Value)
    _tlv: {
        encode: (tag, data) => {
            const { Err: E } = DER;
            if (tag < 0 || tag > 256)
                throw new E('tlv.encode: wrong tag');
            if (data.length & 1)
                throw new E('tlv.encode: unpadded data');
            const dataLen = data.length / 2;
            const len = numberToHexUnpadded$1(dataLen);
            if ((len.length / 2) & 128)
                throw new E('tlv.encode: long form length too big');
            // length of length with long form flag
            const lenLen = dataLen > 127 ? numberToHexUnpadded$1((len.length / 2) | 128) : '';
            const t = numberToHexUnpadded$1(tag);
            return t + lenLen + len + data;
        },
        // v - value, l - left bytes (unparsed)
        decode(tag, data) {
            const { Err: E } = DER;
            let pos = 0;
            if (tag < 0 || tag > 256)
                throw new E('tlv.encode: wrong tag');
            if (data.length < 2 || data[pos++] !== tag)
                throw new E('tlv.decode: wrong tlv');
            const first = data[pos++];
            const isLong = !!(first & 128); // First bit of first length byte is flag for short/long form
            let length = 0;
            if (!isLong)
                length = first;
            else {
                // Long form: [longFlag(1bit), lengthLength(7bit), length (BE)]
                const lenLen = first & 127;
                if (!lenLen)
                    throw new E('tlv.decode(long): indefinite length not supported');
                if (lenLen > 4)
                    throw new E('tlv.decode(long): byte length is too big'); // this will overflow u32 in js
                const lengthBytes = data.subarray(pos, pos + lenLen);
                if (lengthBytes.length !== lenLen)
                    throw new E('tlv.decode: length bytes not complete');
                if (lengthBytes[0] === 0)
                    throw new E('tlv.decode(long): zero leftmost byte');
                for (const b of lengthBytes)
                    length = (length << 8) | b;
                pos += lenLen;
                if (length < 128)
                    throw new E('tlv.decode(long): not minimal encoding');
            }
            const v = data.subarray(pos, pos + length);
            if (v.length !== length)
                throw new E('tlv.decode: wrong value length');
            return { v, l: data.subarray(pos + length) };
        },
    },
    // https://crypto.stackexchange.com/a/57734 Leftmost bit of first byte is 'negative' flag,
    // since we always use positive integers here. It must always be empty:
    // - add zero byte if exists
    // - if next byte doesn't have a flag, leading zero is not allowed (minimal encoding)
    _int: {
        encode(num) {
            const { Err: E } = DER;
            if (num < _0n$1)
                throw new E('integer: negative integers are not allowed');
            let hex = numberToHexUnpadded$1(num);
            // Pad with zero byte if negative flag is present
            if (Number.parseInt(hex[0], 16) & 0b1000)
                hex = '00' + hex;
            if (hex.length & 1)
                throw new E('unexpected DER parsing assertion: unpadded hex');
            return hex;
        },
        decode(data) {
            const { Err: E } = DER;
            if (data[0] & 128)
                throw new E('invalid signature integer: negative');
            if (data[0] === 0x00 && !(data[1] & 128))
                throw new E('invalid signature integer: unnecessary leading zero');
            return bytesToNumberBE(data);
        },
    },
    toSig(hex) {
        // parse DER signature
        const { Err: E, _int: int, _tlv: tlv } = DER;
        const data = ensureBytes$1('signature', hex);
        const { v: seqBytes, l: seqLeftBytes } = tlv.decode(0x30, data);
        if (seqLeftBytes.length)
            throw new E('invalid signature: left bytes after parsing');
        const { v: rBytes, l: rLeftBytes } = tlv.decode(0x02, seqBytes);
        const { v: sBytes, l: sLeftBytes } = tlv.decode(0x02, rLeftBytes);
        if (sLeftBytes.length)
            throw new E('invalid signature: left bytes after parsing');
        return { r: int.decode(rBytes), s: int.decode(sBytes) };
    },
    hexFromSig(sig) {
        const { _tlv: tlv, _int: int } = DER;
        const rs = tlv.encode(0x02, int.encode(sig.r));
        const ss = tlv.encode(0x02, int.encode(sig.s));
        const seq = rs + ss;
        return tlv.encode(0x30, seq);
    },
};
// Be friendly to bad ECMAScript parsers by not using bigint literals
// prettier-ignore
const _0n$1 = BigInt(0), _1n$2 = BigInt(1), _2n$2 = BigInt(2), _3n$1 = BigInt(3), _4n = BigInt(4);
// TODO: remove
function _legacyHelperEquat(Fp, a, b) {
    /**
     * y² = x³ + ax + b: Short weierstrass curve formula. Takes x, returns y².
     * @returns y²
     */
    function weierstrassEquation(x) {
        const x2 = Fp.sqr(x); // x * x
        const x3 = Fp.mul(x2, x); // x² * x
        return Fp.add(Fp.add(x3, Fp.mul(x, a)), b); // x³ + a * x + b
    }
    return weierstrassEquation;
}
function _legacyHelperNormPriv(Fn, allowedPrivateKeyLengths, wrapPrivateKey) {
    const { BYTES: expected } = Fn;
    // Validates if priv key is valid and converts it to bigint.
    function normPrivateKeyToScalar(key) {
        let num;
        if (typeof key === 'bigint') {
            num = key;
        }
        else {
            let bytes = ensureBytes$1('private key', key);
            if (allowedPrivateKeyLengths) {
                if (!allowedPrivateKeyLengths.includes(bytes.length * 2))
                    throw new Error('invalid private key');
                const padded = new Uint8Array(expected);
                padded.set(bytes, padded.length - bytes.length);
                bytes = padded;
            }
            try {
                num = Fn.fromBytes(bytes);
            }
            catch (error) {
                throw new Error(`invalid private key: expected ui8a of size ${expected}, got ${typeof key}`);
            }
        }
        if (wrapPrivateKey)
            num = Fn.create(num); // disabled by default, enabled for BLS
        if (!Fn.isValidNot0(num))
            throw new Error('invalid private key: out of range [1..N-1]');
        return num;
    }
    return normPrivateKeyToScalar;
}
function weierstrassN(CURVE, curveOpts = {}) {
    const { Fp, Fn } = _createCurveFields('weierstrass', CURVE, curveOpts);
    const { h: cofactor, n: CURVE_ORDER } = CURVE;
    _validateObject(curveOpts, {}, {
        allowInfinityPoint: 'boolean',
        clearCofactor: 'function',
        isTorsionFree: 'function',
        fromBytes: 'function',
        toBytes: 'function',
        endo: 'object',
        wrapPrivateKey: 'boolean',
    });
    const { endo } = curveOpts;
    if (endo) {
        // validateObject(endo, { beta: 'bigint', splitScalar: 'function' });
        if (!Fp.is0(CURVE.a) ||
            typeof endo.beta !== 'bigint' ||
            typeof endo.splitScalar !== 'function') {
            throw new Error('invalid endo: expected "beta": bigint and "splitScalar": function');
        }
    }
    function assertCompressionIsSupported() {
        if (!Fp.isOdd)
            throw new Error('compression is not supported: Field does not have .isOdd()');
    }
    // Implements IEEE P1363 point encoding
    function pointToBytes(_c, point, isCompressed) {
        const { x, y } = point.toAffine();
        const bx = Fp.toBytes(x);
        abool$1('isCompressed', isCompressed);
        if (isCompressed) {
            assertCompressionIsSupported();
            const hasEvenY = !Fp.isOdd(y);
            return concatBytes$1(pprefix(hasEvenY), bx);
        }
        else {
            return concatBytes$1(Uint8Array.of(0x04), bx, Fp.toBytes(y));
        }
    }
    function pointFromBytes(bytes) {
        abytes$2(bytes);
        const L = Fp.BYTES;
        const LC = L + 1; // length compressed, e.g. 33 for 32-byte field
        const LU = 2 * L + 1; // length uncompressed, e.g. 65 for 32-byte field
        const length = bytes.length;
        const head = bytes[0];
        const tail = bytes.subarray(1);
        // No actual validation is done here: use .assertValidity()
        if (length === LC && (head === 0x02 || head === 0x03)) {
            const x = Fp.fromBytes(tail);
            if (!Fp.isValid(x))
                throw new Error('bad point: is not on curve, wrong x');
            const y2 = weierstrassEquation(x); // y² = x³ + ax + b
            let y;
            try {
                y = Fp.sqrt(y2); // y = y² ^ (p+1)/4
            }
            catch (sqrtError) {
                const err = sqrtError instanceof Error ? ': ' + sqrtError.message : '';
                throw new Error('bad point: is not on curve, sqrt error' + err);
            }
            assertCompressionIsSupported();
            const isYOdd = Fp.isOdd(y); // (y & _1n) === _1n;
            const isHeadOdd = (head & 1) === 1; // ECDSA-specific
            if (isHeadOdd !== isYOdd)
                y = Fp.neg(y);
            return { x, y };
        }
        else if (length === LU && head === 0x04) {
            // TODO: more checks
            const x = Fp.fromBytes(tail.subarray(L * 0, L * 1));
            const y = Fp.fromBytes(tail.subarray(L * 1, L * 2));
            if (!isValidXY(x, y))
                throw new Error('bad point: is not on curve');
            return { x, y };
        }
        else {
            throw new Error(`bad point: got length ${length}, expected compressed=${LC} or uncompressed=${LU}`);
        }
    }
    const toBytes = curveOpts.toBytes || pointToBytes;
    const fromBytes = curveOpts.fromBytes || pointFromBytes;
    const weierstrassEquation = _legacyHelperEquat(Fp, CURVE.a, CURVE.b);
    // TODO: move top-level
    /** Checks whether equation holds for given x, y: y² == x³ + ax + b */
    function isValidXY(x, y) {
        const left = Fp.sqr(y); // y²
        const right = weierstrassEquation(x); // x³ + ax + b
        return Fp.eql(left, right);
    }
    // Validate whether the passed curve params are valid.
    // Test 1: equation y² = x³ + ax + b should work for generator point.
    if (!isValidXY(CURVE.Gx, CURVE.Gy))
        throw new Error('bad curve params: generator point');
    // Test 2: discriminant Δ part should be non-zero: 4a³ + 27b² != 0.
    // Guarantees curve is genus-1, smooth (non-singular).
    const _4a3 = Fp.mul(Fp.pow(CURVE.a, _3n$1), _4n);
    const _27b2 = Fp.mul(Fp.sqr(CURVE.b), BigInt(27));
    if (Fp.is0(Fp.add(_4a3, _27b2)))
        throw new Error('bad curve params: a or b');
    /** Asserts coordinate is valid: 0 <= n < Fp.ORDER. */
    function acoord(title, n, banZero = false) {
        if (!Fp.isValid(n) || (banZero && Fp.is0(n)))
            throw new Error(`bad point coordinate ${title}`);
        return n;
    }
    function aprjpoint(other) {
        if (!(other instanceof Point))
            throw new Error('ProjectivePoint expected');
    }
    // Memoized toAffine / validity check. They are heavy. Points are immutable.
    // Converts Projective point to affine (x, y) coordinates.
    // Can accept precomputed Z^-1 - for example, from invertBatch.
    // (X, Y, Z) ∋ (x=X/Z, y=Y/Z)
    const toAffineMemo = memoized((p, iz) => {
        const { px: x, py: y, pz: z } = p;
        // Fast-path for normalized points
        if (Fp.eql(z, Fp.ONE))
            return { x, y };
        const is0 = p.is0();
        // If invZ was 0, we return zero point. However we still want to execute
        // all operations, so we replace invZ with a random number, 1.
        if (iz == null)
            iz = is0 ? Fp.ONE : Fp.inv(z);
        const ax = Fp.mul(x, iz);
        const ay = Fp.mul(y, iz);
        const zz = Fp.mul(z, iz);
        if (is0)
            return { x: Fp.ZERO, y: Fp.ZERO };
        if (!Fp.eql(zz, Fp.ONE))
            throw new Error('invZ was invalid');
        return { x: ax, y: ay };
    });
    // NOTE: on exception this will crash 'cached' and no value will be set.
    // Otherwise true will be return
    const assertValidMemo = memoized((p) => {
        if (p.is0()) {
            // (0, 1, 0) aka ZERO is invalid in most contexts.
            // In BLS, ZERO can be serialized, so we allow it.
            // (0, 0, 0) is invalid representation of ZERO.
            if (curveOpts.allowInfinityPoint && !Fp.is0(p.py))
                return;
            throw new Error('bad point: ZERO');
        }
        // Some 3rd-party test vectors require different wording between here & `fromCompressedHex`
        const { x, y } = p.toAffine();
        if (!Fp.isValid(x) || !Fp.isValid(y))
            throw new Error('bad point: x or y not field elements');
        if (!isValidXY(x, y))
            throw new Error('bad point: equation left != right');
        if (!p.isTorsionFree())
            throw new Error('bad point: not in prime-order subgroup');
        return true;
    });
    function finishEndo(endoBeta, k1p, k2p, k1neg, k2neg) {
        k2p = new Point(Fp.mul(k2p.px, endoBeta), k2p.py, k2p.pz);
        k1p = negateCt(k1neg, k1p);
        k2p = negateCt(k2neg, k2p);
        return k1p.add(k2p);
    }
    /**
     * Projective Point works in 3d / projective (homogeneous) coordinates:(X, Y, Z) ∋ (x=X/Z, y=Y/Z).
     * Default Point works in 2d / affine coordinates: (x, y).
     * We're doing calculations in projective, because its operations don't require costly inversion.
     */
    class Point {
        /** Does NOT validate if the point is valid. Use `.assertValidity()`. */
        constructor(px, py, pz) {
            this.px = acoord('x', px);
            this.py = acoord('y', py, true);
            this.pz = acoord('z', pz);
            Object.freeze(this);
        }
        /** Does NOT validate if the point is valid. Use `.assertValidity()`. */
        static fromAffine(p) {
            const { x, y } = p || {};
            if (!p || !Fp.isValid(x) || !Fp.isValid(y))
                throw new Error('invalid affine point');
            if (p instanceof Point)
                throw new Error('projective point not allowed');
            // (0, 0) would've produced (0, 0, 1) - instead, we need (0, 1, 0)
            if (Fp.is0(x) && Fp.is0(y))
                return Point.ZERO;
            return new Point(x, y, Fp.ONE);
        }
        get x() {
            return this.toAffine().x;
        }
        get y() {
            return this.toAffine().y;
        }
        static normalizeZ(points) {
            return normalizeZ(Point, 'pz', points);
        }
        static fromBytes(bytes) {
            abytes$2(bytes);
            return Point.fromHex(bytes);
        }
        /** Converts hash string or Uint8Array to Point. */
        static fromHex(hex) {
            const P = Point.fromAffine(fromBytes(ensureBytes$1('pointHex', hex)));
            P.assertValidity();
            return P;
        }
        /** Multiplies generator point by privateKey. */
        static fromPrivateKey(privateKey) {
            const normPrivateKeyToScalar = _legacyHelperNormPriv(Fn, curveOpts.allowedPrivateKeyLengths, curveOpts.wrapPrivateKey);
            return Point.BASE.multiply(normPrivateKeyToScalar(privateKey));
        }
        /** Multiscalar Multiplication */
        static msm(points, scalars) {
            return pippenger(Point, Fn, points, scalars);
        }
        /**
         *
         * @param windowSize
         * @param isLazy true will defer table computation until the first multiplication
         * @returns
         */
        precompute(windowSize = 8, isLazy = true) {
            wnaf.setWindowSize(this, windowSize);
            if (!isLazy)
                this.multiply(_3n$1); // random number
            return this;
        }
        /** "Private method", don't use it directly */
        _setWindowSize(windowSize) {
            this.precompute(windowSize);
        }
        // TODO: return `this`
        /** A point on curve is valid if it conforms to equation. */
        assertValidity() {
            assertValidMemo(this);
        }
        hasEvenY() {
            const { y } = this.toAffine();
            if (!Fp.isOdd)
                throw new Error("Field doesn't support isOdd");
            return !Fp.isOdd(y);
        }
        /** Compare one point to another. */
        equals(other) {
            aprjpoint(other);
            const { px: X1, py: Y1, pz: Z1 } = this;
            const { px: X2, py: Y2, pz: Z2 } = other;
            const U1 = Fp.eql(Fp.mul(X1, Z2), Fp.mul(X2, Z1));
            const U2 = Fp.eql(Fp.mul(Y1, Z2), Fp.mul(Y2, Z1));
            return U1 && U2;
        }
        /** Flips point to one corresponding to (x, -y) in Affine coordinates. */
        negate() {
            return new Point(this.px, Fp.neg(this.py), this.pz);
        }
        // Renes-Costello-Batina exception-free doubling formula.
        // There is 30% faster Jacobian formula, but it is not complete.
        // https://eprint.iacr.org/2015/1060, algorithm 3
        // Cost: 8M + 3S + 3*a + 2*b3 + 15add.
        double() {
            const { a, b } = CURVE;
            const b3 = Fp.mul(b, _3n$1);
            const { px: X1, py: Y1, pz: Z1 } = this;
            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore
            let t0 = Fp.mul(X1, X1); // step 1
            let t1 = Fp.mul(Y1, Y1);
            let t2 = Fp.mul(Z1, Z1);
            let t3 = Fp.mul(X1, Y1);
            t3 = Fp.add(t3, t3); // step 5
            Z3 = Fp.mul(X1, Z1);
            Z3 = Fp.add(Z3, Z3);
            X3 = Fp.mul(a, Z3);
            Y3 = Fp.mul(b3, t2);
            Y3 = Fp.add(X3, Y3); // step 10
            X3 = Fp.sub(t1, Y3);
            Y3 = Fp.add(t1, Y3);
            Y3 = Fp.mul(X3, Y3);
            X3 = Fp.mul(t3, X3);
            Z3 = Fp.mul(b3, Z3); // step 15
            t2 = Fp.mul(a, t2);
            t3 = Fp.sub(t0, t2);
            t3 = Fp.mul(a, t3);
            t3 = Fp.add(t3, Z3);
            Z3 = Fp.add(t0, t0); // step 20
            t0 = Fp.add(Z3, t0);
            t0 = Fp.add(t0, t2);
            t0 = Fp.mul(t0, t3);
            Y3 = Fp.add(Y3, t0);
            t2 = Fp.mul(Y1, Z1); // step 25
            t2 = Fp.add(t2, t2);
            t0 = Fp.mul(t2, t3);
            X3 = Fp.sub(X3, t0);
            Z3 = Fp.mul(t2, t1);
            Z3 = Fp.add(Z3, Z3); // step 30
            Z3 = Fp.add(Z3, Z3);
            return new Point(X3, Y3, Z3);
        }
        // Renes-Costello-Batina exception-free addition formula.
        // There is 30% faster Jacobian formula, but it is not complete.
        // https://eprint.iacr.org/2015/1060, algorithm 1
        // Cost: 12M + 0S + 3*a + 3*b3 + 23add.
        add(other) {
            aprjpoint(other);
            const { px: X1, py: Y1, pz: Z1 } = this;
            const { px: X2, py: Y2, pz: Z2 } = other;
            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore
            const a = CURVE.a;
            const b3 = Fp.mul(CURVE.b, _3n$1);
            let t0 = Fp.mul(X1, X2); // step 1
            let t1 = Fp.mul(Y1, Y2);
            let t2 = Fp.mul(Z1, Z2);
            let t3 = Fp.add(X1, Y1);
            let t4 = Fp.add(X2, Y2); // step 5
            t3 = Fp.mul(t3, t4);
            t4 = Fp.add(t0, t1);
            t3 = Fp.sub(t3, t4);
            t4 = Fp.add(X1, Z1);
            let t5 = Fp.add(X2, Z2); // step 10
            t4 = Fp.mul(t4, t5);
            t5 = Fp.add(t0, t2);
            t4 = Fp.sub(t4, t5);
            t5 = Fp.add(Y1, Z1);
            X3 = Fp.add(Y2, Z2); // step 15
            t5 = Fp.mul(t5, X3);
            X3 = Fp.add(t1, t2);
            t5 = Fp.sub(t5, X3);
            Z3 = Fp.mul(a, t4);
            X3 = Fp.mul(b3, t2); // step 20
            Z3 = Fp.add(X3, Z3);
            X3 = Fp.sub(t1, Z3);
            Z3 = Fp.add(t1, Z3);
            Y3 = Fp.mul(X3, Z3);
            t1 = Fp.add(t0, t0); // step 25
            t1 = Fp.add(t1, t0);
            t2 = Fp.mul(a, t2);
            t4 = Fp.mul(b3, t4);
            t1 = Fp.add(t1, t2);
            t2 = Fp.sub(t0, t2); // step 30
            t2 = Fp.mul(a, t2);
            t4 = Fp.add(t4, t2);
            t0 = Fp.mul(t1, t4);
            Y3 = Fp.add(Y3, t0);
            t0 = Fp.mul(t5, t4); // step 35
            X3 = Fp.mul(t3, X3);
            X3 = Fp.sub(X3, t0);
            t0 = Fp.mul(t3, t1);
            Z3 = Fp.mul(t5, Z3);
            Z3 = Fp.add(Z3, t0); // step 40
            return new Point(X3, Y3, Z3);
        }
        subtract(other) {
            return this.add(other.negate());
        }
        is0() {
            return this.equals(Point.ZERO);
        }
        /**
         * Constant time multiplication.
         * Uses wNAF method. Windowed method may be 10% faster,
         * but takes 2x longer to generate and consumes 2x memory.
         * Uses precomputes when available.
         * Uses endomorphism for Koblitz curves.
         * @param scalar by which the point would be multiplied
         * @returns New point
         */
        multiply(scalar) {
            const { endo } = curveOpts;
            if (!Fn.isValidNot0(scalar))
                throw new Error('invalid scalar: out of range'); // 0 is invalid
            let point, fake; // Fake point is used to const-time mult
            const mul = (n) => wnaf.wNAFCached(this, n, Point.normalizeZ);
            /** See docs for {@link EndomorphismOpts} */
            if (endo) {
                const { k1neg, k1, k2neg, k2 } = endo.splitScalar(scalar);
                const { p: k1p, f: k1f } = mul(k1);
                const { p: k2p, f: k2f } = mul(k2);
                fake = k1f.add(k2f);
                point = finishEndo(endo.beta, k1p, k2p, k1neg, k2neg);
            }
            else {
                const { p, f } = mul(scalar);
                point = p;
                fake = f;
            }
            // Normalize `z` for both points, but return only real one
            return Point.normalizeZ([point, fake])[0];
        }
        /**
         * Non-constant-time multiplication. Uses double-and-add algorithm.
         * It's faster, but should only be used when you don't care about
         * an exposed private key e.g. sig verification, which works over *public* keys.
         */
        multiplyUnsafe(sc) {
            const { endo } = curveOpts;
            const p = this;
            if (!Fn.isValid(sc))
                throw new Error('invalid scalar: out of range'); // 0 is valid
            if (sc === _0n$1 || p.is0())
                return Point.ZERO;
            if (sc === _1n$2)
                return p; // fast-path
            if (wnaf.hasPrecomputes(this))
                return this.multiply(sc);
            if (endo) {
                const { k1neg, k1, k2neg, k2 } = endo.splitScalar(sc);
                // `wNAFCachedUnsafe` is 30% slower
                const { p1, p2 } = mulEndoUnsafe(Point, p, k1, k2);
                return finishEndo(endo.beta, p1, p2, k1neg, k2neg);
            }
            else {
                return wnaf.wNAFCachedUnsafe(p, sc);
            }
        }
        multiplyAndAddUnsafe(Q, a, b) {
            const sum = this.multiplyUnsafe(a).add(Q.multiplyUnsafe(b));
            return sum.is0() ? undefined : sum;
        }
        /**
         * Converts Projective point to affine (x, y) coordinates.
         * @param invertedZ Z^-1 (inverted zero) - optional, precomputation is useful for invertBatch
         */
        toAffine(invertedZ) {
            return toAffineMemo(this, invertedZ);
        }
        /**
         * Checks whether Point is free of torsion elements (is in prime subgroup).
         * Always torsion-free for cofactor=1 curves.
         */
        isTorsionFree() {
            const { isTorsionFree } = curveOpts;
            if (cofactor === _1n$2)
                return true;
            if (isTorsionFree)
                return isTorsionFree(Point, this);
            return wnaf.wNAFCachedUnsafe(this, CURVE_ORDER).is0();
        }
        clearCofactor() {
            const { clearCofactor } = curveOpts;
            if (cofactor === _1n$2)
                return this; // Fast-path
            if (clearCofactor)
                return clearCofactor(Point, this);
            return this.multiplyUnsafe(cofactor);
        }
        toBytes(isCompressed = true) {
            abool$1('isCompressed', isCompressed);
            this.assertValidity();
            return toBytes(Point, this, isCompressed);
        }
        /** @deprecated use `toBytes` */
        toRawBytes(isCompressed = true) {
            return this.toBytes(isCompressed);
        }
        toHex(isCompressed = true) {
            return bytesToHex$2(this.toBytes(isCompressed));
        }
        toString() {
            return `<Point ${this.is0() ? 'ZERO' : this.toHex()}>`;
        }
    }
    // base / generator point
    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, Fp.ONE);
    // zero / infinity / identity point
    Point.ZERO = new Point(Fp.ZERO, Fp.ONE, Fp.ZERO); // 0, 1, 0
    // fields
    Point.Fp = Fp;
    Point.Fn = Fn;
    const bits = Fn.BITS;
    const wnaf = wNAF(Point, curveOpts.endo ? Math.ceil(bits / 2) : bits);
    return Point;
}
// Points start with byte 0x02 when y is even; otherwise 0x03
function pprefix(hasEvenY) {
    return Uint8Array.of(hasEvenY ? 0x02 : 0x03);
}
function ecdsa(Point, ecdsaOpts, curveOpts = {}) {
    _validateObject(ecdsaOpts, { hash: 'function' }, {
        hmac: 'function',
        lowS: 'boolean',
        randomBytes: 'function',
        bits2int: 'function',
        bits2int_modN: 'function',
    });
    const randomBytes_ = ecdsaOpts.randomBytes || randomBytes$1;
    const hmac_ = ecdsaOpts.hmac ||
        ((key, ...msgs) => hmac(ecdsaOpts.hash, key, concatBytes$1(...msgs)));
    const { Fp, Fn } = Point;
    const { ORDER: CURVE_ORDER, BITS: fnBits } = Fn;
    function isBiggerThanHalfOrder(number) {
        const HALF = CURVE_ORDER >> _1n$2;
        return number > HALF;
    }
    function normalizeS(s) {
        return isBiggerThanHalfOrder(s) ? Fn.neg(s) : s;
    }
    function aValidRS(title, num) {
        if (!Fn.isValidNot0(num))
            throw new Error(`invalid signature ${title}: out of range 1..CURVE.n`);
    }
    /**
     * ECDSA signature with its (r, s) properties. Supports DER & compact representations.
     */
    class Signature {
        constructor(r, s, recovery) {
            aValidRS('r', r); // r in [1..N-1]
            aValidRS('s', s); // s in [1..N-1]
            this.r = r;
            this.s = s;
            if (recovery != null)
                this.recovery = recovery;
            Object.freeze(this);
        }
        // pair (bytes of r, bytes of s)
        static fromCompact(hex) {
            const L = Fn.BYTES;
            const b = ensureBytes$1('compactSignature', hex, L * 2);
            return new Signature(Fn.fromBytes(b.subarray(0, L)), Fn.fromBytes(b.subarray(L, L * 2)));
        }
        // DER encoded ECDSA signature
        // https://bitcoin.stackexchange.com/questions/57644/what-are-the-parts-of-a-bitcoin-transaction-input-script
        static fromDER(hex) {
            const { r, s } = DER.toSig(ensureBytes$1('DER', hex));
            return new Signature(r, s);
        }
        /**
         * @todo remove
         * @deprecated
         */
        assertValidity() { }
        addRecoveryBit(recovery) {
            return new Signature(this.r, this.s, recovery);
        }
        // ProjPointType<bigint>
        recoverPublicKey(msgHash) {
            const FIELD_ORDER = Fp.ORDER;
            const { r, s, recovery: rec } = this;
            if (rec == null || ![0, 1, 2, 3].includes(rec))
                throw new Error('recovery id invalid');
            // ECDSA recovery is hard for cofactor > 1 curves.
            // In sign, `r = q.x mod n`, and here we recover q.x from r.
            // While recovering q.x >= n, we need to add r+n for cofactor=1 curves.
            // However, for cofactor>1, r+n may not get q.x:
            // r+n*i would need to be done instead where i is unknown.
            // To easily get i, we either need to:
            // a. increase amount of valid recid values (4, 5...); OR
            // b. prohibit non-prime-order signatures (recid > 1).
            const hasCofactor = CURVE_ORDER * _2n$2 < FIELD_ORDER;
            if (hasCofactor && rec > 1)
                throw new Error('recovery id is ambiguous for h>1 curve');
            const radj = rec === 2 || rec === 3 ? r + CURVE_ORDER : r;
            if (!Fp.isValid(radj))
                throw new Error('recovery id 2 or 3 invalid');
            const x = Fp.toBytes(radj);
            const R = Point.fromHex(concatBytes$1(pprefix((rec & 1) === 0), x));
            const ir = Fn.inv(radj); // r^-1
            const h = bits2int_modN(ensureBytes$1('msgHash', msgHash)); // Truncate hash
            const u1 = Fn.create(-h * ir); // -hr^-1
            const u2 = Fn.create(s * ir); // sr^-1
            // (sr^-1)R-(hr^-1)G = -(hr^-1)G + (sr^-1). unsafe is fine: there is no private data.
            const Q = Point.BASE.multiplyUnsafe(u1).add(R.multiplyUnsafe(u2));
            if (Q.is0())
                throw new Error('point at infinify');
            Q.assertValidity();
            return Q;
        }
        // Signatures should be low-s, to prevent malleability.
        hasHighS() {
            return isBiggerThanHalfOrder(this.s);
        }
        normalizeS() {
            return this.hasHighS() ? new Signature(this.r, Fn.neg(this.s), this.recovery) : this;
        }
        toBytes(format) {
            if (format === 'compact')
                return concatBytes$1(Fn.toBytes(this.r), Fn.toBytes(this.s));
            if (format === 'der')
                return hexToBytes$2(DER.hexFromSig(this));
            throw new Error('invalid format');
        }
        // DER-encoded
        toDERRawBytes() {
            return this.toBytes('der');
        }
        toDERHex() {
            return bytesToHex$2(this.toBytes('der'));
        }
        // padded bytes of r, then padded bytes of s
        toCompactRawBytes() {
            return this.toBytes('compact');
        }
        toCompactHex() {
            return bytesToHex$2(this.toBytes('compact'));
        }
    }
    const normPrivateKeyToScalar = _legacyHelperNormPriv(Fn, curveOpts.allowedPrivateKeyLengths, curveOpts.wrapPrivateKey);
    const utils = {
        isValidPrivateKey(privateKey) {
            try {
                normPrivateKeyToScalar(privateKey);
                return true;
            }
            catch (error) {
                return false;
            }
        },
        normPrivateKeyToScalar: normPrivateKeyToScalar,
        /**
         * Produces cryptographically secure private key from random of size
         * (groupLen + ceil(groupLen / 2)) with modulo bias being negligible.
         */
        randomPrivateKey: () => {
            const n = CURVE_ORDER;
            return mapHashToField(randomBytes_(getMinHashLength(n)), n);
        },
        precompute(windowSize = 8, point = Point.BASE) {
            return point.precompute(windowSize, false);
        },
    };
    /**
     * Computes public key for a private key. Checks for validity of the private key.
     * @param privateKey private key
     * @param isCompressed whether to return compact (default), or full key
     * @returns Public key, full when isCompressed=false; short when isCompressed=true
     */
    function getPublicKey(privateKey, isCompressed = true) {
        return Point.fromPrivateKey(privateKey).toBytes(isCompressed);
    }
    /**
     * Quick and dirty check for item being public key. Does not validate hex, or being on-curve.
     */
    function isProbPub(item) {
        if (typeof item === 'bigint')
            return false;
        if (item instanceof Point)
            return true;
        const arr = ensureBytes$1('key', item);
        const length = arr.length;
        const L = Fp.BYTES;
        const LC = L + 1; // e.g. 33 for 32
        const LU = 2 * L + 1; // e.g. 65 for 32
        if (curveOpts.allowedPrivateKeyLengths || Fn.BYTES === LC) {
            return undefined;
        }
        else {
            return length === LC || length === LU;
        }
    }
    /**
     * ECDH (Elliptic Curve Diffie Hellman).
     * Computes shared public key from private key and public key.
     * Checks: 1) private key validity 2) shared key is on-curve.
     * Does NOT hash the result.
     * @param privateA private key
     * @param publicB different public key
     * @param isCompressed whether to return compact (default), or full key
     * @returns shared public key
     */
    function getSharedSecret(privateA, publicB, isCompressed = true) {
        if (isProbPub(privateA) === true)
            throw new Error('first arg must be private key');
        if (isProbPub(publicB) === false)
            throw new Error('second arg must be public key');
        const b = Point.fromHex(publicB); // check for being on-curve
        return b.multiply(normPrivateKeyToScalar(privateA)).toBytes(isCompressed);
    }
    // RFC6979: ensure ECDSA msg is X bytes and < N. RFC suggests optional truncating via bits2octets.
    // FIPS 186-4 4.6 suggests the leftmost min(nBitLen, outLen) bits, which matches bits2int.
    // bits2int can produce res>N, we can do mod(res, N) since the bitLen is the same.
    // int2octets can't be used; pads small msgs with 0: unacceptatble for trunc as per RFC vectors
    const bits2int = ecdsaOpts.bits2int ||
        function (bytes) {
            // Our custom check "just in case", for protection against DoS
            if (bytes.length > 8192)
                throw new Error('input is too large');
            // For curves with nBitLength % 8 !== 0: bits2octets(bits2octets(m)) !== bits2octets(m)
            // for some cases, since bytes.length * 8 is not actual bitLength.
            const num = bytesToNumberBE(bytes); // check for == u8 done here
            const delta = bytes.length * 8 - fnBits; // truncate to nBitLength leftmost bits
            return delta > 0 ? num >> BigInt(delta) : num;
        };
    const bits2int_modN = ecdsaOpts.bits2int_modN ||
        function (bytes) {
            return Fn.create(bits2int(bytes)); // can't use bytesToNumberBE here
        };
    // NOTE: pads output with zero as per spec
    const ORDER_MASK = bitMask(fnBits);
    /**
     * Converts to bytes. Checks if num in `[0..ORDER_MASK-1]` e.g.: `[0..2^256-1]`.
     */
    function int2octets(num) {
        // IMPORTANT: the check ensures working for case `Fn.BYTES != Fn.BITS * 8`
        aInRange('num < 2^' + fnBits, num, _0n$1, ORDER_MASK);
        return Fn.toBytes(num);
    }
    // Steps A, D of RFC6979 3.2
    // Creates RFC6979 seed; converts msg/privKey to numbers.
    // Used only in sign, not in verify.
    // NOTE: we cannot assume here that msgHash has same amount of bytes as curve order,
    // this will be invalid at least for P521. Also it can be bigger for P224 + SHA256
    function prepSig(msgHash, privateKey, opts = defaultSigOpts) {
        if (['recovered', 'canonical'].some((k) => k in opts))
            throw new Error('sign() legacy options not supported');
        const { hash } = ecdsaOpts;
        let { lowS, prehash, extraEntropy: ent } = opts; // generates low-s sigs by default
        if (lowS == null)
            lowS = true; // RFC6979 3.2: we skip step A, because we already provide hash
        msgHash = ensureBytes$1('msgHash', msgHash);
        validateSigVerOpts(opts);
        if (prehash)
            msgHash = ensureBytes$1('prehashed msgHash', hash(msgHash));
        // We can't later call bits2octets, since nested bits2int is broken for curves
        // with fnBits % 8 !== 0. Because of that, we unwrap it here as int2octets call.
        // const bits2octets = (bits) => int2octets(bits2int_modN(bits))
        const h1int = bits2int_modN(msgHash);
        const d = normPrivateKeyToScalar(privateKey); // validate private key, convert to bigint
        const seedArgs = [int2octets(d), int2octets(h1int)];
        // extraEntropy. RFC6979 3.6: additional k' (optional).
        if (ent != null && ent !== false) {
            // K = HMAC_K(V || 0x00 || int2octets(x) || bits2octets(h1) || k')
            const e = ent === true ? randomBytes_(Fp.BYTES) : ent; // generate random bytes OR pass as-is
            seedArgs.push(ensureBytes$1('extraEntropy', e)); // check for being bytes
        }
        const seed = concatBytes$1(...seedArgs); // Step D of RFC6979 3.2
        const m = h1int; // NOTE: no need to call bits2int second time here, it is inside truncateHash!
        // Converts signature params into point w r/s, checks result for validity.
        // Can use scalar blinding b^-1(bm + bdr) where b ∈ [1,q−1] according to
        // https://tches.iacr.org/index.php/TCHES/article/view/7337/6509. We've decided against it:
        // a) dependency on CSPRNG b) 15% slowdown c) doesn't really help since bigints are not CT
        function k2sig(kBytes) {
            // RFC 6979 Section 3.2, step 3: k = bits2int(T)
            // Important: all mod() calls here must be done over N
            const k = bits2int(kBytes); // Cannot use fields methods, since it is group element
            if (!Fn.isValidNot0(k))
                return; // Valid scalars (including k) must be in 1..N-1
            const ik = Fn.inv(k); // k^-1 mod n
            const q = Point.BASE.multiply(k).toAffine(); // q = Gk
            const r = Fn.create(q.x); // r = q.x mod n
            if (r === _0n$1)
                return;
            const s = Fn.create(ik * Fn.create(m + r * d)); // Not using blinding here, see comment above
            if (s === _0n$1)
                return;
            let recovery = (q.x === r ? 0 : 2) | Number(q.y & _1n$2); // recovery bit (2 or 3, when q.x > n)
            let normS = s;
            if (lowS && isBiggerThanHalfOrder(s)) {
                normS = normalizeS(s); // if lowS was passed, ensure s is always
                recovery ^= 1; // // in the bottom half of N
            }
            return new Signature(r, normS, recovery); // use normS, not s
        }
        return { seed, k2sig };
    }
    const defaultSigOpts = { lowS: ecdsaOpts.lowS, prehash: false };
    const defaultVerOpts = { lowS: ecdsaOpts.lowS, prehash: false };
    /**
     * Signs message hash with a private key.
     * ```
     * sign(m, d, k) where
     *   (x, y) = G × k
     *   r = x mod n
     *   s = (m + dr)/k mod n
     * ```
     * @param msgHash NOT message. msg needs to be hashed to `msgHash`, or use `prehash`.
     * @param privKey private key
     * @param opts lowS for non-malleable sigs. extraEntropy for mixing randomness into k. prehash will hash first arg.
     * @returns signature with recovery param
     */
    function sign(msgHash, privKey, opts = defaultSigOpts) {
        const { seed, k2sig } = prepSig(msgHash, privKey, opts); // Steps A, D of RFC6979 3.2.
        const drbg = createHmacDrbg(ecdsaOpts.hash.outputLen, Fn.BYTES, hmac_);
        return drbg(seed, k2sig); // Steps B, C, D, E, F, G
    }
    // Enable precomputes. Slows down first publicKey computation by 20ms.
    Point.BASE.precompute(8);
    /**
     * Verifies a signature against message hash and public key.
     * Rejects lowS signatures by default: to override,
     * specify option `{lowS: false}`. Implements section 4.1.4 from https://www.secg.org/sec1-v2.pdf:
     *
     * ```
     * verify(r, s, h, P) where
     *   U1 = hs^-1 mod n
     *   U2 = rs^-1 mod n
     *   R = U1⋅G - U2⋅P
     *   mod(R.x, n) == r
     * ```
     */
    function verify(signature, msgHash, publicKey, opts = defaultVerOpts) {
        const sg = signature;
        msgHash = ensureBytes$1('msgHash', msgHash);
        publicKey = ensureBytes$1('publicKey', publicKey);
        // Verify opts
        validateSigVerOpts(opts);
        const { lowS, prehash, format } = opts;
        // TODO: remove
        if ('strict' in opts)
            throw new Error('options.strict was renamed to lowS');
        if (format !== undefined && !['compact', 'der', 'js'].includes(format))
            throw new Error('format must be "compact", "der" or "js"');
        const isHex = typeof sg === 'string' || isBytes$3(sg);
        const isObj = !isHex &&
            !format &&
            typeof sg === 'object' &&
            sg !== null &&
            typeof sg.r === 'bigint' &&
            typeof sg.s === 'bigint';
        if (!isHex && !isObj)
            throw new Error('invalid signature, expected Uint8Array, hex string or Signature instance');
        let _sig = undefined;
        let P;
        // deduce signature format
        try {
            // if (format === 'js') {
            //   if (sg != null && !isBytes(sg)) _sig = new Signature(sg.r, sg.s);
            // } else if (format === 'compact') {
            //   _sig = Signature.fromCompact(sg);
            // } else if (format === 'der') {
            //   _sig = Signature.fromDER(sg);
            // } else {
            //   throw new Error('invalid format');
            // }
            if (isObj) {
                if (format === undefined || format === 'js') {
                    _sig = new Signature(sg.r, sg.s);
                }
                else {
                    throw new Error('invalid format');
                }
            }
            if (isHex) {
                // TODO: remove this malleable check
                // Signature can be represented in 2 ways: compact (2*Fn.BYTES) & DER (variable-length).
                // Since DER can also be 2*Fn.BYTES bytes, we check for it first.
                try {
                    if (format !== 'compact')
                        _sig = Signature.fromDER(sg);
                }
                catch (derError) {
                    if (!(derError instanceof DER.Err))
                        throw derError;
                }
                if (!_sig && format !== 'der')
                    _sig = Signature.fromCompact(sg);
            }
            P = Point.fromHex(publicKey);
        }
        catch (error) {
            return false;
        }
        if (!_sig)
            return false;
        if (lowS && _sig.hasHighS())
            return false;
        // todo: optional.hash => hash
        if (prehash)
            msgHash = ecdsaOpts.hash(msgHash);
        const { r, s } = _sig;
        const h = bits2int_modN(msgHash); // Cannot use fields methods, since it is group element
        const is = Fn.inv(s); // s^-1
        const u1 = Fn.create(h * is); // u1 = hs^-1 mod n
        const u2 = Fn.create(r * is); // u2 = rs^-1 mod n
        const R = Point.BASE.multiplyUnsafe(u1).add(P.multiplyUnsafe(u2));
        if (R.is0())
            return false;
        const v = Fn.create(R.x); // v = r.x mod n
        return v === r;
    }
    // TODO: clarify API for cloning .clone({hash: sha512}) ? .createWith({hash: sha512})?
    // const clone = (hash: CHash): ECDSA => ecdsa(Point, { ...ecdsaOpts, ...getHash(hash) }, curveOpts);
    return Object.freeze({
        getPublicKey,
        getSharedSecret,
        sign,
        verify,
        utils,
        Point,
        Signature,
    });
}
function _weierstrass_legacy_opts_to_new(c) {
    const CURVE = {
        a: c.a,
        b: c.b,
        p: c.Fp.ORDER,
        n: c.n,
        h: c.h,
        Gx: c.Gx,
        Gy: c.Gy,
    };
    const Fp = c.Fp;
    const Fn = Field(CURVE.n, c.nBitLength);
    const curveOpts = {
        Fp,
        Fn,
        allowedPrivateKeyLengths: c.allowedPrivateKeyLengths,
        allowInfinityPoint: c.allowInfinityPoint,
        endo: c.endo,
        wrapPrivateKey: c.wrapPrivateKey,
        isTorsionFree: c.isTorsionFree,
        clearCofactor: c.clearCofactor,
        fromBytes: c.fromBytes,
        toBytes: c.toBytes,
    };
    return { CURVE, curveOpts };
}
function _ecdsa_legacy_opts_to_new(c) {
    const { CURVE, curveOpts } = _weierstrass_legacy_opts_to_new(c);
    const ecdsaOpts = {
        hash: c.hash,
        hmac: c.hmac,
        randomBytes: c.randomBytes,
        lowS: c.lowS,
        bits2int: c.bits2int,
        bits2int_modN: c.bits2int_modN,
    };
    return { CURVE, curveOpts, ecdsaOpts };
}
function _ecdsa_new_output_to_legacy(c, ecdsa) {
    return Object.assign({}, ecdsa, {
        ProjectivePoint: ecdsa.Point,
        CURVE: c,
    });
}
// _ecdsa_legacy
function weierstrass$1(c) {
    const { CURVE, curveOpts, ecdsaOpts } = _ecdsa_legacy_opts_to_new(c);
    const Point = weierstrassN(CURVE, curveOpts);
    const signs = ecdsa(Point, ecdsaOpts, curveOpts);
    return _ecdsa_new_output_to_legacy(c, signs);
}

/**
 * Utilities for short weierstrass curves, combined with noble-hashes.
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
function createCurve(curveDef, defHash) {
    const create = (hash) => weierstrass$1({ ...curveDef, hash: hash });
    return { ...create(defHash), create };
}

/**
 * SECG secp256k1. See [pdf](https://www.secg.org/sec2-v2.pdf).
 *
 * Belongs to Koblitz curves: it has efficiently-computable GLV endomorphism ψ,
 * check out {@link EndomorphismOpts}. Seems to be rigid (not backdoored).
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Seems like generator was produced from some seed:
// `Point.BASE.multiply(Point.Fn.inv(2n, N)).toAffine().x`
// // gives short x 0x3b78ce563f89a0ed9414f5aa28ad0d96d6795f9c63n
const secp256k1_CURVE = {
    p: BigInt('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f'),
    n: BigInt('0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141'),
    h: BigInt(1),
    a: BigInt(0),
    b: BigInt(7),
    Gx: BigInt('0x79be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798'),
    Gy: BigInt('0x483ada7726a3c4655da4fbfc0e1108a8fd17b448a68554199c47d08ffb10d4b8'),
};
BigInt(0);
const _1n$1 = BigInt(1);
const _2n$1 = BigInt(2);
const divNearest$1 = (a, b) => (a + b / _2n$1) / b;
/**
 * √n = n^((p+1)/4) for fields p = 3 mod 4. We unwrap the loop and multiply bit-by-bit.
 * (P+1n/4n).toString(2) would produce bits [223x 1, 0, 22x 1, 4x 0, 11, 00]
 */
function sqrtMod$1(y) {
    const P = secp256k1_CURVE.p;
    // prettier-ignore
    const _3n = BigInt(3), _6n = BigInt(6), _11n = BigInt(11), _22n = BigInt(22);
    // prettier-ignore
    const _23n = BigInt(23), _44n = BigInt(44), _88n = BigInt(88);
    const b2 = (y * y * y) % P; // x^3, 11
    const b3 = (b2 * b2 * y) % P; // x^7
    const b6 = (pow2$1(b3, _3n, P) * b3) % P;
    const b9 = (pow2$1(b6, _3n, P) * b3) % P;
    const b11 = (pow2$1(b9, _2n$1, P) * b2) % P;
    const b22 = (pow2$1(b11, _11n, P) * b11) % P;
    const b44 = (pow2$1(b22, _22n, P) * b22) % P;
    const b88 = (pow2$1(b44, _44n, P) * b44) % P;
    const b176 = (pow2$1(b88, _88n, P) * b88) % P;
    const b220 = (pow2$1(b176, _44n, P) * b44) % P;
    const b223 = (pow2$1(b220, _3n, P) * b3) % P;
    const t1 = (pow2$1(b223, _23n, P) * b22) % P;
    const t2 = (pow2$1(t1, _6n, P) * b2) % P;
    const root = pow2$1(t2, _2n$1, P);
    if (!Fpk1.eql(Fpk1.sqr(root), y))
        throw new Error('Cannot find square root');
    return root;
}
const Fpk1 = Field(secp256k1_CURVE.p, undefined, undefined, { sqrt: sqrtMod$1 });
/**
 * secp256k1 curve, ECDSA and ECDH methods.
 *
 * Field: `2n**256n - 2n**32n - 2n**9n - 2n**8n - 2n**7n - 2n**6n - 2n**4n - 1n`
 *
 * @example
 * ```js
 * import { secp256k1 } from '@noble/curves/secp256k1';
 * const priv = secp256k1.utils.randomPrivateKey();
 * const pub = secp256k1.getPublicKey(priv);
 * const msg = new Uint8Array(32).fill(1); // message hash (not message) in ecdsa
 * const sig = secp256k1.sign(msg, priv); // `{prehash: true}` option is available
 * const isValid = secp256k1.verify(sig, msg, pub) === true;
 * ```
 */
const secp256k1 = createCurve({
    ...secp256k1_CURVE,
    Fp: Fpk1,
    lowS: true, // Allow only low-S signatures by default in sign() and verify()
    endo: {
        // Endomorphism, see above
        beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
        splitScalar: (k) => {
            const n = secp256k1_CURVE.n;
            const a1 = BigInt('0x3086d221a7d46bcde86c90e49284eb15');
            const b1 = -_1n$1 * BigInt('0xe4437ed6010e88286f547fa90abfe4c3');
            const a2 = BigInt('0x114ca50f7a8e2f3f657c1108d9d44cfd8');
            const b2 = a1;
            const POW_2_128 = BigInt('0x100000000000000000000000000000000'); // (2n**128n).toString(16)
            const c1 = divNearest$1(b2 * k, n);
            const c2 = divNearest$1(-b1 * k, n);
            let k1 = mod$1(k - c1 * a1 - c2 * a2, n);
            let k2 = mod$1(-c1 * b1 - c2 * b2, n);
            const k1neg = k1 > POW_2_128;
            const k2neg = k2 > POW_2_128;
            if (k1neg)
                k1 = n - k1;
            if (k2neg)
                k2 = n - k2;
            if (k1 > POW_2_128 || k2 > POW_2_128) {
                throw new Error('splitScalar: Endomorphism failed, k=' + k);
            }
            return { k1neg, k1, k2neg, k2 };
        },
    },
}, sha256$1);

const PUBLIC_KEY_BYTE_LENGTH = 33;
/**
 * Hash message and verify signature with public key
 */
function hashAndVerify(key, sig, msg, options) {
    const p = sha256$2.digest(msg instanceof Uint8Array ? msg : msg.subarray());
    if (isPromise$2(p)) {
        return p
            .then(({ digest }) => {
            options?.signal?.throwIfAborted();
            return secp256k1.verify(sig, digest, key);
        })
            .catch(err => {
            if (err.name === 'AbortError') {
                throw err;
            }
            throw new VerificationError(String(err));
        });
    }
    try {
        options?.signal?.throwIfAborted();
        return secp256k1.verify(sig, p.digest, key);
    }
    catch (err) {
        throw new VerificationError(String(err));
    }
}

class Secp256k1PublicKey {
    type = 'secp256k1';
    raw;
    _key;
    constructor(key) {
        this._key = validateSecp256k1PublicKey(key);
        this.raw = compressSecp256k1PublicKey(this._key);
    }
    toMultihash() {
        return identity.digest(publicKeyToProtobuf(this));
    }
    toCID() {
        return CID.createV1(114, this.toMultihash());
    }
    toString() {
        return base58btc.encode(this.toMultihash().bytes).substring(1);
    }
    equals(key) {
        if (key == null || !(key.raw instanceof Uint8Array)) {
            return false;
        }
        return equals(this.raw, key.raw);
    }
    verify(data, sig, options) {
        return hashAndVerify(this._key, sig, data, options);
    }
}

function unmarshalSecp256k1PublicKey(bytes) {
    return new Secp256k1PublicKey(bytes);
}
function compressSecp256k1PublicKey(key) {
    const point = secp256k1.ProjectivePoint.fromHex(key).toRawBytes(true);
    return point;
}
function validateSecp256k1PublicKey(key) {
    try {
        secp256k1.ProjectivePoint.fromHex(key);
        return key;
    }
    catch (err) {
        throw new InvalidPublicKeyError(String(err));
    }
}

/**
 * @packageDocumentation
 *
 * ## Supported Key Types
 *
 * Currently the `'RSA'`, `'ed25519'`, and `secp256k1` types are supported, although ed25519 and secp256k1 keys support only signing and verification of messages.
 *
 * For encryption / decryption support, RSA keys should be used.
 */
async function generateKeyPair(type, bits) {
    {
        return generateEd25519KeyPair();
    }
}
/**
 * Converts a protobuf serialized public key into its representative object.
 *
 * For RSA public keys optionally pass the multihash digest of the public key if
 * it is known. If the digest is omitted it will be calculated which can be
 * expensive.
 *
 * For other key types the digest option is ignored.
 */
function publicKeyFromProtobuf(buf, digest) {
    const { Type, Data } = PublicKey.decode(buf);
    const data = Data ?? new Uint8Array();
    switch (Type) {
        case KeyType.RSA:
            return pkixToRSAPublicKey(data, digest);
        case KeyType.Ed25519:
            return unmarshalEd25519PublicKey(data);
        case KeyType.secp256k1:
            return unmarshalSecp256k1PublicKey(data);
        case KeyType.ECDSA:
            return unmarshalECDSAPublicKey(data);
        default:
            throw new UnsupportedKeyTypeError();
    }
}
/**
 * Creates a public key from the raw key bytes
 */
function publicKeyFromRaw(buf) {
    if (buf.byteLength === PUBLIC_KEY_BYTE_LENGTH$1) {
        return unmarshalEd25519PublicKey(buf);
    }
    else if (buf.byteLength === PUBLIC_KEY_BYTE_LENGTH) {
        return unmarshalSecp256k1PublicKey(buf);
    }
    const message = decodeDer(buf);
    const ecdsaOid = message[1]?.[0];
    if (ecdsaOid === ECDSA_P_256_OID || ecdsaOid === ECDSA_P_384_OID || ecdsaOid === ECDSA_P_521_OID) {
        return pkiMessageToECDSAPublicKey(message);
    }
    if (message[0]?.[0] === RSAES_PKCS1_V1_5_OID) {
        return pkixMessageToRSAPublicKey(message, buf);
    }
    throw new InvalidParametersError$1('Could not extract public key from raw bytes');
}
/**
 * Creates a public key from an identity multihash which contains a protobuf
 * encoded Ed25519 or secp256k1 public key.
 *
 * RSA keys are not supported as in practice we they are not stored in identity
 * multihash since the hash would be very large.
 */
function publicKeyFromMultihash(digest) {
    const { Type, Data } = PublicKey.decode(digest.digest);
    const data = Data ?? new Uint8Array();
    switch (Type) {
        case KeyType.Ed25519:
            return unmarshalEd25519PublicKey(data);
        case KeyType.secp256k1:
            return unmarshalSecp256k1PublicKey(data);
        case KeyType.ECDSA:
            return unmarshalECDSAPublicKey(data);
        default:
            throw new UnsupportedKeyTypeError();
    }
}
/**
 * Converts a public key object into a protobuf serialized public key
 */
function publicKeyToProtobuf(key) {
    return PublicKey.encode({
        Type: KeyType[key.type],
        Data: key.raw
    });
}

/**
 * @packageDocumentation
 *
 * An implementation of a peer id
 *
 * @example
 *
 * ```TypeScript
 * import { peerIdFromString } from '@libp2p/peer-id'
 * const peer = peerIdFromString('k51qzi5uqu5dkwkqm42v9j9kqcam2jiuvloi16g72i4i4amoo2m8u3ol3mqu6s')
 *
 * console.log(peer.toCID()) // CID(bafzaa...)
 * console.log(peer.toString()) // "12D3K..."
 * ```
 */
const inspect$1 = Symbol.for('nodejs.util.inspect.custom');
// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv
const LIBP2P_KEY_CODE$1 = 0x72;
class PeerIdImpl {
    type;
    multihash;
    publicKey;
    string;
    constructor(init) {
        this.type = init.type;
        this.multihash = init.multihash;
        // mark string cache as non-enumerable
        Object.defineProperty(this, 'string', {
            enumerable: false,
            writable: true
        });
    }
    get [Symbol.toStringTag]() {
        return `PeerId(${this.toString()})`;
    }
    [peerIdSymbol] = true;
    toString() {
        if (this.string == null) {
            this.string = base58btc.encode(this.multihash.bytes).slice(1);
        }
        return this.string;
    }
    toMultihash() {
        return this.multihash;
    }
    // return self-describing String representation
    // in default format from RFC 0001: https://github.com/libp2p/specs/pull/209
    toCID() {
        return CID.createV1(LIBP2P_KEY_CODE$1, this.multihash);
    }
    toJSON() {
        return this.toString();
    }
    /**
     * Checks the equality of `this` peer against a given PeerId
     */
    equals(id) {
        if (id == null) {
            return false;
        }
        if (id instanceof Uint8Array) {
            return equals(this.multihash.bytes, id);
        }
        else if (typeof id === 'string') {
            return this.toString() === id;
        }
        else if (id?.toMultihash()?.bytes != null) {
            return equals(this.multihash.bytes, id.toMultihash().bytes);
        }
        else {
            throw new Error('not valid Id');
        }
    }
    /**
     * Returns PeerId as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```TypeScript
     * import { peerIdFromString } from '@libp2p/peer-id'
     *
     * console.info(peerIdFromString('QmFoo'))
     * // 'PeerId(QmFoo)'
     * ```
     */
    [inspect$1]() {
        return `PeerId(${this.toString()})`;
    }
}
class RSAPeerId extends PeerIdImpl {
    type = 'RSA';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'RSA' });
        this.publicKey = init.publicKey;
    }
}
class Ed25519PeerId extends PeerIdImpl {
    type = 'Ed25519';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'Ed25519' });
        this.publicKey = init.publicKey;
    }
}
class Secp256k1PeerId extends PeerIdImpl {
    type = 'secp256k1';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'secp256k1' });
        this.publicKey = init.publicKey;
    }
}
// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv
const TRANSPORT_IPFS_GATEWAY_HTTP_CODE$1 = 0x0920;
class URLPeerId {
    type = 'url';
    multihash;
    publicKey;
    url;
    constructor(url) {
        this.url = url.toString();
        this.multihash = identity.digest(fromString(this.url));
    }
    [inspect$1]() {
        return `PeerId(${this.url})`;
    }
    [peerIdSymbol] = true;
    toString() {
        return this.toCID().toString();
    }
    toMultihash() {
        return this.multihash;
    }
    toCID() {
        return CID.createV1(TRANSPORT_IPFS_GATEWAY_HTTP_CODE$1, this.toMultihash());
    }
    toJSON() {
        return this.toString();
    }
    equals(other) {
        if (other == null) {
            return false;
        }
        if (other instanceof Uint8Array) {
            other = toString(other);
        }
        return other.toString() === this.toString();
    }
}

/**
 * @packageDocumentation
 *
 * An implementation of a peer id
 *
 * @example
 *
 * ```TypeScript
 * import { peerIdFromString } from '@libp2p/peer-id'
 * const peer = peerIdFromString('12D3KooWKnDdG3iXw9eTFijk3EWSunZcFi54Zka4wmtqtt6rPxc8')
 *
 * console.log(peer.toCID()) // CID(bafzaa...)
 * console.log(peer.toString()) // "12D3K..."
 * ```
 */
// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv
const LIBP2P_KEY_CODE = 0x72;
const TRANSPORT_IPFS_GATEWAY_HTTP_CODE = 0x0920;
function peerIdFromString$1(str, decoder) {
    let multihash;
    if (str.charAt(0) === '1' || str.charAt(0) === 'Q') {
        // identity hash ed25519/secp256k1 key or sha2-256 hash of
        // rsa public key - base58btc encoded either way
        multihash = decode$3(base58btc.decode(`z${str}`));
    }
    else if (str.startsWith('k51qzi5uqu5') || str.startsWith('kzwfwjn5ji4') || str.startsWith('k2k4r8') || str.startsWith('bafz')) {
        // base36 encoded CIDv1 with libp2p-key and identity hash (for ed25519/secp256k1/rsa) or base32 encoded CIDv1 with libp2p-key and identity hash (for ed25519/secp256k1/rsa)
        return peerIdFromCID(CID.parse(str));
    }
    else {
        {
            throw new InvalidParametersError$1('Please pass a multibase decoder for strings that do not start with "1" or "Q"');
        }
    }
    return peerIdFromMultihash(multihash);
}
function peerIdFromPublicKey(publicKey) {
    if (publicKey.type === 'Ed25519') {
        return new Ed25519PeerId({
            multihash: publicKey.toCID().multihash,
            publicKey
        });
    }
    else if (publicKey.type === 'secp256k1') {
        return new Secp256k1PeerId({
            multihash: publicKey.toCID().multihash,
            publicKey
        });
    }
    else if (publicKey.type === 'RSA') {
        return new RSAPeerId({
            multihash: publicKey.toCID().multihash,
            publicKey
        });
    }
    throw new UnsupportedKeyTypeError();
}
function peerIdFromPrivateKey(privateKey) {
    return peerIdFromPublicKey(privateKey.publicKey);
}
function peerIdFromMultihash(multihash) {
    if (isSha256Multihash(multihash)) {
        return new RSAPeerId({ multihash });
    }
    else if (isIdentityMultihash(multihash)) {
        try {
            const publicKey = publicKeyFromMultihash(multihash);
            if (publicKey.type === 'Ed25519') {
                return new Ed25519PeerId({ multihash, publicKey });
            }
            else if (publicKey.type === 'secp256k1') {
                return new Secp256k1PeerId({ multihash, publicKey });
            }
        }
        catch (err) {
            // was not Ed or secp key, try URL
            const url = toString(multihash.digest);
            return new URLPeerId(new URL(url));
        }
    }
    throw new InvalidMultihashError('Supplied PeerID Multihash is invalid');
}
function peerIdFromCID(cid) {
    if (cid?.multihash == null || cid.version == null || (cid.version === 1 && (cid.code !== LIBP2P_KEY_CODE) && cid.code !== TRANSPORT_IPFS_GATEWAY_HTTP_CODE)) {
        throw new InvalidCIDError('Supplied PeerID CID is invalid');
    }
    if (cid.code === TRANSPORT_IPFS_GATEWAY_HTTP_CODE) {
        const url = toString(cid.multihash.digest);
        return new URLPeerId(new URL(url));
    }
    return peerIdFromMultihash(cid.multihash);
}
function isIdentityMultihash(multihash) {
    return multihash.code === identity.code;
}
function isSha256Multihash(multihash) {
    return multihash.code === sha256$2.code;
}

/**
 * Thrown when an invalid multiaddr is encountered
 */
class InvalidMultiaddrError extends Error {
    static name = 'InvalidMultiaddrError';
    name = 'InvalidMultiaddrError';
}
class ValidationError extends Error {
    static name = 'ValidationError';
    name = 'ValidationError';
}
class InvalidParametersError extends Error {
    static name = 'InvalidParametersError';
    name = 'InvalidParametersError';
}
class UnknownProtocolError extends Error {
    static name = 'UnknownProtocolError';
    name = 'UnknownProtocolError';
}

/* eslint-disable @typescript-eslint/no-unsafe-return */
class Parser {
    index = 0;
    input = "";
    new(input) {
        this.index = 0;
        this.input = input;
        return this;
    }
    /** Run a parser, and restore the pre-parse state if it fails. */
    readAtomically(fn) {
        const index = this.index;
        const result = fn();
        if (result === undefined) {
            this.index = index;
        }
        return result;
    }
    /** Run a parser, but fail if the entire input wasn't consumed. Doesn't run atomically. */
    parseWith(fn) {
        const result = fn();
        if (this.index !== this.input.length) {
            return undefined;
        }
        return result;
    }
    /** Peek the next character from the input */
    peekChar() {
        if (this.index >= this.input.length) {
            return undefined;
        }
        return this.input[this.index];
    }
    /** Read the next character from the input */
    readChar() {
        if (this.index >= this.input.length) {
            return undefined;
        }
        return this.input[this.index++];
    }
    /** Read the next character from the input if it matches the target. */
    readGivenChar(target) {
        return this.readAtomically(() => {
            const char = this.readChar();
            if (char !== target) {
                return undefined;
            }
            return char;
        });
    }
    /**
     * Helper for reading separators in an indexed loop. Reads the separator
     * character iff index > 0, then runs the parser. When used in a loop,
     * the separator character will only be read on index > 0 (see
     * readIPv4Addr for an example)
     */
    readSeparator(sep, index, inner) {
        return this.readAtomically(() => {
            if (index > 0) {
                if (this.readGivenChar(sep) === undefined) {
                    return undefined;
                }
            }
            return inner();
        });
    }
    /**
     * Read a number off the front of the input in the given radix, stopping
     * at the first non-digit character or eof. Fails if the number has more
     * digits than max_digits or if there is no number.
     */
    readNumber(radix, maxDigits, allowZeroPrefix, maxBytes) {
        return this.readAtomically(() => {
            let result = 0;
            let digitCount = 0;
            const leadingChar = this.peekChar();
            if (leadingChar === undefined) {
                return undefined;
            }
            const hasLeadingZero = leadingChar === "0";
            const maxValue = 2 ** (8 * maxBytes) - 1;
            // eslint-disable-next-line no-constant-condition
            while (true) {
                const digit = this.readAtomically(() => {
                    const char = this.readChar();
                    if (char === undefined) {
                        return undefined;
                    }
                    const num = Number.parseInt(char, radix);
                    if (Number.isNaN(num)) {
                        return undefined;
                    }
                    return num;
                });
                if (digit === undefined) {
                    break;
                }
                result *= radix;
                result += digit;
                if (result > maxValue) {
                    return undefined;
                }
                digitCount += 1;
                if (maxDigits !== undefined) {
                    if (digitCount > maxDigits) {
                        return undefined;
                    }
                }
            }
            if (digitCount === 0) {
                return undefined;
            }
            else if (!allowZeroPrefix && hasLeadingZero && digitCount > 1) {
                return undefined;
            }
            else {
                return result;
            }
        });
    }
    /** Read an IPv4 address. */
    readIPv4Addr() {
        return this.readAtomically(() => {
            const out = new Uint8Array(4);
            for (let i = 0; i < out.length; i++) {
                const ix = this.readSeparator(".", i, () => this.readNumber(10, 3, false, 1));
                if (ix === undefined) {
                    return undefined;
                }
                out[i] = ix;
            }
            return out;
        });
    }
    /** Read an IPv6 Address. */
    readIPv6Addr() {
        /**
         * Read a chunk of an IPv6 address into `groups`. Returns the number
         * of groups read, along with a bool indicating if an embedded
         * trailing IPv4 address was read. Specifically, read a series of
         * colon-separated IPv6 groups (0x0000 - 0xFFFF), with an optional
         * trailing embedded IPv4 address.
         */
        const readGroups = (groups) => {
            for (let i = 0; i < groups.length / 2; i++) {
                const ix = i * 2;
                // Try to read a trailing embedded IPv4 address. There must be at least 4 groups left.
                if (i < groups.length - 3) {
                    const ipv4 = this.readSeparator(":", i, () => this.readIPv4Addr());
                    if (ipv4 !== undefined) {
                        groups[ix] = ipv4[0];
                        groups[ix + 1] = ipv4[1];
                        groups[ix + 2] = ipv4[2];
                        groups[ix + 3] = ipv4[3];
                        return [ix + 4, true];
                    }
                }
                const group = this.readSeparator(":", i, () => this.readNumber(16, 4, true, 2));
                if (group === undefined) {
                    return [ix, false];
                }
                groups[ix] = group >> 8;
                groups[ix + 1] = group & 255;
            }
            return [groups.length, false];
        };
        return this.readAtomically(() => {
            // Read the front part of the address; either the whole thing, or up to the first ::
            const head = new Uint8Array(16);
            const [headSize, headIp4] = readGroups(head);
            if (headSize === 16) {
                return head;
            }
            // IPv4 part is not allowed before `::`
            if (headIp4) {
                return undefined;
            }
            // Read `::` if previous code parsed less than 8 groups.
            // `::` indicates one or more groups of 16 bits of zeros.
            if (this.readGivenChar(":") === undefined) {
                return undefined;
            }
            if (this.readGivenChar(":") === undefined) {
                return undefined;
            }
            // Read the back part of the address. The :: must contain at least one
            // set of zeroes, so our max length is 7.
            const tail = new Uint8Array(14);
            const limit = 16 - (headSize + 2);
            const [tailSize] = readGroups(tail.subarray(0, limit));
            // Concat the head and tail of the IP address
            head.set(tail.subarray(0, tailSize), 16 - tailSize);
            return head;
        });
    }
    /** Read an IP Address, either IPv4 or IPv6. */
    readIPAddr() {
        return this.readIPv4Addr() ?? this.readIPv6Addr();
    }
}

// See https://stackoverflow.com/questions/166132/maximum-length-of-the-textual-representation-of-an-ipv6-address
const MAX_IPV6_LENGTH = 45;
const MAX_IPV4_LENGTH = 15;
const parser = new Parser();
/** Parse `input` into IPv4 bytes. */
function parseIPv4(input) {
    if (input.length > MAX_IPV4_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPv4Addr());
}
/** Parse `input` into IPv6 bytes. */
function parseIPv6(input) {
    // strip zone index if it is present
    if (input.includes("%")) {
        input = input.split("%")[0];
    }
    if (input.length > MAX_IPV6_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPv6Addr());
}
/** Parse `input` into IPv4 or IPv6 bytes. */
function parseIP(input, mapIPv4ToIPv6 = false) {
    // strip zone index if it is present
    if (input.includes("%")) {
        input = input.split("%")[0];
    }
    if (input.length > MAX_IPV6_LENGTH) {
        return undefined;
    }
    const addr = parser.new(input).parseWith(() => parser.readIPAddr());
    if (!addr) {
        return undefined;
    }
    if (mapIPv4ToIPv6 && addr.length === 4) {
        return Uint8Array.from([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0xff, 0xff, addr[0], addr[1], addr[2], addr[3]]);
    }
    return addr;
}

/** Check if `input` is IPv4. */
function isIPv4(input) {
    return Boolean(parseIPv4(input));
}
/** Check if `input` is IPv6. */
function isIPv6(input) {
    return Boolean(parseIPv6(input));
}

// the values here come from https://github.com/multiformats/multiaddr/blob/master/protocols.csv
const CODE_IP4 = 4;
const CODE_TCP = 6;
const CODE_UDP = 273;
const CODE_DCCP = 33;
const CODE_IP6 = 41;
const CODE_IP6ZONE = 42;
const CODE_IPCIDR = 43;
const CODE_DNS = 53;
const CODE_DNS4 = 54;
const CODE_DNS6 = 55;
const CODE_DNSADDR = 56;
const CODE_SCTP = 132;
const CODE_UDT = 301;
const CODE_UTP = 302;
const CODE_UNIX = 400;
const CODE_P2P = 421; // also IPFS
const CODE_ONION = 444;
const CODE_ONION3 = 445;
const CODE_GARLIC64 = 446;
const CODE_GARLIC32 = 447;
const CODE_TLS = 448;
const CODE_SNI = 449;
const CODE_NOISE = 454;
const CODE_QUIC = 460;
const CODE_QUIC_V1 = 461;
const CODE_WEBTRANSPORT = 465;
const CODE_CERTHASH = 466;
const CODE_HTTP = 480;
const CODE_HTTP_PATH = 481;
const CODE_HTTPS = 443;
const CODE_WS = 477;
const CODE_WSS = 478;
const CODE_P2P_WEBSOCKET_STAR = 479;
const CODE_P2P_STARDUST = 277;
const CODE_P2P_WEBRTC_STAR = 275;
const CODE_P2P_WEBRTC_DIRECT = 276;
const CODE_WEBRTC_DIRECT = 280;
const CODE_WEBRTC = 281;
const CODE_P2P_CIRCUIT = 290;
const CODE_MEMORY = 777;

function bytesToString(base) {
    return (buf) => {
        return toString(buf, base);
    };
}
function stringToBytes(base) {
    return (buf) => {
        return fromString(buf, base);
    };
}
function bytes2port(buf) {
    const view = new DataView(buf.buffer);
    return view.getUint16(buf.byteOffset).toString();
}
function port2bytes(port) {
    const buf = new ArrayBuffer(2);
    const view = new DataView(buf);
    view.setUint16(0, typeof port === 'string' ? parseInt(port) : port);
    return new Uint8Array(buf);
}
function onion2bytes(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 16) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = fromString(addr[0], 'base32');
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes(port);
    return concat([buf, portBuf], buf.length + portBuf.length);
}
function onion32bytes(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 56) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion3 address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$2.decode(`b${addr[0]}`);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes(port);
    return concat([buf, portBuf], buf.length + portBuf.length);
}
function bytes2onion(buf) {
    const addrBytes = buf.subarray(0, buf.length - 2);
    const portBytes = buf.subarray(buf.length - 2);
    const addr = toString(addrBytes, 'base32');
    const port = bytes2port(portBytes);
    return `${addr}:${port}`;
}
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L7
// but with buf/offset args removed because we don't use them
const ip4ToBytes = function (ip) {
    ip = ip.toString().trim();
    const bytes = new Uint8Array(4);
    ip.split(/\./g).forEach((byte, index) => {
        const value = parseInt(byte, 10);
        if (isNaN(value) || value < 0 || value > 0xff) {
            throw new InvalidMultiaddrError('Invalid byte value in IP address');
        }
        bytes[index] = value;
    });
    return bytes;
};
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L7
// but with buf/offset args removed because we don't use them
const ip6ToBytes = function (ip) {
    let offset = 0;
    ip = ip.toString().trim();
    const sections = ip.split(':', 8);
    let i;
    for (i = 0; i < sections.length; i++) {
        const isv4 = isIPv4(sections[i]);
        let v4Buffer;
        if (isv4) {
            v4Buffer = ip4ToBytes(sections[i]);
            sections[i] = toString(v4Buffer.subarray(0, 2), 'base16');
        }
        if (v4Buffer != null && ++i < 8) {
            sections.splice(i, 0, toString(v4Buffer.subarray(2, 4), 'base16'));
        }
    }
    if (sections[0] === '') {
        while (sections.length < 8) {
            sections.unshift('0');
        }
    }
    else if (sections[sections.length - 1] === '') {
        while (sections.length < 8) {
            sections.push('0');
        }
    }
    else if (sections.length < 8) {
        for (i = 0; i < sections.length && sections[i] !== ''; i++) { }
        const argv = [i, 1];
        for (i = 9 - sections.length; i > 0; i--) {
            argv.push('0');
        }
        sections.splice.apply(sections, argv);
    }
    const bytes = new Uint8Array(offset + 16);
    for (i = 0; i < sections.length; i++) {
        if (sections[i] === '') {
            sections[i] = '0';
        }
        const word = parseInt(sections[i], 16);
        if (isNaN(word) || word < 0 || word > 0xffff) {
            throw new InvalidMultiaddrError('Invalid byte value in IP address');
        }
        bytes[offset++] = (word >> 8) & 0xff;
        bytes[offset++] = word & 0xff;
    }
    return bytes;
};
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L63
const ip4ToString = function (buf) {
    if (buf.byteLength !== 4) {
        throw new InvalidMultiaddrError('IPv4 address was incorrect length');
    }
    const result = [];
    for (let i = 0; i < buf.byteLength; i++) {
        result.push(buf[i]);
    }
    return result.join('.');
};
const ip6ToString = function (buf) {
    if (buf.byteLength !== 16) {
        throw new InvalidMultiaddrError('IPv6 address was incorrect length');
    }
    const result = [];
    for (let i = 0; i < buf.byteLength; i += 2) {
        const byte1 = buf[i];
        const byte2 = buf[i + 1];
        const tuple = `${byte1.toString(16).padStart(2, '0')}${byte2.toString(16).padStart(2, '0')}`;
        result.push(tuple);
    }
    const ip = result.join(':');
    try {
        const url = new URL(`http://[${ip}]`);
        return url.hostname.substring(1, url.hostname.length - 1);
    }
    catch {
        throw new InvalidMultiaddrError(`Invalid IPv6 address "${ip}"`);
    }
};
function ip6StringToValue(str) {
    try {
        const url = new URL(`http://[${str}]`);
        return url.hostname.substring(1, url.hostname.length - 1);
    }
    catch {
        throw new InvalidMultiaddrError(`Invalid IPv6 address "${str}"`);
    }
}
const decoders = Object.values(bases).map((c) => c.decoder);
const anybaseDecoder = (function () {
    let acc = decoders[0].or(decoders[1]);
    decoders.slice(2).forEach((d) => (acc = acc.or(d)));
    return acc;
})();
function mb2bytes(mbstr) {
    return anybaseDecoder.decode(mbstr);
}
function bytes2mb(base) {
    return (buf) => {
        return base.encoder.encode(buf);
    };
}

function integer(value) {
    const int = parseInt(value);
    if (int.toString() !== value) {
        throw new ValidationError('Value must be an integer');
    }
}
function positive(value) {
    if (value < 0) {
        throw new ValidationError('Value must be a positive integer, or zero');
    }
}
function maxValue(max) {
    return (value) => {
        if (value > max) {
            throw new ValidationError(`Value must be smaller than or equal to ${max}`);
        }
    };
}
function validate$1(...funcs) {
    return (value) => {
        for (const fn of funcs) {
            fn(value);
        }
    };
}
const validatePort = validate$1(integer, positive, maxValue(65_535));

const V$1 = -1;
class Registry {
    protocolsByCode = new Map();
    protocolsByName = new Map();
    getProtocol(key) {
        let codec;
        if (typeof key === 'string') {
            codec = this.protocolsByName.get(key);
        }
        else {
            codec = this.protocolsByCode.get(key);
        }
        if (codec == null) {
            throw new UnknownProtocolError(`Protocol ${key} was unknown`);
        }
        return codec;
    }
    addProtocol(codec) {
        this.protocolsByCode.set(codec.code, codec);
        this.protocolsByName.set(codec.name, codec);
        codec.aliases?.forEach(alias => {
            this.protocolsByName.set(alias, codec);
        });
    }
    removeProtocol(code) {
        const codec = this.protocolsByCode.get(code);
        if (codec == null) {
            return;
        }
        this.protocolsByCode.delete(codec.code);
        this.protocolsByName.delete(codec.name);
        codec.aliases?.forEach(alias => {
            this.protocolsByName.delete(alias);
        });
    }
}
const registry = new Registry();
const codecs = [{
        code: CODE_IP4,
        name: 'ip4',
        size: 32,
        valueToBytes: ip4ToBytes,
        bytesToValue: ip4ToString,
        validate: (value) => {
            if (!isIPv4(value)) {
                throw new ValidationError(`Invalid IPv4 address "${value}"`);
            }
        }
    }, {
        code: CODE_TCP,
        name: 'tcp',
        size: 16,
        valueToBytes: port2bytes,
        bytesToValue: bytes2port,
        validate: validatePort
    }, {
        code: CODE_UDP,
        name: 'udp',
        size: 16,
        valueToBytes: port2bytes,
        bytesToValue: bytes2port,
        validate: validatePort
    }, {
        code: CODE_DCCP,
        name: 'dccp',
        size: 16,
        valueToBytes: port2bytes,
        bytesToValue: bytes2port,
        validate: validatePort
    }, {
        code: CODE_IP6,
        name: 'ip6',
        size: 128,
        valueToBytes: ip6ToBytes,
        bytesToValue: ip6ToString,
        stringToValue: ip6StringToValue,
        validate: (value) => {
            if (!isIPv6(value)) {
                throw new ValidationError(`Invalid IPv6 address "${value}"`);
            }
        }
    }, {
        code: CODE_IP6ZONE,
        name: 'ip6zone',
        size: V$1
    }, {
        code: CODE_IPCIDR,
        name: 'ipcidr',
        size: 8,
        bytesToValue: bytesToString('base10'),
        valueToBytes: stringToBytes('base10')
    }, {
        code: CODE_DNS,
        name: 'dns',
        size: V$1,
        resolvable: true
    }, {
        code: CODE_DNS4,
        name: 'dns4',
        size: V$1,
        resolvable: true
    }, {
        code: CODE_DNS6,
        name: 'dns6',
        size: V$1,
        resolvable: true
    }, {
        code: CODE_DNSADDR,
        name: 'dnsaddr',
        size: V$1,
        resolvable: true
    }, {
        code: CODE_SCTP,
        name: 'sctp',
        size: 16,
        valueToBytes: port2bytes,
        bytesToValue: bytes2port,
        validate: validatePort
    }, {
        code: CODE_UDT,
        name: 'udt'
    }, {
        code: CODE_UTP,
        name: 'utp'
    }, {
        code: CODE_UNIX,
        name: 'unix',
        size: V$1,
        path: true,
        stringToValue: (str) => decodeURIComponent(str),
        valueToString: (val) => encodeURIComponent(val)
    }, {
        code: CODE_P2P,
        name: 'p2p',
        aliases: ['ipfs'],
        size: V$1,
        bytesToValue: bytesToString('base58btc'),
        valueToBytes: (val) => {
            if (val.startsWith('Q') || val.startsWith('1')) {
                return stringToBytes('base58btc')(val);
            }
            return CID.parse(val).multihash.bytes;
        }
    }, {
        code: CODE_ONION,
        name: 'onion',
        size: 96,
        bytesToValue: bytes2onion,
        valueToBytes: onion2bytes
    }, {
        code: CODE_ONION3,
        name: 'onion3',
        size: 296,
        bytesToValue: bytes2onion,
        valueToBytes: onion32bytes
    }, {
        code: CODE_GARLIC64,
        name: 'garlic64',
        size: V$1
    }, {
        code: CODE_GARLIC32,
        name: 'garlic32',
        size: V$1
    }, {
        code: CODE_TLS,
        name: 'tls'
    }, {
        code: CODE_SNI,
        name: 'sni',
        size: V$1
    }, {
        code: CODE_NOISE,
        name: 'noise'
    }, {
        code: CODE_QUIC,
        name: 'quic'
    }, {
        code: CODE_QUIC_V1,
        name: 'quic-v1'
    }, {
        code: CODE_WEBTRANSPORT,
        name: 'webtransport'
    }, {
        code: CODE_CERTHASH,
        name: 'certhash',
        size: V$1,
        bytesToValue: bytes2mb(base64url),
        valueToBytes: mb2bytes
    }, {
        code: CODE_HTTP,
        name: 'http'
    }, {
        code: CODE_HTTP_PATH,
        name: 'http-path',
        size: V$1,
        stringToValue: (str) => `/${decodeURIComponent(str)}`,
        valueToString: (val) => encodeURIComponent(val.substring(1))
    }, {
        code: CODE_HTTPS,
        name: 'https'
    }, {
        code: CODE_WS,
        name: 'ws'
    }, {
        code: CODE_WSS,
        name: 'wss'
    }, {
        code: CODE_P2P_WEBSOCKET_STAR,
        name: 'p2p-websocket-star'
    }, {
        code: CODE_P2P_STARDUST,
        name: 'p2p-stardust'
    }, {
        code: CODE_P2P_WEBRTC_STAR,
        name: 'p2p-webrtc-star'
    }, {
        code: CODE_P2P_WEBRTC_DIRECT,
        name: 'p2p-webrtc-direct'
    }, {
        code: CODE_WEBRTC_DIRECT,
        name: 'webrtc-direct'
    }, {
        code: CODE_WEBRTC,
        name: 'webrtc'
    }, {
        code: CODE_P2P_CIRCUIT,
        name: 'p2p-circuit'
    }, {
        code: CODE_MEMORY,
        name: 'memory',
        size: V$1
    }];
codecs.forEach(codec => {
    registry.addProtocol(codec);
});

function bytesToComponents(bytes) {
    const components = [];
    let i = 0;
    while (i < bytes.length) {
        const code = decode$8(bytes, i);
        const codec = registry.getProtocol(code);
        const codeLength = encodingLength$1(code);
        const size = sizeForAddr(codec, bytes, i + codeLength);
        let sizeLength = 0;
        if (size > 0 && codec.size === V$1) {
            sizeLength = encodingLength$1(size);
        }
        const componentLength = codeLength + sizeLength + size;
        const component = {
            code,
            name: codec.name,
            bytes: bytes.subarray(i, i + componentLength)
        };
        if (size > 0) {
            const valueOffset = i + codeLength + sizeLength;
            const valueBytes = bytes.subarray(valueOffset, valueOffset + size);
            component.value = codec.bytesToValue?.(valueBytes) ?? toString(valueBytes);
        }
        components.push(component);
        i += componentLength;
    }
    return components;
}
function componentsToBytes(components) {
    let length = 0;
    const bytes = [];
    for (const component of components) {
        if (component.bytes == null) {
            const codec = registry.getProtocol(component.code);
            const codecLength = encodingLength$1(component.code);
            let valueBytes;
            let valueLength = 0;
            let valueLengthLength = 0;
            if (component.value != null) {
                valueBytes = codec.valueToBytes?.(component.value) ?? fromString(component.value);
                valueLength = valueBytes.byteLength;
                if (codec.size === V$1) {
                    valueLengthLength = encodingLength$1(valueLength);
                }
            }
            const bytes = new Uint8Array(codecLength + valueLengthLength + valueLength);
            // encode the protocol code
            let offset = 0;
            encodeUint8Array(component.code, bytes, offset);
            offset += codecLength;
            // if there is a value
            if (valueBytes != null) {
                // if the value has variable length, encode the length
                if (codec.size === V$1) {
                    encodeUint8Array(valueLength, bytes, offset);
                    offset += valueLengthLength;
                }
                // finally encode the value
                bytes.set(valueBytes, offset);
            }
            component.bytes = bytes;
        }
        bytes.push(component.bytes);
        length += component.bytes.byteLength;
    }
    return concat(bytes, length);
}
function stringToComponents(string) {
    if (string.charAt(0) !== '/') {
        throw new InvalidMultiaddrError('String multiaddr must start with "/"');
    }
    const components = [];
    let collecting = 'protocol';
    let value = '';
    let protocol = '';
    for (let i = 1; i < string.length; i++) {
        const char = string.charAt(i);
        if (char !== '/') {
            if (collecting === 'protocol') {
                protocol += string.charAt(i);
            }
            else {
                value += string.charAt(i);
            }
        }
        const ended = i === string.length - 1;
        if (char === '/' || ended) {
            const codec = registry.getProtocol(protocol);
            if (collecting === 'protocol') {
                if (codec.size == null || codec.size === 0) {
                    // a protocol without an address, eg. `/tls`
                    components.push({
                        code: codec.code,
                        name: codec.name
                    });
                    value = '';
                    protocol = '';
                    collecting = 'protocol';
                    continue;
                }
                else if (ended) {
                    throw new InvalidMultiaddrError(`Component ${protocol} was missing value`);
                }
                // continue collecting value
                collecting = 'value';
            }
            else if (collecting === 'value') {
                const component = {
                    code: codec.code,
                    name: codec.name
                };
                if (codec.size != null && codec.size !== 0) {
                    if (value === '') {
                        throw new InvalidMultiaddrError(`Component ${protocol} was missing value`);
                    }
                    component.value = codec.stringToValue?.(value) ?? value;
                }
                components.push(component);
                value = '';
                protocol = '';
                collecting = 'protocol';
            }
        }
    }
    if (protocol !== '' && value !== '') {
        throw new InvalidMultiaddrError('Incomplete multiaddr');
    }
    return components;
}
function componentsToString(components) {
    return `/${components.flatMap(component => {
        if (component.value == null) {
            return component.name;
        }
        const codec = registry.getProtocol(component.code);
        if (codec == null) {
            throw new InvalidMultiaddrError(`Unknown protocol code ${component.code}`);
        }
        return [
            component.name,
            codec.valueToString?.(component.value) ?? component.value
        ];
    }).join('/')}`;
}
/**
 * For the passed address, return the serialized size
 */
function sizeForAddr(codec, bytes, offset) {
    if (codec.size == null || codec.size === 0) {
        return 0;
    }
    if (codec.size > 0) {
        return codec.size / 8;
    }
    return decode$8(bytes, offset);
}

const inspect = Symbol.for('nodejs.util.inspect.custom');
const symbol = Symbol.for('@multiformats/multiaddr');
const DNS_CODES = [
    CODE_DNS,
    CODE_DNS4,
    CODE_DNS6,
    CODE_DNSADDR
];
class NoAvailableResolverError extends Error {
    constructor(message = 'No available resolver') {
        super(message);
        this.name = 'NoAvailableResolverError';
    }
}
function toComponents(addr) {
    if (addr == null) {
        addr = '/';
    }
    if (isMultiaddr(addr)) {
        return addr.getComponents();
    }
    if (addr instanceof Uint8Array) {
        return bytesToComponents(addr);
    }
    if (typeof addr === 'string') {
        addr = addr
            .replace(/\/(\/)+/, '/')
            .replace(/(\/)+$/, '');
        if (addr === '') {
            addr = '/';
        }
        return stringToComponents(addr);
    }
    if (Array.isArray(addr)) {
        return addr;
    }
    throw new InvalidMultiaddrError('Must be a string, Uint8Array, Component[], or another Multiaddr');
}
/**
 * Creates a {@link Multiaddr} from a {@link MultiaddrInput}
 */
class Multiaddr {
    [symbol] = true;
    #components;
    // cache string representation
    #string;
    // cache byte representation
    #bytes;
    constructor(addr = '/', options = {}) {
        this.#components = toComponents(addr);
        if (options.validate !== false) {
            validate(this);
        }
    }
    get bytes() {
        if (this.#bytes == null) {
            this.#bytes = componentsToBytes(this.#components);
        }
        return this.#bytes;
    }
    toString() {
        if (this.#string == null) {
            this.#string = componentsToString(this.#components);
        }
        return this.#string;
    }
    toJSON() {
        return this.toString();
    }
    toOptions() {
        let family;
        let transport;
        let host;
        let port;
        let zone = '';
        for (const { code, name, value } of this.#components) {
            if (code === CODE_IP6ZONE) {
                zone = `%${value ?? ''}`;
            }
            // default to https when protocol & port are omitted from DNS addrs
            if (DNS_CODES.includes(code)) {
                transport = 'tcp';
                port = 443;
                host = `${value ?? ''}${zone}`;
                family = code === CODE_DNS6 ? 6 : 4;
            }
            if (code === CODE_TCP || code === CODE_UDP) {
                transport = name === 'tcp' ? 'tcp' : 'udp';
                port = parseInt(value ?? '');
            }
            if (code === CODE_IP4 || code === CODE_IP6) {
                transport = 'tcp';
                host = `${value ?? ''}${zone}`;
                family = code === CODE_IP6 ? 6 : 4;
            }
        }
        if (family == null || transport == null || host == null || port == null) {
            throw new Error('multiaddr must have a valid format: "/{ip4, ip6, dns4, dns6, dnsaddr}/{address}/{tcp, udp}/{port}".');
        }
        const opts = {
            family,
            host,
            transport,
            port
        };
        return opts;
    }
    getComponents() {
        return [
            ...this.#components
        ];
    }
    protos() {
        return this.#components.map(({ code, value }) => {
            const codec = registry.getProtocol(code);
            return {
                code,
                size: codec.size ?? 0,
                name: codec.name,
                resolvable: Boolean(codec.resolvable),
                path: Boolean(codec.path)
            };
        });
    }
    protoCodes() {
        return this.#components.map(({ code }) => code);
    }
    protoNames() {
        return this.#components.map(({ name }) => name);
    }
    tuples() {
        return this.#components.map(({ code, value }) => {
            if (value == null) {
                return [code];
            }
            const codec = registry.getProtocol(code);
            const output = [code];
            if (value != null) {
                output.push(codec.valueToBytes?.(value) ?? fromString(value));
            }
            return output;
        });
    }
    stringTuples() {
        return this.#components.map(({ code, value }) => {
            if (value == null) {
                return [code];
            }
            return [code, value];
        });
    }
    encapsulate(addr) {
        const ma = new Multiaddr(addr);
        return new Multiaddr([
            ...this.#components,
            ...ma.getComponents()
        ], {
            validate: false
        });
    }
    decapsulate(addr) {
        const addrString = addr.toString();
        const s = this.toString();
        const i = s.lastIndexOf(addrString);
        if (i < 0) {
            throw new InvalidParametersError(`Address ${this.toString()} does not contain subaddress: ${addr.toString()}`);
        }
        return new Multiaddr(s.slice(0, i), {
            validate: false
        });
    }
    decapsulateCode(code) {
        let index;
        for (let i = this.#components.length - 1; i > -1; i--) {
            if (this.#components[i].code === code) {
                index = i;
                break;
            }
        }
        return new Multiaddr(this.#components.slice(0, index), {
            validate: false
        });
    }
    getPeerId() {
        try {
            let tuples = [];
            this.#components.forEach(({ code, value }) => {
                if (code === CODE_P2P) {
                    tuples.push([code, value]);
                }
                // if this is a p2p-circuit address, return the target peer id if present
                // not the peer id of the relay
                if (code === CODE_P2P_CIRCUIT) {
                    tuples = [];
                }
            });
            // Get the last ipfs tuple ['p2p', 'peerid string']
            const tuple = tuples.pop();
            if (tuple?.[1] != null) {
                const peerIdStr = tuple[1];
                // peer id is base58btc encoded string but not multibase encoded so add the `z`
                // prefix so we can validate that it is correctly encoded
                if (peerIdStr[0] === 'Q' || peerIdStr[0] === '1') {
                    return toString(base58btc.decode(`z${peerIdStr}`), 'base58btc');
                }
                // try to parse peer id as CID
                return toString(CID.parse(peerIdStr).multihash.bytes, 'base58btc');
            }
            return null;
        }
        catch (e) {
            return null;
        }
    }
    getPath() {
        for (const component of this.#components) {
            const codec = registry.getProtocol(component.code);
            if (!codec.path) {
                continue;
            }
            return component.value ?? null;
        }
        return null;
    }
    equals(addr) {
        return equals(this.bytes, addr.bytes);
    }
    async resolve(options) {
        const resolvableProto = this.protos().find((p) => p.resolvable);
        // Multiaddr is not resolvable?
        if (resolvableProto == null) {
            return [this];
        }
        const resolver = resolvers.get(resolvableProto.name);
        if (resolver == null) {
            throw new NoAvailableResolverError(`no available resolver for ${resolvableProto.name}`);
        }
        const result = await resolver(this, options);
        return result.map(str => multiaddr(str));
    }
    nodeAddress() {
        const options = this.toOptions();
        if (options.transport !== 'tcp' && options.transport !== 'udp') {
            throw new Error(`multiaddr must have a valid format - no protocol with name: "${options.transport}". Must have a valid transport protocol: "{tcp, udp}"`);
        }
        return {
            family: options.family,
            address: options.host,
            port: options.port
        };
    }
    isThinWaistAddress() {
        if (this.#components.length !== 2) {
            return false;
        }
        if (this.#components[0].code !== CODE_IP4 && this.#components[0].code !== CODE_IP6) {
            return false;
        }
        if (this.#components[1].code !== CODE_TCP && this.#components[1].code !== CODE_UDP) {
            return false;
        }
        return true;
    }
    /**
     * Returns Multiaddr as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```js
     * import { multiaddr } from '@multiformats/multiaddr'
     *
     * console.info(multiaddr('/ip4/127.0.0.1/tcp/4001'))
     * // 'Multiaddr(/ip4/127.0.0.1/tcp/4001)'
     * ```
     */
    [inspect]() {
        return `Multiaddr(${this.toString()})`;
    }
}
/**
 * Ensures all multiaddr tuples are correct. Throws if any invalid protocols or
 * values are encountered.
 */
function validate(addr) {
    addr.getComponents()
        .forEach(component => {
        const codec = registry.getProtocol(component.code);
        if (component.value == null) {
            return;
        }
        codec.validate?.(component.value);
    });
}

function allFF(a, from, to) {
    let i = 0;
    for (const e of a) {
        if (i < from)
            continue;
        if (i > to)
            break;
        if (e !== 0xff)
            return false;
        i++;
    }
    return true;
}
function deepEqual(a, b, from, to) {
    let i = 0;
    for (const e of a) {
        if (i < from)
            continue;
        if (i > to)
            break;
        if (e !== b[i])
            return false;
        i++;
    }
    return true;
}
/***
 * Returns long ip format
 */
function ipToString(ip) {
    switch (ip.length) {
        case IPv4Len: {
            return ip.join(".");
        }
        case IPv6Len: {
            const result = [];
            for (let i = 0; i < ip.length; i++) {
                if (i % 2 === 0) {
                    result.push(ip[i].toString(16).padStart(2, "0") +
                        ip[i + 1].toString(16).padStart(2, "0"));
                }
            }
            return result.join(":");
        }
        default: {
            throw new Error("Invalid ip length");
        }
    }
}
/**
 * If mask is a sequence of 1 bits followed by 0 bits, return number of 1 bits else -1
 */
function simpleMaskLength(mask) {
    let ones = 0;
    // eslint-disable-next-line prefer-const
    for (let [index, byte] of mask.entries()) {
        if (byte === 0xff) {
            ones += 8;
            continue;
        }
        while ((byte & 0x80) != 0) {
            ones++;
            byte = byte << 1;
        }
        if ((byte & 0x80) != 0) {
            return -1;
        }
        for (let i = index + 1; i < mask.length; i++) {
            if (mask[i] != 0) {
                return -1;
            }
        }
        break;
    }
    return ones;
}
function maskToHex(mask) {
    let hex = "0x";
    for (const byte of mask) {
        hex += (byte >> 4).toString(16) + (byte & 0x0f).toString(16);
    }
    return hex;
}

const IPv4Len = 4;
const IPv6Len = 16;
const ipv4Prefix = new Uint8Array([
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255,
]);
function maskIp(ip, mask) {
    if (mask.length === IPv6Len && ip.length === IPv4Len && allFF(mask, 0, 11)) {
        mask = mask.slice(12);
    }
    if (mask.length === IPv4Len &&
        ip.length === IPv6Len &&
        deepEqual(ip, ipv4Prefix, 0, 11)) {
        ip = ip.slice(12);
    }
    const n = ip.length;
    if (n != mask.length) {
        throw new Error("Failed to mask ip");
    }
    const out = new Uint8Array(n);
    for (let i = 0; i < n; i++) {
        out[i] = ip[i] & mask[i];
    }
    return out;
}
function containsIp(net, ip) {
    if (typeof ip === "string") {
        ip = parseIP(ip);
    }
    if (ip == null)
        throw new Error("Invalid ip");
    if (ip.length !== net.network.length) {
        return false;
    }
    for (let i = 0; i < ip.length; i++) {
        if ((net.network[i] & net.mask[i]) !== (ip[i] & net.mask[i])) {
            return false;
        }
    }
    return true;
}

function parseCidr(s) {
    const [address, maskString] = s.split("/");
    if (!address || !maskString)
        throw new Error("Failed to parse given CIDR: " + s);
    let ipLength = IPv4Len;
    let ip = parseIPv4(address);
    if (ip == null) {
        ipLength = IPv6Len;
        ip = parseIPv6(address);
        if (ip == null)
            throw new Error("Failed to parse given CIDR: " + s);
    }
    const m = parseInt(maskString, 10);
    if (Number.isNaN(m) ||
        String(m).length !== maskString.length ||
        m < 0 ||
        m > ipLength * 8) {
        throw new Error("Failed to parse given CIDR: " + s);
    }
    const mask = cidrMask(m, 8 * ipLength);
    return {
        network: maskIp(ip, mask),
        mask,
    };
}
function cidrMask(ones, bits) {
    if (bits !== 8 * IPv4Len && bits !== 8 * IPv6Len)
        throw new Error("Invalid CIDR mask");
    if (ones < 0 || ones > bits)
        throw new Error("Invalid CIDR mask");
    const l = bits / 8;
    const m = new Uint8Array(l);
    for (let i = 0; i < l; i++) {
        if (ones >= 8) {
            m[i] = 0xff;
            ones -= 8;
            continue;
        }
        m[i] = 255 - (0xff >> ones);
        ones = 0;
    }
    return m;
}

class IpNet {
    /**
     *
     * @param ipOrCidr either network ip or full cidr address
     * @param mask in case ipOrCidr is network this can be either mask in decimal format or as ip address
     */
    constructor(ipOrCidr, mask) {
        if (mask == null) {
            ({ network: this.network, mask: this.mask } = parseCidr(ipOrCidr));
        }
        else {
            const ipResult = parseIP(ipOrCidr);
            if (ipResult == null) {
                throw new Error("Failed to parse network");
            }
            mask = String(mask);
            const m = parseInt(mask, 10);
            if (Number.isNaN(m) ||
                String(m).length !== mask.length ||
                m < 0 ||
                m > ipResult.length * 8) {
                const maskResult = parseIP(mask);
                if (maskResult == null) {
                    throw new Error("Failed to parse mask");
                }
                this.mask = maskResult;
            }
            else {
                this.mask = cidrMask(m, 8 * ipResult.length);
            }
            this.network = maskIp(ipResult, this.mask);
        }
    }
    /**
     * Checks if netmask contains ip address
     * @param ip
     * @returns
     */
    contains(ip) {
        return containsIp({ network: this.network, mask: this.mask }, ip);
    }
    /**Serializes back to string format */
    toString() {
        const l = simpleMaskLength(this.mask);
        const mask = l !== -1 ? String(l) : maskToHex(this.mask);
        return ipToString(this.network) + "/" + mask;
    }
}

/**
 * Checks if cidr block contains ip address
 * @param cidr ipv4 or ipv6 formatted cidr . Example 198.51.100.14/24 or 2001:db8::/48
 * @param ip ipv4 or ipv6 address Example 198.51.100.14 or 2001:db8::
 *
 */
function cidrContains(cidr, ip) {
    const ipnet = new IpNet(cidr);
    return ipnet.contains(ip);
}

function convertToIpNet(multiaddr) {
    let mask;
    let addr;
    multiaddr.getComponents().forEach(component => {
        if (component.name === 'ip4' || component.name === 'ip6') {
            addr = component.value;
        }
        if (component.name === 'ipcidr') {
            mask = component.value;
        }
    });
    if (mask == null || addr == null) {
        throw new Error('Invalid multiaddr');
    }
    return new IpNet(addr, mask);
}
/**
 * Convert [code, Uint8Array] to string
 *
 * @deprecated Will be removed in a future release
 */
function convertToString(proto, buf) {
    const protocol = registry.getProtocol(proto);
    return protocol.bytesToValue?.(buf) ?? toString(buf, 'base16'); // no clue. convert to hex
}
/**
 * Convert [code, string] to Uint8Array
 *
 * @deprecated Will be removed in a future release
 */
function convertToBytes(proto, str) {
    const protocol = registry.getProtocol(proto);
    return protocol.valueToBytes?.(str) ?? fromString(str, 'base16'); // no clue. convert from hex
}

/**
 * @packageDocumentation
 *
 * A standard way to represent addresses that
 *
 * - support any standard network protocol
 * - are self-describing
 * - have a binary packed format
 * - have a nice string representation
 * - encapsulate well
 *
 * @example
 *
 * ```TypeScript
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const addr = multiaddr('/ip4/127.0.0.1/udp/1234')
 * // Multiaddr(/ip4/127.0.0.1/udp/1234)
 *
 * addr.bytes
 * // <Uint8Array 04 7f 00 00 01 11 04 d2>
 *
 * addr.toString()
 * // '/ip4/127.0.0.1/udp/1234'
 *
 * addr.protos()
 * // [
 * //   {code: 4, name: 'ip4', size: 32},
 * //   {code: 273, name: 'udp', size: 16}
 * // ]
 *
 * // gives you an object that is friendly with what Node.js core modules expect for addresses
 * addr.nodeAddress()
 * // {
 * //   family: 4,
 * //   port: 1234,
 * //   address: "127.0.0.1"
 * // }
 *
 * addr.encapsulate('/sctp/5678')
 * // Multiaddr(/ip4/127.0.0.1/udp/1234/sctp/5678)
 * ```
 *
 * ## Resolving DNSADDR addresses
 *
 * [DNSADDR](https://github.com/multiformats/multiaddr/blob/master/protocols/DNSADDR.md) is a spec that allows storing a TXT DNS record that contains a Multiaddr.
 *
 * To resolve DNSADDR addresses, call the `.resolve()` function the multiaddr, optionally passing a `DNS` resolver.
 *
 * DNSADDR addresses can resolve to multiple multiaddrs, since there is no limit to the number of TXT records that can be stored.
 *
 * @example Resolving DNSADDR Multiaddrs
 *
 * ```TypeScript
 * import { multiaddr, resolvers } from '@multiformats/multiaddr'
 * import { dnsaddrResolver } from '@multiformats/multiaddr/resolvers'
 *
 * resolvers.set('dnsaddr', dnsaddrResolver)
 *
 * const ma = multiaddr('/dnsaddr/bootstrap.libp2p.io')
 *
 * // resolve with a 5s timeout
 * const resolved = await ma.resolve({
 *   signal: AbortSignal.timeout(5000)
 * })
 *
 * console.info(resolved)
 * // [Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...')...]
 * ```
 *
 * @example Using a custom DNS resolver to resolve DNSADDR Multiaddrs
 *
 * See the docs for [@multiformats/dns](https://www.npmjs.com/package/@multiformats/dns) for a full breakdown of how to specify multiple resolvers or resolvers that can be used for specific TLDs.
 *
 * ```TypeScript
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { dns } from '@multiformats/dns'
 * import { dnsJsonOverHttps } from '@multiformats/dns/resolvers'
 *
 * const resolver = dns({
 *   resolvers: {
 *     '.': dnsJsonOverHttps('https://cloudflare-dns.com/dns-query')
 *   }
 * })
 *
 * const ma = multiaddr('/dnsaddr/bootstrap.libp2p.io')
 * const resolved = await ma.resolve({
 *  dns: resolver
 * })
 *
 * console.info(resolved)
 * // [Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...')...]
 * ```
 *
 * @example Adding custom protocols
 *
 * To add application-specific or experimental protocols, add a protocol codec
 * to the protocol registry:
 *
 * ```ts
 * import { registry, V, multiaddr } from '@multiformats/multiaddr'
 * import type { ProtocolCodec } from '@multiformats/multiaddr'
 *
 * const maWithCustomTuple = '/custom-protocol/hello'
 *
 * // throws UnknownProtocolError
 * multiaddr(maWithCustomTuple)
 *
 * const protocol: ProtocolCodec = {
 *   code: 2059,
 *   name: 'custom-protocol',
 *   size: V
 *   // V means variable length, can also be 0, a positive integer (e.g. a fixed
 *   // length or omitted
 * }
 *
 * registry.addProtocol(protocol)
 *
 * // does not throw UnknownProtocolError
 * multiaddr(maWithCustomTuple)
 *
 * // protocols can also be removed
 * registry.removeProtocol(protocol.code)
 * ```
 */
/**
 * All configured {@link Resolver}s
 *
 * @deprecated DNS resolving will be removed in a future release
 */
const resolvers = new Map();
/**
 * Check if object is a {@link Multiaddr} instance
 *
 * @example
 *
 * ```js
 * import { isMultiaddr, multiaddr } from '@multiformats/multiaddr'
 *
 * isMultiaddr(5)
 * // false
 * isMultiaddr(multiaddr('/ip4/127.0.0.1'))
 * // true
 * ```
 */
function isMultiaddr(value) {
    return Boolean(value?.[symbol]);
}
/**
 * A function that takes a {@link MultiaddrInput} and returns a {@link Multiaddr}
 *
 * @example
 * ```js
 * import { multiaddr } from '@libp2p/multiaddr'
 *
 * multiaddr('/ip4/127.0.0.1/tcp/4001')
 * // Multiaddr(/ip4/127.0.0.1/tcp/4001)
 * ```
 *
 * @param {MultiaddrInput} [addr] - If String or Uint8Array, needs to adhere to the address format of a [multiaddr](https://github.com/multiformats/multiaddr#string-format)
 */
function multiaddr(addr) {
    return new Multiaddr(addr);
}
/**
 * For the passed proto string or number, return a {@link Protocol}
 *
 * @example
 *
 * ```js
 * import { protocol } from '@multiformats/multiaddr'
 *
 * console.info(protocol(4))
 * // { code: 4, size: 32, name: 'ip4', resolvable: false, path: false }
 * ```
 *
 * @deprecated This will be removed in a future version
 */
function protocols(proto) {
    const codec = registry.getProtocol(proto);
    return {
        code: codec.code,
        size: codec.size ?? 0,
        name: codec.name,
        resolvable: Boolean(codec.resolvable),
        path: Boolean(codec.path)
    };
}

/**
 * Reads peer's metadata and retrieves ping value.
 * @param peer Peer or null
 * @returns -1 if no ping attached, otherwise returns ping value
 */
const getPeerPing = (peer) => {
    if (!peer) {
        return -1;
    }
    try {
        const bytes = peer.metadata.get("ping");
        if (!bytes) {
            return -1;
        }
        return Number(bytesToUtf8(bytes));
    }
    catch (e) {
        return -1;
    }
};
/**
 * Maps a PeerId or MultiaddrInput to a PeerId or Multiaddr.
 * @param input - The PeerId or MultiaddrInput to map.
 * @returns The PeerId or Multiaddr.
 * @throws {Error} If the input is not a valid PeerId or MultiaddrInput.
 */
const mapToPeerIdOrMultiaddr = (input) => {
    return isPeerId(input) ? input : multiaddr(input);
};
/**
 * Maps a PeerId or MultiaddrInput to a PeerId.
 * @param input - The PeerId or MultiaddrInput to map.
 * @returns The PeerId.
 * @throws {Error} If the input is not a valid PeerId or MultiaddrInput.
 */
const mapToPeerId = (input) => {
    return isPeerId(input)
        ? input
        : peerIdFromString$1(multiaddr(input).getPeerId());
};

const log$m = new Logger$1("connection-manager");
const DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED = 3;
const DEFAULT_PING_KEEP_ALIVE_SEC = 5 * 60;
const DEFAULT_RELAY_KEEP_ALIVE_SEC = 5 * 60;
const DEFAULT_ENABLE_AUTO_RECOVERY = true;
const DEFAULT_MAX_CONNECTIONS = 10;
const DEFAULT_MAX_DIALING_PEERS = 3;
const DEFAULT_FAILED_DIAL_COOLDOWN_SEC = 60;
const DEFAULT_DIAL_COOLDOWN_SEC = 10;
class ConnectionManager {
    keepAliveManager;
    discoveryDialer;
    dialer;
    shardReader;
    networkMonitor;
    connectionLimiter;
    options;
    libp2p;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.options = {
            maxBootstrapPeers: DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED,
            maxConnections: DEFAULT_MAX_CONNECTIONS,
            pingKeepAlive: DEFAULT_PING_KEEP_ALIVE_SEC,
            relayKeepAlive: DEFAULT_RELAY_KEEP_ALIVE_SEC,
            enableAutoRecovery: DEFAULT_ENABLE_AUTO_RECOVERY,
            maxDialingPeers: DEFAULT_MAX_DIALING_PEERS,
            failedDialCooldown: DEFAULT_FAILED_DIAL_COOLDOWN_SEC,
            dialCooldown: DEFAULT_DIAL_COOLDOWN_SEC,
            ...options.config
        };
        this.keepAliveManager = new KeepAliveManager({
            relay: options.relay,
            libp2p: options.libp2p,
            options: {
                pingKeepAlive: this.options.pingKeepAlive,
                relayKeepAlive: this.options.relayKeepAlive
            }
        });
        this.shardReader = new ShardReader({
            libp2p: options.libp2p,
            networkConfig: options.networkConfig
        });
        this.dialer = new Dialer({
            libp2p: options.libp2p,
            shardReader: this.shardReader,
            options: this.options
        });
        this.discoveryDialer = new DiscoveryDialer({
            libp2p: options.libp2p,
            dialer: this.dialer
        });
        this.networkMonitor = new NetworkMonitor({
            libp2p: options.libp2p,
            events: options.events
        });
        this.connectionLimiter = new ConnectionLimiter({
            libp2p: options.libp2p,
            events: options.events,
            networkMonitor: this.networkMonitor,
            dialer: this.dialer,
            options: this.options
        });
    }
    start() {
        this.dialer.start();
        this.networkMonitor.start();
        this.discoveryDialer.start();
        this.keepAliveManager.start();
        this.connectionLimiter.start();
    }
    stop() {
        this.dialer.stop();
        this.networkMonitor.stop();
        this.discoveryDialer.stop();
        this.keepAliveManager.stop();
        this.connectionLimiter.stop();
    }
    isConnected() {
        return this.networkMonitor.isConnected();
    }
    async dial(peer, protocolCodecs) {
        const ma = mapToPeerIdOrMultiaddr(peer);
        log$m.info(`Dialing peer ${ma.toString()} with protocols ${protocolCodecs}`);
        // must use libp2p directly instead of dialer because we need to dial the peer right away
        const stream = await this.libp2p.dialProtocol(ma, protocolCodecs);
        log$m.info(`Dialed peer ${ma.toString()} with protocols ${protocolCodecs}`);
        return stream;
    }
    async hangUp(peer) {
        const peerId = mapToPeerId(peer);
        try {
            log$m.info(`Dropping connection with peer ${peerId.toString()}`);
            await this.libp2p.hangUp(peerId);
            log$m.info(`Dropped connection with peer ${peerId.toString()}`);
            return true;
        }
        catch (error) {
            log$m.error(`Error dropping connection with peer ${peerId.toString()} - ${error}`);
            return false;
        }
    }
    async getConnectedPeers(codec) {
        const peerIDs = this.libp2p.getPeers();
        log$m.info(`Getting connected peers for codec ${codec}`);
        if (peerIDs.length === 0) {
            log$m.info(`No connected peers`);
            return [];
        }
        const peers = await Promise.all(peerIDs.map(async (id) => {
            try {
                return await this.libp2p.peerStore.get(id);
            }
            catch (e) {
                return null;
            }
        }));
        const result = peers
            .filter((p) => !!p)
            .filter((p) => (codec ? p.protocols.includes(codec) : true))
            .sort((left, right) => getPeerPing(left) - getPeerPing(right));
        log$m.info(`Found ${result.length} connected peers for codec ${codec}`);
        return result;
    }
    async hasShardInfo(peerId) {
        return this.shardReader.hasShardInfo(peerId);
    }
    async isPeerOnTopic(peerId, pubsubTopic) {
        return this.shardReader.isPeerOnTopic(peerId, pubsubTopic);
    }
}

const log$l = new Logger$1("metadata");
const MetadataCodec = "/vac/waku/metadata/1.0.0";
class Metadata {
    clusterId;
    streamManager;
    libp2pComponents;
    handshakesConfirmed = new Map();
    multicodec = MetadataCodec;
    constructor(clusterId, libp2p) {
        this.clusterId = clusterId;
        this.streamManager = new StreamManager(MetadataCodec, libp2p);
        this.libp2pComponents = libp2p;
        void libp2p.registrar.handle(MetadataCodec, (streamData) => {
            void this.onRequest(streamData);
        });
    }
    /**
     * Make a metadata query to a peer
     */
    async query(peerId) {
        const request = WakuMetadataRequest.encode({
            clusterId: this.clusterId,
            shards: [] // Only services node need to provide shards
        });
        const peer = await this.libp2pComponents.peerStore.get(peerId);
        if (!peer) {
            return {
                shardInfo: null,
                error: ProtocolError$1.NO_PEER_AVAILABLE
            };
        }
        let stream;
        try {
            stream = await this.streamManager.getStream(peerId);
        }
        catch (error) {
            log$l.error("Failed to get stream", error);
            return {
                shardInfo: null,
                error: ProtocolError$1.NO_STREAM_AVAILABLE
            };
        }
        const encodedResponse = await pipe([request], encode$3, stream, decode$2, async (source) => await all$1(source));
        const { error, shardInfo } = this.decodeMetadataResponse(encodedResponse);
        if (error) {
            return {
                shardInfo: null,
                error
            };
        }
        await this.savePeerShardInfo(peerId, shardInfo);
        return {
            shardInfo,
            error: null
        };
    }
    async confirmOrAttemptHandshake(peerId) {
        const shardInfo = this.handshakesConfirmed.get(peerId.toString());
        if (shardInfo) {
            return {
                shardInfo,
                error: null
            };
        }
        return await this.query(peerId);
    }
    /**
     * Handle an incoming metadata request
     */
    async onRequest(streamData) {
        try {
            const { stream, connection } = streamData;
            const encodedShardInfo = WakuMetadataResponse.encode({
                clusterId: this.clusterId,
                shards: [] // Only service nodes need to provide shards
            });
            const encodedResponse = await pipe([encodedShardInfo], encode$3, stream, decode$2, async (source) => await all$1(source));
            const { error, shardInfo } = this.decodeMetadataResponse(encodedResponse);
            if (error) {
                return;
            }
            await this.savePeerShardInfo(connection.remotePeer, shardInfo);
        }
        catch (error) {
            log$l.error("Error handling metadata request", error);
        }
    }
    decodeMetadataResponse(encodedResponse) {
        const bytes = new Uint8ArrayList();
        encodedResponse.forEach((chunk) => {
            bytes.append(chunk);
        });
        const response = WakuMetadataResponse.decode(bytes);
        if (!response) {
            log$l.error("Error decoding metadata response");
            return {
                shardInfo: null,
                error: ProtocolError$1.DECODE_FAILED
            };
        }
        return {
            shardInfo: response,
            error: null
        };
    }
    async savePeerShardInfo(peerId, shardInfo) {
        // add or update the shardInfo to peer store
        await this.libp2pComponents.peerStore.merge(peerId, {
            metadata: {
                shardInfo: encodeRelayShard(shardInfo)
            }
        });
        this.handshakesConfirmed.set(peerId.toString(), shardInfo);
    }
}
function wakuMetadata(clusterId) {
    return (components) => new Metadata(clusterId, components);
}

/**
 * Deterministic Message Hashing as defined in
 * [14/WAKU2-MESSAGE](https://rfc.vac.dev/spec/14/#deterministic-message-hashing)
 *
 * Computes a SHA-256 hash of the concatenation of pubsub topic, payload, content topic, meta, and timestamp.
 *
 * @param pubsubTopic - The pubsub topic string
 * @param message - The message to be hashed
 * @returns A Uint8Array containing the SHA-256 hash
 *
 * @example
 * ```typescript
 * import { messageHash } from "@waku/core";
 *
 * const pubsubTopic = "/waku/2/default-waku/proto";
 * const message = {
 *   payload: new Uint8Array([1, 2, 3, 4]),
 *   contentTopic: "/waku/2/default-content/proto",
 *   meta: new Uint8Array([5, 6, 7, 8]),
 *   timestamp: new Date()
 * };
 *
 * const hash = messageHash(pubsubTopic, message);
 * ```
 */
function messageHash(pubsubTopic, message) {
    const pubsubTopicBytes = utf8ToBytes$1(pubsubTopic);
    const contentTopicBytes = utf8ToBytes$1(message.contentTopic);
    const timestampBytes = tryConvertTimestampToBytes(message.timestamp);
    const bytes = concat$1([
        pubsubTopicBytes,
        message.payload,
        contentTopicBytes,
        message.meta,
        timestampBytes
    ].filter(isDefined));
    return sha256(bytes);
}
function tryConvertTimestampToBytes(timestamp) {
    if (!timestamp) {
        return;
    }
    let bigIntTimestamp;
    if (typeof timestamp === "bigint") {
        bigIntTimestamp = timestamp;
    }
    else {
        bigIntTimestamp = BigInt(timestamp.valueOf()) * 1000000n;
    }
    return numberToBytes(bigIntTimestamp);
}
/**
 * Computes a deterministic message hash and returns it as a hexadecimal string.
 * This is a convenience wrapper around messageHash that converts the result to a hex string.
 *
 * @param pubsubTopic - The pubsub topic string
 * @param message - The message to be hashed
 * @returns A string containing the hex representation of the SHA-256 hash
 *
 * @example
 * ```typescript
 * import { messageHashStr } from "@waku/core";
 *
 * const pubsubTopic = "/waku/2/default-waku/proto";
 * const message = {
 *   payload: new Uint8Array([1, 2, 3, 4]),
 *   contentTopic: "/waku/2/default-content/proto",
 *   meta: new Uint8Array([5, 6, 7, 8]),
 *   timestamp: new Date()
 * };
 *
 * const hashString = messageHashStr(pubsubTopic, message);
 * console.log(hashString); // e.g. "a1b2c3d4..."
 * ```
 */
function messageHashStr(pubsubTopic, message) {
    const hash = messageHash(pubsubTopic, message);
    const hashStr = bytesToHex$1(hash);
    return hashStr;
}

var index = /*#__PURE__*/Object.freeze({
    __proto__: null,
    ConnectionManager: ConnectionManager,
    FilterCodecs: FilterCodecs,
    FilterCore: FilterCore,
    LightPushCodec: LightPushCodec,
    LightPushCore: LightPushCore,
    MetadataCodec: MetadataCodec,
    StoreCodec: StoreCodec,
    StoreCore: StoreCore,
    StreamManager: StreamManager,
    createDecoder: createDecoder,
    createEncoder: createEncoder,
    message: index$4,
    messageHash: messageHash,
    messageHashStr: messageHashStr,
    wakuMetadata: wakuMetadata,
    waku_filter: index$3,
    waku_light_push: index$2,
    waku_store: index$1
});

const log$k = new Logger$1("peer-manager");
const DEFAULT_NUM_PEERS_TO_USE = 2;
var PeerManagerEventNames;
(function (PeerManagerEventNames) {
    PeerManagerEventNames["Connect"] = "filter:connect";
    PeerManagerEventNames["Disconnect"] = "filter:disconnect";
})(PeerManagerEventNames || (PeerManagerEventNames = {}));
/**
 * @description
 * PeerManager is responsible for:
 * - finding available peers based on shard / protocols;
 * - notifying when peers for a specific protocol are connected;
 * - notifying when peers for a specific protocol are disconnected;
 */
class PeerManager {
    events = new TypedEventEmitter();
    numPeersToUse;
    libp2p;
    connectionManager;
    lockedPeers = new Set();
    unlockedPeers = new Map();
    constructor(params) {
        this.onConnected = this.onConnected.bind(this);
        this.onDisconnected = this.onDisconnected.bind(this);
        this.numPeersToUse =
            params?.config?.numPeersToUse || DEFAULT_NUM_PEERS_TO_USE;
        this.libp2p = params.libp2p;
        this.connectionManager = params.connectionManager;
    }
    start() {
        this.libp2p.addEventListener("peer:identify", this.onConnected);
        this.libp2p.addEventListener("peer:disconnect", this.onDisconnected);
    }
    stop() {
        this.libp2p.removeEventListener("peer:identify", this.onConnected);
        this.libp2p.removeEventListener("peer:disconnect", this.onDisconnected);
    }
    async getPeers(params) {
        log$k.info(`Getting peers for protocol: ${params.protocol}, pubsubTopic: ${params.pubsubTopic}`);
        const connectedPeers = await this.connectionManager.getConnectedPeers();
        log$k.info(`Found ${connectedPeers.length} connected peers`);
        let results = [];
        for (const peer of connectedPeers) {
            const hasProtocol = this.hasPeerProtocol(peer, params.protocol);
            const hasSamePubsub = await this.connectionManager.isPeerOnTopic(peer.id, params.pubsubTopic);
            const isPeerAvailableForUse = this.isPeerAvailableForUse(peer.id);
            if (hasProtocol && hasSamePubsub && isPeerAvailableForUse) {
                results.push(peer);
                log$k.info(`Peer ${peer.id} qualifies for protocol ${params.protocol}`);
            }
        }
        const lockedPeers = results.filter((p) => this.isPeerLocked(p.id));
        log$k.info(`Found ${lockedPeers.length} locked peers out of ${results.length} qualifying peers`);
        if (lockedPeers.length >= this.numPeersToUse) {
            const selectedPeers = lockedPeers
                .slice(0, this.numPeersToUse)
                .map((p) => p.id);
            log$k.info(`Using ${selectedPeers.length} locked peers: ${selectedPeers.map((p) => p.toString())}`);
            return selectedPeers;
        }
        const notLockedPeers = results.filter((p) => !this.isPeerLocked(p.id));
        log$k.info(`Found ${notLockedPeers.length} unlocked peers, need ${this.numPeersToUse - lockedPeers.length} more`);
        results = [...lockedPeers, ...notLockedPeers]
            .slice(0, this.numPeersToUse)
            .map((p) => {
            this.lockPeer(p.id);
            return p;
        });
        const finalPeers = results.map((p) => p.id);
        log$k.info(`Selected ${finalPeers.length} peers: ${finalPeers.map((p) => p.toString())}`);
        return finalPeers;
    }
    async renewPeer(id, params) {
        log$k.info(`Renewing peer ${id} for protocol: ${params.protocol}, pubsubTopic: ${params.pubsubTopic}`);
        const connectedPeers = await this.connectionManager.getConnectedPeers();
        const renewedPeer = connectedPeers.find((p) => p.id.equals(id));
        if (!renewedPeer) {
            log$k.warn(`Cannot renew peer:${id}, no connection to the peer.`);
            return;
        }
        log$k.info(`Found peer ${id} in connected peers, unlocking and getting new peers`);
        this.unlockPeer(renewedPeer.id);
        await this.getPeers(params);
    }
    async isPeerOnPubsub(id, pubsubTopic) {
        const hasShardInfo = await this.connectionManager.hasShardInfo(id);
        // allow to use peers that we don't know information about yet
        if (!hasShardInfo) {
            return true;
        }
        return this.connectionManager.isPeerOnTopic(id, pubsubTopic);
    }
    async onConnected(event) {
        const result = event.detail;
        const isFilterPeer = result.protocols.includes(this.matchProtocolToCodec(Protocols.Filter));
        if (isFilterPeer) {
            this.dispatchFilterPeerConnect(result.peerId);
        }
    }
    async onDisconnected(event) {
        const peerId = event.detail;
        try {
            // we need to read from peerStore as peer is already disconnected
            const peer = await this.libp2p.peerStore.get(peerId);
            const isFilterPeer = this.hasPeerProtocol(peer, Protocols.Filter);
            if (isFilterPeer) {
                this.dispatchFilterPeerDisconnect(peer.id);
            }
        }
        catch (error) {
            log$k.error(`Failed to dispatch Filter disconnect event:${error}`);
        }
    }
    hasPeerProtocol(peer, protocol) {
        return peer.protocols.includes(this.matchProtocolToCodec(protocol));
    }
    lockPeer(id) {
        log$k.info(`Locking peer ${id}`);
        this.lockedPeers.add(id.toString());
        this.libp2p
            .getConnections()
            .filter((c) => c.remotePeer.equals(id))
            .forEach((c) => c.tags.push(CONNECTION_LOCKED_TAG));
        this.unlockedPeers.delete(id.toString());
    }
    isPeerLocked(id) {
        return this.lockedPeers.has(id.toString());
    }
    unlockPeer(id) {
        log$k.info(`Unlocking peer ${id}`);
        this.lockedPeers.delete(id.toString());
        this.libp2p
            .getConnections()
            .filter((c) => c.remotePeer.equals(id))
            .forEach((c) => {
            c.tags = c.tags.filter((t) => t !== CONNECTION_LOCKED_TAG);
        });
        this.unlockedPeers.set(id.toString(), Date.now());
    }
    isPeerAvailableForUse(id) {
        const value = this.unlockedPeers.get(id.toString());
        if (!value) {
            return true;
        }
        const wasUnlocked = new Date(value).getTime();
        return Date.now() - wasUnlocked >= 10_000 ? true : false;
    }
    dispatchFilterPeerConnect(id) {
        this.events.dispatchEvent(new CustomEvent(PeerManagerEventNames.Connect, { detail: id }));
    }
    dispatchFilterPeerDisconnect(id) {
        this.events.dispatchEvent(new CustomEvent(PeerManagerEventNames.Disconnect, { detail: id }));
    }
    matchProtocolToCodec(protocol) {
        const protocolToCodec = {
            [Protocols.Filter]: FilterCodecs.SUBSCRIBE,
            [Protocols.LightPush]: LightPushCodec,
            [Protocols.Store]: StoreCodec,
            [Protocols.Relay]: ""
        };
        return protocolToCodec[protocol];
    }
}

class TTLSet {
    ttlMs;
    cleanupIntervalId = null;
    entryTimestamps = new Map();
    /**
     * Creates a new CustomSet with TTL functionality.
     * @param ttlMs - The time-to-live in milliseconds for each entry.
     * @param cleanupIntervalMs - Optional interval between cleanup operations (default: 5000ms).
     */
    constructor(ttlMs, cleanupIntervalMs = 5000) {
        this.ttlMs = ttlMs;
        this.startCleanupInterval(cleanupIntervalMs);
    }
    dispose() {
        if (this.cleanupIntervalId !== null) {
            clearInterval(this.cleanupIntervalId);
            this.cleanupIntervalId = null;
        }
        this.entryTimestamps.clear();
    }
    add(entry) {
        this.entryTimestamps.set(entry, Date.now());
        return this;
    }
    has(entry) {
        return this.entryTimestamps.has(entry);
    }
    startCleanupInterval(intervalMs) {
        this.cleanupIntervalId = setInterval(() => {
            this.removeExpiredEntries();
        }, intervalMs);
    }
    removeExpiredEntries() {
        const now = Date.now();
        for (const [entry, timestamp] of this.entryTimestamps.entries()) {
            if (now - timestamp > this.ttlMs) {
                this.entryTimestamps.delete(entry);
            }
        }
    }
}

const log$j = new Logger$1("sdk:filter-subscription");
class Subscription {
    pubsubTopic;
    protocol;
    peerManager;
    config;
    isStarted = false;
    inProgress = false;
    // Map and Set cannot reliably use PeerId type as a key
    peers = new Map();
    peerFailures = new Map();
    receivedMessages = new TTLSet(60_000);
    callbacks = new Map();
    messageEmitter = new TypedEventEmitter();
    toSubscribeContentTopics = new Set();
    toUnsubscribeContentTopics = new Set();
    subscribeIntervalId = null;
    keepAliveIntervalId = null;
    get contentTopics() {
        const allTopics = Array.from(this.callbacks.keys()).map((k) => k.contentTopic);
        const uniqueTopics = new Set(allTopics).values();
        return Array.from(uniqueTopics);
    }
    constructor(params) {
        this.config = params.config;
        this.pubsubTopic = params.pubsubTopic;
        this.protocol = params.protocol;
        this.peerManager = params.peerManager;
        this.onPeerConnected = this.onPeerConnected.bind(this);
        this.onPeerDisconnected = this.onPeerDisconnected.bind(this);
    }
    start() {
        log$j.info(`Starting subscription for pubsubTopic: ${this.pubsubTopic}`);
        if (this.isStarted || this.inProgress) {
            log$j.info("Subscription already started or in progress, skipping start");
            return;
        }
        this.inProgress = true;
        void this.attemptSubscribe({
            useNewContentTopics: false
        });
        this.setupSubscriptionInterval();
        this.setupKeepAliveInterval();
        this.setupEventListeners();
        this.isStarted = true;
        this.inProgress = false;
        log$j.info(`Subscription started for pubsubTopic: ${this.pubsubTopic}`);
    }
    stop() {
        log$j.info(`Stopping subscription for pubsubTopic: ${this.pubsubTopic}`);
        if (!this.isStarted || this.inProgress) {
            log$j.info("Subscription not started or stop in progress, skipping stop");
            return;
        }
        this.inProgress = true;
        this.disposeEventListeners();
        this.disposeIntervals();
        void this.disposePeers();
        this.disposeHandlers();
        this.receivedMessages.dispose();
        this.inProgress = false;
        this.isStarted = false;
        log$j.info(`Subscription stopped for pubsubTopic: ${this.pubsubTopic}`);
    }
    isEmpty() {
        return this.callbacks.size === 0;
    }
    async add(decoder, callback) {
        const decoders = Array.isArray(decoder) ? decoder : [decoder];
        for (const decoder of decoders) {
            this.addSingle(decoder, callback);
        }
        return this.toSubscribeContentTopics.size > 0
            ? await this.attemptSubscribe({ useNewContentTopics: true })
            : true; // if content topic is not new - subscription, most likely exists
    }
    async remove(decoder) {
        const decoders = Array.isArray(decoder) ? decoder : [decoder];
        for (const decoder of decoders) {
            this.removeSingle(decoder);
        }
        return this.toUnsubscribeContentTopics.size > 0
            ? await this.attemptUnsubscribe({ useNewContentTopics: true })
            : true; // no need to unsubscribe if there are other decoders on the contentTopic
    }
    invoke(message, _peerId) {
        if (this.isMessageReceived(message)) {
            log$j.info(`Skipping invoking callbacks for already received message: pubsubTopic:${this.pubsubTopic}, peerId:${_peerId.toString()}, contentTopic:${message.contentTopic}`);
            return;
        }
        log$j.info(`Invoking message for contentTopic: ${message.contentTopic}`);
        this.messageEmitter.dispatchEvent(new CustomEvent(message.contentTopic, {
            detail: message
        }));
    }
    addSingle(decoder, callback) {
        log$j.info(`Adding subscription for contentTopic: ${decoder.contentTopic}`);
        const isNewContentTopic = !this.contentTopics.includes(decoder.contentTopic);
        if (isNewContentTopic) {
            this.toSubscribeContentTopics.add(decoder.contentTopic);
        }
        if (this.callbacks.has(decoder)) {
            log$j.warn(`Replacing callback associated associated with decoder with pubsubTopic:${decoder.pubsubTopic} and contentTopic:${decoder.contentTopic}`);
            const callback = this.callbacks.get(decoder);
            this.callbacks.delete(decoder);
            this.messageEmitter.removeEventListener(decoder.contentTopic, callback);
        }
        const eventHandler = (event) => {
            void (async () => {
                try {
                    const message = await decoder.fromProtoObj(decoder.pubsubTopic, event.detail);
                    void callback(message);
                }
                catch (err) {
                    log$j.error("Error decoding message", err);
                }
            })();
        };
        this.callbacks.set(decoder, eventHandler);
        this.messageEmitter.addEventListener(decoder.contentTopic, eventHandler);
        log$j.info(`Subscription added for contentTopic: ${decoder.contentTopic}, isNewContentTopic: ${isNewContentTopic}`);
    }
    removeSingle(decoder) {
        log$j.info(`Removing subscription for contentTopic: ${decoder.contentTopic}`);
        const callback = this.callbacks.get(decoder);
        if (!callback) {
            log$j.warn(`No callback associated with decoder with pubsubTopic:${decoder.pubsubTopic} and contentTopic:${decoder.contentTopic}`);
        }
        this.callbacks.delete(decoder);
        this.messageEmitter.removeEventListener(decoder.contentTopic, callback);
        const isCompletelyRemoved = !this.contentTopics.includes(decoder.contentTopic);
        if (isCompletelyRemoved) {
            this.toUnsubscribeContentTopics.add(decoder.contentTopic);
        }
        log$j.info(`Subscription removed for contentTopic: ${decoder.contentTopic}, isCompletelyRemoved: ${isCompletelyRemoved}`);
    }
    isMessageReceived(message) {
        try {
            const messageHash = messageHashStr(this.pubsubTopic, message);
            if (this.receivedMessages.has(messageHash)) {
                return true;
            }
            this.receivedMessages.add(messageHash);
        }
        catch (e) {
            // do nothing on throw, message will be handled as not received
        }
        return false;
    }
    setupSubscriptionInterval() {
        const subscriptionRefreshIntervalMs = 1000;
        log$j.info(`Setting up subscription interval with period ${subscriptionRefreshIntervalMs}ms`);
        this.subscribeIntervalId = setInterval(() => {
            const run = async () => {
                if (this.toSubscribeContentTopics.size > 0) {
                    log$j.info(`Subscription interval: ${this.toSubscribeContentTopics.size} topics to subscribe`);
                    void (await this.attemptSubscribe({ useNewContentTopics: true }));
                }
                if (this.toUnsubscribeContentTopics.size > 0) {
                    log$j.info(`Subscription interval: ${this.toUnsubscribeContentTopics.size} topics to unsubscribe`);
                    void (await this.attemptUnsubscribe({ useNewContentTopics: true }));
                }
            };
            void run();
        }, subscriptionRefreshIntervalMs);
    }
    setupKeepAliveInterval() {
        log$j.info(`Setting up keep-alive interval with period ${this.config.keepAliveIntervalMs}ms`);
        this.keepAliveIntervalId = setInterval(() => {
            const run = async () => {
                log$j.info(`Keep-alive interval running for ${this.peers.size} peers`);
                let peersToReplace = await Promise.all(Array.from(this.peers.values()).map(async (peer) => {
                    const response = await this.protocol.ping(peer);
                    if (response.success) {
                        log$j.info(`Ping successful for peer: ${peer.toString()}`);
                        this.peerFailures.set(peer.toString(), 0);
                        return;
                    }
                    let failures = this.peerFailures.get(peer.toString()) || 0;
                    failures += 1;
                    this.peerFailures.set(peer.toString(), failures);
                    log$j.warn(`Ping failed for peer: ${peer.toString()}, failures: ${failures}/${this.config.pingsBeforePeerRenewed}`);
                    if (failures < this.config.pingsBeforePeerRenewed) {
                        return;
                    }
                    log$j.info(`Peer ${peer.toString()} exceeded max failures (${this.config.pingsBeforePeerRenewed}), will be replaced`);
                    return peer;
                }));
                peersToReplace = peersToReplace.filter((p) => !!p);
                await Promise.all(peersToReplace.map((p) => {
                    this.peers.delete(p?.toString());
                    this.peerFailures.delete(p?.toString());
                    return this.requestUnsubscribe(p, this.contentTopics);
                }));
                if (peersToReplace.length > 0) {
                    log$j.info(`Replacing ${peersToReplace.length} failed peers`);
                    void (await this.attemptSubscribe({
                        useNewContentTopics: false,
                        useOnlyNewPeers: true
                    }));
                }
            };
            void run();
        }, this.config.keepAliveIntervalMs);
    }
    setupEventListeners() {
        this.peerManager.events.addEventListener(PeerManagerEventNames.Connect, this.onPeerConnected);
        this.peerManager.events.addEventListener(PeerManagerEventNames.Disconnect, this.onPeerDisconnected);
    }
    disposeIntervals() {
        if (this.subscribeIntervalId) {
            clearInterval(this.subscribeIntervalId);
        }
        if (this.keepAliveIntervalId) {
            clearInterval(this.keepAliveIntervalId);
        }
    }
    disposeHandlers() {
        for (const [decoder, handler] of this.callbacks.entries()) {
            this.messageEmitter.removeEventListener(decoder.contentTopic, handler);
        }
        this.callbacks.clear();
    }
    async disposePeers() {
        await this.attemptUnsubscribe({ useNewContentTopics: false });
        this.peers.clear();
        this.peerFailures = new Map();
    }
    disposeEventListeners() {
        this.peerManager.events.removeEventListener(PeerManagerEventNames.Connect, this.onPeerConnected);
        this.peerManager.events.removeEventListener(PeerManagerEventNames.Disconnect, this.onPeerDisconnected);
    }
    async onPeerConnected(event) {
        const id = event.detail?.toString();
        log$j.info(`Peer connected: ${id}`);
        const usablePeer = await this.peerManager.isPeerOnPubsub(event.detail, this.pubsubTopic);
        if (!usablePeer) {
            log$j.info(`Peer ${id} doesn't support pubsubTopic:${this.pubsubTopic}`);
            return;
        }
        // skip the peer we already subscribe to
        if (this.peers.has(id)) {
            log$j.info(`Peer ${id} already subscribed, skipping`);
            return;
        }
        await this.attemptSubscribe({
            useNewContentTopics: false,
            useOnlyNewPeers: true
        });
    }
    async onPeerDisconnected(event) {
        const id = event.detail?.toString();
        log$j.info(`Peer disconnected: ${id}`);
        const usablePeer = await this.peerManager.isPeerOnPubsub(event.detail, this.pubsubTopic);
        if (!usablePeer) {
            log$j.info(`Peer ${id} doesn't support pubsubTopic:${this.pubsubTopic}`);
            return;
        }
        // ignore as the peer is not the one that is in use
        if (!this.peers.has(id)) {
            log$j.info(`Disconnected peer ${id} not in use, ignoring`);
            return;
        }
        log$j.info(`Active peer ${id} disconnected, removing from peers list`);
        this.peers.delete(id);
        void this.attemptSubscribe({
            useNewContentTopics: false,
            useOnlyNewPeers: true
        });
    }
    async attemptSubscribe(params) {
        const { useNewContentTopics, useOnlyNewPeers = false } = params;
        const contentTopics = useNewContentTopics
            ? Array.from(this.toSubscribeContentTopics)
            : this.contentTopics;
        log$j.info(`Attempting to subscribe: useNewContentTopics=${useNewContentTopics}, useOnlyNewPeers=${useOnlyNewPeers}, contentTopics=${contentTopics.length}`);
        if (!contentTopics.length) {
            log$j.warn("Requested content topics is an empty array, skipping");
            return false;
        }
        const prevPeers = new Set(this.peers.keys());
        const peersToAdd = await this.peerManager.getPeers({
            protocol: Protocols.Filter,
            pubsubTopic: this.pubsubTopic
        });
        for (const peer of peersToAdd) {
            if (this.peers.size >= this.config.numPeersToUse) {
                break;
            }
            this.peers.set(peer.toString(), peer);
        }
        const peersToUse = useOnlyNewPeers
            ? Array.from(this.peers.values()).filter((p) => !prevPeers.has(p.toString()))
            : Array.from(this.peers.values());
        log$j.info(`Subscribing with ${peersToUse.length} peers for ${contentTopics.length} content topics`);
        if (useOnlyNewPeers && peersToUse.length === 0) {
            log$j.warn(`Requested to use only new peers, but no peers found, skipping`);
            return false;
        }
        const results = await Promise.all(peersToUse.map((p) => this.requestSubscribe(p, contentTopics)));
        const successCount = results.filter((r) => r).length;
        log$j.info(`Subscribe attempts completed: ${successCount}/${results.length} successful`);
        if (useNewContentTopics) {
            this.toSubscribeContentTopics = new Set();
        }
        return results.some((v) => v);
    }
    async requestSubscribe(peerId, contentTopics) {
        log$j.info(`requestSubscribe: pubsubTopic:${this.pubsubTopic}\tcontentTopics:${contentTopics.join(",")}`);
        if (!contentTopics.length || !this.pubsubTopic) {
            log$j.warn(`requestSubscribe: no contentTopics or pubsubTopic provided, not sending subscribe request`);
            return false;
        }
        const response = await this.protocol.subscribe(this.pubsubTopic, peerId, contentTopics);
        if (response.failure) {
            log$j.warn(`requestSubscribe: Failed to subscribe ${this.pubsubTopic} to ${peerId.toString()} with error:${response.failure.error} for contentTopics:${contentTopics}`);
            return false;
        }
        log$j.info(`requestSubscribe: Subscribed ${this.pubsubTopic} to ${peerId.toString()} for contentTopics:${contentTopics}`);
        return true;
    }
    async attemptUnsubscribe(params) {
        const { useNewContentTopics } = params;
        const contentTopics = useNewContentTopics
            ? Array.from(this.toUnsubscribeContentTopics)
            : this.contentTopics;
        log$j.info(`Attempting to unsubscribe: useNewContentTopics=${useNewContentTopics}, contentTopics=${contentTopics.length}`);
        if (!contentTopics.length) {
            log$j.warn("Requested content topics is an empty array, skipping");
            return false;
        }
        const peersToUse = Array.from(this.peers.values());
        const result = await Promise.all(peersToUse.map((p) => this.requestUnsubscribe(p, useNewContentTopics ? contentTopics : undefined)));
        const successCount = result.filter((r) => r).length;
        log$j.info(`Unsubscribe attempts completed: ${successCount}/${result.length} successful`);
        if (useNewContentTopics) {
            this.toUnsubscribeContentTopics = new Set();
        }
        return result.some((v) => v);
    }
    async requestUnsubscribe(peerId, contentTopics) {
        const response = contentTopics
            ? await this.protocol.unsubscribe(this.pubsubTopic, peerId, contentTopics)
            : await this.protocol.unsubscribeAll(this.pubsubTopic, peerId);
        if (response.failure) {
            log$j.warn(`requestUnsubscribe: Failed to unsubscribe for pubsubTopic:${this.pubsubTopic} from peerId:${peerId.toString()} with error:${response.failure?.error} for contentTopics:${contentTopics}`);
            return false;
        }
        log$j.info(`requestUnsubscribe: Unsubscribed pubsubTopic:${this.pubsubTopic} from peerId:${peerId.toString()} for contentTopics:${contentTopics}`);
        return true;
    }
}

const log$i = new Logger$1("sdk:filter");
class Filter {
    protocol;
    peerManager;
    config;
    subscriptions = new Map();
    constructor(params) {
        this.config = {
            numPeersToUse: 2,
            pingsBeforePeerRenewed: 3,
            keepAliveIntervalMs: 60_000,
            ...params.options
        };
        this.peerManager = params.peerManager;
        this.protocol = new FilterCore(this.onIncomingMessage.bind(this), params.libp2p);
    }
    get multicodec() {
        return this.protocol.multicodec;
    }
    unsubscribeAll() {
        for (const subscription of this.subscriptions.values()) {
            subscription.stop();
        }
        this.subscriptions.clear();
    }
    async subscribe(decoder, callback) {
        const decoders = Array.isArray(decoder) ? decoder : [decoder];
        if (decoders.length === 0) {
            throw Error("Cannot subscribe with 0 decoders.");
        }
        const pubsubTopics = decoders.map((v) => v.pubsubTopic);
        const singlePubsubTopic = pubsubTopics[0];
        const contentTopics = decoders.map((v) => v.contentTopic);
        log$i.info(`Subscribing to contentTopics: ${contentTopics}, pubsubTopic: ${singlePubsubTopic}`);
        this.throwIfTopicNotSame(pubsubTopics);
        let subscription = this.subscriptions.get(singlePubsubTopic);
        if (!subscription) {
            subscription = new Subscription({
                pubsubTopic: singlePubsubTopic,
                protocol: this.protocol,
                config: this.config,
                peerManager: this.peerManager
            });
            subscription.start();
        }
        const result = await subscription.add(decoders, callback);
        this.subscriptions.set(singlePubsubTopic, subscription);
        log$i.info(`Subscription ${result ? "successful" : "failed"} for content topic: ${contentTopics}`);
        return result;
    }
    async unsubscribe(decoder) {
        const decoders = Array.isArray(decoder) ? decoder : [decoder];
        if (decoders.length === 0) {
            throw Error("Cannot unsubscribe with 0 decoders.");
        }
        const pubsubTopics = decoders.map((v) => v.pubsubTopic);
        const singlePubsubTopic = pubsubTopics[0];
        const contentTopics = decoders.map((v) => v.contentTopic);
        log$i.info(`Unsubscribing from contentTopics: ${contentTopics}, pubsubTopic: ${singlePubsubTopic}`);
        this.throwIfTopicNotSame(pubsubTopics);
        const subscription = this.subscriptions.get(singlePubsubTopic);
        if (!subscription) {
            log$i.warn("No subscriptions associated with the decoder.");
            return false;
        }
        const result = await subscription.remove(decoders);
        if (subscription.isEmpty()) {
            log$i.warn("Subscription has no decoders anymore, terminating it.");
            subscription.stop();
            this.subscriptions.delete(singlePubsubTopic);
        }
        log$i.info(`Unsubscribing ${result ? "successful" : "failed"} for content topic: ${contentTopics}`);
        return result;
    }
    async onIncomingMessage(pubsubTopic, message, peerId) {
        log$i.info(`Received message for pubsubTopic:${pubsubTopic}, contentTopic:${message.contentTopic}, peerId:${peerId.toString()}`);
        const subscription = this.subscriptions.get(pubsubTopic);
        if (!subscription) {
            log$i.error(`No subscription locally registered for topic ${pubsubTopic}`);
            return;
        }
        subscription.invoke(message, peerId);
    }
    // Limiting to one pubsubTopic for simplicity reasons, we can enable subscription for more than one PubsubTopic at once later when requested
    throwIfTopicNotSame(pubsubTopics) {
        const first = pubsubTopics[0];
        const isSameTopic = pubsubTopics.every((t) => t === first);
        if (!isSameTopic) {
            throw Error(`Cannot subscribe to more than one pubsub topic at the same time, got pubsubTopics:${pubsubTopics}`);
        }
    }
}

const log$h = new Logger$1("health-indicator");
class HealthIndicator {
    libp2p;
    events;
    value = HealthStatus.Unhealthy;
    constructor(params) {
        this.libp2p = params.libp2p;
        this.events = params.events;
        this.onPeerIdentify = this.onPeerIdentify.bind(this);
        this.onPeerDisconnected = this.onPeerDisconnected.bind(this);
    }
    start() {
        log$h.info("start: adding listeners to libp2p");
        this.libp2p.addEventListener("peer:identify", this.onPeerIdentify);
        this.libp2p.addEventListener("peer:disconnect", this.onPeerDisconnected);
    }
    stop() {
        log$h.info("stop: removing listeners to libp2p");
        this.libp2p.removeEventListener("peer:identify", this.onPeerIdentify);
        this.libp2p.removeEventListener("peer:disconnect", this.onPeerDisconnected);
    }
    toValue() {
        return this.value;
    }
    async onPeerDisconnected(_event) {
        log$h.info(`onPeerDisconnected: received libp2p event`);
        const connections = this.libp2p.getConnections();
        // we handle only Unhealthy here and onPeerIdentify will cover other cases
        if (connections.length > 0) {
            log$h.info("onPeerDisconnected: has connections, ignoring");
        }
        this.value = HealthStatus.Unhealthy;
        log$h.info(`onPeerDisconnected: node identified as ${this.value}`);
        this.dispatchHealthEvent();
    }
    async onPeerIdentify(_event) {
        log$h.info(`onPeerIdentify: received libp2p event`);
        const connections = this.libp2p.getConnections();
        const peers = await Promise.all(connections.map(async (c) => {
            try {
                return await this.libp2p.peerStore.get(c.remotePeer);
            }
            catch (e) {
                return null;
            }
        }));
        const filterPeers = peers.filter((p) => p?.protocols.includes(FilterCodecs.SUBSCRIBE)).length;
        const lightPushPeers = peers.filter((p) => p?.protocols.includes(LightPushCodec)).length;
        if (filterPeers === 0 || lightPushPeers === 0) {
            this.value = HealthStatus.Unhealthy;
        }
        else if (filterPeers >= 2 && lightPushPeers >= 2) {
            this.value = HealthStatus.SufficientlyHealthy;
        }
        else if (filterPeers === 1 && lightPushPeers === 1) {
            this.value = HealthStatus.MinimallyHealthy;
        }
        else {
            log$h.error(`onPeerChange: unexpected state, cannot identify health status of the node: Filter:${filterPeers}; LightPush:${lightPushPeers}`);
        }
        log$h.info(`onPeerChange: node identified as ${this.value}`);
        this.dispatchHealthEvent();
    }
    dispatchHealthEvent() {
        this.events.dispatchEvent(new CustomEvent("waku:health", {
            detail: this.value
        }));
    }
}

const shouldPeerBeChanged = (failure) => {
    const toBeChanged = failure === ProtocolError$1.REMOTE_PEER_REJECTED ||
        failure === ProtocolError$1.NO_RESPONSE ||
        failure === ProtocolError$1.RLN_PROOF_GENERATION ||
        failure === ProtocolError$1.NO_PEER_AVAILABLE;
    if (toBeChanged) {
        return true;
    }
    return false;
};
const timeout = (timeout) => {
    return new Promise((_, reject) => setTimeout(() => reject(new Error("Task timeout")), timeout));
};

const MAX_CONCURRENT_TASKS = 5;
const TASK_TIMEOUT_MS = 10_000;
const log$g = new Logger$1("sdk:retry-manager");
class RetryManager {
    intervalID = null;
    retryIntervalMs;
    inProgress = 0;
    queue = [];
    peerManager;
    constructor(config) {
        this.peerManager = config.peerManager;
        this.retryIntervalMs = config.retryIntervalMs || 1000;
    }
    start() {
        this.intervalID = setInterval(() => {
            this.processQueue();
        }, this.retryIntervalMs);
    }
    stop() {
        if (this.intervalID) {
            clearInterval(this.intervalID);
            this.intervalID = null;
        }
    }
    push(callback, maxAttempts, pubsubTopic) {
        this.queue.push({
            maxAttempts,
            callback,
            pubsubTopic
        });
    }
    processQueue() {
        if (this.queue.length === 0) {
            return;
        }
        while (this.queue.length && this.inProgress < MAX_CONCURRENT_TASKS) {
            const task = this.queue.shift();
            if (task) {
                this.scheduleTask(task);
            }
        }
    }
    scheduleTask(task) {
        const delayedTask = async () => {
            return this.taskExecutor(task);
        };
        // schedule execution ASAP
        // need to use setTimeout to avoid blocking main execution
        setTimeout(delayedTask, 100);
    }
    async taskExecutor(task) {
        if (task.maxAttempts <= 0) {
            log$g.warn("scheduleTask: max attempts has reached, removing from queue");
            return;
        }
        const peerId = (await this.peerManager.getPeers({
            protocol: Protocols.LightPush,
            pubsubTopic: task.pubsubTopic
        }))[0];
        if (!peerId) {
            log$g.warn("scheduleTask: no peers, putting back to queue");
            this.queue.push({
                ...task,
                maxAttempts: task.maxAttempts - 1
            });
            return;
        }
        try {
            this.inProgress += 1;
            const response = await Promise.race([
                timeout(TASK_TIMEOUT_MS),
                task.callback(peerId)
            ]);
            if (response?.failure) {
                throw Error(response.failure.error);
            }
            log$g.info("scheduleTask: executed successfully");
            if (task.maxAttempts === 0) {
                log$g.warn("scheduleTask: discarded a task due to limit of max attempts");
                return;
            }
            this.queue.push({
                ...task,
                maxAttempts: task.maxAttempts - 1
            });
        }
        catch (_err) {
            const error = _err;
            log$g.error("scheduleTask: task execution failed with error:", error);
            if (shouldPeerBeChanged(error.message)) {
                await this.peerManager.renewPeer(peerId, {
                    protocol: Protocols.LightPush,
                    pubsubTopic: task.pubsubTopic
                });
            }
            if (task.maxAttempts === 0) {
                log$g.warn("scheduleTask: discarded a task due to limit of max attempts");
                return;
            }
            this.queue.push({
                ...task,
                maxAttempts: task.maxAttempts - 1
            });
        }
        finally {
            this.inProgress -= 1;
        }
    }
}

const log$f = new Logger$1("sdk:light-push");
const DEFAULT_MAX_ATTEMPTS = 3;
const DEFAULT_SEND_OPTIONS = {
    autoRetry: true,
    retryIntervalMs: 1000,
    maxAttempts: DEFAULT_MAX_ATTEMPTS,
    numPeersToUse: 1
};
class LightPush {
    config;
    retryManager;
    peerManager;
    protocol;
    constructor(params) {
        this.config = {
            ...DEFAULT_SEND_OPTIONS,
            ...(params.options || {})
        };
        this.peerManager = params.peerManager;
        this.protocol = new LightPushCore(params.libp2p);
        this.retryManager = new RetryManager({
            peerManager: params.peerManager,
            retryIntervalMs: this.config.retryIntervalMs
        });
    }
    get multicodec() {
        return this.protocol.multicodec;
    }
    start() {
        this.retryManager.start();
    }
    stop() {
        this.retryManager.stop();
    }
    async send(encoder, message, options = {}) {
        options = {
            ...this.config,
            ...options
        };
        const { pubsubTopic } = encoder;
        log$f.info("send: attempting to send a message to pubsubTopic:", pubsubTopic);
        const peerIds = await this.peerManager.getPeers({
            protocol: Protocols.LightPush,
            pubsubTopic: encoder.pubsubTopic
        });
        const coreResults = peerIds?.length > 0
            ? await Promise.all(peerIds.map((peerId) => this.protocol.send(encoder, message, peerId).catch((_e) => ({
                success: null,
                failure: {
                    error: ProtocolError$1.GENERIC_FAIL
                }
            }))))
            : [];
        const results = coreResults.length
            ? {
                successes: coreResults
                    .filter((v) => v.success)
                    .map((v) => v.success),
                failures: coreResults
                    .filter((v) => v.failure)
                    .map((v) => v.failure)
            }
            : {
                successes: [],
                failures: [
                    {
                        error: ProtocolError$1.NO_PEER_AVAILABLE
                    }
                ]
            };
        if (options.autoRetry && results.successes.length === 0) {
            const sendCallback = (peerId) => this.protocol.send(encoder, message, peerId);
            this.retryManager.push(sendCallback.bind(this), options.maxAttempts || DEFAULT_MAX_ATTEMPTS, encoder.pubsubTopic);
        }
        return results;
    }
}

const log$e = new Logger$1("store-sdk");
/**
 * StoreSDK is an implementation of the IStoreSDK interface.
 * It provides methods to interact with the Waku Store protocol.
 */
class Store {
    options;
    libp2p;
    peerManager;
    protocol;
    constructor(params) {
        this.options = params.options || {};
        this.peerManager = params.peerManager;
        this.libp2p = params.libp2p;
        this.protocol = new StoreCore(params.libp2p);
    }
    get multicodec() {
        return this.protocol.multicodec;
    }
    /**
     * Queries the Waku Store for historical messages using the provided decoders and options.
     * Returns an asynchronous generator that yields promises of decoded messages.
     *
     * @param decoders - An array of message decoders.
     * @param options - Optional query parameters.
     * @returns An asynchronous generator of promises of decoded messages.
     * @throws If no peers are available to query or if an error occurs during the query.
     */
    async *queryGenerator(decoders, options) {
        const { decodersAsMap, queryOptions } = this.buildQueryParams(decoders, options);
        for (const queryOption of queryOptions) {
            const peer = await this.getPeerToUse(queryOption.pubsubTopic);
            if (!peer) {
                log$e.error("No peers available to query");
                throw new Error("No peers available to query");
            }
            log$e.info(`Querying store with options: ${JSON.stringify(queryOption)}`);
            const responseGenerator = this.protocol.queryPerPage(queryOption, decodersAsMap, peer);
            for await (const messages of responseGenerator) {
                yield messages;
            }
        }
    }
    /**
     * Queries the Waku Store for historical messages and processes them with the provided callback in order.
     *
     * @param decoders - An array of message decoders.
     * @param callback - A callback function to process each decoded message.
     * @param options - Optional query parameters.
     * @returns A promise that resolves when the query and message processing are completed.
     */
    async queryWithOrderedCallback(decoders, callback, options) {
        log$e.info("Querying store with ordered callback");
        for await (const promises of this.queryGenerator(decoders, options)) {
            if (await this.processMessages(promises, callback))
                break;
        }
    }
    /**
     * Queries the Waku Store for historical messages and processes them with the provided callback using promises.
     *
     * @param decoders - An array of message decoders.
     * @param callback - A callback function to process each promise of a decoded message.
     * @param options - Optional query parameters.
     * @returns A promise that resolves when the query and message processing are completed.
     */
    async queryWithPromiseCallback(decoders, callback, options) {
        log$e.info("Querying store with promise callback");
        let abort = false;
        for await (const page of this.queryGenerator(decoders, options)) {
            const _promises = page.map(async (msgPromise) => {
                if (abort)
                    return;
                abort = Boolean(await callback(msgPromise));
            });
            await Promise.all(_promises);
            if (abort)
                break;
        }
    }
    /**
     * Processes messages based on the provided callback and options.
     *
     * @param messages - An array of promises of decoded messages.
     * @param callback - A callback function to process each decoded message.
     * @returns A promise that resolves to a boolean indicating whether the processing should abort.
     * @private
     */
    async processMessages(messages, callback) {
        let abort = false;
        const messagesOrUndef = await Promise.all(messages);
        const processedMessages = messagesOrUndef.filter(isDefined);
        await Promise.all(processedMessages.map(async (msg) => {
            if (msg && !abort) {
                abort = Boolean(await callback(msg));
            }
        }));
        return abort;
    }
    /**
     * Creates a cursor based on the provided decoded message.
     *
     * @param message - The decoded message.
     * @returns A StoreCursor representing the message.
     */
    createCursor(message) {
        return messageHash(message.pubsubTopic, message);
    }
    /**
     * Validates the provided decoders and pubsub topic.
     *
     * @param decoders - An array of message decoders.
     * @returns An object containing the pubsub topic, content topics, and a map of decoders.
     * @throws If no decoders are provided, if multiple pubsub topics are provided, or if no decoders are found for the pubsub topic.
     * @private
     */
    validateDecodersAndPubsubTopic(decoders) {
        if (decoders.length === 0) {
            log$e.error("No decoders provided");
            throw new Error("No decoders provided");
        }
        const uniquePubsubTopicsInQuery = Array.from(new Set(decoders.map((decoder) => decoder.pubsubTopic)));
        if (uniquePubsubTopicsInQuery.length > 1) {
            log$e.error("API does not support querying multiple pubsub topics at once");
            throw new Error("API does not support querying multiple pubsub topics at once");
        }
        const pubsubTopicForQuery = uniquePubsubTopicsInQuery[0];
        const decodersAsMap = new Map();
        decoders.forEach((dec) => {
            if (decodersAsMap.has(dec.contentTopic)) {
                log$e.error("API does not support different decoder per content topic");
                throw new Error("API does not support different decoder per content topic");
            }
            decodersAsMap.set(dec.contentTopic, dec);
        });
        const contentTopics = decoders
            .filter((decoder) => decoder.pubsubTopic === pubsubTopicForQuery)
            .map((dec) => dec.contentTopic);
        if (contentTopics.length === 0) {
            log$e.error(`No decoders found for topic ${pubsubTopicForQuery}`);
            throw new Error("No decoders found for topic " + pubsubTopicForQuery);
        }
        return {
            pubsubTopic: pubsubTopicForQuery,
            contentTopics,
            decodersAsMap
        };
    }
    async getPeerToUse(pubsubTopic) {
        const peers = await this.peerManager.getPeers({
            protocol: Protocols.Store,
            pubsubTopic
        });
        return this.options.peers
            ? await this.getPeerFromConfigurationOrFirst(peers, this.options.peers)
            : peers[0];
    }
    async getPeerFromConfigurationOrFirst(peerIds, configPeers) {
        const storeConfigPeers = configPeers.map(multiaddr);
        const missing = [];
        for (const peer of storeConfigPeers) {
            const matchedPeer = peerIds.find((id) => id.toString() === peer.getPeerId()?.toString());
            if (matchedPeer) {
                return matchedPeer;
            }
            missing.push(peer);
        }
        while (missing.length) {
            const toDial = missing.pop();
            if (!toDial) {
                return;
            }
            try {
                const conn = await this.libp2p.dial(toDial);
                if (conn) {
                    return peerIdFromString$1(toDial.getPeerId());
                }
            }
            catch (e) {
                log$e.warn(`Failed to dial peer from options.peers list for Store protocol. Peer:${toDial.getPeerId()}, error:${e}`);
            }
        }
        log$e.warn(`Passed node to use for Store not found: ${configPeers.toString()}. Attempting to use first available peers.`);
        return peerIds[0];
    }
    buildQueryParams(decoders, options) {
        // For message hash queries, don't validate decoders but still need decodersAsMap
        const isHashQuery = options?.messageHashes && options.messageHashes.length > 0;
        let pubsubTopic;
        let contentTopics;
        let decodersAsMap;
        if (isHashQuery) {
            // For hash queries, we still need decoders to decode messages
            // but we don't validate pubsubTopic consistency
            // Use pubsubTopic from options if provided, otherwise from first decoder
            pubsubTopic = options.pubsubTopic || decoders[0]?.pubsubTopic || "";
            contentTopics = [];
            decodersAsMap = new Map();
            decoders.forEach((dec) => {
                decodersAsMap.set(dec.contentTopic, dec);
            });
        }
        else {
            const validated = this.validateDecodersAndPubsubTopic(decoders);
            pubsubTopic = validated.pubsubTopic;
            contentTopics = validated.contentTopics;
            decodersAsMap = validated.decodersAsMap;
        }
        const subTimeRanges = [];
        if (options?.timeStart && options?.timeEnd) {
            let start = options.timeStart;
            const end = options.timeEnd;
            while (end.getTime() - start.getTime() > this.protocol.maxTimeLimit) {
                const subEnd = new Date(start.getTime() + this.protocol.maxTimeLimit);
                subTimeRanges.push([start, subEnd]);
                start = subEnd;
            }
            if (subTimeRanges.length === 0) {
                log$e.info("Using single time range");
                subTimeRanges.push([start, end]);
            }
        }
        if (subTimeRanges.length === 0) {
            log$e.info("No sub time ranges");
            return {
                decodersAsMap,
                queryOptions: [
                    {
                        pubsubTopic,
                        contentTopics,
                        includeData: true,
                        paginationForward: true,
                        ...options
                    }
                ]
            };
        }
        log$e.info(`Building ${subTimeRanges.length} sub time ranges`);
        return {
            decodersAsMap,
            queryOptions: subTimeRanges.map(([start, end]) => ({
                pubsubTopic,
                contentTopics,
                includeData: true,
                paginationForward: true,
                ...options,
                timeStart: start,
                timeEnd: end
            }))
        };
    }
}

const decoderParamsToShardInfo = (params, networkConfig) => {
    const clusterId = (params.shardInfo?.clusterId ||
        networkConfig.clusterId);
    const shardsUnderCluster = params.shardInfo && "shardsUnderCluster" in params.shardInfo
        ? params.shardInfo.shardsUnderCluster
        : DEFAULT_NUM_SHARDS;
    const shardIndex = params.shardInfo && "shard" in params.shardInfo
        ? params.shardInfo.shard
        : contentTopicToShardIndex(params.contentTopic, shardsUnderCluster);
    return {
        clusterId,
        shard: shardIndex
    };
};
const isShardCompatible = (shardInfo, networkConfig) => {
    if (networkConfig.clusterId !== shardInfo.clusterId) {
        return false;
    }
    if ("shards" in networkConfig &&
        !networkConfig.shards.includes(shardInfo.shard)) {
        return false;
    }
    return true;
};

const log$d = new Logger$1("wait-for-remote-peer");
/**
 * @deprecated Since @waku/sdk 0.29.0. Will be removed from 0.31.0
 *
 * Wait for a remote peer to be ready given the passed protocols.
 * Must be used after attempting to connect to nodes, using
 * {@link @waku/sdk!WakuNode.dial} or a bootstrap method with
 * {@link @waku/sdk!createLightNode}.
 *
 * If the passed protocols is a GossipSub protocol, then it resolves only once
 * a peer is in a mesh, to help ensure that other peers will send and receive
 * message to us.
 *
 * @param waku The Waku Node
 * @param protocols The protocols that need to be enabled by remote peers.
 * @param timeoutMs A timeout value in milliseconds..
 *
 * @returns A promise that **resolves** if all desired protocols are fulfilled by
 * remote nodes, **rejects** if the timeoutMs is reached.
 * @throws If passing a protocol that is not mounted
 * @default Wait for remote peers with protocols enabled locally and no time out is applied.
 */
async function waitForRemotePeer(waku, protocols, timeoutMs) {
    // if no protocols or empty array passed - try to derive from mounted
    protocols = protocols?.length ? protocols : getEnabledProtocols(waku);
    const connections = waku.libp2p.getConnections();
    if (!waku.isStarted()) {
        throw Error("Waku node is not started");
    }
    for (const protocol of protocols) {
        switch (protocol) {
            case Protocols.Relay:
                if (!waku.relay)
                    throw Error("Cannot wait for Relay peer: protocol not mounted");
                break;
            case Protocols.LightPush:
                if (!waku.lightPush)
                    throw Error("Cannot wait for LightPush peer: protocol not mounted");
                break;
            case Protocols.Store:
                if (!waku.store)
                    throw Error("Cannot wait for Store peer: protocol not mounted");
                break;
            case Protocols.Filter:
                if (!waku.filter)
                    throw Error("Cannot wait for Filter peer: protocol not mounted");
                break;
        }
    }
    const promises = [waitForProtocols(waku, protocols)];
    if (connections.length > 0 && !protocols.includes(Protocols.Relay)) {
        promises.push(waitForMetadata(waku, protocols));
    }
    if (timeoutMs) {
        await rejectOnTimeout(Promise.any(promises), timeoutMs, "Timed out waiting for a remote peer.");
    }
    else {
        await Promise.any(promises);
    }
}
/**
 * Waits for required peers to be connected.
 */
async function waitForProtocols(waku, protocols) {
    const promises = [];
    if (waku.relay && protocols.includes(Protocols.Relay)) {
        promises.push(waku.relay.waitForPeers());
    }
    if (waku.store && protocols.includes(Protocols.Store)) {
        promises.push(waitForConnectedPeer(StoreCodec, waku.libp2p));
    }
    if (waku.lightPush && protocols.includes(Protocols.LightPush)) {
        promises.push(waitForConnectedPeer(LightPushCodec, waku.libp2p));
    }
    if (waku.filter && protocols.includes(Protocols.Filter)) {
        promises.push(waitForConnectedPeer(FilterCodecs.SUBSCRIBE, waku.libp2p));
    }
    return Promise.all(promises);
}
/**
 * Wait for a peer with the given protocol to be connected.
 * If sharding is enabled on the node, it will also wait for the peer to be confirmed by the metadata service.
 */
async function waitForConnectedPeer(codec, libp2p) {
    log$d.info(`Waiting for ${codec} peer.`);
    await new Promise((resolve) => {
        const cb = (async (evt) => {
            if (evt.detail?.protocols?.includes(codec)) {
                const metadataService = libp2p.services.metadata;
                if (!metadataService) {
                    libp2p.removeEventListener("peer:identify", cb);
                    resolve();
                    return;
                }
                try {
                    await metadataService.confirmOrAttemptHandshake(evt.detail.peerId);
                    libp2p.removeEventListener("peer:identify", cb);
                    resolve();
                }
                catch (e) {
                    // eslint-disable-next-line @typescript-eslint/no-explicit-any
                    if (e.code === "ERR_CONNECTION_BEING_CLOSED") {
                        log$d.error("Connection closed. Some peers can be on different shard.");
                    }
                    log$d.error(`Error waiting for metadata: ${e}`);
                }
            }
        });
        libp2p.addEventListener("peer:identify", cb);
    });
}
/**
 * Checks existing connections for needed metadata.
 */
async function waitForMetadata(waku, protocols) {
    const connectedPeers = waku.libp2p.getPeers();
    const metadataService = waku.libp2p.services.metadata;
    const enabledCodes = mapProtocolsToCodecs(protocols);
    if (!connectedPeers.length || !metadataService) {
        log$d.info(`Skipping waitForMetadata due to missing connections:${connectedPeers.length} or metadataService:${!!metadataService}`);
        return;
    }
    for (const peerId of connectedPeers) {
        try {
            const peer = await waku.libp2p.peerStore.get(peerId);
            const hasSomeCodes = peer.protocols.some((c) => enabledCodes.has(c));
            if (hasSomeCodes) {
                const response = await metadataService.confirmOrAttemptHandshake(peerId);
                if (!response.error) {
                    peer.protocols.forEach((c) => {
                        if (enabledCodes.has(c)) {
                            enabledCodes.set(c, true);
                        }
                    });
                    const confirmedAllCodecs = Array.from(enabledCodes.values()).every((v) => v);
                    if (confirmedAllCodecs) {
                        return;
                    }
                }
            }
        }
        catch (e) {
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            if (e.code === "ERR_CONNECTION_BEING_CLOSED") {
                log$d.error("Connection closed. Some peers can be on different shard.");
            }
            log$d.error(`Error while iterating through peers: ${e}`);
            continue;
        }
    }
}
const awaitTimeout = (ms, rejectReason) => new Promise((_resolve, reject) => setTimeout(() => reject(Error(rejectReason)), ms));
async function rejectOnTimeout(promise, timeoutMs, rejectReason) {
    await Promise.race([promise, awaitTimeout(timeoutMs, rejectReason)]);
}
function getEnabledProtocols(waku) {
    const protocols = [];
    if (waku.relay) {
        protocols.push(Protocols.Relay);
    }
    if (waku.filter) {
        protocols.push(Protocols.Filter);
    }
    if (waku.store) {
        protocols.push(Protocols.Store);
    }
    if (waku.lightPush) {
        protocols.push(Protocols.LightPush);
    }
    return protocols;
}
function mapProtocolsToCodecs(protocols) {
    const codecs = new Map();
    const protocolToCodec = {
        [Protocols.Filter]: FilterCodecs.SUBSCRIBE,
        [Protocols.LightPush]: LightPushCodec,
        [Protocols.Store]: StoreCodec
    };
    for (const protocol of protocols) {
        if (protocolToCodec[protocol]) {
            codecs.set(protocolToCodec[protocol], false);
        }
    }
    return codecs;
}

const log$c = new Logger$1("waku");
class WakuNode {
    libp2p;
    relay;
    store;
    filter;
    lightPush;
    events = new TypedEventEmitter();
    networkConfig;
    // needed to create a lock for async operations
    _nodeStateLock = false;
    _nodeStarted = false;
    connectionManager;
    peerManager;
    healthIndicator;
    constructor(options, libp2p, protocolsEnabled, relay) {
        this.relay = relay;
        this.libp2p = libp2p;
        this.networkConfig = options.networkConfig || DefaultNetworkConfig;
        protocolsEnabled = {
            filter: false,
            lightpush: false,
            store: false,
            ...protocolsEnabled
        };
        const peerId = this.libp2p.peerId.toString();
        this.connectionManager = new ConnectionManager({
            libp2p,
            relay: this.relay,
            events: this.events,
            networkConfig: this.networkConfig,
            config: options?.connectionManager
        });
        this.peerManager = new PeerManager({
            libp2p,
            config: {
                numPeersToUse: options.numPeersToUse
            },
            connectionManager: this.connectionManager
        });
        this.healthIndicator = new HealthIndicator({ libp2p, events: this.events });
        if (protocolsEnabled.store) {
            this.store = new Store({
                libp2p,
                peerManager: this.peerManager,
                options: options?.store
            });
        }
        if (protocolsEnabled.lightpush) {
            this.lightPush = new LightPush({
                libp2p,
                peerManager: this.peerManager,
                options: options?.lightPush
            });
        }
        if (protocolsEnabled.filter) {
            this.filter = new Filter({
                libp2p,
                peerManager: this.peerManager,
                options: options.filter
            });
        }
        log$c.info("Waku node created", peerId, `relay: ${!!this.relay}, store: ${!!this.store}, light push: ${!!this
            .lightPush}, filter: ${!!this.filter}`);
    }
    get peerId() {
        return this.libp2p.peerId;
    }
    get protocols() {
        return this.libp2p.getProtocols();
    }
    get health() {
        return this.healthIndicator.toValue();
    }
    async dial(peer, protocols) {
        const _protocols = protocols ?? [];
        if (typeof protocols === "undefined") {
            this.relay && _protocols.push(Protocols.Relay);
            this.store && _protocols.push(Protocols.Store);
            this.filter && _protocols.push(Protocols.Filter);
            this.lightPush && _protocols.push(Protocols.LightPush);
        }
        const codecs = [];
        if (_protocols.includes(Protocols.Relay)) {
            if (this.relay) {
                this.relay.gossipSub.multicodecs.forEach((codec) => codecs.push(codec));
            }
            else {
                log$c.error("Relay codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.Store)) {
            if (this.store) {
                codecs.push(this.store.multicodec);
            }
            else {
                log$c.error("Store codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.LightPush)) {
            if (this.lightPush) {
                codecs.push(this.lightPush.multicodec);
            }
            else {
                log$c.error("Light Push codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.Filter)) {
            if (this.filter) {
                codecs.push(this.filter.multicodec);
            }
            else {
                log$c.error("Filter codec not included in dial codec: protocol not mounted locally");
            }
        }
        log$c.info(`Dialing to ${peer?.toString()} with protocols ${_protocols}`);
        return await this.connectionManager.dial(peer, codecs);
    }
    async hangUp(peer) {
        log$c.info(`Hanging up peer:${peer?.toString()}.`);
        return this.connectionManager.hangUp(peer);
    }
    async start() {
        if (this._nodeStateLock || this.isStarted())
            return;
        this._nodeStateLock = true;
        await this.libp2p.start();
        this.connectionManager.start();
        this.peerManager.start();
        this.healthIndicator.start();
        this.lightPush?.start();
        this._nodeStateLock = false;
        this._nodeStarted = true;
    }
    async stop() {
        if (this._nodeStateLock || !this.isStarted())
            return;
        this._nodeStateLock = true;
        this.lightPush?.stop();
        this.healthIndicator.stop();
        this.peerManager.stop();
        this.connectionManager.stop();
        await this.libp2p.stop();
        this._nodeStateLock = false;
        this._nodeStarted = false;
    }
    async getConnectedPeers() {
        return this.connectionManager.getConnectedPeers();
    }
    async waitForPeers(protocols, timeoutMs) {
        return waitForRemotePeer(this, protocols, timeoutMs);
    }
    isStarted() {
        return this._nodeStarted && this.libp2p.status === "started";
    }
    isConnected() {
        return this.connectionManager.isConnected();
    }
    createDecoder(params) {
        const singleShardInfo = decoderParamsToShardInfo(params, this.networkConfig);
        log$c.info(`Creating Decoder with input:${JSON.stringify(params.shardInfo)}, determined:${JSON.stringify(singleShardInfo)}, expected:${JSON.stringify(this.networkConfig)}.`);
        if (!isShardCompatible(singleShardInfo, this.networkConfig)) {
            throw Error(`Cannot create decoder: incompatible shard configuration.`);
        }
        return createDecoder(params.contentTopic, singleShardInfo);
    }
    createEncoder(params) {
        const singleShardInfo = decoderParamsToShardInfo(params, this.networkConfig);
        log$c.info(`Creating Encoder with input:${JSON.stringify(params.shardInfo)}, determined:${JSON.stringify(singleShardInfo)}, expected:${JSON.stringify(this.networkConfig)}.`);
        if (!isShardCompatible(singleShardInfo, this.networkConfig)) {
            throw Error(`Cannot create encoder: incompatible shard configuration.`);
        }
        return createEncoder({
            contentTopic: params.contentTopic,
            ephemeral: params.ephemeral,
            pubsubTopicShardInfo: singleShardInfo
        });
    }
}

// Maximum length of the length section of the message
const MAX_LENGTH_LENGTH = 8; // Varint.encode(Number.MAX_SAFE_INTEGER).length
// Maximum length of the data section of the message
const MAX_DATA_LENGTH$1 = 1024 * 1024 * 4;

/**
 * The reported length of the next data message was not a positive integer
 */
let InvalidMessageLengthError$1 = class InvalidMessageLengthError extends Error {
    name = 'InvalidMessageLengthError';
    code = 'ERR_INVALID_MSG_LENGTH';
};
/**
 * The reported length of the next data message was larger than the configured
 * max allowable value
 */
let InvalidDataLengthError$2 = class InvalidDataLengthError extends Error {
    name = 'InvalidDataLengthError';
    code = 'ERR_MSG_DATA_TOO_LONG';
};
/**
 * The varint used to specify the length of the next data message contained more
 * bytes than the configured max allowable value
 */
let InvalidDataLengthLengthError$1 = class InvalidDataLengthLengthError extends Error {
    name = 'InvalidDataLengthLengthError';
    code = 'ERR_MSG_LENGTH_TOO_LONG';
};
/**
 * The incoming stream ended before the expected number of bytes were read
 */
let UnexpectedEOFError$1 = class UnexpectedEOFError extends Error {
    name = 'UnexpectedEOFError';
    code = 'ERR_UNEXPECTED_EOF';
};

function isAsyncIterable$5(thing) {
    return thing[Symbol.asyncIterator] != null;
}

/* eslint max-depth: ["error", 6] */
var ReadMode$1;
(function (ReadMode) {
    ReadMode[ReadMode["LENGTH"] = 0] = "LENGTH";
    ReadMode[ReadMode["DATA"] = 1] = "DATA";
})(ReadMode$1 || (ReadMode$1 = {}));
const defaultDecoder = (buf) => {
    const length = decode$8(buf);
    defaultDecoder.bytes = encodingLength$1(length);
    return length;
};
defaultDecoder.bytes = 0;
function decode$1(source, options) {
    const buffer = new Uint8ArrayList();
    let mode = ReadMode$1.LENGTH;
    let dataLength = -1;
    const lengthDecoder = options?.lengthDecoder ?? defaultDecoder;
    const maxLengthLength = options?.maxLengthLength ?? MAX_LENGTH_LENGTH;
    const maxDataLength = options?.maxDataLength ?? MAX_DATA_LENGTH$1;
    function* maybeYield() {
        while (buffer.byteLength > 0) {
            if (mode === ReadMode$1.LENGTH) {
                // read length, ignore errors for short reads
                try {
                    dataLength = lengthDecoder(buffer);
                    if (dataLength < 0) {
                        throw new InvalidMessageLengthError$1('Invalid message length');
                    }
                    if (dataLength > maxDataLength) {
                        throw new InvalidDataLengthError$2('Message length too long');
                    }
                    const dataLengthLength = lengthDecoder.bytes;
                    buffer.consume(dataLengthLength);
                    if (options?.onLength != null) {
                        options.onLength(dataLength);
                    }
                    mode = ReadMode$1.DATA;
                }
                catch (err) {
                    if (err instanceof RangeError) {
                        if (buffer.byteLength > maxLengthLength) {
                            throw new InvalidDataLengthLengthError$1('Message length length too long');
                        }
                        break;
                    }
                    throw err;
                }
            }
            if (mode === ReadMode$1.DATA) {
                if (buffer.byteLength < dataLength) {
                    // not enough data, wait for more
                    break;
                }
                const data = buffer.sublist(0, dataLength);
                buffer.consume(dataLength);
                if (options?.onData != null) {
                    options.onData(data);
                }
                yield data;
                mode = ReadMode$1.LENGTH;
            }
        }
    }
    if (isAsyncIterable$5(source)) {
        return (async function* () {
            for await (const buf of source) {
                buffer.append(buf);
                yield* maybeYield();
            }
            if (buffer.byteLength > 0) {
                throw new UnexpectedEOFError$1('Unexpected end of input');
            }
        })();
    }
    return (function* () {
        for (const buf of source) {
            buffer.append(buf);
            yield* maybeYield();
        }
        if (buffer.byteLength > 0) {
            throw new UnexpectedEOFError$1('Unexpected end of input');
        }
    })();
}
decode$1.fromReader = (reader, options) => {
    let byteLength = 1; // Read single byte chunks until the length is known
    const varByteSource = (async function* () {
        while (true) {
            try {
                const { done, value } = await reader.next(byteLength);
                if (done === true) {
                    return;
                }
                if (value != null) {
                    yield value;
                }
            }
            catch (err) {
                if (err.code === 'ERR_UNDER_READ') {
                    return { done: true, value: null };
                }
                throw err;
            }
            finally {
                // Reset the byteLength so we continue to check for varints
                byteLength = 1;
            }
        }
    }());
    /**
     * Once the length has been parsed, read chunk for that length
     */
    const onLength = (l) => { byteLength = l; };
    return decode$1(varByteSource, {
        ...(options ?? {}),
        onLength
    });
};

/**
 * The incoming stream ended before the expected number of bytes were read
 */
class UnexpectedEOFError extends Error {
    name = 'UnexpectedEOFError';
    code = 'ERR_UNEXPECTED_EOF';
}

/**
 * @packageDocumentation
 *
 * This module makes it easy to send and receive bytes over streams.
 *
 * @example
 *
 * ```typescript
 * import { byteStream } from 'it-byte-stream'
 *
 * const stream = byteStream(duplex)
 *
 * // read the next chunk
 * const bytes = await stream.read()
 *
 * // read the next five bytes
 * const fiveBytes = await stream.read(5)
 *
 * // write bytes into the stream
 * await stream.write(Uint8Array.from([0, 1, 2, 3, 4]))
 * ```
 */
function byteStream(duplex, opts) {
    const write = queuelessPushable();
    duplex.sink(write).catch(async (err) => {
        await write.end(err);
    });
    duplex.sink = async (source) => {
        for await (const buf of source) {
            await write.push(buf);
        }
        await write.end();
    };
    let source = duplex.source;
    if (duplex.source[Symbol.iterator] != null) {
        source = duplex.source[Symbol.iterator]();
    }
    else if (duplex.source[Symbol.asyncIterator] != null) {
        source = duplex.source[Symbol.asyncIterator]();
    }
    const readBuffer = new Uint8ArrayList();
    const W = {
        read: async (options) => {
            options?.signal?.throwIfAborted();
            if (options?.bytes == null) {
                // just read whatever arrives
                const { done, value } = await raceSignal(source.next(), options?.signal);
                if (done === true) {
                    return null;
                }
                return value;
            }
            while (readBuffer.byteLength < options.bytes) {
                const { value, done } = await raceSignal(source.next(), options?.signal);
                if (done === true) {
                    throw new UnexpectedEOFError('unexpected end of input');
                }
                readBuffer.append(value);
            }
            const buf = readBuffer.sublist(0, options.bytes);
            readBuffer.consume(options.bytes);
            return buf;
        },
        write: async (data, options) => {
            options?.signal?.throwIfAborted();
            // just write
            if (data instanceof Uint8Array) {
                await write.push(data, options);
            }
            else {
                await write.push(data.subarray(), options);
            }
        },
        unwrap: () => {
            if (readBuffer.byteLength > 0) {
                const originalStream = duplex.source;
                duplex.source = (async function* () {
                    if (opts?.yieldBytes === false) {
                        yield readBuffer;
                    }
                    else {
                        yield* readBuffer;
                    }
                    yield* originalStream;
                }());
            }
            return duplex;
        }
    };
    return W;
}

/**
 * The reported length of the next data message was not a positive integer
 */
class InvalidMessageLengthError extends Error {
    name = 'InvalidMessageLengthError';
    code = 'ERR_INVALID_MSG_LENGTH';
}
/**
 * The reported length of the next data message was larger than the configured
 * max allowable value
 */
let InvalidDataLengthError$1 = class InvalidDataLengthError extends Error {
    name = 'InvalidDataLengthError';
    code = 'ERR_MSG_DATA_TOO_LONG';
};
/**
 * The varint used to specify the length of the next data message contained more
 * bytes than the configured max allowable value
 */
class InvalidDataLengthLengthError extends Error {
    name = 'InvalidDataLengthLengthError';
    code = 'ERR_MSG_LENGTH_TOO_LONG';
}

/**
 * @packageDocumentation
 *
 * This module makes it easy to send and receive length-prefixed byte arrays over streams.
 *
 * @example
 *
 * ```typescript
 * import { lpStream } from 'it-length-prefixed-stream'
 *
 * const stream = lpStream(duplex)
 *
 * // read the next length-prefixed chunk
 * const bytes = await stream.read()
 *
 * // write a length-prefixed chunk
 * await stream.write(Uint8Array.from([0, 1, 2, 3, 4]))
 *
 * // write several chunks, all individually length-prefixed
 * await stream.writeV([
 *   Uint8Array.from([0, 1, 2, 3, 4]),
 *   Uint8Array.from([5, 6, 7, 8, 9])
 * ])
 * ```
 */
function lpStream(duplex, opts = {}) {
    const bytes = byteStream(duplex, opts);
    if (opts.maxDataLength != null && opts.maxLengthLength == null) {
        // if max data length is set but max length length is not, calculate the
        // max length length needed to encode max data length
        opts.maxLengthLength = encodingLength$1(opts.maxDataLength);
    }
    const decodeLength = opts?.lengthDecoder ?? decode$8;
    const encodeLength = opts?.lengthEncoder ?? encode$8;
    const W = {
        read: async (options) => {
            let dataLength = -1;
            const lengthBuffer = new Uint8ArrayList();
            while (true) {
                // read one byte at a time until we can decode a varint
                lengthBuffer.append(await bytes.read({
                    ...options,
                    bytes: 1
                }));
                try {
                    dataLength = decodeLength(lengthBuffer);
                }
                catch (err) {
                    if (err instanceof RangeError) {
                        continue;
                    }
                    throw err;
                }
                if (dataLength < 0) {
                    throw new InvalidMessageLengthError('Invalid message length');
                }
                if (opts?.maxLengthLength != null && lengthBuffer.byteLength > opts.maxLengthLength) {
                    throw new InvalidDataLengthLengthError('message length length too long');
                }
                if (dataLength > -1) {
                    break;
                }
            }
            if (opts?.maxDataLength != null && dataLength > opts.maxDataLength) {
                throw new InvalidDataLengthError$1('message length too long');
            }
            return bytes.read({
                ...options,
                bytes: dataLength
            });
        },
        write: async (data, options) => {
            // encode, write
            await bytes.write(new Uint8ArrayList(encodeLength(data.byteLength), data), options);
        },
        writeV: async (data, options) => {
            const list = new Uint8ArrayList(...data.flatMap(buf => ([encodeLength(buf.byteLength), buf])));
            // encode, write
            await bytes.write(list, options);
        },
        unwrap: () => {
            return bytes.unwrap();
        }
    };
    return W;
}

/**
 * A pair of streams where one drains from the other
 */
function pair() {
    const deferred = pDefer();
    let piped = false;
    return {
        sink: async (source) => {
            if (piped) {
                throw new Error('already piped');
            }
            piped = true;
            deferred.resolve(source);
        },
        source: (async function* () {
            const source = await deferred.promise;
            yield* source;
        }())
    };
}

/**
 * Two duplex streams that are attached to each other
 */
function duplexPair() {
    const a = pair();
    const b = pair();
    return [
        {
            source: a.source,
            sink: b.sink
        },
        {
            source: b.source,
            sink: a.sink
        }
    ];
}

const NOISE_MSG_MAX_LENGTH_BYTES = 65535;
const NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG = NOISE_MSG_MAX_LENGTH_BYTES - 16;
const DUMP_SESSION_KEYS = Boolean(globalThis.process?.env?.DUMP_SESSION_KEYS);

/**
 * Utilities for hex, bytes, CSPRNG.
 * @module
 */
/*! noble-ciphers - MIT License (c) 2023 Paul Miller (paulmillr.com) */
/** Checks if something is Uint8Array. Be careful: nodejs Buffer will return true. */
function isBytes$2(a) {
    return a instanceof Uint8Array || (ArrayBuffer.isView(a) && a.constructor.name === 'Uint8Array');
}
/** Asserts something is boolean. */
function abool(b) {
    if (typeof b !== 'boolean')
        throw new Error(`boolean expected, not ${b}`);
}
/** Asserts something is positive integer. */
function anumber(n) {
    if (!Number.isSafeInteger(n) || n < 0)
        throw new Error('positive integer expected, got ' + n);
}
/** Asserts something is Uint8Array. */
function abytes$1(b, ...lengths) {
    if (!isBytes$2(b))
        throw new Error('Uint8Array expected');
    if (lengths.length > 0 && !lengths.includes(b.length))
        throw new Error('Uint8Array expected of length ' + lengths + ', got length=' + b.length);
}
/** Asserts a hash instance has not been destroyed / finished */
function aexists(instance, checkFinished = true) {
    if (instance.destroyed)
        throw new Error('Hash instance has been destroyed');
    if (checkFinished && instance.finished)
        throw new Error('Hash#digest() has already been called');
}
/** Asserts output is properly-sized byte array */
function aoutput(out, instance) {
    abytes$1(out);
    const min = instance.outputLen;
    if (out.length < min) {
        throw new Error('digestInto() expects output buffer of length at least ' + min);
    }
}
/** Cast u8 / u16 / u32 to u32. */
function u32(arr) {
    return new Uint32Array(arr.buffer, arr.byteOffset, Math.floor(arr.byteLength / 4));
}
/** Zeroize a byte array. Warning: JS provides no guarantees. */
function clean(...arrays) {
    for (let i = 0; i < arrays.length; i++) {
        arrays[i].fill(0);
    }
}
/** Create DataView of an array for easy byte-level manipulation. */
function createView(arr) {
    return new DataView(arr.buffer, arr.byteOffset, arr.byteLength);
}
/** Is current platform little-endian? Most are. Big-Endian platform: IBM */
const isLE = /* @__PURE__ */ (() => new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44)();
/**
 * Converts string to bytes using UTF8 encoding.
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
function utf8ToBytes(str) {
    if (typeof str !== 'string')
        throw new Error('string expected');
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
/**
 * Normalizes (non-hex) string or Uint8Array to Uint8Array.
 * Warning: when Uint8Array is passed, it would NOT get copied.
 * Keep in mind for future mutable operations.
 */
function toBytes(data) {
    if (typeof data === 'string')
        data = utf8ToBytes(data);
    else if (isBytes$2(data))
        data = copyBytes(data);
    else
        throw new Error('Uint8Array expected, got ' + typeof data);
    return data;
}
function checkOpts(defaults, opts) {
    if (opts == null || typeof opts !== 'object')
        throw new Error('options must be defined');
    const merged = Object.assign(defaults, opts);
    return merged;
}
/** Compares 2 uint8array-s in kinda constant time. */
function equalBytes(a, b) {
    if (a.length !== b.length)
        return false;
    let diff = 0;
    for (let i = 0; i < a.length; i++)
        diff |= a[i] ^ b[i];
    return diff === 0;
}
/**
 * Wraps a cipher: validates args, ensures encrypt() can only be called once.
 * @__NO_SIDE_EFFECTS__
 */
const wrapCipher = (params, constructor) => {
    function wrappedCipher(key, ...args) {
        // Validate key
        abytes$1(key);
        // Big-Endian hardware is rare. Just in case someone still decides to run ciphers:
        if (!isLE)
            throw new Error('Non little-endian hardware is not yet supported');
        // Validate nonce if nonceLength is present
        if (params.nonceLength !== undefined) {
            const nonce = args[0];
            if (!nonce)
                throw new Error('nonce / iv required');
            if (params.varSizeNonce)
                abytes$1(nonce);
            else
                abytes$1(nonce, params.nonceLength);
        }
        // Validate AAD if tagLength present
        const tagl = params.tagLength;
        if (tagl && args[1] !== undefined) {
            abytes$1(args[1]);
        }
        const cipher = constructor(key, ...args);
        const checkOutput = (fnLength, output) => {
            if (output !== undefined) {
                if (fnLength !== 2)
                    throw new Error('cipher output not supported');
                abytes$1(output);
            }
        };
        // Create wrapped cipher with validation and single-use encryption
        let called = false;
        const wrCipher = {
            encrypt(data, output) {
                if (called)
                    throw new Error('cannot encrypt() twice with same key + nonce');
                called = true;
                abytes$1(data);
                checkOutput(cipher.encrypt.length, output);
                return cipher.encrypt(data, output);
            },
            decrypt(data, output) {
                abytes$1(data);
                if (tagl && data.length < tagl)
                    throw new Error('invalid ciphertext length: smaller than tagLength=' + tagl);
                checkOutput(cipher.decrypt.length, output);
                return cipher.decrypt(data, output);
            },
        };
        return wrCipher;
    }
    Object.assign(wrappedCipher, params);
    return wrappedCipher;
};
/**
 * By default, returns u8a of length.
 * When out is available, it checks it for validity and uses it.
 */
function getOutput(expectedLength, out, onlyAligned = true) {
    if (out === undefined)
        return new Uint8Array(expectedLength);
    if (out.length !== expectedLength)
        throw new Error('invalid output length, expected ' + expectedLength + ', got: ' + out.length);
    if (onlyAligned && !isAligned32$1(out))
        throw new Error('invalid output, must be aligned');
    return out;
}
/** Polyfill for Safari 14. */
function setBigUint64(view, byteOffset, value, isLE) {
    if (typeof view.setBigUint64 === 'function')
        return view.setBigUint64(byteOffset, value, isLE);
    const _32n = BigInt(32);
    const _u32_max = BigInt(0xffffffff);
    const wh = Number((value >> _32n) & _u32_max);
    const wl = Number(value & _u32_max);
    const h = 4 ;
    const l = 0 ;
    view.setUint32(byteOffset + h, wh, isLE);
    view.setUint32(byteOffset + l, wl, isLE);
}
function u64Lengths(dataLength, aadLength, isLE) {
    abool(isLE);
    const num = new Uint8Array(16);
    const view = createView(num);
    setBigUint64(view, 0, BigInt(aadLength), isLE);
    setBigUint64(view, 8, BigInt(dataLength), isLE);
    return num;
}
// Is byte array aligned to 4 byte offset (u32)?
function isAligned32$1(bytes) {
    return bytes.byteOffset % 4 === 0;
}
// copy bytes to new u8a (aligned). Because Buffer.slice is broken.
function copyBytes(bytes) {
    return Uint8Array.from(bytes);
}

/**
 * Basic utils for ARX (add-rotate-xor) salsa and chacha ciphers.

RFC8439 requires multi-step cipher stream, where
authKey starts with counter: 0, actual msg with counter: 1.

For this, we need a way to re-use nonce / counter:

    const counter = new Uint8Array(4);
    chacha(..., counter, ...); // counter is now 1
    chacha(..., counter, ...); // counter is now 2

This is complicated:

- 32-bit counters are enough, no need for 64-bit: max ArrayBuffer size in JS is 4GB
- Original papers don't allow mutating counters
- Counter overflow is undefined [^1]
- Idea A: allow providing (nonce | counter) instead of just nonce, re-use it
- Caveat: Cannot be re-used through all cases:
- * chacha has (counter | nonce)
- * xchacha has (nonce16 | counter | nonce16)
- Idea B: separate nonce / counter and provide separate API for counter re-use
- Caveat: there are different counter sizes depending on an algorithm.
- salsa & chacha also differ in structures of key & sigma:
  salsa20:      s[0] | k(4) | s[1] | nonce(2) | ctr(2) | s[2] | k(4) | s[3]
  chacha:       s(4) | k(8) | ctr(1) | nonce(3)
  chacha20orig: s(4) | k(8) | ctr(2) | nonce(2)
- Idea C: helper method such as `setSalsaState(key, nonce, sigma, data)`
- Caveat: we can't re-use counter array

xchacha [^2] uses the subkey and remaining 8 byte nonce with ChaCha20 as normal
(prefixed by 4 NUL bytes, since [RFC8439] specifies a 12-byte nonce).

[^1]: https://mailarchive.ietf.org/arch/msg/cfrg/gsOnTJzcbgG6OqD8Sc0GO5aR_tU/
[^2]: https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-xchacha#appendix-A.2

 * @module
 */
// prettier-ignore
// We can't make top-level var depend on utils.utf8ToBytes
// because it's not present in all envs. Creating a similar fn here
const _utf8ToBytes = (str) => Uint8Array.from(str.split('').map((c) => c.charCodeAt(0)));
const sigma16 = _utf8ToBytes('expand 16-byte k');
const sigma32 = _utf8ToBytes('expand 32-byte k');
const sigma16_32 = u32(sigma16);
const sigma32_32 = u32(sigma32);
function rotl(a, b) {
    return (a << b) | (a >>> (32 - b));
}
// Is byte array aligned to 4 byte offset (u32)?
function isAligned32(b) {
    return b.byteOffset % 4 === 0;
}
// Salsa and Chacha block length is always 512-bit
const BLOCK_LEN = 64;
const BLOCK_LEN32 = 16;
// new Uint32Array([2**32])   // => Uint32Array(1) [ 0 ]
// new Uint32Array([2**32-1]) // => Uint32Array(1) [ 4294967295 ]
const MAX_COUNTER = 2 ** 32 - 1;
const U32_EMPTY = new Uint32Array();
function runCipher(core, sigma, key, nonce, data, output, counter, rounds) {
    const len = data.length;
    const block = new Uint8Array(BLOCK_LEN);
    const b32 = u32(block);
    // Make sure that buffers aligned to 4 bytes
    const isAligned = isAligned32(data) && isAligned32(output);
    const d32 = isAligned ? u32(data) : U32_EMPTY;
    const o32 = isAligned ? u32(output) : U32_EMPTY;
    for (let pos = 0; pos < len; counter++) {
        core(sigma, key, nonce, b32, counter, rounds);
        if (counter >= MAX_COUNTER)
            throw new Error('arx: counter overflow');
        const take = Math.min(BLOCK_LEN, len - pos);
        // aligned to 4 bytes
        if (isAligned && take === BLOCK_LEN) {
            const pos32 = pos / 4;
            if (pos % 4 !== 0)
                throw new Error('arx: invalid block position');
            for (let j = 0, posj; j < BLOCK_LEN32; j++) {
                posj = pos32 + j;
                o32[posj] = d32[posj] ^ b32[j];
            }
            pos += BLOCK_LEN;
            continue;
        }
        for (let j = 0, posj; j < take; j++) {
            posj = pos + j;
            output[posj] = data[posj] ^ block[j];
        }
        pos += take;
    }
}
/** Creates ARX-like (ChaCha, Salsa) cipher stream from core function. */
function createCipher(core, opts) {
    const { allowShortKeys, extendNonceFn, counterLength, counterRight, rounds } = checkOpts({ allowShortKeys: false, counterLength: 8, counterRight: false, rounds: 20 }, opts);
    if (typeof core !== 'function')
        throw new Error('core must be a function');
    anumber(counterLength);
    anumber(rounds);
    abool(counterRight);
    abool(allowShortKeys);
    return (key, nonce, data, output, counter = 0) => {
        abytes$1(key);
        abytes$1(nonce);
        abytes$1(data);
        const len = data.length;
        if (output === undefined)
            output = new Uint8Array(len);
        abytes$1(output);
        anumber(counter);
        if (counter < 0 || counter >= MAX_COUNTER)
            throw new Error('arx: counter overflow');
        if (output.length < len)
            throw new Error(`arx: output (${output.length}) is shorter than data (${len})`);
        const toClean = [];
        // Key & sigma
        // key=16 -> sigma16, k=key|key
        // key=32 -> sigma32, k=key
        let l = key.length;
        let k;
        let sigma;
        if (l === 32) {
            toClean.push((k = copyBytes(key)));
            sigma = sigma32_32;
        }
        else if (l === 16 && allowShortKeys) {
            k = new Uint8Array(32);
            k.set(key);
            k.set(key, 16);
            sigma = sigma16_32;
            toClean.push(k);
        }
        else {
            throw new Error(`arx: invalid 32-byte key, got length=${l}`);
        }
        // Nonce
        // salsa20:      8   (8-byte counter)
        // chacha20orig: 8   (8-byte counter)
        // chacha20:     12  (4-byte counter)
        // xsalsa20:     24  (16 -> hsalsa,  8 -> old nonce)
        // xchacha20:    24  (16 -> hchacha, 8 -> old nonce)
        // Align nonce to 4 bytes
        if (!isAligned32(nonce))
            toClean.push((nonce = copyBytes(nonce)));
        const k32 = u32(k);
        // hsalsa & hchacha: handle extended nonce
        if (extendNonceFn) {
            if (nonce.length !== 24)
                throw new Error(`arx: extended nonce must be 24 bytes`);
            extendNonceFn(sigma, k32, u32(nonce.subarray(0, 16)), k32);
            nonce = nonce.subarray(16);
        }
        // Handle nonce counter
        const nonceNcLen = 16 - counterLength;
        if (nonceNcLen !== nonce.length)
            throw new Error(`arx: nonce must be ${nonceNcLen} or 16 bytes`);
        // Pad counter when nonce is 64 bit
        if (nonceNcLen !== 12) {
            const nc = new Uint8Array(12);
            nc.set(nonce, counterRight ? 0 : 12 - nonce.length);
            nonce = nc;
            toClean.push(nonce);
        }
        const n32 = u32(nonce);
        runCipher(core, sigma, k32, n32, data, output, counter, rounds);
        clean(...toClean);
        return output;
    };
}

/**
 * Poly1305 ([PDF](https://cr.yp.to/mac/poly1305-20050329.pdf),
 * [wiki](https://en.wikipedia.org/wiki/Poly1305))
 * is a fast and parallel secret-key message-authentication code suitable for
 * a wide variety of applications. It was standardized in
 * [RFC 8439](https://datatracker.ietf.org/doc/html/rfc8439) and is now used in TLS 1.3.
 *
 * Polynomial MACs are not perfect for every situation:
 * they lack Random Key Robustness: the MAC can be forged, and can't be used in PAKE schemes.
 * See [invisible salamanders attack](https://keymaterial.net/2020/09/07/invisible-salamanders-in-aes-gcm-siv/).
 * To combat invisible salamanders, `hash(key)` can be included in ciphertext,
 * however, this would violate ciphertext indistinguishability:
 * an attacker would know which key was used - so `HKDF(key, i)`
 * could be used instead.
 *
 * Check out [original website](https://cr.yp.to/mac.html).
 * @module
 */
// Based on Public Domain poly1305-donna https://github.com/floodyberry/poly1305-donna
const u8to16 = (a, i) => (a[i++] & 0xff) | ((a[i++] & 0xff) << 8);
class Poly1305 {
    constructor(key) {
        this.blockLen = 16;
        this.outputLen = 16;
        this.buffer = new Uint8Array(16);
        this.r = new Uint16Array(10);
        this.h = new Uint16Array(10);
        this.pad = new Uint16Array(8);
        this.pos = 0;
        this.finished = false;
        key = toBytes(key);
        abytes$1(key, 32);
        const t0 = u8to16(key, 0);
        const t1 = u8to16(key, 2);
        const t2 = u8to16(key, 4);
        const t3 = u8to16(key, 6);
        const t4 = u8to16(key, 8);
        const t5 = u8to16(key, 10);
        const t6 = u8to16(key, 12);
        const t7 = u8to16(key, 14);
        // https://github.com/floodyberry/poly1305-donna/blob/e6ad6e091d30d7f4ec2d4f978be1fcfcbce72781/poly1305-donna-16.h#L47
        this.r[0] = t0 & 0x1fff;
        this.r[1] = ((t0 >>> 13) | (t1 << 3)) & 0x1fff;
        this.r[2] = ((t1 >>> 10) | (t2 << 6)) & 0x1f03;
        this.r[3] = ((t2 >>> 7) | (t3 << 9)) & 0x1fff;
        this.r[4] = ((t3 >>> 4) | (t4 << 12)) & 0x00ff;
        this.r[5] = (t4 >>> 1) & 0x1ffe;
        this.r[6] = ((t4 >>> 14) | (t5 << 2)) & 0x1fff;
        this.r[7] = ((t5 >>> 11) | (t6 << 5)) & 0x1f81;
        this.r[8] = ((t6 >>> 8) | (t7 << 8)) & 0x1fff;
        this.r[9] = (t7 >>> 5) & 0x007f;
        for (let i = 0; i < 8; i++)
            this.pad[i] = u8to16(key, 16 + 2 * i);
    }
    process(data, offset, isLast = false) {
        const hibit = isLast ? 0 : 1 << 11;
        const { h, r } = this;
        const r0 = r[0];
        const r1 = r[1];
        const r2 = r[2];
        const r3 = r[3];
        const r4 = r[4];
        const r5 = r[5];
        const r6 = r[6];
        const r7 = r[7];
        const r8 = r[8];
        const r9 = r[9];
        const t0 = u8to16(data, offset + 0);
        const t1 = u8to16(data, offset + 2);
        const t2 = u8to16(data, offset + 4);
        const t3 = u8to16(data, offset + 6);
        const t4 = u8to16(data, offset + 8);
        const t5 = u8to16(data, offset + 10);
        const t6 = u8to16(data, offset + 12);
        const t7 = u8to16(data, offset + 14);
        let h0 = h[0] + (t0 & 0x1fff);
        let h1 = h[1] + (((t0 >>> 13) | (t1 << 3)) & 0x1fff);
        let h2 = h[2] + (((t1 >>> 10) | (t2 << 6)) & 0x1fff);
        let h3 = h[3] + (((t2 >>> 7) | (t3 << 9)) & 0x1fff);
        let h4 = h[4] + (((t3 >>> 4) | (t4 << 12)) & 0x1fff);
        let h5 = h[5] + ((t4 >>> 1) & 0x1fff);
        let h6 = h[6] + (((t4 >>> 14) | (t5 << 2)) & 0x1fff);
        let h7 = h[7] + (((t5 >>> 11) | (t6 << 5)) & 0x1fff);
        let h8 = h[8] + (((t6 >>> 8) | (t7 << 8)) & 0x1fff);
        let h9 = h[9] + ((t7 >>> 5) | hibit);
        let c = 0;
        let d0 = c + h0 * r0 + h1 * (5 * r9) + h2 * (5 * r8) + h3 * (5 * r7) + h4 * (5 * r6);
        c = d0 >>> 13;
        d0 &= 0x1fff;
        d0 += h5 * (5 * r5) + h6 * (5 * r4) + h7 * (5 * r3) + h8 * (5 * r2) + h9 * (5 * r1);
        c += d0 >>> 13;
        d0 &= 0x1fff;
        let d1 = c + h0 * r1 + h1 * r0 + h2 * (5 * r9) + h3 * (5 * r8) + h4 * (5 * r7);
        c = d1 >>> 13;
        d1 &= 0x1fff;
        d1 += h5 * (5 * r6) + h6 * (5 * r5) + h7 * (5 * r4) + h8 * (5 * r3) + h9 * (5 * r2);
        c += d1 >>> 13;
        d1 &= 0x1fff;
        let d2 = c + h0 * r2 + h1 * r1 + h2 * r0 + h3 * (5 * r9) + h4 * (5 * r8);
        c = d2 >>> 13;
        d2 &= 0x1fff;
        d2 += h5 * (5 * r7) + h6 * (5 * r6) + h7 * (5 * r5) + h8 * (5 * r4) + h9 * (5 * r3);
        c += d2 >>> 13;
        d2 &= 0x1fff;
        let d3 = c + h0 * r3 + h1 * r2 + h2 * r1 + h3 * r0 + h4 * (5 * r9);
        c = d3 >>> 13;
        d3 &= 0x1fff;
        d3 += h5 * (5 * r8) + h6 * (5 * r7) + h7 * (5 * r6) + h8 * (5 * r5) + h9 * (5 * r4);
        c += d3 >>> 13;
        d3 &= 0x1fff;
        let d4 = c + h0 * r4 + h1 * r3 + h2 * r2 + h3 * r1 + h4 * r0;
        c = d4 >>> 13;
        d4 &= 0x1fff;
        d4 += h5 * (5 * r9) + h6 * (5 * r8) + h7 * (5 * r7) + h8 * (5 * r6) + h9 * (5 * r5);
        c += d4 >>> 13;
        d4 &= 0x1fff;
        let d5 = c + h0 * r5 + h1 * r4 + h2 * r3 + h3 * r2 + h4 * r1;
        c = d5 >>> 13;
        d5 &= 0x1fff;
        d5 += h5 * r0 + h6 * (5 * r9) + h7 * (5 * r8) + h8 * (5 * r7) + h9 * (5 * r6);
        c += d5 >>> 13;
        d5 &= 0x1fff;
        let d6 = c + h0 * r6 + h1 * r5 + h2 * r4 + h3 * r3 + h4 * r2;
        c = d6 >>> 13;
        d6 &= 0x1fff;
        d6 += h5 * r1 + h6 * r0 + h7 * (5 * r9) + h8 * (5 * r8) + h9 * (5 * r7);
        c += d6 >>> 13;
        d6 &= 0x1fff;
        let d7 = c + h0 * r7 + h1 * r6 + h2 * r5 + h3 * r4 + h4 * r3;
        c = d7 >>> 13;
        d7 &= 0x1fff;
        d7 += h5 * r2 + h6 * r1 + h7 * r0 + h8 * (5 * r9) + h9 * (5 * r8);
        c += d7 >>> 13;
        d7 &= 0x1fff;
        let d8 = c + h0 * r8 + h1 * r7 + h2 * r6 + h3 * r5 + h4 * r4;
        c = d8 >>> 13;
        d8 &= 0x1fff;
        d8 += h5 * r3 + h6 * r2 + h7 * r1 + h8 * r0 + h9 * (5 * r9);
        c += d8 >>> 13;
        d8 &= 0x1fff;
        let d9 = c + h0 * r9 + h1 * r8 + h2 * r7 + h3 * r6 + h4 * r5;
        c = d9 >>> 13;
        d9 &= 0x1fff;
        d9 += h5 * r4 + h6 * r3 + h7 * r2 + h8 * r1 + h9 * r0;
        c += d9 >>> 13;
        d9 &= 0x1fff;
        c = ((c << 2) + c) | 0;
        c = (c + d0) | 0;
        d0 = c & 0x1fff;
        c = c >>> 13;
        d1 += c;
        h[0] = d0;
        h[1] = d1;
        h[2] = d2;
        h[3] = d3;
        h[4] = d4;
        h[5] = d5;
        h[6] = d6;
        h[7] = d7;
        h[8] = d8;
        h[9] = d9;
    }
    finalize() {
        const { h, pad } = this;
        const g = new Uint16Array(10);
        let c = h[1] >>> 13;
        h[1] &= 0x1fff;
        for (let i = 2; i < 10; i++) {
            h[i] += c;
            c = h[i] >>> 13;
            h[i] &= 0x1fff;
        }
        h[0] += c * 5;
        c = h[0] >>> 13;
        h[0] &= 0x1fff;
        h[1] += c;
        c = h[1] >>> 13;
        h[1] &= 0x1fff;
        h[2] += c;
        g[0] = h[0] + 5;
        c = g[0] >>> 13;
        g[0] &= 0x1fff;
        for (let i = 1; i < 10; i++) {
            g[i] = h[i] + c;
            c = g[i] >>> 13;
            g[i] &= 0x1fff;
        }
        g[9] -= 1 << 13;
        let mask = (c ^ 1) - 1;
        for (let i = 0; i < 10; i++)
            g[i] &= mask;
        mask = ~mask;
        for (let i = 0; i < 10; i++)
            h[i] = (h[i] & mask) | g[i];
        h[0] = (h[0] | (h[1] << 13)) & 0xffff;
        h[1] = ((h[1] >>> 3) | (h[2] << 10)) & 0xffff;
        h[2] = ((h[2] >>> 6) | (h[3] << 7)) & 0xffff;
        h[3] = ((h[3] >>> 9) | (h[4] << 4)) & 0xffff;
        h[4] = ((h[4] >>> 12) | (h[5] << 1) | (h[6] << 14)) & 0xffff;
        h[5] = ((h[6] >>> 2) | (h[7] << 11)) & 0xffff;
        h[6] = ((h[7] >>> 5) | (h[8] << 8)) & 0xffff;
        h[7] = ((h[8] >>> 8) | (h[9] << 5)) & 0xffff;
        let f = h[0] + pad[0];
        h[0] = f & 0xffff;
        for (let i = 1; i < 8; i++) {
            f = (((h[i] + pad[i]) | 0) + (f >>> 16)) | 0;
            h[i] = f & 0xffff;
        }
        clean(g);
    }
    update(data) {
        aexists(this);
        data = toBytes(data);
        abytes$1(data);
        const { buffer, blockLen } = this;
        const len = data.length;
        for (let pos = 0; pos < len;) {
            const take = Math.min(blockLen - this.pos, len - pos);
            // Fast path: we have at least one block in input
            if (take === blockLen) {
                for (; blockLen <= len - pos; pos += blockLen)
                    this.process(data, pos);
                continue;
            }
            buffer.set(data.subarray(pos, pos + take), this.pos);
            this.pos += take;
            pos += take;
            if (this.pos === blockLen) {
                this.process(buffer, 0, false);
                this.pos = 0;
            }
        }
        return this;
    }
    destroy() {
        clean(this.h, this.r, this.buffer, this.pad);
    }
    digestInto(out) {
        aexists(this);
        aoutput(out, this);
        this.finished = true;
        const { buffer, h } = this;
        let { pos } = this;
        if (pos) {
            buffer[pos++] = 1;
            for (; pos < 16; pos++)
                buffer[pos] = 0;
            this.process(buffer, 0, true);
        }
        this.finalize();
        let opos = 0;
        for (let i = 0; i < 8; i++) {
            out[opos++] = h[i] >>> 0;
            out[opos++] = h[i] >>> 8;
        }
        return out;
    }
    digest() {
        const { buffer, outputLen } = this;
        this.digestInto(buffer);
        const res = buffer.slice(0, outputLen);
        this.destroy();
        return res;
    }
}
function wrapConstructorWithKey(hashCons) {
    const hashC = (msg, key) => hashCons(key).update(toBytes(msg)).digest();
    const tmp = hashCons(new Uint8Array(32));
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = (key) => hashCons(key);
    return hashC;
}
/** Poly1305 MAC from RFC 8439. */
const poly1305 = wrapConstructorWithKey((key) => new Poly1305(key));

/**
 * [ChaCha20](https://cr.yp.to/chacha.html) stream cipher, released
 * in 2008. Developed after Salsa20, ChaCha aims to increase diffusion per round.
 * It was standardized in [RFC 8439](https://datatracker.ietf.org/doc/html/rfc8439) and
 * is now used in TLS 1.3.
 *
 * [XChaCha20](https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-xchacha)
 * extended-nonce variant is also provided. Similar to XSalsa, it's safe to use with
 * randomly-generated nonces.
 *
 * Check out [PDF](http://cr.yp.to/chacha/chacha-20080128.pdf) and
 * [wiki](https://en.wikipedia.org/wiki/Salsa20).
 * @module
 */
/**
 * ChaCha core function.
 */
// prettier-ignore
function chachaCore(s, k, n, out, cnt, rounds = 20) {
    let y00 = s[0], y01 = s[1], y02 = s[2], y03 = s[3], // "expa"   "nd 3"  "2-by"  "te k"
    y04 = k[0], y05 = k[1], y06 = k[2], y07 = k[3], // Key      Key     Key     Key
    y08 = k[4], y09 = k[5], y10 = k[6], y11 = k[7], // Key      Key     Key     Key
    y12 = cnt, y13 = n[0], y14 = n[1], y15 = n[2]; // Counter  Counter	Nonce   Nonce
    // Save state to temporary variables
    let x00 = y00, x01 = y01, x02 = y02, x03 = y03, x04 = y04, x05 = y05, x06 = y06, x07 = y07, x08 = y08, x09 = y09, x10 = y10, x11 = y11, x12 = y12, x13 = y13, x14 = y14, x15 = y15;
    for (let r = 0; r < rounds; r += 2) {
        x00 = (x00 + x04) | 0;
        x12 = rotl(x12 ^ x00, 16);
        x08 = (x08 + x12) | 0;
        x04 = rotl(x04 ^ x08, 12);
        x00 = (x00 + x04) | 0;
        x12 = rotl(x12 ^ x00, 8);
        x08 = (x08 + x12) | 0;
        x04 = rotl(x04 ^ x08, 7);
        x01 = (x01 + x05) | 0;
        x13 = rotl(x13 ^ x01, 16);
        x09 = (x09 + x13) | 0;
        x05 = rotl(x05 ^ x09, 12);
        x01 = (x01 + x05) | 0;
        x13 = rotl(x13 ^ x01, 8);
        x09 = (x09 + x13) | 0;
        x05 = rotl(x05 ^ x09, 7);
        x02 = (x02 + x06) | 0;
        x14 = rotl(x14 ^ x02, 16);
        x10 = (x10 + x14) | 0;
        x06 = rotl(x06 ^ x10, 12);
        x02 = (x02 + x06) | 0;
        x14 = rotl(x14 ^ x02, 8);
        x10 = (x10 + x14) | 0;
        x06 = rotl(x06 ^ x10, 7);
        x03 = (x03 + x07) | 0;
        x15 = rotl(x15 ^ x03, 16);
        x11 = (x11 + x15) | 0;
        x07 = rotl(x07 ^ x11, 12);
        x03 = (x03 + x07) | 0;
        x15 = rotl(x15 ^ x03, 8);
        x11 = (x11 + x15) | 0;
        x07 = rotl(x07 ^ x11, 7);
        x00 = (x00 + x05) | 0;
        x15 = rotl(x15 ^ x00, 16);
        x10 = (x10 + x15) | 0;
        x05 = rotl(x05 ^ x10, 12);
        x00 = (x00 + x05) | 0;
        x15 = rotl(x15 ^ x00, 8);
        x10 = (x10 + x15) | 0;
        x05 = rotl(x05 ^ x10, 7);
        x01 = (x01 + x06) | 0;
        x12 = rotl(x12 ^ x01, 16);
        x11 = (x11 + x12) | 0;
        x06 = rotl(x06 ^ x11, 12);
        x01 = (x01 + x06) | 0;
        x12 = rotl(x12 ^ x01, 8);
        x11 = (x11 + x12) | 0;
        x06 = rotl(x06 ^ x11, 7);
        x02 = (x02 + x07) | 0;
        x13 = rotl(x13 ^ x02, 16);
        x08 = (x08 + x13) | 0;
        x07 = rotl(x07 ^ x08, 12);
        x02 = (x02 + x07) | 0;
        x13 = rotl(x13 ^ x02, 8);
        x08 = (x08 + x13) | 0;
        x07 = rotl(x07 ^ x08, 7);
        x03 = (x03 + x04) | 0;
        x14 = rotl(x14 ^ x03, 16);
        x09 = (x09 + x14) | 0;
        x04 = rotl(x04 ^ x09, 12);
        x03 = (x03 + x04) | 0;
        x14 = rotl(x14 ^ x03, 8);
        x09 = (x09 + x14) | 0;
        x04 = rotl(x04 ^ x09, 7);
    }
    // Write output
    let oi = 0;
    out[oi++] = (y00 + x00) | 0;
    out[oi++] = (y01 + x01) | 0;
    out[oi++] = (y02 + x02) | 0;
    out[oi++] = (y03 + x03) | 0;
    out[oi++] = (y04 + x04) | 0;
    out[oi++] = (y05 + x05) | 0;
    out[oi++] = (y06 + x06) | 0;
    out[oi++] = (y07 + x07) | 0;
    out[oi++] = (y08 + x08) | 0;
    out[oi++] = (y09 + x09) | 0;
    out[oi++] = (y10 + x10) | 0;
    out[oi++] = (y11 + x11) | 0;
    out[oi++] = (y12 + x12) | 0;
    out[oi++] = (y13 + x13) | 0;
    out[oi++] = (y14 + x14) | 0;
    out[oi++] = (y15 + x15) | 0;
}
/**
 * ChaCha stream cipher. Conforms to RFC 8439 (IETF, TLS). 12-byte nonce, 4-byte counter.
 * With 12-byte nonce, it's not safe to use fill it with random (CSPRNG), due to collision chance.
 */
const chacha20 = /* @__PURE__ */ createCipher(chachaCore, {
    counterRight: false,
    counterLength: 4,
    allowShortKeys: false,
});
const ZEROS16 = /* @__PURE__ */ new Uint8Array(16);
// Pad to digest size with zeros
const updatePadded = (h, msg) => {
    h.update(msg);
    const left = msg.length % 16;
    if (left)
        h.update(ZEROS16.subarray(left));
};
const ZEROS32 = /* @__PURE__ */ new Uint8Array(32);
function computeTag(fn, key, nonce, data, AAD) {
    const authKey = fn(key, nonce, ZEROS32);
    const h = poly1305.create(authKey);
    if (AAD)
        updatePadded(h, AAD);
    updatePadded(h, data);
    const num = u64Lengths(data.length, AAD ? AAD.length : 0, true);
    h.update(num);
    const res = h.digest();
    clean(authKey, num);
    return res;
}
/**
 * AEAD algorithm from RFC 8439.
 * Salsa20 and chacha (RFC 8439) use poly1305 differently.
 * We could have composed them similar to:
 * https://github.com/paulmillr/scure-base/blob/b266c73dde977b1dd7ef40ef7a23cc15aab526b3/index.ts#L250
 * But it's hard because of authKey:
 * In salsa20, authKey changes position in salsa stream.
 * In chacha, authKey can't be computed inside computeTag, it modifies the counter.
 */
const _poly1305_aead = (xorStream) => (key, nonce, AAD) => {
    const tagLength = 16;
    return {
        encrypt(plaintext, output) {
            const plength = plaintext.length;
            output = getOutput(plength + tagLength, output, false);
            output.set(plaintext);
            const oPlain = output.subarray(0, -tagLength);
            xorStream(key, nonce, oPlain, oPlain, 1);
            const tag = computeTag(xorStream, key, nonce, oPlain, AAD);
            output.set(tag, plength); // append tag
            clean(tag);
            return output;
        },
        decrypt(ciphertext, output) {
            output = getOutput(ciphertext.length - tagLength, output, false);
            const data = ciphertext.subarray(0, -tagLength);
            const passedTag = ciphertext.subarray(-tagLength);
            const tag = computeTag(xorStream, key, nonce, data, AAD);
            if (!equalBytes(passedTag, tag))
                throw new Error('invalid tag');
            output.set(ciphertext.subarray(0, -tagLength));
            xorStream(key, nonce, output, output, 1); // start stream with i=1
            clean(tag);
            return output;
        },
    };
};
/**
 * ChaCha20-Poly1305 from RFC 8439.
 *
 * Unsafe to use random nonces under the same key, due to collision chance.
 * Prefer XChaCha instead.
 */
const chacha20poly1305 = /* @__PURE__ */ wrapCipher({ blockSize: 64, nonceLength: 12, tagLength: 16 }, _poly1305_aead(chacha20));

/**
 * HKDF (RFC 5869): extract + expand in one step.
 * See https://soatok.blog/2021/11/17/understanding-hkdf/.
 * @module
 */
/**
 * HKDF-extract from spec. Less important part. `HKDF-Extract(IKM, salt) -> PRK`
 * Arguments position differs from spec (IKM is first one, since it is not optional)
 * @param hash - hash function that would be used (e.g. sha256)
 * @param ikm - input keying material, the initial key
 * @param salt - optional salt value (a non-secret random value)
 */
function extract(hash, ikm, salt) {
    ahash(hash);
    // NOTE: some libraries treat zero-length array as 'not provided';
    // we don't, since we have undefined as 'not provided'
    // https://github.com/RustCrypto/KDFs/issues/15
    if (salt === undefined)
        salt = new Uint8Array(hash.outputLen);
    return hmac(hash, toBytes$1(salt), toBytes$1(ikm));
}
const HKDF_COUNTER = /* @__PURE__ */ Uint8Array.from([0]);
const EMPTY_BUFFER = /* @__PURE__ */ Uint8Array.of();
/**
 * HKDF-expand from the spec. The most important part. `HKDF-Expand(PRK, info, L) -> OKM`
 * @param hash - hash function that would be used (e.g. sha256)
 * @param prk - a pseudorandom key of at least HashLen octets (usually, the output from the extract step)
 * @param info - optional context and application specific information (can be a zero-length string)
 * @param length - length of output keying material in bytes
 */
function expand(hash, prk, info, length = 32) {
    ahash(hash);
    anumber$1(length);
    const olen = hash.outputLen;
    if (length > 255 * olen)
        throw new Error('Length should be <= 255*HashLen');
    const blocks = Math.ceil(length / olen);
    if (info === undefined)
        info = EMPTY_BUFFER;
    // first L(ength) octets of T
    const okm = new Uint8Array(blocks * olen);
    // Re-use HMAC instance between blocks
    const HMAC = hmac.create(hash, prk);
    const HMACTmp = HMAC._cloneInto();
    const T = new Uint8Array(HMAC.outputLen);
    for (let counter = 0; counter < blocks; counter++) {
        HKDF_COUNTER[0] = counter + 1;
        // T(0) = empty string (zero length)
        // T(N) = HMAC-Hash(PRK, T(N-1) | info | N)
        HMACTmp.update(counter === 0 ? EMPTY_BUFFER : T)
            .update(info)
            .update(HKDF_COUNTER)
            .digestInto(T);
        okm.set(T, olen * counter);
        HMAC._cloneInto(HMACTmp);
    }
    HMAC.destroy();
    HMACTmp.destroy();
    clean$1(T, HKDF_COUNTER);
    return okm.slice(0, length);
}

const pureJsCrypto = {
    hashSHA256(data) {
        return sha256(data.subarray());
    },
    getHKDF(ck, ikm) {
        const prk = extract(sha256, ikm, ck);
        const okmU8Array = expand(sha256, prk, undefined, 96);
        const okm = okmU8Array;
        const k1 = okm.subarray(0, 32);
        const k2 = okm.subarray(32, 64);
        const k3 = okm.subarray(64, 96);
        return [k1, k2, k3];
    },
    generateX25519KeyPair() {
        const secretKey = x25519.utils.randomPrivateKey();
        const publicKey = x25519.getPublicKey(secretKey);
        return {
            publicKey,
            privateKey: secretKey
        };
    },
    generateX25519KeyPairFromSeed(seed) {
        const publicKey = x25519.getPublicKey(seed);
        return {
            publicKey,
            privateKey: seed
        };
    },
    generateX25519SharedKey(privateKey, publicKey) {
        return x25519.getSharedSecret(privateKey.subarray(), publicKey.subarray());
    },
    chaCha20Poly1305Encrypt(plaintext, nonce, ad, k) {
        return chacha20poly1305(k, nonce, ad).encrypt(plaintext.subarray());
    },
    chaCha20Poly1305Decrypt(ciphertext, nonce, ad, k, dst) {
        return chacha20poly1305(k, nonce, ad).decrypt(ciphertext.subarray(), dst);
    }
};

const defaultCrypto = pureJsCrypto;

function wrapCrypto(crypto) {
    return {
        generateKeypair: crypto.generateX25519KeyPair,
        dh: (keypair, publicKey) => crypto.generateX25519SharedKey(keypair.privateKey, publicKey).subarray(0, 32),
        encrypt: crypto.chaCha20Poly1305Encrypt,
        decrypt: crypto.chaCha20Poly1305Decrypt,
        hash: crypto.hashSHA256,
        hkdf: crypto.getHKDF
    };
}

const uint16BEEncode = (value) => {
    const target = allocUnsafe(2);
    target[0] = value >> 8;
    target[1] = value;
    return target;
};
uint16BEEncode.bytes = 2;
const uint16BEDecode = (data) => {
    if (data.length < 2)
        throw RangeError('Could not decode int16BE');
    if (data instanceof Uint8Array) {
        let value = 0;
        value += data[0] << 8;
        value += data[1];
        return value;
    }
    return data.getUint16(0);
};
uint16BEDecode.bytes = 2;

function registerMetrics(metrics) {
    return {
        xxHandshakeSuccesses: metrics.registerCounter('libp2p_noise_xxhandshake_successes_total', {
            help: 'Total count of noise xxHandshakes successes_'
        }),
        xxHandshakeErrors: metrics.registerCounter('libp2p_noise_xxhandshake_error_total', {
            help: 'Total count of noise xxHandshakes errors'
        }),
        encryptedPackets: metrics.registerCounter('libp2p_noise_encrypted_packets_total', {
            help: 'Total count of noise encrypted packets successfully'
        }),
        decryptedPackets: metrics.registerCounter('libp2p_noise_decrypted_packets_total', {
            help: 'Total count of noise decrypted packets'
        }),
        decryptErrors: metrics.registerCounter('libp2p_noise_decrypt_errors_total', {
            help: 'Total count of noise decrypt errors'
        })
    };
}

function logLocalStaticKeys(s, keyLogger) {
    if (!keyLogger.enabled || !DUMP_SESSION_KEYS) {
        return;
    }
    if (s) {
        keyLogger(`LOCAL_STATIC_PUBLIC_KEY ${toString(s.publicKey, 'hex')}`);
        keyLogger(`LOCAL_STATIC_PRIVATE_KEY ${toString(s.privateKey, 'hex')}`);
    }
    else {
        keyLogger('Missing local static keys.');
    }
}
function logLocalEphemeralKeys(e, keyLogger) {
    if (!keyLogger.enabled || !DUMP_SESSION_KEYS) {
        return;
    }
    if (e) {
        keyLogger(`LOCAL_PUBLIC_EPHEMERAL_KEY ${toString(e.publicKey, 'hex')}`);
        keyLogger(`LOCAL_PRIVATE_EPHEMERAL_KEY ${toString(e.privateKey, 'hex')}`);
    }
    else {
        keyLogger('Missing local ephemeral keys.');
    }
}
function logRemoteStaticKey(rs, keyLogger) {
    if (!keyLogger.enabled || !DUMP_SESSION_KEYS) {
        return;
    }
    if (rs) {
        keyLogger(`REMOTE_STATIC_PUBLIC_KEY ${toString(rs.subarray(), 'hex')}`);
    }
    else {
        keyLogger('Missing remote static public key.');
    }
}
function logRemoteEphemeralKey(re, keyLogger) {
    if (!keyLogger.enabled || !DUMP_SESSION_KEYS) {
        return;
    }
    if (re) {
        keyLogger(`REMOTE_EPHEMERAL_PUBLIC_KEY ${toString(re.subarray(), 'hex')}`);
    }
    else {
        keyLogger('Missing remote ephemeral keys.');
    }
}
function logCipherState(cs1, cs2, keyLogger) {
    if (!keyLogger.enabled || !DUMP_SESSION_KEYS) {
        return;
    }
    keyLogger(`CIPHER_STATE_1 ${cs1.n.getUint64()} ${cs1.k && toString(cs1.k, 'hex')}`);
    keyLogger(`CIPHER_STATE_2 ${cs2.n.getUint64()} ${cs2.k && toString(cs2.k, 'hex')}`);
}

class InvalidCryptoExchangeError extends Error {
    code;
    constructor(message = 'Invalid crypto exchange') {
        super(message);
        this.code = InvalidCryptoExchangeError.code;
    }
    static code = 'ERR_INVALID_CRYPTO_EXCHANGE';
}

const MIN_NONCE = 0;
// For performance reasons, the nonce is represented as a JS `number`
// Although JS `number` can safely represent integers up to 2 ** 53 - 1, we choose to only use
// 4 bytes to store the data for performance reason.
// This is a slight deviation from the noise spec, which describes the max nonce as 2 ** 64 - 2
// The effect is that this implementation will need a new handshake to be performed after fewer messages are exchanged than other implementations with full uint64 nonces.
// this MAX_NONCE is still a large number of messages, so the practical effect of this is negligible.
const MAX_NONCE = 0xffffffff;
const ERR_MAX_NONCE = 'Cipherstate has reached maximum n, a new handshake must be performed';
/**
 * The nonce is an uint that's increased over time.
 * Maintaining different representations help improve performance.
 */
class Nonce {
    n;
    bytes;
    view;
    constructor(n = MIN_NONCE) {
        this.n = n;
        this.bytes = alloc$1(12);
        this.view = new DataView(this.bytes.buffer, this.bytes.byteOffset, this.bytes.byteLength);
        this.view.setUint32(4, n, true);
    }
    increment() {
        this.n++;
        // Even though we're treating the nonce as 8 bytes, RFC7539 specifies 12 bytes for a nonce.
        this.view.setUint32(4, this.n, true);
    }
    getBytes() {
        return this.bytes;
    }
    getUint64() {
        return this.n;
    }
    assertValue() {
        if (this.n > MAX_NONCE) {
            throw new Error(ERR_MAX_NONCE);
        }
    }
}

// Code in this file is a direct translation of a subset of the noise protocol https://noiseprotocol.org/noise.html,
// agnostic to libp2p's usage of noise
const ZEROLEN = alloc$1(0);
class CipherState {
    k;
    n;
    crypto;
    constructor(crypto, k = undefined, n = 0) {
        this.crypto = crypto;
        this.k = k;
        this.n = new Nonce(n);
    }
    hasKey() {
        return Boolean(this.k);
    }
    encryptWithAd(ad, plaintext) {
        if (!this.hasKey()) {
            return plaintext;
        }
        this.n.assertValue();
        const e = this.crypto.encrypt(plaintext, this.n.getBytes(), ad, this.k);
        this.n.increment();
        return e;
    }
    decryptWithAd(ad, ciphertext, dst) {
        if (!this.hasKey()) {
            return ciphertext;
        }
        this.n.assertValue();
        const plaintext = this.crypto.decrypt(ciphertext, this.n.getBytes(), ad, this.k, dst);
        this.n.increment();
        return plaintext;
    }
}
class SymmetricState {
    cs;
    ck;
    h;
    crypto;
    constructor(crypto, protocolName) {
        this.crypto = crypto;
        const protocolNameBytes = fromString(protocolName, 'utf-8');
        this.h = hashProtocolName(crypto, protocolNameBytes);
        this.ck = this.h;
        this.cs = new CipherState(crypto);
    }
    mixKey(ikm) {
        const [ck, tempK] = this.crypto.hkdf(this.ck, ikm);
        this.ck = ck;
        this.cs = new CipherState(this.crypto, tempK);
    }
    mixHash(data) {
        this.h = this.crypto.hash(new Uint8ArrayList(this.h, data));
    }
    encryptAndHash(plaintext) {
        const ciphertext = this.cs.encryptWithAd(this.h, plaintext);
        this.mixHash(ciphertext);
        return ciphertext;
    }
    decryptAndHash(ciphertext) {
        const plaintext = this.cs.decryptWithAd(this.h, ciphertext);
        this.mixHash(ciphertext);
        return plaintext;
    }
    split() {
        const [tempK1, tempK2] = this.crypto.hkdf(this.ck, ZEROLEN);
        return [new CipherState(this.crypto, tempK1), new CipherState(this.crypto, tempK2)];
    }
}
class AbstractHandshakeState {
    ss;
    s;
    e;
    rs;
    re;
    initiator;
    crypto;
    constructor(init) {
        const { crypto, protocolName, prologue, initiator, s, e, rs, re } = init;
        this.crypto = crypto;
        this.ss = new SymmetricState(crypto, protocolName);
        this.ss.mixHash(prologue);
        this.initiator = initiator;
        this.s = s;
        this.e = e;
        this.rs = rs;
        this.re = re;
    }
    writeE() {
        if (this.e) {
            throw new Error('ephemeral keypair is already set');
        }
        const e = this.crypto.generateKeypair();
        this.ss.mixHash(e.publicKey);
        this.e = e;
        return e.publicKey;
    }
    writeS() {
        if (!this.s) {
            throw new Error('static keypair is not set');
        }
        return this.ss.encryptAndHash(this.s.publicKey);
    }
    writeEE() {
        if (!this.e) {
            throw new Error('ephemeral keypair is not set');
        }
        if (!this.re) {
            throw new Error('remote ephemeral public key is not set');
        }
        this.ss.mixKey(this.crypto.dh(this.e, this.re));
    }
    writeES() {
        if (this.initiator) {
            if (!this.e) {
                throw new Error('ephemeral keypair is not set');
            }
            if (!this.rs) {
                throw new Error('remote static public key is not set');
            }
            this.ss.mixKey(this.crypto.dh(this.e, this.rs));
        }
        else {
            if (!this.s) {
                throw new Error('static keypair is not set');
            }
            if (!this.re) {
                throw new Error('remote ephemeral public key is not set');
            }
            this.ss.mixKey(this.crypto.dh(this.s, this.re));
        }
    }
    writeSE() {
        if (this.initiator) {
            if (!this.s) {
                throw new Error('static keypair is not set');
            }
            if (!this.re) {
                throw new Error('remote ephemeral public key is not set');
            }
            this.ss.mixKey(this.crypto.dh(this.s, this.re));
        }
        else {
            if (!this.e) {
                throw new Error('ephemeral keypair is not set');
            }
            if (!this.rs) {
                throw new Error('remote static public key is not set');
            }
            this.ss.mixKey(this.crypto.dh(this.e, this.rs));
        }
    }
    readE(message, offset = 0) {
        if (this.re) {
            throw new Error('remote ephemeral public key is already set');
        }
        if (message.byteLength < offset + 32) {
            throw new Error('message is not long enough');
        }
        this.re = message.sublist(offset, offset + 32);
        this.ss.mixHash(this.re);
    }
    readS(message, offset = 0) {
        if (this.rs) {
            throw new Error('remote static public key is already set');
        }
        const cipherLength = 32 + (this.ss.cs.hasKey() ? 16 : 0);
        if (message.byteLength < offset + cipherLength) {
            throw new Error('message is not long enough');
        }
        const temp = message.sublist(offset, offset + cipherLength);
        this.rs = this.ss.decryptAndHash(temp);
        return cipherLength;
    }
    readEE() {
        this.writeEE();
    }
    readES() {
        this.writeES();
    }
    readSE() {
        this.writeSE();
    }
}
/**
 * A IHandshakeState that's optimized for the XX pattern
 */
class XXHandshakeState extends AbstractHandshakeState {
    // e
    writeMessageA(payload) {
        return new Uint8ArrayList(this.writeE(), this.ss.encryptAndHash(payload));
    }
    // e, ee, s, es
    writeMessageB(payload) {
        const e = this.writeE();
        this.writeEE();
        const encS = this.writeS();
        this.writeES();
        return new Uint8ArrayList(e, encS, this.ss.encryptAndHash(payload));
    }
    // s, se
    writeMessageC(payload) {
        const encS = this.writeS();
        this.writeSE();
        return new Uint8ArrayList(encS, this.ss.encryptAndHash(payload));
    }
    // e
    readMessageA(message) {
        try {
            this.readE(message);
            return this.ss.decryptAndHash(message.sublist(32));
        }
        catch (e) {
            throw new InvalidCryptoExchangeError(`handshake stage 0 validation fail: ${e.message}`);
        }
    }
    // e, ee, s, es
    readMessageB(message) {
        try {
            this.readE(message);
            this.readEE();
            const consumed = this.readS(message, 32);
            this.readES();
            return this.ss.decryptAndHash(message.sublist(32 + consumed));
        }
        catch (e) {
            throw new InvalidCryptoExchangeError(`handshake stage 1 validation fail: ${e.message}`);
        }
    }
    // s, se
    readMessageC(message) {
        try {
            const consumed = this.readS(message);
            this.readSE();
            return this.ss.decryptAndHash(message.sublist(consumed));
        }
        catch (e) {
            throw new InvalidCryptoExchangeError(`handshake stage 2 validation fail: ${e.message}`);
        }
    }
}
function hashProtocolName(crypto, protocolName) {
    if (protocolName.length <= 32) {
        const h = alloc$1(32);
        h.set(protocolName);
        return h;
    }
    else {
        return crypto.hash(protocolName);
    }
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var NoiseExtensions;
(function (NoiseExtensions) {
    let _codec;
    NoiseExtensions.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.webtransportCerthashes != null) {
                    for (const value of obj.webtransportCerthashes) {
                        w.uint32(10);
                        w.bytes(value);
                    }
                }
                if (obj.streamMuxers != null) {
                    for (const value of obj.streamMuxers) {
                        w.uint32(18);
                        w.string(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    webtransportCerthashes: [],
                    streamMuxers: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            if (opts.limits?.webtransportCerthashes != null && obj.webtransportCerthashes.length === opts.limits.webtransportCerthashes) {
                                throw new MaxLengthError('Decode error - map field "webtransportCerthashes" had too many elements');
                            }
                            obj.webtransportCerthashes.push(reader.bytes());
                            break;
                        }
                        case 2: {
                            if (opts.limits?.streamMuxers != null && obj.streamMuxers.length === opts.limits.streamMuxers) {
                                throw new MaxLengthError('Decode error - map field "streamMuxers" had too many elements');
                            }
                            obj.streamMuxers.push(reader.string());
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    NoiseExtensions.encode = (obj) => {
        return encodeMessage(obj, NoiseExtensions.codec());
    };
    NoiseExtensions.decode = (buf, opts) => {
        return decodeMessage(buf, NoiseExtensions.codec(), opts);
    };
})(NoiseExtensions || (NoiseExtensions = {}));
var NoiseHandshakePayload;
(function (NoiseHandshakePayload) {
    let _codec;
    NoiseHandshakePayload.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.identityKey != null && obj.identityKey.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.identityKey);
                }
                if ((obj.identitySig != null && obj.identitySig.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.identitySig);
                }
                if (obj.extensions != null) {
                    w.uint32(34);
                    NoiseExtensions.codec().encode(obj.extensions, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    identityKey: alloc$1(0),
                    identitySig: alloc$1(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.identityKey = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.identitySig = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.extensions = NoiseExtensions.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.extensions
                            });
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    NoiseHandshakePayload.encode = (obj) => {
        return encodeMessage(obj, NoiseHandshakePayload.codec());
    };
    NoiseHandshakePayload.decode = (buf, opts) => {
        return decodeMessage(buf, NoiseHandshakePayload.codec(), opts);
    };
})(NoiseHandshakePayload || (NoiseHandshakePayload = {}));

async function createHandshakePayload(privateKey, staticPublicKey, extensions) {
    const identitySig = await privateKey.sign(getSignaturePayload(staticPublicKey));
    return NoiseHandshakePayload.encode({
        identityKey: publicKeyToProtobuf(privateKey.publicKey),
        identitySig,
        extensions
    });
}
async function decodeHandshakePayload(payloadBytes, remoteStaticKey, remoteIdentityKey) {
    try {
        const payload = NoiseHandshakePayload.decode(payloadBytes);
        const publicKey = publicKeyFromProtobuf(payload.identityKey);
        if (remoteIdentityKey?.equals(publicKey) === false) {
            throw new Error(`Payload identity key ${publicKey} does not match expected remote identity key ${remoteIdentityKey}`);
        }
        if (!remoteStaticKey) {
            throw new Error('Remote static does not exist');
        }
        const signaturePayload = getSignaturePayload(remoteStaticKey);
        if (!(await publicKey.verify(signaturePayload, payload.identitySig))) {
            throw new Error('Invalid payload signature');
        }
        return payload;
    }
    catch (e) {
        throw new UnexpectedPeerError(e.message);
    }
}
function getSignaturePayload(publicKey) {
    const prefix = fromString('noise-libp2p-static-key:');
    if (publicKey instanceof Uint8Array) {
        return concat([prefix, publicKey], prefix.length + publicKey.length);
    }
    publicKey.prepend(prefix);
    return publicKey;
}

async function performHandshakeInitiator(init, options) {
    const { log, connection, crypto, privateKey, prologue, s, remoteIdentityKey, extensions } = init;
    const payload = await createHandshakePayload(privateKey, s.publicKey, extensions);
    const xx = new XXHandshakeState({
        crypto,
        protocolName: 'Noise_XX_25519_ChaChaPoly_SHA256',
        initiator: true,
        prologue,
        s
    });
    logLocalStaticKeys(xx.s, log);
    log.trace('Stage 0 - Initiator starting to send first message.');
    await connection.write(xx.writeMessageA(ZEROLEN), options);
    log.trace('Stage 0 - Initiator finished sending first message.');
    logLocalEphemeralKeys(xx.e, log);
    log.trace('Stage 1 - Initiator waiting to receive first message from responder...');
    const plaintext = xx.readMessageB(await connection.read(options));
    log.trace('Stage 1 - Initiator received the message.');
    logRemoteEphemeralKey(xx.re, log);
    logRemoteStaticKey(xx.rs, log);
    log.trace("Initiator going to check remote's signature...");
    const receivedPayload = await decodeHandshakePayload(plaintext, xx.rs, remoteIdentityKey);
    log.trace('All good with the signature!');
    log.trace('Stage 2 - Initiator sending third handshake message.');
    await connection.write(xx.writeMessageC(payload), options);
    log.trace('Stage 2 - Initiator sent message with signed payload.');
    const [cs1, cs2] = xx.ss.split();
    logCipherState(cs1, cs2, log);
    return {
        payload: receivedPayload,
        encrypt: (plaintext) => cs1.encryptWithAd(ZEROLEN, plaintext),
        decrypt: (ciphertext, dst) => cs2.decryptWithAd(ZEROLEN, ciphertext, dst)
    };
}
async function performHandshakeResponder(init, options) {
    const { log, connection, crypto, privateKey, prologue, s, remoteIdentityKey, extensions } = init;
    const payload = await createHandshakePayload(privateKey, s.publicKey, extensions);
    const xx = new XXHandshakeState({
        crypto,
        protocolName: 'Noise_XX_25519_ChaChaPoly_SHA256',
        initiator: false,
        prologue,
        s
    });
    logLocalStaticKeys(xx.s, log);
    log.trace('Stage 0 - Responder waiting to receive first message.');
    xx.readMessageA(await connection.read(options));
    log.trace('Stage 0 - Responder received first message.');
    logRemoteEphemeralKey(xx.re, log);
    log.trace('Stage 1 - Responder sending out first message with signed payload and static key.');
    await connection.write(xx.writeMessageB(payload), options);
    log.trace('Stage 1 - Responder sent the second handshake message with signed payload.');
    logLocalEphemeralKeys(xx.e, log);
    log.trace('Stage 2 - Responder waiting for third handshake message...');
    const plaintext = xx.readMessageC(await connection.read(options));
    log.trace('Stage 2 - Responder received the message, finished handshake.');
    const receivedPayload = await decodeHandshakePayload(plaintext, xx.rs, remoteIdentityKey);
    const [cs1, cs2] = xx.ss.split();
    logCipherState(cs1, cs2, log);
    return {
        payload: receivedPayload,
        encrypt: (plaintext) => cs2.encryptWithAd(ZEROLEN, plaintext),
        decrypt: (ciphertext, dst) => cs1.decryptWithAd(ZEROLEN, ciphertext, dst)
    };
}

const CHACHA_TAG_LENGTH = 16;
// Returns generator that encrypts payload from the user
function encryptStream(handshake, metrics) {
    return async function* (source) {
        for await (const chunk of source) {
            for (let i = 0; i < chunk.length; i += NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG) {
                let end = i + NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG;
                if (end > chunk.length) {
                    end = chunk.length;
                }
                let data;
                if (chunk instanceof Uint8Array) {
                    data = handshake.encrypt(chunk.subarray(i, end));
                }
                else {
                    data = handshake.encrypt(chunk.sublist(i, end));
                }
                metrics?.encryptedPackets.increment();
                yield new Uint8ArrayList(uint16BEEncode(data.byteLength), data);
            }
        }
    };
}
// Decrypt received payload to the user
function decryptStream(handshake, metrics) {
    return async function* (source) {
        for await (const chunk of source) {
            for (let i = 0; i < chunk.length; i += NOISE_MSG_MAX_LENGTH_BYTES) {
                let end = i + NOISE_MSG_MAX_LENGTH_BYTES;
                if (end > chunk.length) {
                    end = chunk.length;
                }
                if (end - CHACHA_TAG_LENGTH < i) {
                    throw new Error('Invalid chunk');
                }
                const encrypted = chunk.sublist(i, end);
                // memory allocation is not cheap so reuse the encrypted Uint8Array
                // see https://github.com/ChainSafe/js-libp2p-noise/pull/242#issue-1422126164
                // this is ok because chacha20 reads bytes one by one and don't reread after that
                // it's also tested in https://github.com/ChainSafe/as-chacha20poly1305/pull/1/files#diff-25252846b58979dcaf4e41d47b3eadd7e4f335e7fb98da6c049b1f9cd011f381R48
                const dst = chunk.subarray(i, end - CHACHA_TAG_LENGTH);
                try {
                    const plaintext = handshake.decrypt(encrypted, dst);
                    metrics?.decryptedPackets.increment();
                    yield plaintext;
                }
                catch (e) {
                    metrics?.decryptErrors.increment();
                    throw e;
                }
            }
        }
    };
}

class Noise {
    protocol = '/noise';
    crypto;
    prologue;
    staticKey;
    extensions;
    metrics;
    components;
    constructor(components, init = {}) {
        const { staticNoiseKey, extensions, crypto, prologueBytes } = init;
        const { metrics } = components;
        this.components = components;
        const _crypto = crypto ?? defaultCrypto;
        this.crypto = wrapCrypto(_crypto);
        this.extensions = {
            webtransportCerthashes: [],
            ...extensions
        };
        this.metrics = metrics ? registerMetrics(metrics) : undefined;
        if (staticNoiseKey) {
            // accepts x25519 private key of length 32
            this.staticKey = _crypto.generateX25519KeyPairFromSeed(staticNoiseKey);
        }
        else {
            this.staticKey = _crypto.generateX25519KeyPair();
        }
        this.prologue = prologueBytes ?? alloc$1(0);
    }
    [Symbol.toStringTag] = '@chainsafe/libp2p-noise';
    [serviceCapabilities] = [
        '@libp2p/connection-encryption',
        '@chainsafe/libp2p-noise'
    ];
    /**
     * Encrypt outgoing data to the remote party (handshake as initiator)
     *
     * @param connection - streaming iterable duplex that will be encrypted
     * @param options
     * @param options.remotePeer - PeerId of the remote peer. Used to validate the integrity of the remote peer
     * @param options.signal - Used to abort the operation
     */
    async secureOutbound(connection, options) {
        const wrappedConnection = lpStream(connection, {
            lengthEncoder: uint16BEEncode,
            lengthDecoder: uint16BEDecode,
            maxDataLength: NOISE_MSG_MAX_LENGTH_BYTES
        });
        const handshake = await this.performHandshakeInitiator(wrappedConnection, this.components.privateKey, options?.remotePeer?.publicKey, options);
        const conn = await this.createSecureConnection(wrappedConnection, handshake);
        connection.source = conn.source;
        connection.sink = conn.sink;
        const publicKey = publicKeyFromProtobuf(handshake.payload.identityKey);
        return {
            conn: connection,
            remoteExtensions: handshake.payload.extensions,
            remotePeer: peerIdFromPublicKey(publicKey),
            streamMuxer: options?.skipStreamMuxerNegotiation === true ? undefined : this.getStreamMuxer(handshake.payload.extensions?.streamMuxers)
        };
    }
    getStreamMuxer(protocols) {
        if (protocols == null || protocols.length === 0) {
            return;
        }
        const streamMuxers = this.components.upgrader.getStreamMuxers();
        if (streamMuxers != null) {
            for (const protocol of protocols) {
                const streamMuxer = streamMuxers.get(protocol);
                if (streamMuxer != null) {
                    return streamMuxer;
                }
            }
        }
        if (protocols.length) {
            throw new InvalidCryptoExchangeError$1('Early muxer negotiation was requested but the initiator and responder had no common muxers');
        }
    }
    /**
     * Decrypt incoming data (handshake as responder).
     *
     * @param connection - streaming iterable duplex that will be encrypted
     * @param options
     * @param options.remotePeer - PeerId of the remote peer. Used to validate the integrity of the remote peer
     * @param options.signal - Used to abort the operation
     */
    async secureInbound(connection, options) {
        const wrappedConnection = lpStream(connection, {
            lengthEncoder: uint16BEEncode,
            lengthDecoder: uint16BEDecode,
            maxDataLength: NOISE_MSG_MAX_LENGTH_BYTES
        });
        const handshake = await this.performHandshakeResponder(wrappedConnection, this.components.privateKey, options?.remotePeer?.publicKey, options);
        const conn = await this.createSecureConnection(wrappedConnection, handshake);
        connection.source = conn.source;
        connection.sink = conn.sink;
        const publicKey = publicKeyFromProtobuf(handshake.payload.identityKey);
        return {
            conn: connection,
            remoteExtensions: handshake.payload.extensions,
            remotePeer: peerIdFromPublicKey(publicKey),
            streamMuxer: options?.skipStreamMuxerNegotiation === true ? undefined : this.getStreamMuxer(handshake.payload.extensions?.streamMuxers)
        };
    }
    /**
     * Perform XX handshake as initiator.
     */
    async performHandshakeInitiator(connection, 
    // TODO: pass private key in noise constructor via Components
    privateKey, remoteIdentityKey, options) {
        let result;
        const streamMuxers = options?.skipStreamMuxerNegotiation === true ? [] : [...this.components.upgrader.getStreamMuxers().keys()];
        try {
            result = await performHandshakeInitiator({
                connection,
                privateKey,
                remoteIdentityKey,
                log: this.components.logger.forComponent('libp2p:noise:xxhandshake'),
                crypto: this.crypto,
                prologue: this.prologue,
                s: this.staticKey,
                extensions: {
                    streamMuxers,
                    webtransportCerthashes: [],
                    ...this.extensions
                }
            }, options);
            this.metrics?.xxHandshakeSuccesses.increment();
        }
        catch (e) {
            this.metrics?.xxHandshakeErrors.increment();
            throw e;
        }
        return result;
    }
    /**
     * Perform XX handshake as responder.
     */
    async performHandshakeResponder(connection, privateKey, remoteIdentityKey, options) {
        let result;
        const streamMuxers = options?.skipStreamMuxerNegotiation === true ? [] : [...this.components.upgrader.getStreamMuxers().keys()];
        try {
            result = await performHandshakeResponder({
                connection,
                privateKey,
                remoteIdentityKey,
                log: this.components.logger.forComponent('libp2p:noise:xxhandshake'),
                crypto: this.crypto,
                prologue: this.prologue,
                s: this.staticKey,
                extensions: {
                    streamMuxers,
                    webtransportCerthashes: [],
                    ...this.extensions
                }
            }, options);
            this.metrics?.xxHandshakeSuccesses.increment();
        }
        catch (e) {
            this.metrics?.xxHandshakeErrors.increment();
            throw e;
        }
        return result;
    }
    async createSecureConnection(connection, handshake) {
        // Create encryption box/unbox wrapper
        const [secure, user] = duplexPair();
        const network = connection.unwrap();
        await pipe(secure, // write to wrapper
        encryptStream(handshake, this.metrics), // encrypt data + prefix with message length
        network, // send to the remote peer
        (source) => decode$1(source, { lengthDecoder: uint16BEDecode }), // read message length prefix
        decryptStream(handshake, this.metrics), // decrypt the incoming data
        secure // pipe to the wrapper
        );
        return user;
    }
}

/**
 * @packageDocumentation
 *
 * This repository contains TypeScript implementation of noise protocol, an encryption protocol used in libp2p.
 *
 * ## Usage
 *
 * Install with `yarn add @chainsafe/libp2p-noise` or `npm i @chainsafe/libp2p-noise`.
 *
 * Example of using default noise configuration and passing it to the libp2p config:
 *
 * ```ts
 * import {createLibp2p} from "libp2p"
 * import {noise} from "@chainsafe/libp2p-noise"
 *
 * //custom noise configuration, pass it instead of `noise()`
 * //x25519 private key
 * const n = noise({ staticNoiseKey });
 *
 * const libp2p = await createLibp2p({
 *   connectionEncrypters: [noise()],
 *   //... other options
 * })
 * ```
 *
 * See the [NoiseInit](https://github.com/ChainSafe/js-libp2p-noise/blob/master/src/noise.ts#L22-L30) interface for noise configuration options.
 *
 * ## API
 *
 * This module exposes an implementation of the [ConnectionEncrypter](https://libp2p.github.io/js-libp2p/interfaces/_libp2p_interface.ConnectionEncrypter.html) interface.
 *
 * ## Bring your own crypto
 *
 * You can provide a custom crypto implementation (instead of the default, based on [@noble](https://paulmillr.com/noble/)) by adding a `crypto` field to the init argument passed to the `Noise` factory.
 *
 * The implementation must conform to the `ICryptoInterface`, defined in <https://github.com/ChainSafe/js-libp2p-noise/blob/master/src/crypto.ts>
 */
function noise(init = {}) {
    return (components) => new Noise(components, init);
}

/*
 * Valid combinations
 */
const DNS4 = base('dns4');
const DNS6 = base('dns6');
const DNSADDR = base('dnsaddr');
const DNS$1 = or$1(base('dns'), DNSADDR, DNS4, DNS6);
const IP = or$1(base('ip4'), base('ip6'));
const TCP$1 = or$1(and$1(IP, base('tcp')), and$1(DNS$1, base('tcp')));
const UDP = and$1(IP, base('udp'));
const UTP = and$1(UDP, base('utp'));
const QUIC = and$1(UDP, base('quic'));
const QUICV1$1 = and$1(UDP, base('quic-v1'));
const _WebSockets$1 = or$1(and$1(TCP$1, base('ws')), and$1(DNS$1, base('ws')));
const WebSockets$2 = or$1(and$1(_WebSockets$1, base('p2p')), _WebSockets$1);
const _WebSocketsSecure$1 = or$1(and$1(TCP$1, base('wss')), and$1(DNS$1, base('wss')), and$1(TCP$1, base('tls'), base('ws')), and$1(DNS$1, base('tls'), base('ws')));
const WebSocketsSecure$1 = or$1(and$1(_WebSocketsSecure$1, base('p2p')), _WebSocketsSecure$1);
const HTTP = or$1(and$1(TCP$1, base('http')), and$1(IP, base('http')), and$1(DNS$1, base('http')));
const HTTPS = or$1(and$1(TCP$1, base('https')), and$1(IP, base('https')), and$1(DNS$1, base('https')));
const _WebRTCDirect$1 = and$1(UDP, base('webrtc-direct'), base('certhash'));
const WebRTCDirect$1 = or$1(and$1(_WebRTCDirect$1, base('p2p')), _WebRTCDirect$1);
const _WebTransport$1 = and$1(QUICV1$1, base('webtransport'), base('certhash'), base('certhash'));
const WebTransport$1 = or$1(and$1(_WebTransport$1, base('p2p')), _WebTransport$1);
/**
 * @deprecated
 */
const P2PWebRTCStar = or$1(and$1(WebSockets$2, base('p2p-webrtc-star'), base('p2p')), and$1(WebSocketsSecure$1, base('p2p-webrtc-star'), base('p2p')), and$1(WebSockets$2, base('p2p-webrtc-star')), and$1(WebSocketsSecure$1, base('p2p-webrtc-star')));
or$1(and$1(WebSockets$2, base('p2p-websocket-star'), base('p2p')), and$1(WebSocketsSecure$1, base('p2p-websocket-star'), base('p2p')), and$1(WebSockets$2, base('p2p-websocket-star')), and$1(WebSocketsSecure$1, base('p2p-websocket-star')));
/**
 * @deprecated
 */
const P2PWebRTCDirect = or$1(and$1(HTTP, base('p2p-webrtc-direct'), base('p2p')), and$1(HTTPS, base('p2p-webrtc-direct'), base('p2p')), and$1(HTTP, base('p2p-webrtc-direct')), and$1(HTTPS, base('p2p-webrtc-direct')));
const Reliable = or$1(_WebSockets$1, _WebSocketsSecure$1, HTTP, HTTPS, P2PWebRTCStar, P2PWebRTCDirect, TCP$1, UTP, QUIC, DNS$1, WebRTCDirect$1, WebTransport$1);
// Unlike ws-star, stardust can run over any transport thus removing the requirement for websockets (but don't even think about running a stardust server over webrtc-star ;) )
or$1(and$1(Reliable, base('p2p-stardust'), base('p2p')), and$1(Reliable, base('p2p-stardust')));
const _P2P$1 = or$1(and$1(Reliable, base('p2p')), P2PWebRTCStar, P2PWebRTCDirect, WebRTCDirect$1, WebTransport$1, base('p2p'));
const _Circuit$1 = or$1(and$1(_P2P$1, base('p2p-circuit'), _P2P$1), and$1(_P2P$1, base('p2p-circuit')), and$1(base('p2p-circuit'), _P2P$1), and$1(Reliable, base('p2p-circuit')), and$1(base('p2p-circuit'), Reliable), base('p2p-circuit'));
const CircuitRecursive = () => or$1(and$1(_Circuit$1, CircuitRecursive), _Circuit$1);
const Circuit$1 = CircuitRecursive();
const P2P = or$1(and$1(Circuit$1, _P2P$1, Circuit$1), and$1(_P2P$1, Circuit$1), and$1(Circuit$1, _P2P$1), Circuit$1, _P2P$1);
or$1(and$1(Circuit$1, base('webrtc'), base('p2p')), and$1(Circuit$1, base('webrtc')), and$1(Reliable, base('webrtc'), base('p2p')), and$1(Reliable, base('webrtc')), base('webrtc'));
/*
 * Validation funcs
 */
function makeMatchesFunction(partialMatch) {
    function matches(a) {
        let ma;
        try {
            ma = multiaddr(a);
        }
        catch (err) { // catch error
            return false; // also if it's invalid it's probably not matching as well so return false
        }
        const out = partialMatch(ma.protoNames());
        if (out === null) {
            return false;
        }
        if (out === true || out === false) {
            return out;
        }
        return out.length === 0;
    }
    return matches;
}
function and$1(...args) {
    function partialMatch(a) {
        if (a.length < args.length) {
            return null;
        }
        let out = a;
        args.some((arg) => {
            out = typeof arg === 'function'
                ? arg().partialMatch(a)
                : arg.partialMatch(a);
            if (Array.isArray(out)) {
                a = out;
            }
            if (out === null) {
                return true;
            }
            return false;
        });
        return out;
    }
    return {
        toString: function () { return '{ ' + args.join(' ') + ' }'; },
        input: args,
        matches: makeMatchesFunction(partialMatch),
        partialMatch
    };
}
function or$1(...args) {
    function partialMatch(a) {
        let out = null;
        args.some((arg) => {
            const res = typeof arg === 'function'
                ? arg().partialMatch(a)
                : arg.partialMatch(a);
            if (res != null) {
                out = res;
                return true;
            }
            return false;
        });
        return out;
    }
    const result = {
        toString: function () { return '{ ' + args.join(' ') + ' }'; },
        input: args,
        matches: makeMatchesFunction(partialMatch),
        partialMatch
    };
    return result;
}
function base(n) {
    const name = n;
    function matches(a) {
        let ma;
        try {
            ma = multiaddr(a);
        }
        catch (err) { // catch error
            return false; // also if it's invalid it's probably not matching as well so return false
        }
        const pnames = ma.protoNames();
        if (pnames.length === 1 && pnames[0] === name) {
            return true;
        }
        return false;
    }
    function partialMatch(protos) {
        if (protos.length === 0) {
            return null;
        }
        if (protos[0] === name) {
            return protos.slice(1);
        }
        return null;
    }
    return {
        toString: function () { return name; },
        matches,
        partialMatch
    };
}

/**
 * @packageDocumentation
 *
 * The configured bootstrap peers will be discovered after the configured timeout. This will ensure there are some peers in the peer store for the node to use to discover other peers.
 *
 * They will be tagged with a tag with the name `'bootstrap'` tag, the value `50` and it will expire after two minutes which means the nodes connections may be closed if the maximum number of connections is reached.
 *
 * Clients that need constant connections to bootstrap nodes (e.g. browsers) can set the TTL to `Infinity`.
 *
 * @example Configuring a list of bootstrap nodes
 *
 * ```TypeScript
 * import { createLibp2p } from 'libp2p'
 * import { bootstrap } from '@libp2p/bootstrap'
 *
 * const libp2p = await createLibp2p({
 *   peerDiscovery: [
 *     bootstrap({
 *       list: [
 *         // a list of bootstrap peer multiaddrs to connect to on node startup
 *         '/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ',
 *         '/dnsaddr/bootstrap.libp2p.io/ipfs/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN',
 *         '/dnsaddr/bootstrap.libp2p.io/ipfs/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa'
 *       ]
 *     })
 *   ]
 * })
 *
 * libp2p.addEventListener('peer:discovery', (evt) => {
 *   console.log('found peer: ', evt.detail.toString())
 * })
 * ```
 */
const DEFAULT_BOOTSTRAP_TAG_NAME$1 = 'bootstrap';
const DEFAULT_BOOTSTRAP_TAG_VALUE$1 = 50;
const DEFAULT_BOOTSTRAP_DISCOVERY_TIMEOUT = 1000;
/**
 * Emits 'peer' events on a regular interval for each peer in the provided list.
 */
class Bootstrap extends TypedEventEmitter {
    static tag = 'bootstrap';
    log;
    timer;
    list;
    timeout;
    components;
    _init;
    constructor(components, options = { list: [] }) {
        if (options.list == null || options.list.length === 0) {
            throw new Error('Bootstrap requires a list of peer addresses');
        }
        super();
        this.components = components;
        this.log = components.logger.forComponent('libp2p:bootstrap');
        this.timeout = options.timeout ?? DEFAULT_BOOTSTRAP_DISCOVERY_TIMEOUT;
        this.list = [];
        for (const candidate of options.list) {
            if (!P2P.matches(candidate)) {
                this.log.error('Invalid multiaddr');
                continue;
            }
            const ma = multiaddr(candidate);
            const peerIdStr = ma.getPeerId();
            if (peerIdStr == null) {
                this.log.error('Invalid bootstrap multiaddr without peer id');
                continue;
            }
            const peerData = {
                id: peerIdFromString$1(peerIdStr),
                multiaddrs: [ma]
            };
            this.list.push(peerData);
        }
        this._init = options;
    }
    [peerDiscoverySymbol] = this;
    [Symbol.toStringTag] = '@libp2p/bootstrap';
    [serviceCapabilities] = [
        '@libp2p/peer-discovery'
    ];
    isStarted() {
        return Boolean(this.timer);
    }
    /**
     * Start emitting events
     */
    start() {
        if (this.isStarted()) {
            return;
        }
        this.log('Starting bootstrap node discovery, discovering peers after %s ms', this.timeout);
        this.timer = setTimeout(() => {
            void this._discoverBootstrapPeers()
                .catch(err => {
                this.log.error(err);
            });
        }, this.timeout);
    }
    /**
     * Emit each address in the list as a PeerInfo
     */
    async _discoverBootstrapPeers() {
        if (this.timer == null) {
            return;
        }
        for (const peerData of this.list) {
            await this.components.peerStore.merge(peerData.id, {
                tags: {
                    [this._init.tagName ?? DEFAULT_BOOTSTRAP_TAG_NAME$1]: {
                        value: this._init.tagValue ?? DEFAULT_BOOTSTRAP_TAG_VALUE$1,
                        ttl: this._init.tagTTL
                    }
                },
                multiaddrs: peerData.multiaddrs
            });
            // check we are still running
            if (this.timer == null) {
                return;
            }
            this.safeDispatchEvent('peer', { detail: peerData });
            this.components.connectionManager.openConnection(peerData.id)
                .catch(err => {
                this.log.error('could not dial bootstrap peer %p', peerData.id, err);
            });
        }
    }
    /**
     * Stop emitting events
     */
    stop() {
        if (this.timer != null) {
            clearTimeout(this.timer);
        }
        this.timer = undefined;
    }
}
function bootstrap(init) {
    return (components) => new Bootstrap(components, init);
}

var Envelope;
(function (Envelope) {
    let _codec;
    Envelope.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.publicKey != null && obj.publicKey.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.publicKey);
                }
                if ((obj.payloadType != null && obj.payloadType.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.payloadType);
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.payload);
                }
                if ((obj.signature != null && obj.signature.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.signature);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    publicKey: alloc$1(0),
                    payloadType: alloc$1(0),
                    payload: alloc$1(0),
                    signature: alloc$1(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.publicKey = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.payloadType = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.signature = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Envelope.encode = (obj) => {
        return encodeMessage(obj, Envelope.codec());
    };
    Envelope.decode = (buf, opts) => {
        return decodeMessage(buf, Envelope.codec(), opts);
    };
})(Envelope || (Envelope = {}));

/**
 * The key in the record is not valid for the domain
 */
class InvalidSignatureError extends Error {
    constructor(message = 'Invalid signature') {
        super(message);
        this.name = 'InvalidSignatureError';
    }
}

class RecordEnvelope {
    /**
     * Unmarshal a serialized Envelope protobuf message
     */
    static createFromProtobuf = (data) => {
        const envelopeData = Envelope.decode(data);
        const publicKey = publicKeyFromProtobuf(envelopeData.publicKey);
        return new RecordEnvelope({
            publicKey,
            payloadType: envelopeData.payloadType,
            payload: envelopeData.payload,
            signature: envelopeData.signature
        });
    };
    /**
     * Seal marshals the given Record, places the marshaled bytes inside an Envelope
     * and signs it with the given peerId's private key
     */
    static seal = async (record, privateKey, options) => {
        if (privateKey == null) {
            throw new Error('Missing private key');
        }
        const domain = record.domain;
        const payloadType = record.codec;
        const payload = record.marshal();
        const signData = formatSignaturePayload(domain, payloadType, payload);
        const signature = await privateKey.sign(signData.subarray(), options);
        return new RecordEnvelope({
            publicKey: privateKey.publicKey,
            payloadType,
            payload,
            signature
        });
    };
    /**
     * Open and certify a given marshaled envelope.
     * Data is unmarshaled and the signature validated for the given domain.
     */
    static openAndCertify = async (data, domain, options) => {
        const envelope = RecordEnvelope.createFromProtobuf(data);
        const valid = await envelope.validate(domain, options);
        if (!valid) {
            throw new InvalidSignatureError('Envelope signature is not valid for the given domain');
        }
        return envelope;
    };
    publicKey;
    payloadType;
    payload;
    signature;
    marshaled;
    /**
     * The Envelope is responsible for keeping an arbitrary signed record
     * by a libp2p peer.
     */
    constructor(init) {
        const { publicKey, payloadType, payload, signature } = init;
        this.publicKey = publicKey;
        this.payloadType = payloadType;
        this.payload = payload;
        this.signature = signature;
    }
    /**
     * Marshal the envelope content
     */
    marshal() {
        if (this.marshaled == null) {
            this.marshaled = Envelope.encode({
                publicKey: publicKeyToProtobuf(this.publicKey),
                payloadType: this.payloadType,
                payload: this.payload.subarray(),
                signature: this.signature
            });
        }
        return this.marshaled;
    }
    /**
     * Verifies if the other Envelope is identical to this one
     */
    equals(other) {
        if (other == null) {
            return false;
        }
        return equals(this.marshal(), other.marshal());
    }
    /**
     * Validate envelope data signature for the given domain
     */
    async validate(domain, options) {
        const signData = formatSignaturePayload(domain, this.payloadType, this.payload);
        return this.publicKey.verify(signData.subarray(), this.signature, options);
    }
}
/**
 * Helper function that prepares a Uint8Array to sign or verify a signature
 */
const formatSignaturePayload = (domain, payloadType, payload) => {
    // When signing, a peer will prepare a Uint8Array by concatenating the following:
    // - The length of the domain separation string string in bytes
    // - The domain separation string, encoded as UTF-8
    // - The length of the payload_type field in bytes
    // - The value of the payload_type field
    // - The length of the payload field in bytes
    // - The value of the payload field
    const domainUint8Array = fromString(domain);
    const domainLength = encode$8(domainUint8Array.byteLength);
    const payloadTypeLength = encode$8(payloadType.length);
    const payloadLength = encode$8(payload.length);
    return new Uint8ArrayList(domainLength, domainUint8Array, payloadTypeLength, payloadType, payloadLength, payload);
};

/**
 * @packageDocumentation
 *
 * Provides strategies ensure arrays are equivalent.
 *
 * @example
 *
 * ```typescript
 * import { arrayEquals } from '@libp2p/utils/array-equals'
 * import { multiaddr } from '@multformats/multiaddr'
 *
 * const ma1 = multiaddr('/ip4/127.0.0.1/tcp/9000'),
 * const ma2 = multiaddr('/ip4/82.41.53.1/tcp/9000')
 *
 * console.info(arrayEquals([ma1], [ma1])) // true
 * console.info(arrayEquals([ma1], [ma2])) // false
 * ```
 */
/**
 * Verify if two arrays of non primitive types with the "equals" function are equal.
 * Compatible with multiaddr, peer-id and others.
 */
function arrayEquals(a, b) {
    const sort = (a, b) => a.toString().localeCompare(b.toString());
    if (a.length !== b.length) {
        return false;
    }
    b.sort(sort);
    return a.sort(sort).every((item, index) => b[index].equals(item));
}

// The domain string used for peer records contained in a Envelope.
const ENVELOPE_DOMAIN_PEER_RECORD = 'libp2p-peer-record';
// The type hint used to identify peer records in a Envelope.
// Defined in https://github.com/multiformats/multicodec/blob/master/table.csv
// with name "libp2p-peer-record"
const ENVELOPE_PAYLOAD_TYPE_PEER_RECORD = Uint8Array.from([3, 1]);

var PeerRecord$1;
(function (PeerRecord) {
    (function (AddressInfo) {
        let _codec;
        AddressInfo.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.multiaddr != null && obj.multiaddr.byteLength > 0)) {
                        w.uint32(10);
                        w.bytes(obj.multiaddr);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length, opts = {}) => {
                    const obj = {
                        multiaddr: alloc$1(0)
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1: {
                                obj.multiaddr = reader.bytes();
                                break;
                            }
                            default: {
                                reader.skipType(tag & 7);
                                break;
                            }
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        AddressInfo.encode = (obj) => {
            return encodeMessage(obj, AddressInfo.codec());
        };
        AddressInfo.decode = (buf, opts) => {
            return decodeMessage(buf, AddressInfo.codec(), opts);
        };
    })(PeerRecord.AddressInfo || (PeerRecord.AddressInfo = {}));
    let _codec;
    PeerRecord.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.peerId != null && obj.peerId.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.peerId);
                }
                if ((obj.seq != null && obj.seq !== 0n)) {
                    w.uint32(16);
                    w.uint64(obj.seq);
                }
                if (obj.addresses != null) {
                    for (const value of obj.addresses) {
                        w.uint32(26);
                        PeerRecord.AddressInfo.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    peerId: alloc$1(0),
                    seq: 0n,
                    addresses: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.peerId = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.seq = reader.uint64();
                            break;
                        }
                        case 3: {
                            if (opts.limits?.addresses != null && obj.addresses.length === opts.limits.addresses) {
                                throw new MaxLengthError('Decode error - map field "addresses" had too many elements');
                            }
                            obj.addresses.push(PeerRecord.AddressInfo.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.addresses$
                            }));
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerRecord.encode = (obj) => {
        return encodeMessage(obj, PeerRecord.codec());
    };
    PeerRecord.decode = (buf, opts) => {
        return decodeMessage(buf, PeerRecord.codec(), opts);
    };
})(PeerRecord$1 || (PeerRecord$1 = {}));

/**
 * The PeerRecord is used for distributing peer routing records across the network.
 * It contains the peer's reachable listen addresses.
 */
class PeerRecord {
    /**
     * Unmarshal Peer Record Protobuf
     */
    static createFromProtobuf = (buf) => {
        const peerRecord = PeerRecord$1.decode(buf);
        const peerId = peerIdFromMultihash(decode$3(peerRecord.peerId));
        const multiaddrs = (peerRecord.addresses ?? []).map((a) => multiaddr(a.multiaddr));
        const seqNumber = peerRecord.seq;
        return new PeerRecord({ peerId, multiaddrs, seqNumber });
    };
    static DOMAIN = ENVELOPE_DOMAIN_PEER_RECORD;
    static CODEC = ENVELOPE_PAYLOAD_TYPE_PEER_RECORD;
    peerId;
    multiaddrs;
    seqNumber;
    domain = PeerRecord.DOMAIN;
    codec = PeerRecord.CODEC;
    marshaled;
    constructor(init) {
        const { peerId, multiaddrs, seqNumber } = init;
        this.peerId = peerId;
        this.multiaddrs = multiaddrs ?? [];
        this.seqNumber = seqNumber ?? BigInt(Date.now());
    }
    /**
     * Marshal a record to be used in an envelope
     */
    marshal() {
        if (this.marshaled == null) {
            this.marshaled = PeerRecord$1.encode({
                peerId: this.peerId.toMultihash().bytes,
                seq: BigInt(this.seqNumber),
                addresses: this.multiaddrs.map((m) => ({
                    multiaddr: m.bytes
                }))
            });
        }
        return this.marshaled;
    }
    /**
     * Returns true if `this` record equals the `other`
     */
    equals(other) {
        if (!(other instanceof PeerRecord)) {
            return false;
        }
        // Validate PeerId
        if (!this.peerId.equals(other.peerId)) {
            return false;
        }
        // Validate seqNumber
        if (this.seqNumber !== other.seqNumber) {
            return false;
        }
        // Validate multiaddrs
        if (!arrayEquals(this.multiaddrs, other.multiaddrs)) {
            return false;
        }
        return true;
    }
}

/**
 * Returns a function wrapper that will only call the passed function once
 *
 * Important - the passed function should not throw or reject
 */
function debounce$1(func, wait) {
    let timeout;
    const output = function () {
        const later = function () {
            timeout = undefined;
            void func();
        };
        clearTimeout(timeout);
        timeout = setTimeout(later, wait);
    };
    output.start = () => { };
    output.stop = () => {
        clearTimeout(timeout);
    };
    return output;
}

/**
 * @packageDocumentation
 *
 * Mostly useful for tests or when you want to be explicit about consuming an iterable without doing anything with any yielded values.
 *
 * @example
 *
 * ```javascript
 * import drain from 'it-drain'
 *
 * // This can also be an iterator, generator, etc
 * const values = [0, 1, 2, 3, 4]
 *
 * drain(values)
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import drain from 'it-drain'
 *
 * const values = async function * {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * await drain(values())
 * ```
 */
function isAsyncIterable$4(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function drain(source) {
    if (isAsyncIterable$4(source)) {
        return (async () => {
            for await (const _ of source) { } // eslint-disable-line no-empty,@typescript-eslint/no-unused-vars
        })();
    }
    else {
        for (const _ of source) { } // eslint-disable-line no-empty,@typescript-eslint/no-unused-vars
    }
}

/**
 * @packageDocumentation
 *
 * Takes an (async) iterable that emits promise-returning functions, invokes them in parallel up to the concurrency limit and emits the results as they become available, optionally in the same order as the input
 *
 * @example
 *
 * ```javascript
 * import parallel from 'it-parallel'
 * import all from 'it-all'
 * import delay from 'delay'
 *
 * // This can also be an iterator, async iterator, generator, etc
 * const input = [
 *   async () => {
 *     console.info('start 1')
 *     await delay(500)
 *
 *     console.info('end 1')
 *     return 1
 *   },
 *   async () => {
 *     console.info('start 2')
 *     await delay(200)
 *
 *     console.info('end 2')
 *     return 2
 *   },
 *   async () => {
 *     console.info('start 3')
 *     await delay(100)
 *
 *     console.info('end 3')
 *     return 3
 *   }
 * ]
 *
 * const result = await all(parallel(input, {
 *   concurrency: 2
 * }))
 *
 * // output:
 * // start 1
 * // start 2
 * // end 2
 * // start 3
 * // end 3
 * // end 1
 *
 * console.info(result) // [2, 3, 1]
 * ```
 *
 * If order is important, pass `ordered: true` as an option:
 *
 * ```javascript
 * const result = await all(parallel(input, {
 *   concurrency: 2,
 *   ordered: true
 * }))
 *
 * // output:
 * // start 1
 * // start 2
 * // end 2
 * // start 3
 * // end 3
 * // end 1
 *
 * console.info(result) // [1, 2, 3]
 * ```
 */
const CustomEvent$1 = globalThis.CustomEvent ?? Event;
/**
 * Takes an (async) iterator that emits promise-returning functions,
 * invokes them in parallel and emits the results as they become available but
 * in the same order as the input
 */
async function* parallel(source, options = {}) {
    let concurrency = options.concurrency ?? Infinity;
    if (concurrency < 1) {
        concurrency = Infinity;
    }
    const ordered = options.ordered ?? false;
    const emitter = new EventTarget();
    const ops = [];
    let slotAvailable = pDefer();
    let resultAvailable = pDefer();
    let sourceFinished = false;
    let sourceErr;
    let opErred = false;
    emitter.addEventListener('task-complete', () => {
        resultAvailable.resolve();
    });
    void Promise.resolve().then(async () => {
        try {
            for await (const task of source) {
                if (ops.length === concurrency) {
                    slotAvailable = pDefer();
                    await slotAvailable.promise;
                }
                if (opErred) {
                    break;
                }
                const op = {
                    done: false
                };
                ops.push(op);
                task()
                    .then(result => {
                    op.done = true;
                    op.ok = true;
                    op.value = result;
                    emitter.dispatchEvent(new CustomEvent$1('task-complete'));
                }, err => {
                    op.done = true;
                    op.err = err;
                    emitter.dispatchEvent(new CustomEvent$1('task-complete'));
                });
            }
            sourceFinished = true;
            emitter.dispatchEvent(new CustomEvent$1('task-complete'));
        }
        catch (err) {
            sourceErr = err;
            emitter.dispatchEvent(new CustomEvent$1('task-complete'));
        }
    });
    function valuesAvailable() {
        if (ordered) {
            return ops[0]?.done;
        }
        return Boolean(ops.find(op => op.done));
    }
    function* yieldOrderedValues() {
        while ((ops.length > 0) && ops[0].done) {
            const op = ops[0];
            ops.shift();
            if (op.ok) {
                yield op.value;
            }
            else {
                // allow the source to exit
                opErred = true;
                slotAvailable.resolve();
                throw op.err;
            }
            slotAvailable.resolve();
        }
    }
    function* yieldUnOrderedValues() {
        // more values can become available while we wait for `yield`
        // to return control to this function
        while (valuesAvailable()) {
            for (let i = 0; i < ops.length; i++) {
                if (ops[i].done) {
                    const op = ops[i];
                    ops.splice(i, 1);
                    i--;
                    if (op.ok) {
                        yield op.value;
                    }
                    else {
                        opErred = true;
                        slotAvailable.resolve();
                        throw op.err;
                    }
                    slotAvailable.resolve();
                }
            }
        }
    }
    while (true) {
        if (!valuesAvailable()) {
            resultAvailable = pDefer();
            await resultAvailable.promise;
        }
        if (sourceErr != null) {
            // the source threw an error, propagate it
            throw sourceErr;
        }
        if (ordered) {
            yield* yieldOrderedValues();
        }
        else {
            yield* yieldUnOrderedValues();
        }
        if (sourceErr != null) {
            // if the source yields an array that is `yield *`, it can throw while the
            // onward consumer is processing the array contents - make sure we
            // propagate the error
            // eslint-disable-next-line @typescript-eslint/only-throw-error
            throw sourceErr;
        }
        if (sourceFinished && ops.length === 0) {
            // not waiting for any results and no more tasks so we are done
            break;
        }
    }
}

/**
 * @packageDocumentation
 *
 * This module makes it easy to send and receive length-prefixed Protobuf encoded
 * messages over streams.
 *
 * @example
 *
 * ```typescript
 * import { pbStream } from 'it-protobuf-stream'
 * import { MessageType } from './src/my-message-type.js'
 *
 * // RequestType and ResponseType have been generate from `.proto` files and have
 * // `.encode` and `.decode` methods for serialization/deserialization
 *
 * const stream = pbStream(duplex)
 *
 * // write a message to the stream
 * stream.write({
 *   foo: 'bar'
 * }, MessageType)
 *
 * // read a message from the stream
 * const res = await stream.read(MessageType)
 * ```
 */
function pbStream(duplex, opts) {
    const lp = lpStream(duplex, opts);
    const W = {
        read: async (proto, options) => {
            // readLP, decode
            const value = await lp.read(options);
            return proto.decode(value);
        },
        write: async (message, proto, options) => {
            // encode, writeLP
            await lp.write(proto.encode(message), options);
        },
        writeV: async (messages, proto, options) => {
            // encode, writeLP
            await lp.writeV(messages.map(message => proto.encode(message)), options);
        },
        pb: (proto) => {
            return {
                read: async (options) => W.read(proto, options),
                write: async (d, options) => W.write(d, proto, options),
                writeV: async (d, options) => W.writeV(d, proto, options),
                unwrap: () => W
            };
        },
        unwrap: () => {
            return lp.unwrap();
        }
    };
    return W;
}

const IDENTIFY_PROTOCOL_VERSION = '0.1.0';
const MULTICODEC_IDENTIFY_PROTOCOL_NAME = 'id';
const MULTICODEC_IDENTIFY_PROTOCOL_VERSION = '1.0.0';
// https://github.com/libp2p/go-libp2p/blob/8d2e54e1637041d5cf4fac1e531287560bd1f4ac/p2p/protocol/identify/id.go#L52
const MAX_IDENTIFY_MESSAGE_SIZE = 1024 * 8;

var Identify$1;
(function (Identify) {
    let _codec;
    Identify.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.protocolVersion != null) {
                    w.uint32(42);
                    w.string(obj.protocolVersion);
                }
                if (obj.agentVersion != null) {
                    w.uint32(50);
                    w.string(obj.agentVersion);
                }
                if (obj.publicKey != null) {
                    w.uint32(10);
                    w.bytes(obj.publicKey);
                }
                if (obj.listenAddrs != null) {
                    for (const value of obj.listenAddrs) {
                        w.uint32(18);
                        w.bytes(value);
                    }
                }
                if (obj.observedAddr != null) {
                    w.uint32(34);
                    w.bytes(obj.observedAddr);
                }
                if (obj.protocols != null) {
                    for (const value of obj.protocols) {
                        w.uint32(26);
                        w.string(value);
                    }
                }
                if (obj.signedPeerRecord != null) {
                    w.uint32(66);
                    w.bytes(obj.signedPeerRecord);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    listenAddrs: [],
                    protocols: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 5: {
                            obj.protocolVersion = reader.string();
                            break;
                        }
                        case 6: {
                            obj.agentVersion = reader.string();
                            break;
                        }
                        case 1: {
                            obj.publicKey = reader.bytes();
                            break;
                        }
                        case 2: {
                            if (opts.limits?.listenAddrs != null && obj.listenAddrs.length === opts.limits.listenAddrs) {
                                throw new MaxLengthError('Decode error - map field "listenAddrs" had too many elements');
                            }
                            obj.listenAddrs.push(reader.bytes());
                            break;
                        }
                        case 4: {
                            obj.observedAddr = reader.bytes();
                            break;
                        }
                        case 3: {
                            if (opts.limits?.protocols != null && obj.protocols.length === opts.limits.protocols) {
                                throw new MaxLengthError('Decode error - map field "protocols" had too many elements');
                            }
                            obj.protocols.push(reader.string());
                            break;
                        }
                        case 8: {
                            obj.signedPeerRecord = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Identify.encode = (obj) => {
        return encodeMessage(obj, Identify.codec());
    };
    Identify.decode = (buf, opts) => {
        return decodeMessage(buf, Identify.codec(), opts);
    };
})(Identify$1 || (Identify$1 = {}));

const defaultValues$3 = {
    protocolPrefix: 'ipfs',
    timeout: 5000,
    maxInboundStreams: 1,
    maxOutboundStreams: 1,
    maxObservedAddresses: 10,
    maxMessageSize: MAX_IDENTIFY_MESSAGE_SIZE,
    runOnConnectionOpen: true,
    runOnLimitedConnection: true};
/**
 * Takes the `addr` and converts it to a Multiaddr if possible
 */
function getCleanMultiaddr(addr) {
    if (addr != null && addr.length > 0) {
        try {
            return multiaddr(addr);
        }
        catch {
        }
    }
}
function getAgentVersion(nodeInfo, agentVersion) {
    if (agentVersion != null) {
        return agentVersion;
    }
    return nodeInfo.userAgent;
}
async function consumeIdentifyMessage(peerStore, events, log, connection, message) {
    log('received identify from %p', connection.remotePeer);
    if (message == null) {
        throw new InvalidMessageError('message was null or undefined');
    }
    const peer = {};
    if (message.listenAddrs.length > 0) {
        peer.addresses = message.listenAddrs.map(buf => ({
            isCertified: false,
            multiaddr: multiaddr(buf)
        }));
    }
    if (message.protocols.length > 0) {
        peer.protocols = message.protocols;
    }
    if (message.publicKey != null) {
        const publicKey = publicKeyFromProtobuf(message.publicKey);
        const peerId = peerIdFromPublicKey(publicKey);
        if (!peerId.equals(connection.remotePeer)) {
            throw new InvalidMessageError('public key did not match remote PeerId');
        }
        peer.publicKey = publicKey;
    }
    let output;
    // if the peer record has been sent, prefer the addresses in the record as they are signed by the remote peer
    if (message.signedPeerRecord != null) {
        log.trace('received signedPeerRecord from %p', connection.remotePeer);
        let peerRecordEnvelope = message.signedPeerRecord;
        const envelope = await RecordEnvelope.openAndCertify(peerRecordEnvelope, PeerRecord.DOMAIN);
        let peerRecord = PeerRecord.createFromProtobuf(envelope.payload);
        const envelopePeer = peerIdFromCID(envelope.publicKey.toCID());
        // Verify peerId
        if (!peerRecord.peerId.equals(envelopePeer)) {
            throw new InvalidMessageError('signing key does not match PeerId in the PeerRecord');
        }
        // Make sure remote peer is the one sending the record
        if (!connection.remotePeer.equals(peerRecord.peerId)) {
            throw new InvalidMessageError('signing key does not match remote PeerId');
        }
        let existingPeer;
        try {
            existingPeer = await peerStore.get(peerRecord.peerId);
        }
        catch (err) {
            if (err.name !== 'NotFoundError') {
                throw err;
            }
        }
        if (existingPeer != null) {
            // don't lose any existing metadata
            peer.metadata = existingPeer.metadata;
            // if we have previously received a signed record for this peer, compare it to the incoming one
            if (existingPeer.peerRecordEnvelope != null) {
                const storedEnvelope = RecordEnvelope.createFromProtobuf(existingPeer.peerRecordEnvelope);
                const storedRecord = PeerRecord.createFromProtobuf(storedEnvelope.payload);
                // ensure seq is greater than, or equal to, the last received
                if (storedRecord.seqNumber >= peerRecord.seqNumber) {
                    log('sequence number was lower or equal to existing sequence number - stored: %d received: %d', storedRecord.seqNumber, peerRecord.seqNumber);
                    peerRecord = storedRecord;
                    peerRecordEnvelope = existingPeer.peerRecordEnvelope;
                }
            }
        }
        // store the signed record for next time
        peer.peerRecordEnvelope = peerRecordEnvelope;
        // override the stored addresses with the signed multiaddrs
        peer.addresses = peerRecord.multiaddrs.map(multiaddr => ({
            isCertified: true,
            multiaddr
        }));
        output = {
            seq: peerRecord.seqNumber,
            addresses: peerRecord.multiaddrs
        };
    }
    else {
        log('%p did not send a signed peer record', connection.remotePeer);
    }
    log.trace('patching %p with', connection.remotePeer, peer);
    await peerStore.patch(connection.remotePeer, peer);
    if (message.agentVersion != null || message.protocolVersion != null) {
        const metadata = {};
        if (message.agentVersion != null) {
            metadata.AgentVersion = fromString(message.agentVersion);
        }
        if (message.protocolVersion != null) {
            metadata.ProtocolVersion = fromString(message.protocolVersion);
        }
        log.trace('merging %p metadata', connection.remotePeer, metadata);
        await peerStore.merge(connection.remotePeer, {
            metadata
        });
    }
    const result = {
        peerId: connection.remotePeer,
        protocolVersion: message.protocolVersion,
        agentVersion: message.agentVersion,
        publicKey: message.publicKey,
        listenAddrs: message.listenAddrs.map(buf => multiaddr(buf)),
        observedAddr: message.observedAddr == null ? undefined : multiaddr(message.observedAddr),
        protocols: message.protocols,
        signedPeerRecord: output,
        connection
    };
    events.safeDispatchEvent('peer:identify', { detail: result });
    return result;
}
class AbstractIdentify {
    host;
    protocol;
    started;
    timeout;
    peerId;
    privateKey;
    peerStore;
    registrar;
    addressManager;
    maxInboundStreams;
    maxOutboundStreams;
    maxMessageSize;
    maxObservedAddresses;
    events;
    runOnLimitedConnection;
    log;
    constructor(components, init) {
        this.protocol = init.protocol;
        this.started = false;
        this.peerId = components.peerId;
        this.privateKey = components.privateKey;
        this.peerStore = components.peerStore;
        this.registrar = components.registrar;
        this.addressManager = components.addressManager;
        this.events = components.events;
        this.log = init.log;
        this.timeout = init.timeout ?? defaultValues$3.timeout;
        this.maxInboundStreams = init.maxInboundStreams ?? defaultValues$3.maxInboundStreams;
        this.maxOutboundStreams = init.maxOutboundStreams ?? defaultValues$3.maxOutboundStreams;
        this.maxMessageSize = init.maxMessageSize ?? defaultValues$3.maxMessageSize;
        this.maxObservedAddresses = init.maxObservedAddresses ?? defaultValues$3.maxObservedAddresses;
        this.runOnLimitedConnection = init.runOnLimitedConnection ?? defaultValues$3.runOnLimitedConnection;
        // Store self host metadata
        this.host = {
            protocolVersion: `${init.protocolPrefix ?? defaultValues$3.protocolPrefix}/${IDENTIFY_PROTOCOL_VERSION}`,
            agentVersion: getAgentVersion(components.nodeInfo, init.agentVersion)
        };
    }
    isStarted() {
        return this.started;
    }
    async start() {
        if (this.started) {
            return;
        }
        await this.peerStore.merge(this.peerId, {
            metadata: {
                AgentVersion: fromString(this.host.agentVersion),
                ProtocolVersion: fromString(this.host.protocolVersion)
            }
        });
        await this.registrar.handle(this.protocol, (data) => {
            void this.handleProtocol(data).catch(err => {
                this.log.error(err);
            });
        }, {
            maxInboundStreams: this.maxInboundStreams,
            maxOutboundStreams: this.maxOutboundStreams,
            runOnLimitedConnection: this.runOnLimitedConnection
        });
        this.started = true;
    }
    async stop() {
        await this.registrar.unhandle(this.protocol);
        this.started = false;
    }
}

/**
 * Check if a given multiaddr is an IPv6 global unicast address
 */
function isGlobalUnicast(ma) {
    try {
        for (const { code, value } of ma.getComponents()) {
            if (value == null) {
                continue;
            }
            if (code === CODE_IP6) {
                return cidrContains('2000::/3', value);
            }
        }
    }
    catch {
    }
    return false;
}

var Netmask_1;
// Generated by CoffeeScript 1.12.7
(function() {
  var Netmask, atob, chr, chr0, chrA, chra, ip2long, long2ip;

  long2ip = function(long) {
    var a, b, c, d;
    a = (long & (0xff << 24)) >>> 24;
    b = (long & (0xff << 16)) >>> 16;
    c = (long & (0xff << 8)) >>> 8;
    d = long & 0xff;
    return [a, b, c, d].join('.');
  };

  ip2long = function(ip) {
    var b, c, i, j, n, ref;
    b = [];
    for (i = j = 0; j <= 3; i = ++j) {
      if (ip.length === 0) {
        break;
      }
      if (i > 0) {
        if (ip[0] !== '.') {
          throw new Error('Invalid IP');
        }
        ip = ip.substring(1);
      }
      ref = atob(ip), n = ref[0], c = ref[1];
      ip = ip.substring(c);
      b.push(n);
    }
    if (ip.length !== 0) {
      throw new Error('Invalid IP');
    }
    switch (b.length) {
      case 1:
        if (b[0] > 0xFFFFFFFF) {
          throw new Error('Invalid IP');
        }
        return b[0] >>> 0;
      case 2:
        if (b[0] > 0xFF || b[1] > 0xFFFFFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1]) >>> 0;
      case 3:
        if (b[0] > 0xFF || b[1] > 0xFF || b[2] > 0xFFFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1] << 16 | b[2]) >>> 0;
      case 4:
        if (b[0] > 0xFF || b[1] > 0xFF || b[2] > 0xFF || b[3] > 0xFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1] << 16 | b[2] << 8 | b[3]) >>> 0;
      default:
        throw new Error('Invalid IP');
    }
  };

  chr = function(b) {
    return b.charCodeAt(0);
  };

  chr0 = chr('0');

  chra = chr('a');

  chrA = chr('A');

  atob = function(s) {
    var base, dmax, i, n, start;
    n = 0;
    base = 10;
    dmax = '9';
    i = 0;
    if (s.length > 1 && s[i] === '0') {
      if (s[i + 1] === 'x' || s[i + 1] === 'X') {
        i += 2;
        base = 16;
      } else if ('0' <= s[i + 1] && s[i + 1] <= '9') {
        i++;
        base = 8;
        dmax = '7';
      }
    }
    start = i;
    while (i < s.length) {
      if ('0' <= s[i] && s[i] <= dmax) {
        n = (n * base + (chr(s[i]) - chr0)) >>> 0;
      } else if (base === 16) {
        if ('a' <= s[i] && s[i] <= 'f') {
          n = (n * base + (10 + chr(s[i]) - chra)) >>> 0;
        } else if ('A' <= s[i] && s[i] <= 'F') {
          n = (n * base + (10 + chr(s[i]) - chrA)) >>> 0;
        } else {
          break;
        }
      } else {
        break;
      }
      if (n > 0xFFFFFFFF) {
        throw new Error('too large');
      }
      i++;
    }
    if (i === start) {
      throw new Error('empty octet');
    }
    return [n, i];
  };

  Netmask = (function() {
    function Netmask(net, mask) {
      var i, j, ref;
      if (typeof net !== 'string') {
        throw new Error("Missing `net' parameter");
      }
      if (!mask) {
        ref = net.split('/', 2), net = ref[0], mask = ref[1];
      }
      if (!mask) {
        mask = 32;
      }
      if (typeof mask === 'string' && mask.indexOf('.') > -1) {
        try {
          this.maskLong = ip2long(mask);
        } catch (error1) {
          throw new Error("Invalid mask: " + mask);
        }
        for (i = j = 32; j >= 0; i = --j) {
          if (this.maskLong === (0xffffffff << (32 - i)) >>> 0) {
            this.bitmask = i;
            break;
          }
        }
      } else if (mask || mask === 0) {
        this.bitmask = parseInt(mask, 10);
        this.maskLong = 0;
        if (this.bitmask > 0) {
          this.maskLong = (0xffffffff << (32 - this.bitmask)) >>> 0;
        }
      } else {
        throw new Error("Invalid mask: empty");
      }
      try {
        this.netLong = (ip2long(net) & this.maskLong) >>> 0;
      } catch (error1) {
        throw new Error("Invalid net address: " + net);
      }
      if (!(this.bitmask <= 32)) {
        throw new Error("Invalid mask for ip4: " + mask);
      }
      this.size = Math.pow(2, 32 - this.bitmask);
      this.base = long2ip(this.netLong);
      this.mask = long2ip(this.maskLong);
      this.hostmask = long2ip(~this.maskLong);
      this.first = this.bitmask <= 30 ? long2ip(this.netLong + 1) : this.base;
      this.last = this.bitmask <= 30 ? long2ip(this.netLong + this.size - 2) : long2ip(this.netLong + this.size - 1);
      this.broadcast = this.bitmask <= 30 ? long2ip(this.netLong + this.size - 1) : void 0;
    }

    Netmask.prototype.contains = function(ip) {
      if (typeof ip === 'string' && (ip.indexOf('/') > 0 || ip.split('.').length !== 4)) {
        ip = new Netmask(ip);
      }
      if (ip instanceof Netmask) {
        return this.contains(ip.base) && this.contains(ip.broadcast || ip.last);
      } else {
        return (ip2long(ip) & this.maskLong) >>> 0 === (this.netLong & this.maskLong) >>> 0;
      }
    };

    Netmask.prototype.next = function(count) {
      if (count == null) {
        count = 1;
      }
      return new Netmask(long2ip(this.netLong + (this.size * count)), this.mask);
    };

    Netmask.prototype.forEach = function(fn) {
      var index, lastLong, long;
      long = ip2long(this.first);
      lastLong = ip2long(this.last);
      index = 0;
      while (long <= lastLong) {
        fn(long2ip(long), long, index);
        index++;
        long++;
      }
    };

    Netmask.prototype.toString = function() {
      return this.base + "/" + this.bitmask;
    };

    return Netmask;

  })();

  Netmask_1 = Netmask;

}).call(commonjsGlobal);

const PRIVATE_IP_RANGES = [
    '0.0.0.0/8',
    '10.0.0.0/8',
    '100.64.0.0/10',
    '127.0.0.0/8',
    '169.254.0.0/16',
    '172.16.0.0/12',
    '192.0.0.0/24',
    '192.0.0.0/29',
    '192.0.0.8/32',
    '192.0.0.9/32',
    '192.0.0.10/32',
    '192.0.0.170/32',
    '192.0.0.171/32',
    '192.0.2.0/24',
    '192.31.196.0/24',
    '192.52.193.0/24',
    '192.88.99.0/24',
    '192.168.0.0/16',
    '192.175.48.0/24',
    '198.18.0.0/15',
    '198.51.100.0/24',
    '203.0.113.0/24',
    '240.0.0.0/4',
    '255.255.255.255/32'
];
const NETMASK_RANGES = PRIVATE_IP_RANGES.map(ipRange => new Netmask_1(ipRange));
function ipv4Check(ipAddr) {
    for (const r of NETMASK_RANGES) {
        if (r.contains(ipAddr)) {
            return true;
        }
    }
    return false;
}
function isIpv4MappedIpv6(ipAddr) {
    return /^::ffff:([0-9a-fA-F]{1,4}):([0-9a-fA-F]{1,4})$/.test(ipAddr);
}
/**
 * @see https://datatracker.ietf.org/doc/html/rfc4291#section-2.5.5.2
 */
function ipv4MappedIpv6Check(ipAddr) {
    const parts = ipAddr.split(':');
    if (parts.length < 2) {
        return false;
    }
    const octet34 = parts[parts.length - 1].padStart(4, '0');
    const octet12 = parts[parts.length - 2].padStart(4, '0');
    const ip4 = `${parseInt(octet12.substring(0, 2), 16)}.${parseInt(octet12.substring(2), 16)}.${parseInt(octet34.substring(0, 2), 16)}.${parseInt(octet34.substring(2), 16)}`;
    return ipv4Check(ip4);
}
/**
 * @see https://datatracker.ietf.org/doc/html/rfc4291#section-2.2 example 3
 */
function isIpv4EmbeddedIpv6(ipAddr) {
    return /^::ffff:([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/.test(ipAddr);
}
function ipv4EmbeddedIpv6Check(ipAddr) {
    const parts = ipAddr.split(':');
    const ip4 = parts[parts.length - 1];
    return ipv4Check(ip4);
}
function ipv6Check(ipAddr) {
    return /^::$/.test(ipAddr) ||
        /^::1$/.test(ipAddr) ||
        /^64:ff9b::([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/.test(ipAddr) ||
        /^100::([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||
        /^2001::([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||
        /^2001:2[0-9a-fA-F]:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||
        /^2001:db8:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||
        /^2002:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||
        /^f[c-d]([0-9a-fA-F]{2,2}):/i.test(ipAddr) ||
        /^fe[8-9a-bA-B][0-9a-fA-F]:/i.test(ipAddr) ||
        /^ff([0-9a-fA-F]{2,2}):/i.test(ipAddr);
}
function isPrivateIp(ip) {
    if (isIPv4(ip)) {
        return ipv4Check(ip);
    }
    if (isIpv4MappedIpv6(ip)) {
        return ipv4MappedIpv6Check(ip);
    }
    if (isIpv4EmbeddedIpv6(ip)) {
        return ipv4EmbeddedIpv6Check(ip);
    }
    if (isIPv6(ip)) {
        return ipv6Check(ip);
    }
}

/**
 * Check if a given multiaddr is IP-based
 */
function isIpBased(ma) {
    try {
        for (const { code } of ma.getComponents()) {
            if (code === CODE_IP6ZONE) {
                continue;
            }
            return code === CODE_IP4 || code === CODE_IP6;
        }
    }
    catch {
    }
    return false;
}

/**
 * Check if a given multiaddr starts with a private address
 */
function isPrivate(ma) {
    try {
        if (!isIpBased(ma)) {
            // not an IP based multiaddr, cannot be private
            return false;
        }
        const [[, value]] = ma.stringTuples();
        if (value == null) {
            return false;
        }
        return isPrivateIp(value) ?? false;
    }
    catch {
    }
    return true;
}

/**
 * Split a multiaddr into path components
 */
const toParts = (ma) => {
    return ma.toString().split('/').slice(1);
};
const func = (fn) => {
    return {
        match: (vals) => {
            if (vals.length < 1) {
                return false;
            }
            if (fn(vals[0])) {
                return vals.slice(1);
            }
            return false;
        },
        pattern: 'fn'
    };
};
const literal = (str) => {
    return {
        match: (vals) => func((val) => val === str).match(vals),
        pattern: str
    };
};
const string = () => {
    return {
        match: (vals) => func((val) => typeof val === 'string').match(vals),
        pattern: '{string}'
    };
};
const number = () => {
    return {
        match: (vals) => func((val) => !isNaN(parseInt(val))).match(vals),
        pattern: '{number}'
    };
};
const peerId = () => {
    return {
        match: (vals) => {
            if (vals.length < 2) {
                return false;
            }
            if (vals[0] !== 'p2p' && vals[0] !== 'ipfs') {
                return false;
            }
            // Q is RSA, 1 is Ed25519 or Secp256k1
            if (vals[1].startsWith('Q') || vals[1].startsWith('1')) {
                try {
                    base58btc.decode(`z${vals[1]}`);
                }
                catch (err) {
                    return false;
                }
            }
            else {
                return false;
            }
            return vals.slice(2);
        },
        pattern: '/p2p/{peerid}'
    };
};
const certhash = () => {
    return {
        match: (vals) => {
            if (vals.length < 2) {
                return false;
            }
            if (vals[0] !== 'certhash') {
                return false;
            }
            try {
                base64url.decode(vals[1]);
            }
            catch {
                return false;
            }
            return vals.slice(2);
        },
        pattern: '/certhash/{certhash}'
    };
};
const optional = (matcher) => {
    return {
        match: (vals) => {
            const result = matcher.match(vals);
            if (result === false) {
                return vals;
            }
            return result;
        },
        pattern: `optional(${matcher.pattern})`
    };
};
const or = (...matchers) => {
    return {
        match: (vals) => {
            let matches;
            for (const matcher of matchers) {
                const result = matcher.match(vals);
                // no match
                if (result === false) {
                    continue;
                }
                // choose greediest matcher
                if (matches == null || result.length < matches.length) {
                    matches = result;
                }
            }
            if (matches == null) {
                return false;
            }
            return matches;
        },
        pattern: `or(${matchers.map(m => m.pattern).join(', ')})`
    };
};
const and = (...matchers) => {
    return {
        match: (vals) => {
            for (const matcher of matchers) {
                // pass what's left of the array
                const result = matcher.match(vals);
                // no match
                if (result === false) {
                    return false;
                }
                vals = result;
            }
            return vals;
        },
        pattern: `and(${matchers.map(m => m.pattern).join(', ')})`
    };
};
function fmt(...matchers) {
    function match(ma) {
        let parts = toParts(ma);
        for (const matcher of matchers) {
            const result = matcher.match(parts);
            if (result === false) {
                return false;
            }
            parts = result;
        }
        return parts;
    }
    function matches(ma) {
        const result = match(ma);
        return result !== false;
    }
    function exactMatch(ma) {
        const result = match(ma);
        if (result === false) {
            return false;
        }
        return result.length === 0;
    }
    return {
        matchers,
        matches,
        exactMatch
    };
}

/**
 * @packageDocumentation
 *
 * This module exports various matchers that can be used to infer the type of a
 * passed multiaddr.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNS } from '@multiformats/multiaddr-matcher'
 *
 * const ma = multiaddr('/dnsaddr/example.org')
 *
 * DNS.matches(ma) // true - this is a multiaddr with a DNS address at the start
 * ```
 *
 * @example
 *
 * The default matching behaviour ignores any subsequent tuples in the multiaddr.
 * If you want stricter matching you can use `.exactMatch`:
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNS, Circuit } from '@multiformats/multiaddr-matcher'
 *
 * const ma = multiaddr('/dnsaddr/example.org/p2p/QmFoo/p2p-circuit/p2p/QmBar')
 *
 * DNS.exactMatch(ma) // false - this address has extra tuples after the DNS component
 * Circuit.matches(ma) // true
 * Circuit.exactMatch(ma) // true - the extra tuples are circuit relay related
 * ```
 */
/**
 * Matches PeerId addresses
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { PEER_ID } from '@multiformats/multiaddr-matcher'
 *
 * PEER_ID.matches(multiaddr('/p2p/Qmfoo')) // true
 * PEER_ID.matches(multiaddr('/ipfs/Qmfoo')) // true
 * ```
 */
const _PEER_ID = peerId();
const PEER_ID = fmt(_PEER_ID);
/**
 * DNS matchers
 */
const _DNS4 = and(literal('dns4'), string());
const _DNS6 = and(literal('dns6'), string());
const _DNSADDR = and(literal('dnsaddr'), string());
const _DNS = and(literal('dns'), string());
/**
 * Matches dns4 addresses.
 *
 * Use {@link DNS DNS} instead to match any type of DNS address.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNS4 } from '@multiformats/multiaddr-matcher'
 *
 * DNS4.matches(multiaddr('/dns4/example.org')) // true
 * ```
 */
fmt(_DNS4, optional(peerId()));
/**
 * Matches dns6 addresses.
 *
 * Use {@link DNS DNS} instead to match any type of DNS address.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNS6 } from '@multiformats/multiaddr-matcher'
 *
 * DNS6.matches(multiaddr('/dns6/example.org')) // true
 * ```
 */
fmt(_DNS6, optional(peerId()));
/**
 * Matches dnsaddr addresses.
 *
 * Use {@link DNS DNS} instead to match any type of DNS address.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNSADDR } from '@multiformats/multiaddr-matcher'
 *
 * DNSADDR.matches(multiaddr('/dnsaddr/example.org')) // true
 * DNSADDR.matches(multiaddr('/dnsaddr/example.org/p2p/Qmfoo')) // true
 * ```
 */
fmt(_DNSADDR, optional(peerId()));
/**
 * Matches any dns address.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNS } from '@multiformats/multiaddr-matcher'
 *
 * DNS.matches(multiaddr('/dnsaddr/example.org')) // true
 * DNS.matches(multiaddr('/dns4/example.org')) // true
 * DNS.matches(multiaddr('/dns6/example.org')) // true
 * DNS.matches(multiaddr('/dns6/example.org/p2p/Qmfoo')) // true
 * ```
 */
fmt(or(_DNS, _DNSADDR, _DNS4, _DNS6), optional(peerId()));
const _IP4 = and(literal('ip4'), func(isIPv4));
const _IP6 = and(literal('ip6'), func(isIPv6));
const _IP = or(_IP4, _IP6);
const _IP_OR_DOMAIN = or(_IP, _DNS, _DNS4, _DNS6, _DNSADDR);
/**
 * A matcher for addresses that start with IP or DNS tuples.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { IP_OR_DOMAIN } from '@multiformats/multiaddr-matcher'
 *
 * IP_OR_DOMAIN.matches(multiaddr('/ip4/123.123.123.123')) // true
 * IP_OR_DOMAIN.matches(multiaddr('/ip4/123.123.123.123/p2p/QmFoo')) // true
 * IP_OR_DOMAIN.matches(multiaddr('/dns/example.com/p2p/QmFoo')) // true
 * IP_OR_DOMAIN.matches(multiaddr('/p2p/QmFoo')) // false
 * ```
 */
const IP_OR_DOMAIN = fmt(or(_IP, and(or(_DNS, _DNSADDR, _DNS4, _DNS6), optional(peerId()))));
/**
 * Matches ip4 addresses.
 *
 * Use {@link IP IP} instead to match any ip4/ip6 address.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { IP4 } from '@multiformats/multiaddr-matcher'
 *
 * const ma = multiaddr('/ip4/123.123.123.123')
 *
 * IP4.matches(ma) // true
 * ```
 */
const IP4 = fmt(_IP4);
/**
 * Matches ip6 addresses.
 *
 * Use {@link IP IP} instead to match any ip4/ip6 address.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { IP6 } from '@multiformats/multiaddr-matcher'
 *
 * const ma = multiaddr('/ip6/fe80::1cc1:a3b8:322f:cf22')
 *
 * IP6.matches(ma) // true
 * ```
 */
const IP6 = fmt(_IP6);
/**
 * Matches ip4 or ip6 addresses.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { IP } from '@multiformats/multiaddr-matcher'
 *
 * IP.matches(multiaddr('/ip4/123.123.123.123')) // true
 * IP.matches(multiaddr('/ip6/fe80::1cc1:a3b8:322f:cf22')) // true
 * ```
 */
fmt(_IP);
const _TCP = and(_IP_OR_DOMAIN, literal('tcp'), number());
const _UDP = and(_IP_OR_DOMAIN, literal('udp'), number());
/**
 * Matches TCP addresses.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { TCP } from '@multiformats/multiaddr-matcher'
 *
 * TCP.matches(multiaddr('/ip4/123.123.123.123/tcp/1234')) // true
 * ```
 */
const TCP = fmt(and(_TCP, optional(peerId())));
/**
 * Matches UDP addresses.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { UDP } from '@multiformats/multiaddr-matcher'
 *
 * UDP.matches(multiaddr('/ip4/123.123.123.123/udp/1234')) // true
 * ```
 */
fmt(_UDP);
const _QUIC = and(_UDP, literal('quic'), optional(peerId()));
const _QUICV1 = and(_UDP, literal('quic-v1'), optional(peerId()));
const QUIC_V0_OR_V1 = or(_QUIC, _QUICV1);
/**
 * Matches QUIC addresses.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { QUIC } from '@multiformats/multiaddr-matcher'
 *
 * QUIC.matches(multiaddr('/ip4/123.123.123.123/udp/1234/quic')) // true
 * ```
 */
fmt(_QUIC);
/**
 * Matches QUICv1 addresses.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { QUICV1 } from '@multiformats/multiaddr-matcher'
 *
 * QUICV1.matches(multiaddr('/ip4/123.123.123.123/udp/1234/quic-v1')) // true
 * ```
 */
const QUICV1 = fmt(_QUICV1);
const _WEB = or(_IP_OR_DOMAIN, _TCP, _UDP, _QUIC, _QUICV1);
const _WebSockets = or(and(_WEB, literal('ws'), optional(peerId())));
/**
 * Matches WebSocket addresses.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { WebSockets } from '@multiformats/multiaddr-matcher'
 *
 * WebSockets.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/ws')) // true
 * ```
 */
const WebSockets$1 = fmt(_WebSockets);
const _WebSocketsSecure = or(and(_WEB, literal('wss'), optional(peerId())), and(_WEB, literal('tls'), optional(and(literal('sni'), string())), literal('ws'), optional(peerId())));
/**
 * Matches secure WebSocket addresses.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { WebSocketsSecure } from '@multiformats/multiaddr-matcher'
 *
 * WebSocketsSecure.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/wss')) // true
 * ```
 */
const WebSocketsSecure = fmt(_WebSocketsSecure);
const _WebRTCDirect = and(_UDP, literal('webrtc-direct'), optional(certhash()), optional(certhash()), optional(peerId()));
/**
 * Matches WebRTC-direct addresses.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { WebRTCDirect } from '@multiformats/multiaddr-matcher'
 *
 * WebRTCDirect.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/p2p/QmFoo/webrtc-direct/certhash/u....')) // true
 * ```
 */
const WebRTCDirect = fmt(_WebRTCDirect);
const _WebTransport = and(_QUICV1, literal('webtransport'), optional(certhash()), optional(certhash()), optional(peerId()));
/**
 * Matches WebTransport addresses.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { WebRTCDirect } from '@multiformats/multiaddr-matcher'
 *
 * WebRTCDirect.matches(multiaddr('/ip4/123.123.123.123/udp/1234/quic-v1/webtransport/certhash/u..../certhash/u..../p2p/QmFoo')) // true
 * ```
 */
const WebTransport = fmt(_WebTransport);
const _P2P = or(_WebSockets, _WebSocketsSecure, and(_TCP, optional(peerId())), and(QUIC_V0_OR_V1, optional(peerId())), and(_IP_OR_DOMAIN, optional(peerId())), _WebRTCDirect, _WebTransport, peerId());
/**
 * Matches peer addresses
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { P2P } from '@multiformats/multiaddr-matcher'
 *
 * P2P.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/p2p/QmFoo')) // true
 * ```
 */
fmt(_P2P);
const _Circuit = and(_P2P, literal('p2p-circuit'), peerId());
/**
 * Matches circuit relay addresses
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { Circuit } from '@multiformats/multiaddr-matcher'
 *
 * Circuit.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/p2p/QmRelay/p2p-circuit/p2p/QmTarget')) // true
 * ```
 */
const Circuit = fmt(_Circuit);
const _WebRTC = or(and(_P2P, literal('p2p-circuit'), literal('webrtc'), optional(peerId())), and(_P2P, literal('webrtc'), optional(peerId())), and(literal('webrtc'), optional(peerId())));
/**
 * Matches WebRTC addresses
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { WebRTC } from '@multiformats/multiaddr-matcher'
 *
 * WebRTC.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/p2p/QmRelay/p2p-circuit/webrtc/p2p/QmTarget')) // true
 * ```
 */
const WebRTC = fmt(_WebRTC);
const _HTTP = or(and(_IP_OR_DOMAIN, literal('tcp'), number(), literal('http'), optional(peerId())), and(_IP_OR_DOMAIN, literal('http'), optional(peerId())));
/**
 * Matches HTTP addresses
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { HTTP } from '@multiformats/multiaddr-matcher'
 *
 * HTTP.matches(multiaddr('/dns/example.org/http')) // true
 * ```
 */
fmt(_HTTP);
const _HTTPS = or(and(_IP_OR_DOMAIN, literal('tcp'), or(and(literal('443'), literal('http')), and(number(), literal('https')), and(number(), literal('tls'), literal('http'))), optional(peerId())), and(_IP_OR_DOMAIN, literal('tls'), literal('http'), optional(peerId())), and(_IP_OR_DOMAIN, literal('https'), optional(peerId())));
/**
 * Matches HTTPS addresses
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { HTTP } from '@multiformats/multiaddr-matcher'
 *
 * HTTP.matches(multiaddr('/dns/example.org/tls/http')) // true
 * ```
 */
fmt(_HTTPS);
const _Memory = or(and(literal('memory'), string(), optional(peerId())));
/**
 * Matches Memory addresses
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { Memory } from '@multiformats/multiaddr-matcher'
 *
 * Memory.matches(multiaddr('/memory/0xDEADBEEF')) // true
 * ```
 */
fmt(_Memory);

class Identify extends AbstractIdentify {
    constructor(components, init = {}) {
        super(components, {
            ...init,
            protocol: `/${init.protocolPrefix ?? defaultValues$3.protocolPrefix}/${MULTICODEC_IDENTIFY_PROTOCOL_NAME}/${MULTICODEC_IDENTIFY_PROTOCOL_VERSION}`,
            log: components.logger.forComponent('libp2p:identify')
        });
        if (init.runOnConnectionOpen ?? defaultValues$3.runOnConnectionOpen) {
            // When a new connection happens, trigger identify
            components.events.addEventListener('connection:open', (evt) => {
                const connection = evt.detail;
                this.identify(connection)
                    .catch(err => {
                    if (err.name === UnsupportedProtocolError.name) {
                        // the remote did not support identify, ignore the error
                        return;
                    }
                    this.log.error('error during identify trigged by connection:open', err);
                });
            });
        }
    }
    [serviceCapabilities] = [
        '@libp2p/identify'
    ];
    async _identify(connection, options = {}) {
        let stream;
        if (options.signal == null) {
            const signal = AbortSignal.timeout(this.timeout);
            options = {
                ...options,
                signal
            };
        }
        try {
            stream = await connection.newStream(this.protocol, {
                ...options,
                runOnLimitedConnection: this.runOnLimitedConnection
            });
            const pb = pbStream(stream, {
                maxDataLength: this.maxMessageSize
            }).pb(Identify$1);
            const message = await pb.read(options);
            await stream.close(options);
            return message;
        }
        catch (err) {
            stream?.abort(err);
            throw err;
        }
    }
    async identify(connection, options = {}) {
        const message = await this._identify(connection, options);
        const { publicKey, protocols, observedAddr } = message;
        if (publicKey == null) {
            throw new InvalidMessageError('public key was missing from identify message');
        }
        const key = publicKeyFromProtobuf(publicKey);
        const id = peerIdFromCID(key.toCID());
        if (!connection.remotePeer.equals(id)) {
            throw new InvalidMessageError('identified peer does not match the expected peer');
        }
        if (this.peerId.equals(id)) {
            throw new InvalidMessageError('identified peer is our own peer id?');
        }
        // if the observed address is publicly routable, add it to the address
        // manager for verification via AutoNAT
        this.maybeAddObservedAddress(observedAddr);
        this.log('identify completed for peer %p and protocols %o', id, protocols);
        return consumeIdentifyMessage(this.peerStore, this.events, this.log, connection, message);
    }
    maybeAddObservedAddress(observedAddr) {
        const cleanObservedAddr = getCleanMultiaddr(observedAddr);
        if (cleanObservedAddr == null) {
            return;
        }
        this.log.trace('our observed address was %a', cleanObservedAddr);
        if (isPrivate(cleanObservedAddr)) {
            this.log.trace('our observed address was private');
            return;
        }
        const tuples = cleanObservedAddr.getComponents();
        if (((tuples[0].code === CODE_IP6) || (tuples[0].code === CODE_IP6ZONE && tuples[1].code === CODE_IP6)) && !isGlobalUnicast(cleanObservedAddr)) {
            this.log.trace('our observed address was IPv6 but not a global unicast address');
            return;
        }
        if (TCP.exactMatch(cleanObservedAddr)) {
            // TODO: because socket dials can't use the same local port as the TCP
            // listener, many unique observed addresses are reported so ignore all
            // TCP addresses until https://github.com/libp2p/js-libp2p/issues/2620
            // is resolved
            return;
        }
        this.log.trace('storing the observed address');
        this.addressManager.addObservedAddr(cleanObservedAddr);
    }
    /**
     * Sends the `Identify` response with the Signed Peer Record
     * to the requesting peer over the given `connection`
     */
    async handleProtocol(data) {
        const { connection, stream } = data;
        const signal = AbortSignal.timeout(this.timeout);
        try {
            const peerData = await this.peerStore.get(this.peerId);
            const multiaddrs = this.addressManager.getAddresses().map(ma => ma.decapsulateCode(protocols('p2p').code));
            let signedPeerRecord = peerData.peerRecordEnvelope;
            if (multiaddrs.length > 0 && signedPeerRecord == null) {
                const peerRecord = new PeerRecord({
                    peerId: this.peerId,
                    multiaddrs
                });
                const envelope = await RecordEnvelope.seal(peerRecord, this.privateKey);
                signedPeerRecord = envelope.marshal().subarray();
            }
            let observedAddr = connection.remoteAddr.bytes;
            if (!IP_OR_DOMAIN.matches(connection.remoteAddr)) {
                observedAddr = undefined;
            }
            const pb = pbStream(stream).pb(Identify$1);
            await pb.write({
                protocolVersion: this.host.protocolVersion,
                agentVersion: this.host.agentVersion,
                publicKey: publicKeyToProtobuf(this.privateKey.publicKey),
                listenAddrs: multiaddrs.map(addr => addr.bytes),
                signedPeerRecord,
                observedAddr,
                protocols: peerData.protocols
            }, {
                signal
            });
            await stream.close({
                signal
            });
        }
        catch (err) {
            this.log.error('could not respond to identify request', err);
            stream.abort(err);
        }
    }
}

/**
 * @packageDocumentation
 *
 * Use the `identify` function to add support for the [Identify protocol](https://github.com/libp2p/specs/blob/master/identify/README.md) to libp2p.
 *
 * This protocol allows network peers to discover the multiaddrs the current node listens on, and the protocols it supports.
 *
 * A second function, `identifyPush` is also exported to add support for [identify/push](https://github.com/libp2p/specs/blob/master/identify/README.md#identifypush).
 *
 * This protocol will send updates to all connected peers when the multiaddrs or protocols of the current node change.
 *
 * > [!TIP]
 * > For maximum network compatibility you should configure both protocols
 *
 * @example Enabling identify
 *
 * ```typescript
 * import { createLibp2p } from 'libp2p'
 * import { identify } from '@libp2p/identify'
 *
 * const node = await createLibp2p({
 *   // ...other options
 *   services: {
 *     identify: identify()
 *   }
 * })
 * ```
 *
 * @example Enabling identify push
 *
 * ```typescript
 * import { createLibp2p } from 'libp2p'
 * import { identifyPush } from '@libp2p/identify'
 *
 * const node = await createLibp2p({
 *   // ...other options
 *   services: {
 *     identifyPush: identifyPush()
 *   }
 * })
 * ```
 */
function identify(init = {}) {
    return (components) => new Identify(components, init);
}

function getIterator(obj) {
    if (obj != null) {
        if (typeof obj[Symbol.iterator] === 'function') {
            return obj[Symbol.iterator]();
        }
        if (typeof obj[Symbol.asyncIterator] === 'function') {
            return obj[Symbol.asyncIterator]();
        }
        if (typeof obj.next === 'function') {
            return obj; // probably an iterator
        }
    }
    throw new Error('argument is not an iterator or iterable');
}

function isPromise$1(thing) {
    if (thing == null) {
        return false;
    }
    return typeof thing.then === 'function' &&
        typeof thing.catch === 'function' &&
        typeof thing.finally === 'function';
}

function closeSource(source, log) {
    const res = getIterator(source).return?.();
    if (isPromise$1(res)) {
        res.catch(err => {
            log.error('could not cause iterator to return', err);
        });
    }
}

// From https://github.com/sindresorhus/random-int/blob/c37741b56f76b9160b0b63dae4e9c64875128146/index.js#L13-L15

const createAbortError = () => {
	const error = new Error('Delay aborted');
	error.name = 'AbortError';
	return error;
};

const clearMethods = new WeakMap();

function createDelay({clearTimeout: defaultClear, setTimeout: defaultSet} = {}) {
	// We cannot use `async` here as we need the promise identity.
	return (milliseconds, {value, signal} = {}) => {
		// TODO: Use `signal?.throwIfAborted()` when targeting Node.js 18.
		if (signal?.aborted) {
			return Promise.reject(createAbortError());
		}

		let timeoutId;
		let settle;
		let rejectFunction;
		const clear = defaultClear ?? clearTimeout;

		const signalListener = () => {
			clear(timeoutId);
			rejectFunction(createAbortError());
		};

		const cleanup = () => {
			if (signal) {
				signal.removeEventListener('abort', signalListener);
			}
		};

		const delayPromise = new Promise((resolve, reject) => {
			settle = () => {
				cleanup();
				resolve(value);
			};

			rejectFunction = reject;
			timeoutId = (defaultSet ?? setTimeout)(settle, milliseconds);
		});

		if (signal) {
			signal.addEventListener('abort', signalListener, {once: true});
		}

		clearMethods.set(delayPromise, () => {
			clear(timeoutId);
			timeoutId = null;
			settle();
		});

		return delayPromise;
	};
}

const delay = createDelay();

/**
 * A rate limit was hit
 */
class RateLimitError extends Error {
    remainingPoints;
    msBeforeNext;
    consumedPoints;
    isFirstInDuration;
    constructor(message = 'Rate limit exceeded', props) {
        super(message);
        this.name = 'RateLimitError';
        this.remainingPoints = props.remainingPoints;
        this.msBeforeNext = props.msBeforeNext;
        this.consumedPoints = props.consumedPoints;
        this.isFirstInDuration = props.isFirstInDuration;
    }
}
let QueueFullError$1 = class QueueFullError extends Error {
    static name = 'QueueFullError';
    constructor(message = 'The queue was full') {
        super(message);
        this.name = 'QueueFullError';
    }
};

class RateLimiter {
    memoryStorage;
    points;
    duration;
    blockDuration;
    execEvenly;
    execEvenlyMinDelayMs;
    keyPrefix;
    constructor(opts = {}) {
        this.points = opts.points ?? 4;
        this.duration = opts.duration ?? 1;
        this.blockDuration = opts.blockDuration ?? 0;
        this.execEvenly = opts.execEvenly ?? false;
        this.execEvenlyMinDelayMs = opts.execEvenlyMinDelayMs ?? (this.duration * 1000 / this.points);
        this.keyPrefix = opts.keyPrefix ?? 'rlflx';
        this.memoryStorage = new MemoryStorage();
    }
    async consume(key, pointsToConsume = 1, options = {}) {
        const rlKey = this.getKey(key);
        const secDuration = this._getKeySecDuration(options);
        let res = this.memoryStorage.incrby(rlKey, pointsToConsume, secDuration);
        res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
        if (res.consumedPoints > this.points) {
            // Block only first time when consumed more than points
            if (this.blockDuration > 0 && res.consumedPoints <= (this.points + pointsToConsume)) {
                // Block key
                res = this.memoryStorage.set(rlKey, res.consumedPoints, this.blockDuration);
            }
            throw new RateLimitError('Rate limit exceeded', res);
        }
        else if (this.execEvenly && res.msBeforeNext > 0 && !res.isFirstInDuration) {
            // Execute evenly
            let delayMs = Math.ceil(res.msBeforeNext / (res.remainingPoints + 2));
            if (delayMs < this.execEvenlyMinDelayMs) {
                delayMs = res.consumedPoints * this.execEvenlyMinDelayMs;
            }
            await delay(delayMs);
        }
        return res;
    }
    penalty(key, points = 1, options = {}) {
        const rlKey = this.getKey(key);
        const secDuration = this._getKeySecDuration(options);
        const res = this.memoryStorage.incrby(rlKey, points, secDuration);
        res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
        return res;
    }
    reward(key, points = 1, options = {}) {
        const rlKey = this.getKey(key);
        const secDuration = this._getKeySecDuration(options);
        const res = this.memoryStorage.incrby(rlKey, -points, secDuration);
        res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
        return res;
    }
    /**
     * Block any key for secDuration seconds
     *
     * @param key
     * @param secDuration
     */
    block(key, secDuration) {
        const msDuration = secDuration * 1000;
        const initPoints = this.points + 1;
        this.memoryStorage.set(this.getKey(key), initPoints, secDuration);
        return {
            remainingPoints: 0,
            msBeforeNext: msDuration === 0 ? -1 : msDuration,
            consumedPoints: initPoints,
            isFirstInDuration: false
        };
    }
    set(key, points, secDuration = 0) {
        const msDuration = (secDuration >= 0 ? secDuration : this.duration) * 1000;
        this.memoryStorage.set(this.getKey(key), points, secDuration);
        return {
            remainingPoints: 0,
            msBeforeNext: msDuration === 0 ? -1 : msDuration,
            consumedPoints: points,
            isFirstInDuration: false
        };
    }
    get(key) {
        const res = this.memoryStorage.get(this.getKey(key));
        if (res != null) {
            res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
        }
        return res;
    }
    delete(key) {
        this.memoryStorage.delete(this.getKey(key));
    }
    _getKeySecDuration(options) {
        if (options?.customDuration != null && options.customDuration >= 0) {
            return options.customDuration;
        }
        return this.duration;
    }
    getKey(key) {
        return this.keyPrefix.length > 0 ? `${this.keyPrefix}:${key}` : key;
    }
    parseKey(rlKey) {
        return rlKey.substring(this.keyPrefix.length);
    }
}
class MemoryStorage {
    storage;
    constructor() {
        this.storage = new Map();
    }
    incrby(key, value, durationSec) {
        const existing = this.storage.get(key);
        if (existing != null) {
            const msBeforeExpires = existing.expiresAt != null
                ? existing.expiresAt.getTime() - new Date().getTime()
                : -1;
            if (existing.expiresAt == null || msBeforeExpires > 0) {
                // Change value
                existing.value += value;
                return {
                    remainingPoints: 0,
                    msBeforeNext: msBeforeExpires,
                    consumedPoints: existing.value,
                    isFirstInDuration: false
                };
            }
            return this.set(key, value, durationSec);
        }
        return this.set(key, value, durationSec);
    }
    set(key, value, durationSec) {
        const durationMs = durationSec * 1000;
        const existing = this.storage.get(key);
        if (existing != null) {
            clearTimeout(existing.timeoutId);
        }
        const record = {
            value,
            expiresAt: durationMs > 0 ? new Date(Date.now() + durationMs) : undefined
        };
        this.storage.set(key, record);
        if (durationMs > 0) {
            record.timeoutId = setTimeout(() => {
                this.storage.delete(key);
            }, durationMs);
            if (record.timeoutId.unref != null) {
                record.timeoutId.unref();
            }
        }
        return {
            remainingPoints: 0,
            msBeforeNext: durationMs === 0 ? -1 : durationMs,
            consumedPoints: record.value,
            isFirstInDuration: true
        };
    }
    get(key) {
        const existing = this.storage.get(key);
        if (existing != null) {
            const msBeforeExpires = existing.expiresAt != null
                ? existing.expiresAt.getTime() - new Date().getTime()
                : -1;
            return {
                remainingPoints: 0,
                msBeforeNext: msBeforeExpires,
                consumedPoints: existing.value,
                isFirstInDuration: false
            };
        }
    }
    delete(key) {
        const record = this.storage.get(key);
        if (record != null) {
            if (record.timeoutId != null) {
                clearTimeout(record.timeoutId);
            }
            this.storage.delete(key);
            return true;
        }
        return false;
    }
}

var MessageTypes;
(function (MessageTypes) {
    MessageTypes[MessageTypes["NEW_STREAM"] = 0] = "NEW_STREAM";
    MessageTypes[MessageTypes["MESSAGE_RECEIVER"] = 1] = "MESSAGE_RECEIVER";
    MessageTypes[MessageTypes["MESSAGE_INITIATOR"] = 2] = "MESSAGE_INITIATOR";
    MessageTypes[MessageTypes["CLOSE_RECEIVER"] = 3] = "CLOSE_RECEIVER";
    MessageTypes[MessageTypes["CLOSE_INITIATOR"] = 4] = "CLOSE_INITIATOR";
    MessageTypes[MessageTypes["RESET_RECEIVER"] = 5] = "RESET_RECEIVER";
    MessageTypes[MessageTypes["RESET_INITIATOR"] = 6] = "RESET_INITIATOR";
})(MessageTypes || (MessageTypes = {}));
const MessageTypeNames = Object.freeze({
    0: 'NEW_STREAM',
    1: 'MESSAGE_RECEIVER',
    2: 'MESSAGE_INITIATOR',
    3: 'CLOSE_RECEIVER',
    4: 'CLOSE_INITIATOR',
    5: 'RESET_RECEIVER',
    6: 'RESET_INITIATOR'
});
const InitiatorMessageTypes = Object.freeze({
    NEW_STREAM: MessageTypes.NEW_STREAM,
    MESSAGE: MessageTypes.MESSAGE_INITIATOR,
    CLOSE: MessageTypes.CLOSE_INITIATOR,
    RESET: MessageTypes.RESET_INITIATOR
});
const ReceiverMessageTypes = Object.freeze({
    MESSAGE: MessageTypes.MESSAGE_RECEIVER,
    CLOSE: MessageTypes.CLOSE_RECEIVER,
    RESET: MessageTypes.RESET_RECEIVER
});

const MAX_MSG_SIZE = 1 << 20; // 1MB
const MAX_MSG_QUEUE_SIZE = 4 << 20; // 4MB
class Decoder {
    _buffer;
    _headerInfo;
    _maxMessageSize;
    _maxUnprocessedMessageQueueSize;
    constructor(maxMessageSize = MAX_MSG_SIZE, maxUnprocessedMessageQueueSize = MAX_MSG_QUEUE_SIZE) {
        this._buffer = new Uint8ArrayList();
        this._headerInfo = null;
        this._maxMessageSize = maxMessageSize;
        this._maxUnprocessedMessageQueueSize = maxUnprocessedMessageQueueSize;
    }
    write(chunk) {
        if (chunk == null || chunk.length === 0) {
            return [];
        }
        this._buffer.append(chunk);
        if (this._buffer.byteLength > this._maxUnprocessedMessageQueueSize) {
            throw new InvalidMessageError('Unprocessed message queue size too large!');
        }
        const msgs = [];
        while (this._buffer.length !== 0) {
            if (this._headerInfo == null) {
                try {
                    this._headerInfo = this._decodeHeader(this._buffer);
                }
                catch (err) {
                    if (err.name === 'InvalidMessageError') {
                        throw err;
                    }
                    break; // We haven't received enough data yet
                }
            }
            const { id, type, length, offset } = this._headerInfo;
            const bufferedDataLength = this._buffer.length - offset;
            if (bufferedDataLength < length) {
                break; // not enough data yet
            }
            const msg = {
                id,
                type
            };
            if (type === MessageTypes.NEW_STREAM || type === MessageTypes.MESSAGE_INITIATOR || type === MessageTypes.MESSAGE_RECEIVER) {
                msg.data = this._buffer.sublist(offset, offset + length);
            }
            msgs.push(msg);
            this._buffer.consume(offset + length);
            this._headerInfo = null;
        }
        return msgs;
    }
    /**
     * Attempts to decode the message header from the buffer
     */
    _decodeHeader(data) {
        const { value: h, offset } = readVarInt(data);
        const { value: length, offset: end } = readVarInt(data, offset);
        const type = h & 7;
        // @ts-expect-error h is a number not a CODE
        if (MessageTypeNames[type] == null) {
            throw new Error(`Invalid type received: ${type}`);
        }
        // test message type varint + data length
        if (length > this._maxMessageSize) {
            throw new InvalidMessageError('Message size too large');
        }
        // @ts-expect-error h is a number not a CODE
        return { id: h >> 3, type, offset: offset + end, length };
    }
}
const MSB = 0x80;
const REST = 0x7F;
function readVarInt(buf, offset = 0) {
    let res = 0;
    let shift = 0;
    let counter = offset;
    let b;
    const l = buf.length;
    do {
        if (counter >= l || shift > 49) {
            offset = 0;
            throw new RangeError('Could not decode varint');
        }
        b = buf.get(counter++);
        res += shift < 28
            ? (b & REST) << shift
            : (b & REST) * Math.pow(2, shift);
        shift += 7;
    } while (b >= MSB);
    offset = counter - offset;
    return {
        value: res,
        offset
    };
}

const POOL_SIZE = 10 * 1024;
class Encoder {
    _pool;
    _poolOffset;
    constructor() {
        this._pool = allocUnsafe(POOL_SIZE);
        this._poolOffset = 0;
    }
    /**
     * Encodes the given message and adds it to the passed list
     */
    write(msg, list) {
        const pool = this._pool;
        let offset = this._poolOffset;
        encode$8(msg.id << 3 | msg.type, pool, offset);
        offset += encodingLength$1(msg.id << 3 | msg.type);
        if ((msg.type === MessageTypes.NEW_STREAM || msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) && msg.data != null) {
            encode$8(msg.data.length, pool, offset);
            offset += encodingLength$1(msg.data.length);
        }
        else {
            encode$8(0, pool, offset);
            offset += encodingLength$1(0);
        }
        const header = pool.subarray(this._poolOffset, offset);
        if (POOL_SIZE - offset < 100) {
            this._pool = allocUnsafe(POOL_SIZE);
            this._poolOffset = 0;
        }
        else {
            this._poolOffset = offset;
        }
        list.append(header);
        if ((msg.type === MessageTypes.NEW_STREAM || msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) && msg.data != null) {
            list.append(msg.data);
        }
    }
}
const encoder = new Encoder();
/**
 * Encode and yield one or more messages
 */
async function* encode$2(source) {
    for await (const message of source) {
        const list = new Uint8ArrayList();
        encoder.write(message, list);
        yield list;
    }
}

/**
 * There was an error in the stream input buffer
 */
class StreamInputBufferError extends Error {
    constructor(message = 'Stream input buffer error') {
        super(message);
        this.name = 'StreamInputBufferError';
    }
}

const DEFAULT_SEND_CLOSE_WRITE_TIMEOUT = 5000;
function isPromise(thing) {
    if (thing == null) {
        return false;
    }
    return typeof thing.then === 'function' &&
        typeof thing.catch === 'function' &&
        typeof thing.finally === 'function';
}
class AbstractStream {
    id;
    direction;
    timeline;
    protocol;
    metadata;
    source;
    status;
    readStatus;
    writeStatus;
    log;
    sinkController;
    sinkEnd;
    closed;
    endErr;
    streamSource;
    onEnd;
    onCloseRead;
    onCloseWrite;
    onReset;
    onAbort;
    sendCloseWriteTimeout;
    sendingData;
    constructor(init) {
        this.sinkController = new AbortController();
        this.sinkEnd = pDefer();
        this.closed = pDefer();
        this.log = init.log;
        // stream status
        this.status = 'open';
        this.readStatus = 'ready';
        this.writeStatus = 'ready';
        this.id = init.id;
        this.metadata = init.metadata ?? {};
        this.direction = init.direction;
        this.timeline = {
            open: Date.now()
        };
        this.sendCloseWriteTimeout = init.sendCloseWriteTimeout ?? DEFAULT_SEND_CLOSE_WRITE_TIMEOUT;
        this.onEnd = init.onEnd;
        this.onCloseRead = init.onCloseRead;
        this.onCloseWrite = init.onCloseWrite;
        this.onReset = init.onReset;
        this.onAbort = init.onAbort;
        this.source = this.streamSource = pushable({
            onEnd: (err) => {
                if (err != null) {
                    this.log.trace('source ended with error', err);
                }
                else {
                    this.log.trace('source ended');
                }
                this.onSourceEnd(err);
            }
        });
        // necessary because the libp2p upgrader wraps the sink function
        this.sink = this.sink.bind(this);
    }
    async sink(source) {
        if (this.writeStatus !== 'ready') {
            throw new StreamStateError(`writable end state is "${this.writeStatus}" not "ready"`);
        }
        try {
            this.writeStatus = 'writing';
            const options = {
                signal: this.sinkController.signal
            };
            if (this.direction === 'outbound') { // If initiator, open a new stream
                const res = this.sendNewStream(options);
                if (isPromise(res)) {
                    await res;
                }
            }
            const abortListener = () => {
                closeSource(source, this.log);
            };
            try {
                this.sinkController.signal.addEventListener('abort', abortListener);
                this.log.trace('sink reading from source');
                for await (let data of source) {
                    data = data instanceof Uint8Array ? new Uint8ArrayList(data) : data;
                    const res = this.sendData(data, options);
                    if (isPromise(res)) {
                        this.sendingData = pDefer();
                        await res;
                        this.sendingData.resolve();
                        this.sendingData = undefined;
                    }
                }
            }
            finally {
                this.sinkController.signal.removeEventListener('abort', abortListener);
            }
            this.log.trace('sink finished reading from source, write status is "%s"', this.writeStatus);
            if (this.writeStatus === 'writing') {
                this.writeStatus = 'closing';
                this.log.trace('send close write to remote');
                await this.sendCloseWrite({
                    signal: AbortSignal.timeout(this.sendCloseWriteTimeout)
                });
                this.writeStatus = 'closed';
            }
            this.onSinkEnd();
        }
        catch (err) {
            this.log.trace('sink ended with error, calling abort with error', err);
            this.abort(err);
            throw err;
        }
        finally {
            this.log.trace('resolve sink end');
            this.sinkEnd.resolve();
        }
    }
    onSourceEnd(err) {
        if (this.timeline.closeRead != null) {
            return;
        }
        this.timeline.closeRead = Date.now();
        this.readStatus = 'closed';
        if (err != null && this.endErr == null) {
            this.endErr = err;
        }
        this.onCloseRead?.();
        if (this.timeline.closeWrite != null) {
            this.log.trace('source and sink ended');
            this.timeline.close = Date.now();
            if (this.status !== 'aborted' && this.status !== 'reset') {
                this.status = 'closed';
            }
            if (this.onEnd != null) {
                this.onEnd(this.endErr);
            }
            this.closed.resolve();
        }
        else {
            this.log.trace('source ended, waiting for sink to end');
        }
    }
    onSinkEnd(err) {
        if (this.timeline.closeWrite != null) {
            return;
        }
        this.timeline.closeWrite = Date.now();
        this.writeStatus = 'closed';
        if (err != null && this.endErr == null) {
            this.endErr = err;
        }
        this.onCloseWrite?.();
        if (this.timeline.closeRead != null) {
            this.log.trace('sink and source ended');
            this.timeline.close = Date.now();
            if (this.status !== 'aborted' && this.status !== 'reset') {
                this.status = 'closed';
            }
            if (this.onEnd != null) {
                this.onEnd(this.endErr);
            }
            this.closed.resolve();
        }
        else {
            this.log.trace('sink ended, waiting for source to end');
        }
    }
    // Close for both Reading and Writing
    async close(options) {
        if (this.status !== 'open') {
            return;
        }
        this.log.trace('closing gracefully');
        this.status = 'closing';
        // wait for read and write ends to close
        await raceSignal(Promise.all([
            this.closeWrite(options),
            this.closeRead(options),
            this.closed.promise
        ]), options?.signal);
        this.status = 'closed';
        this.log.trace('closed gracefully');
    }
    async closeRead(options = {}) {
        if (this.readStatus === 'closing' || this.readStatus === 'closed') {
            return;
        }
        this.log.trace('closing readable end of stream with starting read status "%s"', this.readStatus);
        const readStatus = this.readStatus;
        this.readStatus = 'closing';
        if (this.status !== 'reset' && this.status !== 'aborted' && this.timeline.closeRead == null) {
            this.log.trace('send close read to remote');
            await this.sendCloseRead(options);
        }
        if (readStatus === 'ready') {
            this.log.trace('ending internal source queue with %d queued bytes', this.streamSource.readableLength);
            this.streamSource.end();
        }
        this.log.trace('closed readable end of stream');
    }
    async closeWrite(options = {}) {
        if (this.writeStatus === 'closing' || this.writeStatus === 'closed') {
            return;
        }
        this.log.trace('closing writable end of stream with starting write status "%s"', this.writeStatus);
        if (this.writeStatus === 'ready') {
            this.log.trace('sink was never sunk, sink an empty array');
            await raceSignal(this.sink([]), options.signal);
        }
        if (this.writeStatus === 'writing') {
            // try to let sending outgoing data succeed
            if (this.sendingData != null) {
                await raceSignal(this.sendingData.promise, options.signal);
            }
            // stop reading from the source passed to `.sink`
            this.log.trace('aborting source passed to .sink');
            this.sinkController.abort();
            await raceSignal(this.sinkEnd.promise, options.signal);
        }
        this.writeStatus = 'closed';
        this.log.trace('closed writable end of stream');
    }
    /**
     * Close immediately for reading and writing and send a reset message (local
     * error)
     */
    abort(err) {
        if (this.status === 'closed' || this.status === 'aborted' || this.status === 'reset') {
            return;
        }
        this.log('abort with error', err);
        // try to send a reset message
        this.log('try to send reset to remote');
        const res = this.sendReset();
        if (isPromise(res)) {
            res.catch((err) => {
                this.log.error('error sending reset message', err);
            });
        }
        this.status = 'aborted';
        this.timeline.abort = Date.now();
        this._closeSinkAndSource(err);
        this.onAbort?.(err);
    }
    /**
     * Receive a reset message - close immediately for reading and writing (remote
     * error)
     */
    reset() {
        if (this.status === 'closed' || this.status === 'aborted' || this.status === 'reset') {
            return;
        }
        const err = new StreamResetError('stream reset');
        this.status = 'reset';
        this.timeline.reset = Date.now();
        this._closeSinkAndSource(err);
        this.onReset?.();
    }
    _closeSinkAndSource(err) {
        this._closeSink(err);
        this._closeSource(err);
    }
    _closeSink(err) {
        // if the sink function is running, cause it to end
        if (this.writeStatus === 'writing') {
            this.log.trace('end sink source');
            this.sinkController.abort();
        }
        this.onSinkEnd(err);
    }
    _closeSource(err) {
        // if the source is not ending, end it
        if (this.readStatus !== 'closing' && this.readStatus !== 'closed') {
            this.log.trace('ending source with %d bytes to be read by consumer', this.streamSource.readableLength);
            this.readStatus = 'closing';
            this.streamSource.end(err);
        }
    }
    /**
     * The remote closed for writing so we should expect to receive no more
     * messages
     */
    remoteCloseWrite() {
        if (this.readStatus === 'closing' || this.readStatus === 'closed') {
            this.log('received remote close write but local source is already closed');
            return;
        }
        this.log.trace('remote close write');
        this._closeSource();
    }
    /**
     * The remote closed for reading so we should not send any more
     * messages
     */
    remoteCloseRead() {
        if (this.writeStatus === 'closing' || this.writeStatus === 'closed') {
            this.log('received remote close read but local sink is already closed');
            return;
        }
        this.log.trace('remote close read');
        this._closeSink();
    }
    /**
     * The underlying muxer has closed, no more messages can be sent or will
     * be received, close immediately to free up resources
     */
    destroy() {
        if (this.status === 'closed' || this.status === 'aborted' || this.status === 'reset') {
            this.log('received destroy but we are already closed');
            return;
        }
        this.log.trace('stream destroyed');
        this._closeSinkAndSource();
    }
    /**
     * When an extending class reads data from it's implementation-specific source,
     * call this method to allow the stream consumer to read the data.
     */
    sourcePush(data) {
        this.streamSource.push(data);
    }
    /**
     * Returns the amount of unread data - can be used to prevent large amounts of
     * data building up when the stream consumer is too slow.
     */
    sourceReadableLength() {
        return this.streamSource.readableLength;
    }
}

class MplexStream extends AbstractStream {
    name;
    streamId;
    send;
    types;
    maxDataSize;
    constructor(init) {
        super(init);
        this.types = init.direction === 'outbound' ? InitiatorMessageTypes : ReceiverMessageTypes;
        this.send = init.send;
        this.name = init.name;
        this.streamId = init.streamId;
        this.maxDataSize = init.maxDataSize;
    }
    async sendNewStream() {
        await this.send({ id: this.streamId, type: InitiatorMessageTypes.NEW_STREAM, data: new Uint8ArrayList(fromString(this.name)) });
    }
    async sendData(data) {
        data = data.sublist();
        while (data.byteLength > 0) {
            const toSend = Math.min(data.byteLength, this.maxDataSize);
            await this.send({
                id: this.streamId,
                type: this.types.MESSAGE,
                data: data.sublist(0, toSend)
            });
            data.consume(toSend);
        }
    }
    async sendReset() {
        await this.send({ id: this.streamId, type: this.types.RESET });
    }
    async sendCloseWrite() {
        await this.send({ id: this.streamId, type: this.types.CLOSE });
    }
    async sendCloseRead() {
        // mplex does not support close read, only close write
    }
}
function createStream(options) {
    const { id, name, send, onEnd, type = 'initiator', maxMsgSize = MAX_MSG_SIZE } = options;
    return new MplexStream({
        id: type === 'initiator' ? (`i${id}`) : `r${id}`,
        streamId: id,
        name: `${name ?? id}`,
        direction: type === 'initiator' ? 'outbound' : 'inbound',
        maxDataSize: maxMsgSize,
        onEnd,
        send,
        log: options.logger.forComponent(`libp2p:mplex:stream:${type}:${id}`)
    });
}

const MAX_STREAMS_INBOUND_STREAMS_PER_CONNECTION = 1024;
const MAX_STREAMS_OUTBOUND_STREAMS_PER_CONNECTION = 1024;
const MAX_STREAM_BUFFER_SIZE = 1024 * 1024 * 4; // 4MB
const DISCONNECT_THRESHOLD = 5;
const CLOSE_TIMEOUT$2 = 500;
function printMessage(msg) {
    const output = {
        ...msg,
        type: `${MessageTypeNames[msg.type]} (${msg.type})`
    };
    if (msg.type === MessageTypes.NEW_STREAM) {
        output.data = toString(msg.data instanceof Uint8Array ? msg.data : msg.data.subarray());
    }
    if (msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) {
        output.data = toString(msg.data instanceof Uint8Array ? msg.data : msg.data.subarray(), 'base16');
    }
    return output;
}
class MplexStreamMuxer {
    protocol = '/mplex/6.7.0';
    sink;
    source;
    log;
    _streamId;
    _streams;
    _init;
    _source;
    closeController;
    rateLimiter;
    closeTimeout;
    logger;
    constructor(components, init) {
        init = init ?? {};
        this.log = components.logger.forComponent('libp2p:mplex');
        this.logger = components.logger;
        this._streamId = 0;
        this._streams = {
            /**
             * Stream to ids map
             */
            initiators: new Map(),
            /**
             * Stream to ids map
             */
            receivers: new Map()
        };
        this._init = init;
        this.closeTimeout = init.closeTimeout ?? CLOSE_TIMEOUT$2;
        /**
         * An iterable sink
         */
        this.sink = this._createSink();
        /**
         * An iterable source
         */
        this._source = pushable({
            objectMode: true,
            onEnd: () => {
                // the source has ended, we can't write any more messages to gracefully
                // close streams so all we can do is destroy them
                for (const stream of this._streams.initiators.values()) {
                    stream.destroy();
                }
                for (const stream of this._streams.receivers.values()) {
                    stream.destroy();
                }
            }
        });
        this.source = pipe(this._source, source => encode$2(source));
        /**
         * Close controller
         */
        this.closeController = new AbortController();
        this.rateLimiter = new RateLimiter({
            points: init.disconnectThreshold ?? DISCONNECT_THRESHOLD,
            duration: 1
        });
    }
    /**
     * Returns a Map of streams and their ids
     */
    get streams() {
        // Inbound and Outbound streams may have the same ids, so we need to make those unique
        const streams = [];
        for (const stream of this._streams.initiators.values()) {
            streams.push(stream);
        }
        for (const stream of this._streams.receivers.values()) {
            streams.push(stream);
        }
        return streams;
    }
    /**
     * Initiate a new stream with the given name. If no name is
     * provided, the id of the stream will be used.
     */
    newStream(name) {
        if (this.closeController.signal.aborted) {
            throw new MuxerClosedError('Muxer already closed');
        }
        const id = this._streamId++;
        name = name == null ? id.toString() : name.toString();
        const registry = this._streams.initiators;
        return this._newStream({ id, name, type: 'initiator', registry });
    }
    /**
     * Close or abort all tracked streams and stop the muxer
     */
    async close(options) {
        if (this.closeController.signal.aborted) {
            return;
        }
        const signal = options?.signal ?? AbortSignal.timeout(this.closeTimeout);
        try {
            // try to gracefully close all streams
            await Promise.all(this.streams.map(async (s) => s.close({
                signal
            })));
            this._source.end();
            // try to gracefully close the muxer
            await this._source.onEmpty({
                signal
            });
            this.closeController.abort();
        }
        catch (err) {
            this.abort(err);
        }
    }
    abort(err) {
        if (this.closeController.signal.aborted) {
            return;
        }
        this.streams.forEach(s => { s.abort(err); });
        this.closeController.abort(err);
    }
    /**
     * Called whenever an inbound stream is created
     */
    _newReceiverStream(options) {
        const { id, name } = options;
        const registry = this._streams.receivers;
        return this._newStream({ id, name, type: 'receiver', registry });
    }
    _newStream(options) {
        const { id, name, type, registry } = options;
        this.log('new %s stream %s', type, id);
        if (type === 'initiator' && this._streams.initiators.size === (this._init.maxOutboundStreams ?? MAX_STREAMS_OUTBOUND_STREAMS_PER_CONNECTION)) {
            throw new TooManyOutboundProtocolStreamsError('Too many outbound streams open');
        }
        if (registry.has(id)) {
            throw new Error(`${type} stream ${id} already exists!`);
        }
        const send = async (msg) => {
            if (this.log.enabled) {
                this.log.trace('%s stream %s send', type, id, printMessage(msg));
            }
            this._source.push(msg);
        };
        const onEnd = () => {
            this.log('%s stream with id %s and protocol %s ended', type, id, stream.protocol);
            registry.delete(id);
            if (this._init.onStreamEnd != null) {
                this._init.onStreamEnd(stream);
            }
        };
        const stream = createStream({ id, name, send, type, onEnd, maxMsgSize: this._init.maxMsgSize, logger: this.logger });
        registry.set(id, stream);
        return stream;
    }
    /**
     * Creates a sink with an abortable source. Incoming messages will
     * also have their size restricted. All messages will be varint decoded.
     */
    _createSink() {
        const sink = async (source) => {
            const abortListener = () => {
                closeSource(source, this.log);
            };
            this.closeController.signal.addEventListener('abort', abortListener);
            try {
                const decoder = new Decoder(this._init.maxMsgSize, this._init.maxUnprocessedMessageQueueSize);
                for await (const chunk of source) {
                    for (const msg of decoder.write(chunk)) {
                        await this._handleIncoming(msg);
                    }
                }
                this._source.end();
            }
            catch (err) {
                this.log('error in sink', err);
                this._source.end(err); // End the source with an error
            }
            finally {
                this.closeController.signal.removeEventListener('abort', abortListener);
            }
        };
        return sink;
    }
    async _handleIncoming(message) {
        const { id, type } = message;
        if (this.log.enabled) {
            this.log.trace('incoming message', printMessage(message));
        }
        // Create a new stream?
        if (message.type === MessageTypes.NEW_STREAM) {
            if (this._streams.receivers.size === (this._init.maxInboundStreams ?? MAX_STREAMS_INBOUND_STREAMS_PER_CONNECTION)) {
                this.log('too many inbound streams open');
                // not going to allow this stream, send the reset message manually
                // instead of setting it up just to tear it down
                this._source.push({
                    id,
                    type: MessageTypes.RESET_RECEIVER
                });
                // if we've hit our stream limit, and the remote keeps trying to open
                // more new streams, if they are doing this very quickly maybe they
                // are attacking us and we should close the connection
                try {
                    await this.rateLimiter.consume('new-stream', 1);
                }
                catch {
                    this.log('rate limit hit when opening too many new streams over the inbound stream limit - closing remote connection');
                    // since there's no backpressure in mplex, the only thing we can really do to protect ourselves is close the connection
                    this.abort(new Error('Too many open streams'));
                    return;
                }
                return;
            }
            const stream = this._newReceiverStream({ id, name: toString(message.data instanceof Uint8Array ? message.data : message.data.subarray()) });
            if (this._init.onIncomingStream != null) {
                this._init.onIncomingStream(stream);
            }
            return;
        }
        const list = (type & 1) === 1 ? this._streams.initiators : this._streams.receivers;
        const stream = list.get(id);
        if (stream == null) {
            this.log('missing stream %s for message type %s', id, MessageTypeNames[type]);
            // if the remote keeps sending us messages for streams that have been
            // closed or were never opened they may be attacking us so if they do
            // this very quickly all we can do is close the connection
            try {
                await this.rateLimiter.consume('missing-stream', 1);
            }
            catch {
                this.log('rate limit hit when receiving messages for streams that do not exist - closing remote connection');
                // since there's no backpressure in mplex, the only thing we can really do to protect ourselves is close the connection
                this.abort(new Error('Too many messages for missing streams'));
                return;
            }
            return;
        }
        const maxBufferSize = this._init.maxStreamBufferSize ?? MAX_STREAM_BUFFER_SIZE;
        try {
            switch (type) {
                case MessageTypes.MESSAGE_INITIATOR:
                case MessageTypes.MESSAGE_RECEIVER:
                    if (stream.sourceReadableLength() > maxBufferSize) {
                        // Stream buffer has got too large, reset the stream
                        this._source.push({
                            id: message.id,
                            type: type === MessageTypes.MESSAGE_INITIATOR ? MessageTypes.RESET_RECEIVER : MessageTypes.RESET_INITIATOR
                        });
                        // Inform the stream consumer they are not fast enough
                        throw new StreamInputBufferError('Input buffer full - increase Mplex maxBufferSize to accommodate slow consumers');
                    }
                    // We got data from the remote, push it into our local stream
                    stream.sourcePush(message.data);
                    break;
                case MessageTypes.CLOSE_INITIATOR:
                case MessageTypes.CLOSE_RECEIVER:
                    // The remote has stopped writing, so we can stop reading
                    stream.remoteCloseWrite();
                    break;
                case MessageTypes.RESET_INITIATOR:
                case MessageTypes.RESET_RECEIVER:
                    // The remote has errored, stop reading and writing to the stream immediately
                    stream.reset();
                    break;
                default:
                    this.log('unknown message type %s', type);
            }
        }
        catch (err) {
            this.log.error('error while processing message', err);
            stream.abort(err);
        }
    }
}

/**
 * @packageDocumentation
 *
 * This is a [simple stream multiplexer(https://docs.libp2p.io/concepts/multiplex/mplex/) that has been deprecated.
 *
 * Please use [@chainsafe/libp2p-yamux](https://www.npmjs.com/package/@chainsafe/libp2p-yamux) instead.
 *
 * @example
 *
 * ```TypeScript
 * import { mplex } from '@libp2p/mplex'
 * import { pipe } from 'it-pipe'
 *
 * const factory = mplex()
 *
 * const muxer = factory.createStreamMuxer(components, {
 *   onStream: stream => { // Receive a duplex stream from the remote
 *     // ...receive data from the remote and optionally send data back
 *   },
 *   onStreamEnd: stream => {
 *     // ...handle any tracking you may need of stream closures
 *   }
 * })
 *
 * pipe(conn, muxer, conn) // conn is duplex connection to another peer
 *
 * const stream = muxer.newStream() // Create a new duplex stream to the remote
 *
 * // Use the duplex stream to send some data to the remote...
 * pipe([1, 2, 3], stream)
 * ```
 */
class Mplex {
    protocol = '/mplex/6.7.0';
    _init;
    components;
    constructor(components, init = {}) {
        this.components = components;
        this._init = init;
    }
    [Symbol.toStringTag] = '@libp2p/mplex';
    [serviceCapabilities] = [
        '@libp2p/stream-multiplexing'
    ];
    createStreamMuxer(init = {}) {
        return new MplexStreamMuxer(this.components, {
            ...init,
            ...this._init
        });
    }
}
/**
 * @deprecated mplex is deprecated as it has no flow control. Please use yamux instead.
 */
function mplex(init = {}) {
    return (components) => new Mplex(components, init);
}

const PING_LENGTH$1 = 32;
const PROTOCOL_VERSION$1 = '1.0.0';
const PROTOCOL_NAME$1 = 'ping';
const PROTOCOL_PREFIX$1 = 'ipfs';
const TIMEOUT = 10000;
// See https://github.com/libp2p/specs/blob/d4b5fb0152a6bb86cfd9ea/ping/ping.md?plain=1#L38-L43
// The dialing peer MUST NOT keep more than one outbound stream for the ping protocol per peer.
// The listening peer SHOULD accept at most two streams per peer since cross-stream behavior is
// non-linear and stream writes occur asynchronously. The listening peer may perceive the
// dialing peer closing and opening the wrong streams (for instance, closing stream B and
// opening stream A even though the dialing peer is opening stream B and closing stream A).
const MAX_INBOUND_STREAMS = 2;
const MAX_OUTBOUND_STREAMS = 1;

class Ping {
    protocol;
    components;
    started;
    timeout;
    maxInboundStreams;
    maxOutboundStreams;
    runOnLimitedConnection;
    log;
    constructor(components, init = {}) {
        this.components = components;
        this.log = components.logger.forComponent('libp2p:ping');
        this.started = false;
        this.protocol = `/${init.protocolPrefix ?? PROTOCOL_PREFIX$1}/${PROTOCOL_NAME$1}/${PROTOCOL_VERSION$1}`;
        this.timeout = init.timeout ?? TIMEOUT;
        this.maxInboundStreams = init.maxInboundStreams ?? MAX_INBOUND_STREAMS;
        this.maxOutboundStreams = init.maxOutboundStreams ?? MAX_OUTBOUND_STREAMS;
        this.runOnLimitedConnection = init.runOnLimitedConnection ?? true;
        this.handleMessage = this.handleMessage.bind(this);
    }
    [Symbol.toStringTag] = '@libp2p/ping';
    [serviceCapabilities] = [
        '@libp2p/ping'
    ];
    async start() {
        await this.components.registrar.handle(this.protocol, this.handleMessage, {
            maxInboundStreams: this.maxInboundStreams,
            maxOutboundStreams: this.maxOutboundStreams,
            runOnLimitedConnection: this.runOnLimitedConnection
        });
        this.started = true;
    }
    async stop() {
        await this.components.registrar.unhandle(this.protocol);
        this.started = false;
    }
    isStarted() {
        return this.started;
    }
    /**
     * A handler to register with Libp2p to process ping messages
     */
    handleMessage(data) {
        this.log('incoming ping from %p', data.connection.remotePeer);
        const { stream } = data;
        const start = Date.now();
        const bytes = byteStream(stream);
        let pinged = false;
        Promise.resolve().then(async () => {
            while (true) {
                const signal = AbortSignal.timeout(this.timeout);
                signal.addEventListener('abort', () => {
                    stream?.abort(new TimeoutError$1('ping timeout'));
                });
                const buf = await bytes.read({
                    bytes: PING_LENGTH$1,
                    signal
                });
                await bytes.write(buf, {
                    signal
                });
                pinged = true;
            }
        })
            .catch(err => {
            // ignore the error if we've processed at least one ping, the remote
            // closed the stream and we handled or are handling the close cleanly
            if (pinged && err.name === 'UnexpectedEOFError' && stream.readStatus !== 'ready') {
                return;
            }
            this.log.error('incoming ping from %p failed with error - %e', data.connection.remotePeer, err);
            stream?.abort(err);
        })
            .finally(() => {
            const ms = Date.now() - start;
            this.log('incoming ping from %p complete in %dms', data.connection.remotePeer, ms);
            const signal = AbortSignal.timeout(this.timeout);
            stream.close({
                signal
            })
                .catch(err => {
                this.log.error('error closing ping stream from %p - %e', data.connection.remotePeer, err);
                stream?.abort(err);
            });
        });
    }
    /**
     * Ping a given peer and wait for its response, getting the operation latency.
     */
    async ping(peer, options = {}) {
        this.log('pinging %p', peer);
        const start = Date.now();
        const data = randomBytes(PING_LENGTH$1);
        const connection = await this.components.connectionManager.openConnection(peer, options);
        let stream;
        if (options.signal == null) {
            const signal = AbortSignal.timeout(this.timeout);
            options = {
                ...options,
                signal
            };
        }
        try {
            stream = await connection.newStream(this.protocol, {
                ...options,
                runOnLimitedConnection: this.runOnLimitedConnection
            });
            const bytes = byteStream(stream);
            const [, result] = await Promise.all([
                bytes.write(data, options),
                bytes.read({
                    ...options,
                    bytes: PING_LENGTH$1
                })
            ]);
            const ms = Date.now() - start;
            if (!equals(data, result.subarray())) {
                throw new ProtocolError(`Received wrong ping ack after ${ms}ms`);
            }
            this.log('ping %p complete in %dms', connection.remotePeer, ms);
            return ms;
        }
        catch (err) {
            this.log.error('error while pinging %p', connection.remotePeer, err);
            stream?.abort(err);
            throw err;
        }
        finally {
            if (stream != null) {
                await stream.close(options);
            }
        }
    }
}

/**
 * @packageDocumentation
 *
 * The ping service implements the [libp2p ping spec](https://github.com/libp2p/specs/blob/master/ping/ping.md) allowing you to make a latency measurement to a remote peer.
 *
 * @example
 *
 * ```typescript
 * import { createLibp2p } from 'libp2p'
 * import { ping } from '@libp2p/ping'
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const node = await createLibp2p({
 *   services: {
 *     ping: ping()
 *   }
 * })
 *
 * const rtt = await node.services.ping.ping(multiaddr('/ip4/...'))
 *
 * console.info(rtt)
 * ```
 */
function ping(init = {}) {
    return (components) => new Ping(components, init);
}

/**
 * @packageDocumentation
 *
 * This module allows easy conversion of Multiaddrs to string URIs.
 *
 * @example Converting multiaddrs to string URIs
 *
 * ```js
 * import { multiaddrToUri } from '@multiformats/multiaddr-to-uri'
 *
 * console.log(multiaddrToUri('/dnsaddr/protocol.ai/https'))
 * // -> https://protocol.ai
 *
 * console.log(multiaddrToUri('/ip4/127.0.0.1/tcp/8080'))
 * // -> http://127.0.0.1:8080
 *
 * console.log(multiaddrToUri('/ip4/127.0.0.1/tcp/8080', { assumeHttp: false }))
 * // -> tcp://127.0.0.1:8080
 * ```
 *
 * Note:
 *
 * - When `/tcp` is the last (terminating) protocol HTTP is assumed by default (implicit `assumeHttp: true`)
 *   - this means produced URIs will start with `http://` instead of `tcp://`
 *   - passing `{ assumeHttp: false }` disables this behavior
 * - Might be lossy - e.g. a DNSv6 multiaddr
 * - Can throw if the passed multiaddr:
 *   - is not a valid multiaddr
 *   - is not supported as a URI e.g. circuit
 */
const ASSUME_HTTP_CODES = [
    protocols('tcp').code,
    protocols('dns').code,
    protocols('dnsaddr').code,
    protocols('dns4').code,
    protocols('dns6').code
];
function extractSNI(ma) {
    return extractTuple('sni', ma)?.[1];
}
function extractPort(ma) {
    const port = extractTuple('tcp', ma)?.[1];
    if (port == null) {
        return '';
    }
    return `:${port}`;
}
function extractTuple(name, ma) {
    let code;
    try {
        code = protocols(name).code;
    }
    catch (e) {
        // No support for protocol in multiaddr
        return;
    }
    for (const [proto, value] of ma) {
        if (proto === code && value != null) {
            return [proto, value];
        }
    }
}
function hasTLS(ma) {
    return ma.some(([proto, _]) => proto === protocols('tls').code);
}
function interpretNext(headProtoCode, headProtoVal, restMa) {
    const interpreter = interpreters[protocols(headProtoCode).name];
    if (interpreter == null) {
        throw new Error(`Can't interpret protocol ${protocols(headProtoCode).name}`);
    }
    const restVal = interpreter(headProtoVal, restMa);
    if (headProtoCode === protocols('ip6').code) {
        return `[${restVal}]`;
    }
    return restVal;
}
const interpreters = {
    ip4: (value, restMa) => value,
    ip6: (value, restMa) => {
        if (restMa.length === 0) {
            return value;
        }
        return `[${value}]`;
    },
    tcp: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `tcp://${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}:${value}`;
    },
    udp: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `udp://${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}:${value}`;
    },
    dnsaddr: (value, restMa) => value,
    dns4: (value, restMa) => value,
    dns6: (value, restMa) => value,
    dns: (value, restMa) => value,
    ipfs: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}`;
    },
    p2p: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}`;
    },
    http: (value, restMa) => {
        const maHasTLS = hasTLS(restMa);
        const sni = extractSNI(restMa);
        const port = extractPort(restMa);
        if (maHasTLS && sni != null) {
            return `https://${sni}${port}`;
        }
        const protocol = maHasTLS ? 'https://' : 'http://';
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
        // We are reinterpreting the base as http, so we need to remove the tcp:// if it's there
        baseVal = baseVal.replace('tcp://', '');
        return `${protocol}${baseVal}`;
    },
    'http-path': (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        const baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
        const decodedValue = decodeURIComponent(value);
        return `${baseVal}/${decodedValue}`;
    },
    tls: (value, restMa) => {
        // Noop, the parent context knows that it's tls. We don't need to do
        // anything here
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        return interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
    },
    sni: (value, restMa) => {
        // Noop, the parent context uses the sni information, we don't need to do
        // anything here
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        return interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
    },
    https: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
        // We are reinterpreting the base as http, so we need to remove the tcp:// if it's there
        baseVal = baseVal.replace('tcp://', '');
        return `https://${baseVal}`;
    },
    ws: (value, restMa) => {
        const maHasTLS = hasTLS(restMa);
        const sni = extractSNI(restMa);
        const port = extractPort(restMa);
        if (maHasTLS && sni != null) {
            return `wss://${sni}${port}`;
        }
        const protocol = maHasTLS ? 'wss://' : 'ws://';
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
        // We are reinterpreting the base, so we need to remove the tcp:// if it's there
        baseVal = baseVal.replace('tcp://', '');
        return `${protocol}${baseVal}`;
    },
    wss: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto == null) {
            throw new Error('Unexpected end of multiaddr');
        }
        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
        // We are reinterpreting the base as http, so we need to remove the tcp:// if it's there
        baseVal = baseVal.replace('tcp://', '');
        return `wss://${baseVal}`;
    }
};
function multiaddrToUri(input, opts) {
    const ma = multiaddr(input);
    const parts = ma.stringTuples();
    const head = parts.pop();
    if (head == null) {
        throw new Error('Unexpected end of multiaddr');
    }
    const protocol = protocols(head[0]);
    const interpreter = interpreters[protocol.name];
    if (interpreter == null) {
        throw new Error(`No interpreter found for ${protocol.name}`);
    }
    let uri = interpreter(head[1] ?? '', parts);
    if (ASSUME_HTTP_CODES.includes(head[0])) {
        // strip any declared protocol
        uri = uri.replace(/^.*:\/\//, '');
        if (head[1] === '443') {
            uri = `https://${uri}`;
        }
        else {
            uri = `http://${uri}`;
        }
    }
    if (uri.startsWith('http://') || uri.startsWith('https://') || uri.startsWith('ws://') || uri.startsWith('wss://')) {
        // this will strip default ports while keeping paths intact
        uri = new URL(uri).toString();
        // strip trailing slash, e.g. http://127.0.0.1/ -> http://127.0.0.1
        if (uri.endsWith('/')) {
            uri = uri.substring(0, uri.length - 1);
        }
    }
    return uri;
}

var ready = async (socket) => {
    // if the socket is closing or closed, return end
    if (socket.readyState >= 2) {
        throw new Error('socket closed');
    }
    // if open, return
    if (socket.readyState === 1) {
        return;
    }
    await new Promise((resolve, reject) => {
        function cleanup() {
            socket.removeEventListener('open', handleOpen);
            socket.removeEventListener('error', handleErr);
        }
        function handleOpen() {
            cleanup();
            resolve();
        }
        function handleErr(event) {
            cleanup();
            reject(event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`));
        }
        socket.addEventListener('open', handleOpen);
        socket.addEventListener('error', handleErr);
    });
};

var sink = (socket, options) => {
    options = options ?? {};
    options.closeOnEnd = options.closeOnEnd !== false;
    const sink = async (source) => {
        for await (const data of source) {
            try {
                await ready(socket);
            }
            catch (err) {
                if (err.message === 'socket closed')
                    break;
                throw err;
            }
            // the ready promise resolved without error but the socket was closing so
            // exit the loop and don't send data
            if (socket.readyState === socket.CLOSING || socket.readyState === socket.CLOSED) {
                break;
            }
            socket.send(data);
        }
        if (options.closeOnEnd != null && socket.readyState <= 1) {
            await new Promise((resolve, reject) => {
                socket.addEventListener('close', event => {
                    if (event.wasClean || event.code === 1006) {
                        resolve();
                    }
                    else {
                        const err = Object.assign(new Error('ws error'), { event });
                        reject(err);
                    }
                });
                setTimeout(() => { socket.close(); });
            });
        }
    };
    return sink;
};

var dom = {};

var eventIterator = {};

Object.defineProperty(eventIterator, "__esModule", { value: true });
class EventQueue {
    constructor() {
        this.pullQueue = [];
        this.pushQueue = [];
        this.eventHandlers = {};
        this.isPaused = false;
        this.isStopped = false;
    }
    push(value) {
        if (this.isStopped)
            return;
        const resolution = { value, done: false };
        if (this.pullQueue.length) {
            const placeholder = this.pullQueue.shift();
            if (placeholder)
                placeholder.resolve(resolution);
        }
        else {
            this.pushQueue.push(Promise.resolve(resolution));
            if (this.highWaterMark !== undefined &&
                this.pushQueue.length >= this.highWaterMark &&
                !this.isPaused) {
                this.isPaused = true;
                if (this.eventHandlers.highWater) {
                    this.eventHandlers.highWater();
                }
                else if (console) {
                    console.warn(`EventIterator queue reached ${this.pushQueue.length} items`);
                }
            }
        }
    }
    stop() {
        if (this.isStopped)
            return;
        this.isStopped = true;
        this.remove();
        for (const placeholder of this.pullQueue) {
            placeholder.resolve({ value: undefined, done: true });
        }
        this.pullQueue.length = 0;
    }
    fail(error) {
        if (this.isStopped)
            return;
        this.isStopped = true;
        this.remove();
        if (this.pullQueue.length) {
            for (const placeholder of this.pullQueue) {
                placeholder.reject(error);
            }
            this.pullQueue.length = 0;
        }
        else {
            const rejection = Promise.reject(error);
            /* Attach error handler to avoid leaking an unhandled promise rejection. */
            rejection.catch(() => { });
            this.pushQueue.push(rejection);
        }
    }
    remove() {
        Promise.resolve().then(() => {
            if (this.removeCallback)
                this.removeCallback();
        });
    }
    [Symbol.asyncIterator]() {
        return {
            next: (value) => {
                const result = this.pushQueue.shift();
                if (result) {
                    if (this.lowWaterMark !== undefined &&
                        this.pushQueue.length <= this.lowWaterMark &&
                        this.isPaused) {
                        this.isPaused = false;
                        if (this.eventHandlers.lowWater) {
                            this.eventHandlers.lowWater();
                        }
                    }
                    return result;
                }
                else if (this.isStopped) {
                    return Promise.resolve({ value: undefined, done: true });
                }
                else {
                    return new Promise((resolve, reject) => {
                        this.pullQueue.push({ resolve, reject });
                    });
                }
            },
            return: () => {
                this.isStopped = true;
                this.pushQueue.length = 0;
                this.remove();
                return Promise.resolve({ value: undefined, done: true });
            },
        };
    }
}
let EventIterator$1 = class EventIterator {
    constructor(listen, { highWaterMark = 100, lowWaterMark = 1 } = {}) {
        const queue = new EventQueue();
        queue.highWaterMark = highWaterMark;
        queue.lowWaterMark = lowWaterMark;
        queue.removeCallback =
            listen({
                push: value => queue.push(value),
                stop: () => queue.stop(),
                fail: error => queue.fail(error),
                on: (event, fn) => {
                    queue.eventHandlers[event] = fn;
                },
            }) || (() => { });
        this[Symbol.asyncIterator] = () => queue[Symbol.asyncIterator]();
        Object.freeze(this);
    }
};
eventIterator.EventIterator = EventIterator$1;
eventIterator.default = EventIterator$1;

Object.defineProperty(dom, "__esModule", { value: true });
const event_iterator_1 = eventIterator;
var EventIterator = dom.EventIterator = event_iterator_1.EventIterator;
function subscribe(event, options, evOptions) {
    return new event_iterator_1.EventIterator(({ push }) => {
        this.addEventListener(event, push, options);
        return () => this.removeEventListener(event, push, options);
    }, evOptions);
}
dom.subscribe = subscribe;
dom.default = event_iterator_1.EventIterator;

// copied from github.com/feross/buffer
// Some ArrayBuffers are not passing the instanceof check, so we need to do a bit more work :(
function isArrayBuffer(obj) {
    return (obj instanceof ArrayBuffer) ||
        (obj?.constructor?.name === 'ArrayBuffer' && typeof obj?.byteLength === 'number');
}
var source = (socket) => {
    socket.binaryType = 'arraybuffer';
    const connected = async () => {
        await new Promise((resolve, reject) => {
            if (isConnected) {
                resolve();
                return;
            }
            if (connError != null) {
                reject(connError);
                return;
            }
            const cleanUp = (cont) => {
                socket.removeEventListener('open', onOpen);
                socket.removeEventListener('error', onError);
                cont();
            };
            const onOpen = () => { cleanUp(resolve); };
            const onError = (event) => {
                cleanUp(() => { reject(event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`)); });
            };
            socket.addEventListener('open', onOpen);
            socket.addEventListener('error', onError);
        });
    };
    const source = (async function* () {
        const messages = new EventIterator(({ push, stop, fail }) => {
            const onMessage = (event) => {
                let data = null;
                if (typeof event.data === 'string') {
                    data = fromString(event.data);
                }
                if (isArrayBuffer(event.data)) {
                    data = new Uint8Array(event.data);
                }
                if (event.data instanceof Uint8Array) {
                    data = event.data;
                }
                if (data == null) {
                    return;
                }
                push(data);
            };
            const onError = (event) => { fail(event.error ?? new Error('Socket error')); };
            socket.addEventListener('message', onMessage);
            socket.addEventListener('error', onError);
            socket.addEventListener('close', stop);
            return () => {
                socket.removeEventListener('message', onMessage);
                socket.removeEventListener('error', onError);
                socket.removeEventListener('close', stop);
            };
        }, { highWaterMark: Infinity });
        await connected();
        for await (const chunk of messages) {
            yield isArrayBuffer(chunk) ? new Uint8Array(chunk) : chunk;
        }
    }());
    let isConnected = socket.readyState === 1;
    let connError;
    socket.addEventListener('open', () => {
        isConnected = true;
        connError = null;
    });
    socket.addEventListener('close', () => {
        isConnected = false;
        connError = null;
    });
    socket.addEventListener('error', event => {
        if (!isConnected) {
            connError = event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`);
        }
    });
    return Object.assign(source, {
        connected
    });
};

var duplex = (socket, options) => {
    options = options ?? {};
    const connectedSource = source(socket);
    let remoteAddress = options.remoteAddress;
    let remotePort = options.remotePort;
    if (socket.url != null) {
        // only client->server sockets have urls, server->client connections do not
        try {
            const url = new URL(socket.url);
            remoteAddress = url.hostname;
            remotePort = parseInt(url.port, 10);
        }
        catch { }
    }
    if (remoteAddress == null || remotePort == null) {
        throw new Error('Remote connection did not have address and/or port');
    }
    const duplex = {
        sink: sink(socket, options),
        source: connectedSource,
        connected: async () => { await connectedSource.connected(); },
        close: async () => {
            if (socket.readyState === socket.CONNECTING || socket.readyState === socket.OPEN) {
                await new Promise((resolve) => {
                    socket.addEventListener('close', () => {
                        resolve();
                    });
                    socket.close();
                });
            }
        },
        destroy: () => {
            if (socket.terminate != null) {
                socket.terminate();
            }
            else {
                socket.close();
            }
        },
        remoteAddress,
        remotePort,
        socket
    };
    return duplex;
};

/* eslint-env browser */
var WebSocket$1 = WebSocket;

const map = { 'http:': 'ws:', 'https:': 'wss:' };
const defaultProtocol = 'ws:';
var wsurl = (url, location) => {
    if (url.startsWith('//')) {
        url = `${location?.protocol ?? defaultProtocol}${url}`;
    }
    if (url.startsWith('/') && location != null) {
        const proto = location.protocol ?? defaultProtocol;
        const host = location.host;
        const port = location.port != null && host?.endsWith(`:${location.port}`) !== true ? `:${location.port}` : '';
        url = `${proto}//${host}${port}${url}`;
    }
    const wsUrl = new URL(url);
    for (const [httpProto, wsProto] of Object.entries(map)) {
        if (wsUrl.protocol === httpProto) {
            wsUrl.protocol = wsProto;
        }
    }
    return wsUrl;
};

// load websocket library if we are not in the browser
function connect(addr, opts) {
    const location = typeof window === 'undefined' ? undefined : window.location;
    opts = opts ?? {};
    const url = wsurl(addr, location);
    // it's necessary to stringify the URL object otherwise react-native crashes
    const socket = new WebSocket$1(url.toString(), opts.websocket);
    return duplex(socket, opts);
}

/**
 * An implementation of the ProgressEvent interface, this is essentially
 * a typed `CustomEvent` with a `type` property that lets us disambiguate
 * events passed to `progress` callbacks.
 */
class CustomProgressEvent extends Event {
    type;
    detail;
    constructor(type, detail) {
        super(type);
        this.type = type;
        // @ts-expect-error detail may be undefined
        this.detail = detail;
    }
}

/**
 * @deprecated Configure this globally by passing a `connectionGater` to `createLibp2p` with a `denyDialMultiaddr` method that returns `false`
 */
function all(multiaddrs) {
    return multiaddrs.filter((ma) => {
        return WebSocketsSecure.exactMatch(ma) || WebSockets$1.exactMatch(ma);
    });
}
/**
 * @deprecated Configure this globally by passing a `connectionGater` to `createLibp2p`
 */
function wss(multiaddrs) {
    return multiaddrs.filter((ma) => {
        return WebSocketsSecure.exactMatch(ma);
    });
}

function createListener() {
    throw new Error('WebSocket Servers can not be created in the browser!');
}

// Time to wait for a connection to close gracefully before destroying it manually
const CLOSE_TIMEOUT$1 = 500;

// Convert a stream into a MultiaddrConnection
// https://github.com/libp2p/interface-transport#multiaddrconnection
function socketToMaConn(stream, remoteAddr, options) {
    const log = options.logger.forComponent('libp2p:websockets:maconn');
    const metrics = options.metrics;
    const metricPrefix = options.metricPrefix ?? '';
    const maConn = {
        log,
        async sink(source) {
            try {
                await stream.sink((async function* () {
                    for await (const buf of source) {
                        if (buf instanceof Uint8Array) {
                            yield buf;
                        }
                        else {
                            yield buf.subarray();
                        }
                    }
                })());
            }
            catch (err) {
                if (err.type !== 'aborted') {
                    log.error(err);
                }
            }
        },
        source: stream.source,
        remoteAddr,
        timeline: { open: Date.now() },
        async close(options = {}) {
            const start = Date.now();
            if (options.signal == null) {
                const signal = AbortSignal.timeout(CLOSE_TIMEOUT$1);
                options = {
                    ...options,
                    signal
                };
            }
            const listener = () => {
                const { host, port } = maConn.remoteAddr.toOptions();
                log('timeout closing stream to %s:%s after %dms, destroying it manually', host, port, Date.now() - start);
                this.abort(new AbortError$4('Socket close timeout'));
            };
            options.signal?.addEventListener('abort', listener);
            try {
                await stream.close();
            }
            catch (err) {
                log.error('error closing WebSocket gracefully', err);
                this.abort(err);
            }
            finally {
                options.signal?.removeEventListener('abort', listener);
                maConn.timeline.close = Date.now();
            }
        },
        abort(err) {
            const { host, port } = maConn.remoteAddr.toOptions();
            log('timeout closing stream to %s:%s due to error', host, port, err);
            stream.destroy();
            maConn.timeline.close = Date.now();
            // ws WebSocket.terminate does not accept an Error arg to emit an 'error'
            // event on destroy like other node streams so we can't update a metric
            // with an event listener
            // https://github.com/websockets/ws/issues/1752#issuecomment-622380981
            metrics?.increment({ [`${metricPrefix}error`]: true });
        }
    };
    stream.socket.addEventListener('close', () => {
        metrics?.increment({ [`${metricPrefix}close`]: true });
        // In instances where `close` was not explicitly called,
        // such as an iterable stream ending, ensure we have set the close
        // timeline
        if (maConn.timeline.close == null) {
            maConn.timeline.close = Date.now();
        }
    }, { once: true });
    return maConn;
}

/**
 * @packageDocumentation
 *
 * A [libp2p transport](https://docs.libp2p.io/concepts/transports/overview/) based on [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API).
 *
 * @example
 *
 * ```TypeScript
 * import { createLibp2p } from 'libp2p'
 * import { webSockets } from '@libp2p/websockets'
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const node = await createLibp2p({
 *   transports: [
 *     webSockets()
 *   ]
 * //... other config
 * })
 * await node.start()
 *
 * const ma = multiaddr('/dns4/example.com/tcp/9090/tls/ws')
 * await node.dial(ma)
 * ```
 */
class WebSockets {
    log;
    init;
    logger;
    metrics;
    components;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:websockets');
        this.logger = components.logger;
        this.components = components;
        this.init = init;
        if (components.metrics != null) {
            this.metrics = {
                dialerEvents: components.metrics.registerCounterGroup('libp2p_websockets_dialer_events_total', {
                    label: 'event',
                    help: 'Total count of WebSockets dialer events by type'
                })
            };
        }
    }
    [transportSymbol] = true;
    [Symbol.toStringTag] = '@libp2p/websockets';
    [serviceCapabilities] = [
        '@libp2p/transport'
    ];
    async dial(ma, options) {
        this.log('dialing %s', ma);
        options = options ?? {};
        const socket = await this._connect(ma, options);
        const maConn = socketToMaConn(socket, ma, {
            logger: this.logger,
            metrics: this.metrics?.dialerEvents
        });
        this.log('new outbound connection %s', maConn.remoteAddr);
        const conn = await options.upgrader.upgradeOutbound(maConn, options);
        this.log('outbound connection %s upgraded', maConn.remoteAddr);
        return conn;
    }
    async _connect(ma, options) {
        options?.signal?.throwIfAborted();
        const cOpts = ma.toOptions();
        this.log('dialing %s:%s', cOpts.host, cOpts.port);
        const errorPromise = pDefer();
        const rawSocket = connect(multiaddrToUri(ma), this.init);
        rawSocket.socket.addEventListener('error', () => {
            // the WebSocket.ErrorEvent type doesn't actually give us any useful
            // information about what happened
            // https://developer.mozilla.org/en-US/docs/Web/API/WebSocket/error_event
            const err = new ConnectionFailedError(`Could not connect to ${ma.toString()}`);
            this.log.error('connection error:', err);
            this.metrics?.dialerEvents.increment({ error: true });
            errorPromise.reject(err);
        });
        try {
            options.onProgress?.(new CustomProgressEvent('websockets:open-connection'));
            await raceSignal(Promise.race([rawSocket.connected(), errorPromise.promise]), options.signal);
        }
        catch (err) {
            if (options.signal?.aborted) {
                this.metrics?.dialerEvents.increment({ abort: true });
            }
            rawSocket.close()
                .catch(err => {
                this.log.error('error closing raw socket', err);
            });
            throw err;
        }
        this.log('connected %s', ma);
        this.metrics?.dialerEvents.increment({ connect: true });
        return rawSocket;
    }
    /**
     * Creates a WebSockets listener. The provided `handler` function will be called
     * anytime a new incoming Connection has been successfully upgraded via
     * `upgrader.upgradeInbound`
     */
    createListener(options) {
        return createListener({
            logger: this.logger,
            events: this.components.events,
            metrics: this.components.metrics
        }, {
            ...this.init,
            ...options
        });
    }
    /**
     * Takes a list of `Multiaddr`s and returns only valid WebSockets addresses.
     * By default, in a browser environment only DNS+WSS multiaddr is accepted,
     * while in a Node.js environment DNS+{WS, WSS} multiaddrs are accepted.
     */
    listenFilter(multiaddrs) {
        multiaddrs = Array.isArray(multiaddrs) ? multiaddrs : [multiaddrs];
        if (this.init?.filter != null) {
            return this.init?.filter(multiaddrs);
        }
        return all(multiaddrs);
    }
    /**
     * Filter check for all Multiaddrs that this transport can dial
     */
    dialFilter(multiaddrs) {
        return this.listenFilter(multiaddrs);
    }
}
function webSockets(init = {}) {
    return (components) => {
        return new WebSockets(components, init);
    };
}

function isPlainObject(value) {
	if (typeof value !== 'object' || value === null) {
		return false;
	}

	const prototype = Object.getPrototypeOf(value);
	return (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);
}

const { hasOwnProperty } = Object.prototype;
const { propertyIsEnumerable } = Object;
const defineProperty = (object, name, value) => {
    Object.defineProperty(object, name, {
        value,
        writable: true,
        enumerable: true,
        configurable: true
    });
};
const globalThis$1 = undefined;
const defaultMergeOptions = {
    concatArrays: false,
    ignoreUndefined: false
};
const getEnumerableOwnPropertyKeys = (value) => {
    const keys = [];
    for (const key in value) {
        if (hasOwnProperty.call(value, key)) {
            keys.push(key);
        }
    }
    /* istanbul ignore else  */
    if (Object.getOwnPropertySymbols) {
        const symbols = Object.getOwnPropertySymbols(value);
        for (const symbol of symbols) {
            if (propertyIsEnumerable.call(value, symbol)) {
                keys.push(symbol);
            }
        }
    }
    return keys;
};
function clone(value) {
    if (Array.isArray(value)) {
        return cloneArray(value);
    }
    if (isPlainObject(value)) {
        return cloneOptionObject(value);
    }
    return value;
}
function cloneArray(array) {
    const result = array.slice(0, 0);
    getEnumerableOwnPropertyKeys(array).forEach(key => {
        defineProperty(result, key, clone(array[key]));
    });
    return result;
}
function cloneOptionObject(object) {
    const result = Object.getPrototypeOf(object) === null ? Object.create(null) : {};
    getEnumerableOwnPropertyKeys(object).forEach(key => {
        defineProperty(result, key, clone(object[key]));
    });
    return result;
}
const mergeKeys = (merged, source, keys, config) => {
    keys.forEach(key => {
        if (typeof source[key] === 'undefined' && config.ignoreUndefined) {
            return;
        }
        // Do not recurse into prototype chain of merged
        if (key in merged && merged[key] !== Object.getPrototypeOf(merged)) {
            defineProperty(merged, key, merge(merged[key], source[key], config));
        }
        else {
            defineProperty(merged, key, clone(source[key]));
        }
    });
    return merged;
};
/**
 * see [Array.prototype.concat ( ...arguments )](http://www.ecma-international.org/ecma-262/6.0/#sec-array.prototype.concat)
 */
const concatArrays = (merged, source, config) => {
    let result = merged.slice(0, 0);
    let resultIndex = 0;
    [merged, source].forEach(array => {
        const indices = [];
        // `result.concat(array)` with cloning
        for (let k = 0; k < array.length; k++) {
            if (!hasOwnProperty.call(array, k)) {
                continue;
            }
            indices.push(String(k));
            if (array === merged) {
                // Already cloned
                defineProperty(result, resultIndex++, array[k]);
            }
            else {
                defineProperty(result, resultIndex++, clone(array[k]));
            }
        }
        // Merge non-index keys
        result = mergeKeys(result, array, getEnumerableOwnPropertyKeys(array).filter(key => !indices.includes(key)), config);
    });
    return result;
};
function merge(merged, source, config) {
    if (config.concatArrays && Array.isArray(merged) && Array.isArray(source)) {
        return concatArrays(merged, source, config);
    }
    if (!isPlainObject(source) || !isPlainObject(merged)) {
        return clone(source);
    }
    return mergeKeys(merged, source, getEnumerableOwnPropertyKeys(source), config);
}
/**
 * Port of `merge-options` to typescript
 *
 * @see https://github.com/schnittstabil/merge-options/pull/28
 */
function mergeOptions(...options) {
    const config = merge(clone(defaultMergeOptions), (this !== globalThis$1 && this) || {}, defaultMergeOptions);
    let merged = { _: {} };
    for (const option of options) {
        if (option === undefined) {
            continue;
        }
        if (!isPlainObject(option)) {
            throw new TypeError('`' + option + '` is not an Option Object');
        }
        merged = merge(merged, { _: option }, config);
    }
    return merged._;
}

var eventemitter3 = {exports: {}};

(function (module) {

	var has = Object.prototype.hasOwnProperty
	  , prefix = '~';

	/**
	 * Constructor to create a storage for our `EE` objects.
	 * An `Events` instance is a plain object whose properties are event names.
	 *
	 * @constructor
	 * @private
	 */
	function Events() {}

	//
	// We try to not inherit from `Object.prototype`. In some engines creating an
	// instance in this way is faster than calling `Object.create(null)` directly.
	// If `Object.create(null)` is not supported we prefix the event names with a
	// character to make sure that the built-in object properties are not
	// overridden or used as an attack vector.
	//
	if (Object.create) {
	  Events.prototype = Object.create(null);

	  //
	  // This hack is needed because the `__proto__` property is still inherited in
	  // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.
	  //
	  if (!new Events().__proto__) prefix = false;
	}

	/**
	 * Representation of a single event listener.
	 *
	 * @param {Function} fn The listener function.
	 * @param {*} context The context to invoke the listener with.
	 * @param {Boolean} [once=false] Specify if the listener is a one-time listener.
	 * @constructor
	 * @private
	 */
	function EE(fn, context, once) {
	  this.fn = fn;
	  this.context = context;
	  this.once = once || false;
	}

	/**
	 * Add a listener for a given event.
	 *
	 * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} context The context to invoke the listener with.
	 * @param {Boolean} once Specify if the listener is a one-time listener.
	 * @returns {EventEmitter}
	 * @private
	 */
	function addListener(emitter, event, fn, context, once) {
	  if (typeof fn !== 'function') {
	    throw new TypeError('The listener must be a function');
	  }

	  var listener = new EE(fn, context || emitter, once)
	    , evt = prefix ? prefix + event : event;

	  if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;
	  else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);
	  else emitter._events[evt] = [emitter._events[evt], listener];

	  return emitter;
	}

	/**
	 * Clear event by name.
	 *
	 * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
	 * @param {(String|Symbol)} evt The Event name.
	 * @private
	 */
	function clearEvent(emitter, evt) {
	  if (--emitter._eventsCount === 0) emitter._events = new Events();
	  else delete emitter._events[evt];
	}

	/**
	 * Minimal `EventEmitter` interface that is molded against the Node.js
	 * `EventEmitter` interface.
	 *
	 * @constructor
	 * @public
	 */
	function EventEmitter() {
	  this._events = new Events();
	  this._eventsCount = 0;
	}

	/**
	 * Return an array listing the events for which the emitter has registered
	 * listeners.
	 *
	 * @returns {Array}
	 * @public
	 */
	EventEmitter.prototype.eventNames = function eventNames() {
	  var names = []
	    , events
	    , name;

	  if (this._eventsCount === 0) return names;

	  for (name in (events = this._events)) {
	    if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);
	  }

	  if (Object.getOwnPropertySymbols) {
	    return names.concat(Object.getOwnPropertySymbols(events));
	  }

	  return names;
	};

	/**
	 * Return the listeners registered for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Array} The registered listeners.
	 * @public
	 */
	EventEmitter.prototype.listeners = function listeners(event) {
	  var evt = prefix ? prefix + event : event
	    , handlers = this._events[evt];

	  if (!handlers) return [];
	  if (handlers.fn) return [handlers.fn];

	  for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {
	    ee[i] = handlers[i].fn;
	  }

	  return ee;
	};

	/**
	 * Return the number of listeners listening to a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Number} The number of listeners.
	 * @public
	 */
	EventEmitter.prototype.listenerCount = function listenerCount(event) {
	  var evt = prefix ? prefix + event : event
	    , listeners = this._events[evt];

	  if (!listeners) return 0;
	  if (listeners.fn) return 1;
	  return listeners.length;
	};

	/**
	 * Calls each of the listeners registered for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Boolean} `true` if the event had listeners, else `false`.
	 * @public
	 */
	EventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {
	  var evt = prefix ? prefix + event : event;

	  if (!this._events[evt]) return false;

	  var listeners = this._events[evt]
	    , len = arguments.length
	    , args
	    , i;

	  if (listeners.fn) {
	    if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);

	    switch (len) {
	      case 1: return listeners.fn.call(listeners.context), true;
	      case 2: return listeners.fn.call(listeners.context, a1), true;
	      case 3: return listeners.fn.call(listeners.context, a1, a2), true;
	      case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;
	      case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;
	      case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;
	    }

	    for (i = 1, args = new Array(len -1); i < len; i++) {
	      args[i - 1] = arguments[i];
	    }

	    listeners.fn.apply(listeners.context, args);
	  } else {
	    var length = listeners.length
	      , j;

	    for (i = 0; i < length; i++) {
	      if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);

	      switch (len) {
	        case 1: listeners[i].fn.call(listeners[i].context); break;
	        case 2: listeners[i].fn.call(listeners[i].context, a1); break;
	        case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;
	        case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;
	        default:
	          if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {
	            args[j - 1] = arguments[j];
	          }

	          listeners[i].fn.apply(listeners[i].context, args);
	      }
	    }
	  }

	  return true;
	};

	/**
	 * Add a listener for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} [context=this] The context to invoke the listener with.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.on = function on(event, fn, context) {
	  return addListener(this, event, fn, context, false);
	};

	/**
	 * Add a one-time listener for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} [context=this] The context to invoke the listener with.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.once = function once(event, fn, context) {
	  return addListener(this, event, fn, context, true);
	};

	/**
	 * Remove the listeners of a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn Only remove the listeners that match this function.
	 * @param {*} context Only remove the listeners that have this context.
	 * @param {Boolean} once Only remove one-time listeners.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {
	  var evt = prefix ? prefix + event : event;

	  if (!this._events[evt]) return this;
	  if (!fn) {
	    clearEvent(this, evt);
	    return this;
	  }

	  var listeners = this._events[evt];

	  if (listeners.fn) {
	    if (
	      listeners.fn === fn &&
	      (!once || listeners.once) &&
	      (!context || listeners.context === context)
	    ) {
	      clearEvent(this, evt);
	    }
	  } else {
	    for (var i = 0, events = [], length = listeners.length; i < length; i++) {
	      if (
	        listeners[i].fn !== fn ||
	        (once && !listeners[i].once) ||
	        (context && listeners[i].context !== context)
	      ) {
	        events.push(listeners[i]);
	      }
	    }

	    //
	    // Reset the array, or remove it completely if we have no more listeners.
	    //
	    if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;
	    else clearEvent(this, evt);
	  }

	  return this;
	};

	/**
	 * Remove all listeners, or those of the specified event.
	 *
	 * @param {(String|Symbol)} [event] The event name.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {
	  var evt;

	  if (event) {
	    evt = prefix ? prefix + event : event;
	    if (this._events[evt]) clearEvent(this, evt);
	  } else {
	    this._events = new Events();
	    this._eventsCount = 0;
	  }

	  return this;
	};

	//
	// Alias methods names because people roll like that.
	//
	EventEmitter.prototype.off = EventEmitter.prototype.removeListener;
	EventEmitter.prototype.addListener = EventEmitter.prototype.on;

	//
	// Expose the prefix.
	//
	EventEmitter.prefixed = prefix;

	//
	// Allow `EventEmitter` to be imported as module namespace.
	//
	EventEmitter.EventEmitter = EventEmitter;

	//
	// Expose the module.
	//
	{
	  module.exports = EventEmitter;
	} 
} (eventemitter3));

var eventemitter3Exports = eventemitter3.exports;
var EventEmitter = /*@__PURE__*/getDefaultExportFromCjs(eventemitter3Exports);

class TimeoutError extends Error {
	constructor(message) {
		super(message);
		this.name = 'TimeoutError';
	}
}

/**
An error to be thrown when the request is aborted by AbortController.
DOMException is thrown instead of this Error when DOMException is available.
*/
let AbortError$3 = class AbortError extends Error {
	constructor(message) {
		super();
		this.name = 'AbortError';
		this.message = message;
	}
};

/**
TODO: Remove AbortError and just throw DOMException when targeting Node 18.
*/
const getDOMException = errorMessage => globalThis.DOMException === undefined
	? new AbortError$3(errorMessage)
	: new DOMException(errorMessage);

/**
TODO: Remove below function and just 'reject(signal.reason)' when targeting Node 18.
*/
const getAbortedReason = signal => {
	const reason = signal.reason === undefined
		? getDOMException('This operation was aborted.')
		: signal.reason;

	return reason instanceof Error ? reason : getDOMException(reason);
};

function pTimeout(promise, options) {
	const {
		milliseconds,
		fallback,
		message,
		customTimers = {setTimeout, clearTimeout},
	} = options;

	let timer;
	let abortHandler;

	const wrappedPromise = new Promise((resolve, reject) => {
		if (typeof milliseconds !== 'number' || Math.sign(milliseconds) !== 1) {
			throw new TypeError(`Expected \`milliseconds\` to be a positive number, got \`${milliseconds}\``);
		}

		if (options.signal) {
			const {signal} = options;
			if (signal.aborted) {
				reject(getAbortedReason(signal));
			}

			abortHandler = () => {
				reject(getAbortedReason(signal));
			};

			signal.addEventListener('abort', abortHandler, {once: true});
		}

		if (milliseconds === Number.POSITIVE_INFINITY) {
			promise.then(resolve, reject);
			return;
		}

		// We create the error outside of `setTimeout` to preserve the stack trace.
		const timeoutError = new TimeoutError();

		timer = customTimers.setTimeout.call(undefined, () => {
			if (fallback) {
				try {
					resolve(fallback());
				} catch (error) {
					reject(error);
				}

				return;
			}

			if (typeof promise.cancel === 'function') {
				promise.cancel();
			}

			if (message === false) {
				resolve();
			} else if (message instanceof Error) {
				reject(message);
			} else {
				timeoutError.message = message ?? `Promise timed out after ${milliseconds} milliseconds`;
				reject(timeoutError);
			}
		}, milliseconds);

		(async () => {
			try {
				resolve(await promise);
			} catch (error) {
				reject(error);
			}
		})();
	});

	const cancelablePromise = wrappedPromise.finally(() => {
		cancelablePromise.clear();
		if (abortHandler && options.signal) {
			options.signal.removeEventListener('abort', abortHandler);
		}
	});

	cancelablePromise.clear = () => {
		customTimers.clearTimeout.call(undefined, timer);
		timer = undefined;
	};

	return cancelablePromise;
}

// Port of lower_bound from https://en.cppreference.com/w/cpp/algorithm/lower_bound
// Used to compute insertion index to keep queue sorted after insertion
function lowerBound(array, value, comparator) {
    let first = 0;
    let count = array.length;
    while (count > 0) {
        const step = Math.trunc(count / 2);
        let it = first + step;
        if (comparator(array[it], value) <= 0) {
            first = ++it;
            count -= step + 1;
        }
        else {
            count = step;
        }
    }
    return first;
}

let PriorityQueue$1 = class PriorityQueue {
    #queue = [];
    enqueue(run, options) {
        options = {
            priority: 0,
            ...options,
        };
        const element = {
            priority: options.priority,
            id: options.id,
            run,
        };
        if (this.size === 0 || this.#queue[this.size - 1].priority >= options.priority) {
            this.#queue.push(element);
            return;
        }
        const index = lowerBound(this.#queue, element, (a, b) => b.priority - a.priority);
        this.#queue.splice(index, 0, element);
    }
    setPriority(id, priority) {
        const index = this.#queue.findIndex((element) => element.id === id);
        if (index === -1) {
            throw new ReferenceError(`No promise function with the id "${id}" exists in the queue.`);
        }
        const [item] = this.#queue.splice(index, 1);
        this.enqueue(item.run, { priority, id });
    }
    dequeue() {
        const item = this.#queue.shift();
        return item?.run;
    }
    filter(options) {
        return this.#queue.filter((element) => element.priority === options.priority).map((element) => element.run);
    }
    get size() {
        return this.#queue.length;
    }
};

/**
Promise queue with concurrency control.
*/
class PQueue extends EventEmitter {
    #carryoverConcurrencyCount;
    #isIntervalIgnored;
    #intervalCount = 0;
    #intervalCap;
    #interval;
    #intervalEnd = 0;
    #intervalId;
    #timeoutId;
    #queue;
    #queueClass;
    #pending = 0;
    // The `!` is needed because of https://github.com/microsoft/TypeScript/issues/32194
    #concurrency;
    #isPaused;
    #throwOnTimeout;
    // Use to assign a unique identifier to a promise function, if not explicitly specified
    #idAssigner = 1n;
    /**
    Per-operation timeout in milliseconds. Operations fulfill once `timeout` elapses if they haven't already.

    Applies to each future operation.
    */
    timeout;
    // TODO: The `throwOnTimeout` option should affect the return types of `add()` and `addAll()`
    constructor(options) {
        super();
        // eslint-disable-next-line @typescript-eslint/consistent-type-assertions
        options = {
            carryoverConcurrencyCount: false,
            intervalCap: Number.POSITIVE_INFINITY,
            interval: 0,
            concurrency: Number.POSITIVE_INFINITY,
            autoStart: true,
            queueClass: PriorityQueue$1,
            ...options,
        };
        if (!(typeof options.intervalCap === 'number' && options.intervalCap >= 1)) {
            throw new TypeError(`Expected \`intervalCap\` to be a number from 1 and up, got \`${options.intervalCap?.toString() ?? ''}\` (${typeof options.intervalCap})`);
        }
        if (options.interval === undefined || !(Number.isFinite(options.interval) && options.interval >= 0)) {
            throw new TypeError(`Expected \`interval\` to be a finite number >= 0, got \`${options.interval?.toString() ?? ''}\` (${typeof options.interval})`);
        }
        this.#carryoverConcurrencyCount = options.carryoverConcurrencyCount;
        this.#isIntervalIgnored = options.intervalCap === Number.POSITIVE_INFINITY || options.interval === 0;
        this.#intervalCap = options.intervalCap;
        this.#interval = options.interval;
        this.#queue = new options.queueClass();
        this.#queueClass = options.queueClass;
        this.concurrency = options.concurrency;
        this.timeout = options.timeout;
        this.#throwOnTimeout = options.throwOnTimeout === true;
        this.#isPaused = options.autoStart === false;
    }
    get #doesIntervalAllowAnother() {
        return this.#isIntervalIgnored || this.#intervalCount < this.#intervalCap;
    }
    get #doesConcurrentAllowAnother() {
        return this.#pending < this.#concurrency;
    }
    #next() {
        this.#pending--;
        this.#tryToStartAnother();
        this.emit('next');
    }
    #onResumeInterval() {
        this.#onInterval();
        this.#initializeIntervalIfNeeded();
        this.#timeoutId = undefined;
    }
    get #isIntervalPaused() {
        const now = Date.now();
        if (this.#intervalId === undefined) {
            const delay = this.#intervalEnd - now;
            if (delay < 0) {
                // Act as the interval was done
                // We don't need to resume it here because it will be resumed on line 160
                this.#intervalCount = (this.#carryoverConcurrencyCount) ? this.#pending : 0;
            }
            else {
                // Act as the interval is pending
                if (this.#timeoutId === undefined) {
                    this.#timeoutId = setTimeout(() => {
                        this.#onResumeInterval();
                    }, delay);
                }
                return true;
            }
        }
        return false;
    }
    #tryToStartAnother() {
        if (this.#queue.size === 0) {
            // We can clear the interval ("pause")
            // Because we can redo it later ("resume")
            if (this.#intervalId) {
                clearInterval(this.#intervalId);
            }
            this.#intervalId = undefined;
            this.emit('empty');
            if (this.#pending === 0) {
                this.emit('idle');
            }
            return false;
        }
        if (!this.#isPaused) {
            const canInitializeInterval = !this.#isIntervalPaused;
            if (this.#doesIntervalAllowAnother && this.#doesConcurrentAllowAnother) {
                const job = this.#queue.dequeue();
                if (!job) {
                    return false;
                }
                this.emit('active');
                job();
                if (canInitializeInterval) {
                    this.#initializeIntervalIfNeeded();
                }
                return true;
            }
        }
        return false;
    }
    #initializeIntervalIfNeeded() {
        if (this.#isIntervalIgnored || this.#intervalId !== undefined) {
            return;
        }
        this.#intervalId = setInterval(() => {
            this.#onInterval();
        }, this.#interval);
        this.#intervalEnd = Date.now() + this.#interval;
    }
    #onInterval() {
        if (this.#intervalCount === 0 && this.#pending === 0 && this.#intervalId) {
            clearInterval(this.#intervalId);
            this.#intervalId = undefined;
        }
        this.#intervalCount = this.#carryoverConcurrencyCount ? this.#pending : 0;
        this.#processQueue();
    }
    /**
    Executes all queued functions until it reaches the limit.
    */
    #processQueue() {
        // eslint-disable-next-line no-empty
        while (this.#tryToStartAnother()) { }
    }
    get concurrency() {
        return this.#concurrency;
    }
    set concurrency(newConcurrency) {
        if (!(typeof newConcurrency === 'number' && newConcurrency >= 1)) {
            throw new TypeError(`Expected \`concurrency\` to be a number from 1 and up, got \`${newConcurrency}\` (${typeof newConcurrency})`);
        }
        this.#concurrency = newConcurrency;
        this.#processQueue();
    }
    async #throwOnAbort(signal) {
        return new Promise((_resolve, reject) => {
            signal.addEventListener('abort', () => {
                reject(signal.reason);
            }, { once: true });
        });
    }
    /**
    Updates the priority of a promise function by its id, affecting its execution order. Requires a defined concurrency limit to take effect.

    For example, this can be used to prioritize a promise function to run earlier.

    ```js
    import PQueue from 'p-queue';

    const queue = new PQueue({concurrency: 1});

    queue.add(async () => '🦄', {priority: 1});
    queue.add(async () => '🦀', {priority: 0, id: '🦀'});
    queue.add(async () => '🦄', {priority: 1});
    queue.add(async () => '🦄', {priority: 1});

    queue.setPriority('🦀', 2);
    ```

    In this case, the promise function with `id: '🦀'` runs second.

    You can also deprioritize a promise function to delay its execution:

    ```js
    import PQueue from 'p-queue';

    const queue = new PQueue({concurrency: 1});

    queue.add(async () => '🦄', {priority: 1});
    queue.add(async () => '🦀', {priority: 1, id: '🦀'});
    queue.add(async () => '🦄');
    queue.add(async () => '🦄', {priority: 0});

    queue.setPriority('🦀', -1);
    ```
    Here, the promise function with `id: '🦀'` executes last.
    */
    setPriority(id, priority) {
        this.#queue.setPriority(id, priority);
    }
    async add(function_, options = {}) {
        // In case `id` is not defined.
        options.id ??= (this.#idAssigner++).toString();
        options = {
            timeout: this.timeout,
            throwOnTimeout: this.#throwOnTimeout,
            ...options,
        };
        return new Promise((resolve, reject) => {
            this.#queue.enqueue(async () => {
                this.#pending++;
                this.#intervalCount++;
                try {
                    options.signal?.throwIfAborted();
                    let operation = function_({ signal: options.signal });
                    if (options.timeout) {
                        operation = pTimeout(Promise.resolve(operation), { milliseconds: options.timeout });
                    }
                    if (options.signal) {
                        operation = Promise.race([operation, this.#throwOnAbort(options.signal)]);
                    }
                    const result = await operation;
                    resolve(result);
                    this.emit('completed', result);
                }
                catch (error) {
                    if (error instanceof TimeoutError && !options.throwOnTimeout) {
                        resolve();
                        return;
                    }
                    reject(error);
                    this.emit('error', error);
                }
                finally {
                    this.#next();
                }
            }, options);
            this.emit('add');
            this.#tryToStartAnother();
        });
    }
    async addAll(functions, options) {
        return Promise.all(functions.map(async (function_) => this.add(function_, options)));
    }
    /**
    Start (or resume) executing enqueued tasks within concurrency limit. No need to call this if queue is not paused (via `options.autoStart = false` or by `.pause()` method.)
    */
    start() {
        if (!this.#isPaused) {
            return this;
        }
        this.#isPaused = false;
        this.#processQueue();
        return this;
    }
    /**
    Put queue execution on hold.
    */
    pause() {
        this.#isPaused = true;
    }
    /**
    Clear the queue.
    */
    clear() {
        this.#queue = new this.#queueClass();
    }
    /**
    Can be called multiple times. Useful if you for example add additional items at a later time.

    @returns A promise that settles when the queue becomes empty.
    */
    async onEmpty() {
        // Instantly resolve if the queue is empty
        if (this.#queue.size === 0) {
            return;
        }
        await this.#onEvent('empty');
    }
    /**
    @returns A promise that settles when the queue size is less than the given limit: `queue.size < limit`.

    If you want to avoid having the queue grow beyond a certain size you can `await queue.onSizeLessThan()` before adding a new item.

    Note that this only limits the number of items waiting to start. There could still be up to `concurrency` jobs already running that this call does not include in its calculation.
    */
    async onSizeLessThan(limit) {
        // Instantly resolve if the queue is empty.
        if (this.#queue.size < limit) {
            return;
        }
        await this.#onEvent('next', () => this.#queue.size < limit);
    }
    /**
    The difference with `.onEmpty` is that `.onIdle` guarantees that all work from the queue has finished. `.onEmpty` merely signals that the queue is empty, but it could mean that some promises haven't completed yet.

    @returns A promise that settles when the queue becomes empty, and all promises have completed; `queue.size === 0 && queue.pending === 0`.
    */
    async onIdle() {
        // Instantly resolve if none pending and if nothing else is queued
        if (this.#pending === 0 && this.#queue.size === 0) {
            return;
        }
        await this.#onEvent('idle');
    }
    async #onEvent(event, filter) {
        return new Promise(resolve => {
            const listener = () => {
                if (filter && !filter()) {
                    return;
                }
                this.off(event, listener);
                resolve();
            };
            this.on(event, listener);
        });
    }
    /**
    Size of the queue, the number of queued items waiting to run.
    */
    get size() {
        return this.#queue.size;
    }
    /**
    Size of the queue, filtered by the given options.

    For example, this can be used to find the number of items remaining in the queue with a specific priority level.
    */
    sizeBy(options) {
        // eslint-disable-next-line unicorn/no-array-callback-reference
        return this.#queue.filter(options).length;
    }
    /**
    Number of running items (no longer in the queue).
    */
    get pending() {
        return this.#pending;
    }
    /**
    Whether the queue is currently paused.
    */
    get isPaused() {
        return this.#isPaused;
    }
}

function getTypes(types) {
    const DEFAULT_TYPES = [
        RecordType.A
    ];
    if (types == null) {
        return DEFAULT_TYPES;
    }
    if (Array.isArray(types)) {
        if (types.length === 0) {
            return DEFAULT_TYPES;
        }
        return types;
    }
    return [
        types
    ];
}

/**
 * This TTL will be used if the remote service does not return one
 */
const DEFAULT_TTL = 60;
function toDNSResponse(obj) {
    return {
        Status: obj.Status ?? 0,
        TC: obj.TC ?? obj.flag_tc ?? false,
        RD: obj.RD ?? obj.flag_rd ?? false,
        RA: obj.RA ?? obj.flag_ra ?? false,
        AD: obj.AD ?? obj.flag_ad ?? false,
        CD: obj.CD ?? obj.flag_cd ?? false,
        Question: (obj.Question ?? obj.questions ?? []).map((question) => {
            return {
                name: question.name,
                type: RecordType[question.type]
            };
        }),
        Answer: (obj.Answer ?? obj.answers ?? []).map((answer) => {
            return {
                name: answer.name,
                type: RecordType[answer.type],
                TTL: (answer.TTL ?? answer.ttl ?? DEFAULT_TTL),
                data: answer.data instanceof Uint8Array ? toString(answer.data) : answer.data
            };
        })
    };
}

/* eslint-env browser */
/**
 * Browsers limit concurrent connections per host (~6), we don't want to exhaust
 * the limit so this value controls how many DNS queries can be in flight at
 * once.
 */
const DEFAULT_QUERY_CONCURRENCY = 4;
/**
 * Uses the RFC 8427 'application/dns-json' content-type to resolve DNS queries.
 *
 * Supports and server that uses the same schema as Google's DNS over HTTPS
 * resolver.
 *
 * This resolver needs fewer dependencies than the regular DNS-over-HTTPS
 * resolver so can result in a smaller bundle size and consequently is preferred
 * for browser use.
 *
 * @see https://developers.cloudflare.com/1.1.1.1/encryption/dns-over-https/make-api-requests/dns-json/
 * @see https://github.com/curl/curl/wiki/DNS-over-HTTPS#publicly-available-servers
 * @see https://dnsprivacy.org/public_resolvers/
 * @see https://datatracker.ietf.org/doc/html/rfc8427
 */
function dnsJsonOverHttps(url, init = {}) {
    const httpQueue = new PQueue({
        concurrency: init.queryConcurrency ?? DEFAULT_QUERY_CONCURRENCY
    });
    return async (fqdn, options = {}) => {
        const searchParams = new URLSearchParams();
        searchParams.set('name', fqdn);
        getTypes(options.types).forEach(type => {
            // We pass record type as a string to the server because cloudflare DNS bug. see https://github.com/ipfs/helia/issues/474
            searchParams.append('type', RecordType[type]);
        });
        options.onProgress?.(new CustomProgressEvent('dns:query', { detail: fqdn }));
        // query DNS-JSON over HTTPS server
        const response = await httpQueue.add(async () => {
            const res = await fetch(`${url}?${searchParams}`, {
                headers: {
                    accept: 'application/dns-json'
                },
                signal: options?.signal
            });
            if (res.status !== 200) {
                throw new Error(`Unexpected HTTP status: ${res.status} - ${res.statusText}`);
            }
            const response = toDNSResponse(await res.json());
            options.onProgress?.(new CustomProgressEvent('dns:response', { detail: response }));
            return response;
        }, {
            signal: options.signal
        });
        if (response == null) {
            throw new Error('No DNS response received');
        }
        return response;
    };
}

function defaultResolver() {
    return [
        dnsJsonOverHttps('https://cloudflare-dns.com/dns-query'),
        dnsJsonOverHttps('https://dns.google/resolve')
    ];
}

var hashlru = function (max) {

  if (!max) throw Error('hashlru must have a max value, of type number, greater than 0')

  var size = 0, cache = Object.create(null), _cache = Object.create(null);

  function update (key, value) {
    cache[key] = value;
    size ++;
    if(size >= max) {
      size = 0;
      _cache = cache;
      cache = Object.create(null);
    }
  }

  return {
    has: function (key) {
      return cache[key] !== undefined || _cache[key] !== undefined
    },
    remove: function (key) {
      if(cache[key] !== undefined)
        cache[key] = undefined;
      if(_cache[key] !== undefined)
        _cache[key] = undefined;
    },
    get: function (key) {
      var v = cache[key];
      if(v !== undefined) return v
      if((v = _cache[key]) !== undefined) {
        update(key, v);
        return v
      }
    },
    set: function (key, value) {
      if(cache[key] !== undefined) cache[key] = value;
      else update(key, value);
    },
    clear: function () {
      cache = Object.create(null);
      _cache = Object.create(null);
    }
  }
};

var hashlru$1 = /*@__PURE__*/getDefaultExportFromCjs(hashlru);

/**
 * Time Aware Least Recent Used Cache
 *
 * @see https://arxiv.org/pdf/1801.00390
 */
class CachedAnswers {
    lru;
    constructor(maxSize) {
        this.lru = hashlru$1(maxSize);
    }
    get(fqdn, types) {
        let foundAllAnswers = true;
        const answers = [];
        for (const type of types) {
            const cached = this.getAnswers(fqdn, type);
            if (cached.length === 0) {
                foundAllAnswers = false;
                break;
            }
            answers.push(...cached);
        }
        if (foundAllAnswers) {
            return toDNSResponse({ answers });
        }
    }
    getAnswers(domain, type) {
        const key = `${domain.toLowerCase()}-${type}`;
        const answers = this.lru.get(key);
        if (answers != null) {
            const cachedAnswers = answers
                .filter((entry) => {
                return entry.expires > Date.now();
            })
                .map(({ expires, value }) => ({
                ...value,
                TTL: Math.round((expires - Date.now()) / 1000),
                type: RecordType[value.type]
            }));
            if (cachedAnswers.length === 0) {
                this.lru.remove(key);
            }
            // @ts-expect-error hashlru stringifies stored types which turns enums
            // into strings, we convert back into enums above but tsc doesn't know
            return cachedAnswers;
        }
        return [];
    }
    add(domain, answer) {
        const key = `${domain.toLowerCase()}-${answer.type}`;
        const answers = this.lru.get(key) ?? [];
        answers.push({
            expires: Date.now() + ((answer.TTL ?? DEFAULT_TTL) * 1000),
            value: answer
        });
        this.lru.set(key, answers);
    }
    remove(domain, type) {
        const key = `${domain.toLowerCase()}-${type}`;
        this.lru.remove(key);
    }
    clear() {
        this.lru.clear();
    }
}
/**
 * Avoid sending multiple queries for the same hostname by caching results
 */
function cache(size) {
    return new CachedAnswers(size);
}

const DEFAULT_ANSWER_CACHE_SIZE = 1000;
class DNS {
    resolvers;
    cache;
    constructor(init) {
        this.resolvers = {};
        this.cache = cache(init.cacheSize ?? DEFAULT_ANSWER_CACHE_SIZE);
        Object.entries(init.resolvers ?? {}).forEach(([tld, resolver]) => {
            if (!Array.isArray(resolver)) {
                resolver = [resolver];
            }
            // convert `com` -> `com.`
            if (!tld.endsWith('.')) {
                tld = `${tld}.`;
            }
            this.resolvers[tld] = resolver;
        });
        // configure default resolver if none specified
        if (this.resolvers['.'] == null) {
            this.resolvers['.'] = defaultResolver();
        }
    }
    /**
     * Queries DNS resolvers for the passed record types for the passed domain.
     *
     * If cached records exist for all desired types they will be returned
     * instead.
     *
     * Any new responses will be added to the cache for subsequent requests.
     */
    async query(domain, options = {}) {
        const types = getTypes(options.types);
        const cached = options.cached !== false ? this.cache.get(domain, types) : undefined;
        if (cached != null) {
            options.onProgress?.(new CustomProgressEvent('dns:cache', { detail: cached }));
            return cached;
        }
        const tld = `${domain.split('.').pop()}.`;
        const resolvers = (this.resolvers[tld] ?? this.resolvers['.']).sort(() => {
            return (Math.random() > 0.5) ? -1 : 1;
        });
        const errors = [];
        for (const resolver of resolvers) {
            // skip further resolutions if the user aborted the signal
            if (options.signal?.aborted === true) {
                break;
            }
            try {
                const result = await resolver(domain, {
                    ...options,
                    types
                });
                for (const answer of result.Answer) {
                    this.cache.add(domain, answer);
                }
                return result;
            }
            catch (err) {
                errors.push(err);
                options.onProgress?.(new CustomProgressEvent('dns:error', { detail: err }));
            }
        }
        if (errors.length === 1) {
            throw errors[0];
        }
        throw new AggregateError(errors, `DNS lookup of ${domain} ${types} failed`);
    }
}

/**
 * @packageDocumentation
 *
 * Query DNS records using `node:dns`, DNS over HTTP and/or DNSJSON over HTTP.
 *
 * A list of publicly accessible servers can be found [here](https://github.com/curl/curl/wiki/DNS-over-HTTPS#publicly-available-servers).
 *
 * @example Using the default resolver
 *
 * ```TypeScript
 * import { dns } from '@multiformats/dns'
 *
 * const resolver = dns()
 *
 * // resolve A records with a 5s timeout
 * const result = await dns.query('google.com', {
 *   signal: AbortSignal.timeout(5000)
 * })
 * ```
 *
 * @example Using per-TLD resolvers
 *
 * ```TypeScript
 * import { dns } from '@multiformats/dns'
 * import { dnsJsonOverHttps } from '@multiformats/dns/resolvers'
 *
 * const resolver = dns({
 *   resolvers: {
 *     // will only be used to resolve `.com` addresses
 *     'com.': dnsJsonOverHttps('https://cloudflare-dns.com/dns-query'),
 *
 *     // this can also be an array, resolvers will be shuffled and tried in
 *     // series
 *     'net.': [
 *       dnsJsonOverHttps('https://dns.google/resolve'),
 *       dnsJsonOverHttps('https://dns.pub/dns-query')
 *     ],
 *
 *     // will only be used to resolve all other addresses
 *     '.': dnsJsonOverHttps('https://dnsforge.de/dns-query'),
 *   }
 * })
 * ```
 *
 * @example Query for specific record types
 *
 * ```TypeScript
 * import { dns, RecordType } from '@multiformats/dns'
 *
 * const resolver = dns()
 *
 * // resolve only TXT records
 * const result = await dns.query('google.com', {
 *   types: [
 *     RecordType.TXT
 *   ]
 * })
 * ```
 *
 * ## Caching
 *
 * Individual Aanswers are cached so. If you make a request, for which all
 * record types are cached, all values will be pulled from the cache.
 *
 * If any of the record types are not cached, a new request will be resolved as
 * if none of the records were cached, and the cache will be updated to include
 * the new results.
 *
 * @example Ignoring the cache
 *
 * ```TypeScript
 * import { dns, RecordType } from '@multiformats/dns'
 *
 * const resolver = dns()
 *
 * // do not used cached results, always resolve a new query
 * const result = await dns.query('google.com', {
 *   cached: false
 * })
 * ```
 */
/**
 * A subset of DNS Record Types
 *
 * @see https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-4.
 */
var RecordType;
(function (RecordType) {
    RecordType[RecordType["A"] = 1] = "A";
    RecordType[RecordType["CNAME"] = 5] = "CNAME";
    RecordType[RecordType["TXT"] = 16] = "TXT";
    RecordType[RecordType["AAAA"] = 28] = "AAAA";
})(RecordType || (RecordType = {}));
function dns(init = {}) {
    return new DNS(init);
}

const V = -1;
const names = {};
const codes = {};
const table = [
    [4, 32, 'ip4'],
    [6, 16, 'tcp'],
    [33, 16, 'dccp'],
    [41, 128, 'ip6'],
    [42, V, 'ip6zone'],
    [43, 8, 'ipcidr'],
    [53, V, 'dns', true],
    [54, V, 'dns4', true],
    [55, V, 'dns6', true],
    [56, V, 'dnsaddr', true],
    [132, 16, 'sctp'],
    [273, 16, 'udp'],
    [275, 0, 'p2p-webrtc-star'],
    [276, 0, 'p2p-webrtc-direct'],
    [277, 0, 'p2p-stardust'],
    [280, 0, 'webrtc-direct'],
    [281, 0, 'webrtc'],
    [290, 0, 'p2p-circuit'],
    [301, 0, 'udt'],
    [302, 0, 'utp'],
    [400, V, 'unix', false, true],
    // `ipfs` is added before `p2p` for legacy support.
    // All text representations will default to `p2p`, but `ipfs` will
    // still be supported
    [421, V, 'ipfs'],
    // `p2p` is the preferred name for 421, and is now the default
    [421, V, 'p2p'],
    [443, 0, 'https'],
    [444, 96, 'onion'],
    [445, 296, 'onion3'],
    [446, V, 'garlic64'],
    [448, 0, 'tls'],
    [449, V, 'sni'],
    [460, 0, 'quic'],
    [461, 0, 'quic-v1'],
    [465, 0, 'webtransport'],
    [466, V, 'certhash'],
    [477, 0, 'ws'],
    [478, 0, 'wss'],
    [479, 0, 'p2p-websocket-star'],
    [480, 0, 'http'],
    [481, V, 'http-path'],
    [777, V, 'memory']
];
// populate tables
table.forEach(row => {
    const proto = createProtocol(...row);
    codes[proto.code] = proto;
    names[proto.name] = proto;
});
function createProtocol(code, size, name, resolvable, path) {
    return {
        code,
        size,
        name,
        resolvable: Boolean(resolvable),
        path: Boolean(path)
    };
}
/**
 * For the passed proto string or number, return a {@link Protocol}
 *
 * @example
 *
 * ```js
 * import { protocol } from '@multiformats/multiaddr'
 *
 * console.info(protocol(4))
 * // { code: 4, size: 32, name: 'ip4', resolvable: false, path: false }
 * ```
 *
 * @deprecated This will be removed in a future version
 */
function getProtocol(proto) {
    {
        if (names[proto] != null) {
            return names[proto];
        }
        throw new Error(`no protocol with name: ${proto}`);
    }
}

const MAX_RECURSIVE_DEPTH = 32;
const { code: dnsaddrCode } = getProtocol('dnsaddr');
class RecursionLimitError extends Error {
    constructor(message = 'Max recursive depth reached') {
        super(message);
        this.name = 'RecursionLimitError';
    }
}
const dnsaddrResolver = async function dnsaddrResolver(ma, options = {}) {
    const recursionLimit = options.maxRecursiveDepth ?? MAX_RECURSIVE_DEPTH;
    if (recursionLimit === 0) {
        throw new RecursionLimitError('Max recursive depth reached');
    }
    const [, hostname] = ma.stringTuples().find(([proto]) => proto === dnsaddrCode) ?? [];
    const resolver = options?.dns ?? dns();
    const result = await resolver.query(`_dnsaddr.${hostname}`, {
        signal: options?.signal,
        types: [
            RecordType.TXT
        ]
    });
    const peerId = ma.getPeerId();
    const output = [];
    for (const answer of result.Answer) {
        const addr = answer.data
            .replace(/["']/g, '')
            .trim()
            .split('=')[1];
        if (addr == null) {
            continue;
        }
        if (peerId != null && !addr.includes(peerId)) {
            continue;
        }
        const ma = multiaddr(addr);
        if (addr.startsWith('/dnsaddr')) {
            const resolved = await ma.resolve({
                ...options,
                maxRecursiveDepth: recursionLimit - 1
            });
            output.push(...resolved.map(ma => ma.toString()));
        }
        else {
            output.push(ma.toString());
        }
    }
    return output;
};

const DefaultConfig = {
    addresses: {
        listen: [],
        announce: [],
        noAnnounce: [],
        announceFilter: (multiaddrs) => multiaddrs
    },
    connectionManager: {
        resolvers: {
            dnsaddr: dnsaddrResolver
        }
    },
    transportManager: {
        faultTolerance: FaultTolerance.FATAL_ALL
    }
};
async function validateConfig(opts) {
    const resultingOptions = mergeOptions(DefaultConfig, opts);
    if (resultingOptions.connectionProtector === null && globalThis.process?.env?.LIBP2P_FORCE_PNET != null) {
        throw new InvalidParametersError$1('Private network is enforced, but no protector was provided');
    }
    return resultingOptions;
}

// Helpers.
const s = 1000;
const m = s * 60;
const h = m * 60;
const d = h * 24;
const w = d * 7;
const y = d * 365.25;
function ms(value, options) {
    try {
        if (typeof value === 'string' && value.length > 0) {
            return parse(value);
        }
        else if (typeof value === 'number' && isFinite(value)) {
            return options?.long ? fmtLong(value) : fmtShort(value);
        }
        throw new Error('Value is not a string or number.');
    }
    catch (error) {
        const message = isError$1(error)
            ? `${error.message}. value=${JSON.stringify(value)}`
            : 'An unknown error has occured.';
        throw new Error(message);
    }
}
/**
 * Parse the given `str` and return milliseconds.
 */
function parse(str) {
    str = String(str);
    if (str.length > 100) {
        throw new Error('Value exceeds the maximum length of 100 characters.');
    }
    const match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(str);
    if (!match) {
        return NaN;
    }
    const n = parseFloat(match[1]);
    const type = (match[2] || 'ms').toLowerCase();
    switch (type) {
        case 'years':
        case 'year':
        case 'yrs':
        case 'yr':
        case 'y':
            return n * y;
        case 'weeks':
        case 'week':
        case 'w':
            return n * w;
        case 'days':
        case 'day':
        case 'd':
            return n * d;
        case 'hours':
        case 'hour':
        case 'hrs':
        case 'hr':
        case 'h':
            return n * h;
        case 'minutes':
        case 'minute':
        case 'mins':
        case 'min':
        case 'm':
            return n * m;
        case 'seconds':
        case 'second':
        case 'secs':
        case 'sec':
        case 's':
            return n * s;
        case 'milliseconds':
        case 'millisecond':
        case 'msecs':
        case 'msec':
        case 'ms':
            return n;
        default:
            // This should never occur.
            throw new Error(`The unit ${type} was matched, but no matching case exists.`);
    }
}
/**
 * Short format for `ms`.
 */
function fmtShort(ms) {
    const msAbs = Math.abs(ms);
    if (msAbs >= d) {
        return `${Math.round(ms / d)}d`;
    }
    if (msAbs >= h) {
        return `${Math.round(ms / h)}h`;
    }
    if (msAbs >= m) {
        return `${Math.round(ms / m)}m`;
    }
    if (msAbs >= s) {
        return `${Math.round(ms / s)}s`;
    }
    return `${ms}ms`;
}
/**
 * Long format for `ms`.
 */
function fmtLong(ms) {
    const msAbs = Math.abs(ms);
    if (msAbs >= d) {
        return plural(ms, msAbs, d, 'day');
    }
    if (msAbs >= h) {
        return plural(ms, msAbs, h, 'hour');
    }
    if (msAbs >= m) {
        return plural(ms, msAbs, m, 'minute');
    }
    if (msAbs >= s) {
        return plural(ms, msAbs, s, 'second');
    }
    return `${ms} ms`;
}
/**
 * Pluralization helper.
 */
function plural(ms, msAbs, n, name) {
    const isPlural = msAbs >= n * 1.5;
    return `${Math.round(ms / n)} ${name}${isPlural ? 's' : ''}`;
}
/**
 * A type guard for errors.
 */
function isError$1(error) {
    return typeof error === 'object' && error !== null && 'message' in error;
}

/* eslint-disable no-console */
/* eslint-disable @typescript-eslint/strict-boolean-expressions */
/**
 * This is the common logic for both the Node.js and web browser
 * implementations of `debug()`.
 */
function setup(env) {
    createDebug.debug = createDebug;
    createDebug.default = createDebug;
    createDebug.coerce = coerce;
    createDebug.disable = disable;
    createDebug.enable = enable;
    createDebug.enabled = enabled;
    createDebug.humanize = ms;
    createDebug.destroy = destroy;
    Object.keys(env).forEach(key => {
        // @ts-expect-error cannot use string to index type
        createDebug[key] = env[key];
    });
    /**
     * The currently active debug mode names, and names to skip.
     */
    createDebug.names = [];
    createDebug.skips = [];
    /**
     * Map of special "%n" handling functions, for the debug "format" argument.
     *
     * Valid key names are a single, lower or upper-case letter, i.e. "n" and "N".
     */
    createDebug.formatters = {};
    /**
     * Selects a color for a debug namespace
     *
     * @param {string} namespace - The namespace string for the debug instance to be colored
     * @returns {number | string} An ANSI color code for the given namespace
     */
    function selectColor(namespace) {
        let hash = 0;
        for (let i = 0; i < namespace.length; i++) {
            hash = ((hash << 5) - hash) + namespace.charCodeAt(i);
            hash |= 0; // Convert to 32bit integer
        }
        // @ts-expect-error colors is not in the types
        return createDebug.colors[Math.abs(hash) % createDebug.colors.length];
    }
    createDebug.selectColor = selectColor;
    /**
     * Create a debugger with the given `namespace`.
     *
     * @param {string} namespace
     * @returns {Function}
     */
    function createDebug(namespace) {
        let prevTime;
        let enableOverride = null;
        let namespacesCache;
        let enabledCache;
        function debug(...args) {
            // Disabled?
            // @ts-expect-error enabled is not in the types
            if (!debug.enabled) {
                return;
            }
            const self = debug;
            // Set `diff` timestamp
            const curr = Number(new Date());
            const ms = curr - (prevTime || curr);
            self.diff = ms;
            self.prev = prevTime;
            self.curr = curr;
            prevTime = curr;
            args[0] = createDebug.coerce(args[0]);
            if (typeof args[0] !== 'string') {
                // Anything else let's inspect with %O
                args.unshift('%O');
            }
            // Apply any `formatters` transformations
            let index = 0;
            args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {
                // If we encounter an escaped % then don't increase the array index
                if (match === '%%') {
                    return '%';
                }
                index++;
                // @ts-expect-error formatters is not in the types
                const formatter = createDebug.formatters[format];
                if (typeof formatter === 'function') {
                    const val = args[index];
                    match = formatter.call(self, val);
                    // Now we need to remove `args[index]` since it's inlined in the `format`
                    args.splice(index, 1);
                    index--;
                }
                return match;
            });
            // Apply env-specific formatting (colors, etc.)
            // @ts-expect-error formatArgs is not in the types
            createDebug.formatArgs.call(self, args);
            // @ts-expect-error log is not in the types
            const logFn = self.log || createDebug.log;
            logFn.apply(self, args);
        }
        debug.namespace = namespace;
        // @ts-expect-error useColors is not in the types
        debug.useColors = createDebug.useColors();
        debug.color = createDebug.selectColor(namespace);
        debug.extend = extend;
        debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.
        Object.defineProperty(debug, 'enabled', {
            enumerable: true,
            configurable: false,
            get: () => {
                if (enableOverride !== null) {
                    return enableOverride;
                }
                // @ts-expect-error namespaces is not in the types
                if (namespacesCache !== createDebug.namespaces) {
                    // @ts-expect-error namespaces is not in the types
                    namespacesCache = createDebug.namespaces;
                    enabledCache = createDebug.enabled(namespace);
                }
                return enabledCache;
            },
            set: v => {
                enableOverride = v;
            }
        });
        // Env-specific initialization logic for debug instances
        // @ts-expect-error init is not in the types
        if (typeof createDebug.init === 'function') {
            // @ts-expect-error init is not in the types
            createDebug.init(debug);
        }
        // @ts-expect-error some properties are added dynamically
        return debug;
    }
    function extend(namespace, delimiter) {
        const newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);
        newDebug.log = this.log;
        return newDebug;
    }
    /**
     * Enables a debug mode by namespaces. This can include modes
     * separated by a colon and wildcards.
     *
     * @param {string} namespaces
     */
    function enable(namespaces) {
        // @ts-expect-error save is not in the types
        createDebug.save(namespaces);
        // @ts-expect-error namespaces is not in the types
        createDebug.namespaces = namespaces;
        createDebug.names = [];
        createDebug.skips = [];
        let i;
        const split = (typeof namespaces === 'string' ? namespaces : '').split(/[\s,]+/);
        const len = split.length;
        for (i = 0; i < len; i++) {
            if (!split[i]) {
                // ignore empty strings
                continue;
            }
            namespaces = split[i].replace(/\*/g, '.*?');
            if (namespaces[0] === '-') {
                createDebug.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));
            }
            else {
                createDebug.names.push(new RegExp('^' + namespaces + '$'));
            }
        }
    }
    /**
     * Disable debug output.
     *
     * @returns {string} namespaces
     */
    function disable() {
        const namespaces = [
            ...createDebug.names.map(toNamespace),
            ...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)
        ].join(',');
        createDebug.enable('');
        return namespaces;
    }
    /**
     * Returns true if the given mode name is enabled, false otherwise.
     *
     * @param {string} name
     * @returns {boolean}
     */
    function enabled(name) {
        if (name[name.length - 1] === '*') {
            return true;
        }
        let i;
        let len;
        for (i = 0, len = createDebug.skips.length; i < len; i++) {
            if (createDebug.skips[i].test(name)) {
                return false;
            }
        }
        for (i = 0, len = createDebug.names.length; i < len; i++) {
            if (createDebug.names[i].test(name)) {
                return true;
            }
        }
        return false;
    }
    /**
     * Convert regexp to namespace
     */
    function toNamespace(regexp) {
        return regexp.toString()
            .substring(2, regexp.toString().length - 2)
            .replace(/\.\*\?$/, '*');
    }
    /**
     * Coerce `val`.
     */
    function coerce(val) {
        if (val instanceof Error) {
            return val.stack ?? val.message;
        }
        return val;
    }
    /**
     * XXX DO NOT USE. This is a temporary stub function.
     * XXX It WILL be removed in the next major release.
     */
    function destroy() {
        console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
    }
    // @ts-expect-error setupFormatters is not in the types
    createDebug.setupFormatters(createDebug.formatters);
    // @ts-expect-error load is not in the types
    createDebug.enable(createDebug.load());
    // @ts-expect-error some properties are added dynamically
    return createDebug;
}

/* eslint-disable no-console */
/* eslint-disable @typescript-eslint/restrict-plus-operands */
/* eslint-disable @typescript-eslint/strict-boolean-expressions */
/* eslint-env browser */
/**
 * This is the web browser implementation of `debug()`.
 */
const storage = localstorage();
/**
 * Colors.
 */
const colors = [
    '#0000CC',
    '#0000FF',
    '#0033CC',
    '#0033FF',
    '#0066CC',
    '#0066FF',
    '#0099CC',
    '#0099FF',
    '#00CC00',
    '#00CC33',
    '#00CC66',
    '#00CC99',
    '#00CCCC',
    '#00CCFF',
    '#3300CC',
    '#3300FF',
    '#3333CC',
    '#3333FF',
    '#3366CC',
    '#3366FF',
    '#3399CC',
    '#3399FF',
    '#33CC00',
    '#33CC33',
    '#33CC66',
    '#33CC99',
    '#33CCCC',
    '#33CCFF',
    '#6600CC',
    '#6600FF',
    '#6633CC',
    '#6633FF',
    '#66CC00',
    '#66CC33',
    '#9900CC',
    '#9900FF',
    '#9933CC',
    '#9933FF',
    '#99CC00',
    '#99CC33',
    '#CC0000',
    '#CC0033',
    '#CC0066',
    '#CC0099',
    '#CC00CC',
    '#CC00FF',
    '#CC3300',
    '#CC3333',
    '#CC3366',
    '#CC3399',
    '#CC33CC',
    '#CC33FF',
    '#CC6600',
    '#CC6633',
    '#CC9900',
    '#CC9933',
    '#CCCC00',
    '#CCCC33',
    '#FF0000',
    '#FF0033',
    '#FF0066',
    '#FF0099',
    '#FF00CC',
    '#FF00FF',
    '#FF3300',
    '#FF3333',
    '#FF3366',
    '#FF3399',
    '#FF33CC',
    '#FF33FF',
    '#FF6600',
    '#FF6633',
    '#FF9900',
    '#FF9933',
    '#FFCC00',
    '#FFCC33'
];
/**
 * Currently only WebKit-based Web Inspectors, Firefox >= v31,
 * and the Firebug extension (any Firefox version) are known
 * to support "%c" CSS customizations.
 *
 * TODO: add a `localStorage` variable to explicitly enable/disable colors
 */
// eslint-disable-next-line complexity
function useColors() {
    // NB: In an Electron preload script, document will be defined but not fully
    // initialized. Since we know we're in Chrome, we'll just detect this case
    // explicitly
    // @ts-expect-error window.process.type and window.process.__nwjs are not in the types
    if (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {
        return true;
    }
    // Internet Explorer and Edge do not support colors.
    if (typeof navigator !== 'undefined' && (navigator.userAgent?.toLowerCase().match(/(edge|trident)\/(\d+)/) != null)) {
        return false;
    }
    // Is webkit? http://stackoverflow.com/a/16459606/376773
    // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632
    // @ts-expect-error document.documentElement.style.WebkitAppearance is not in the types
    return (typeof document !== 'undefined' && document.documentElement?.style?.WebkitAppearance) ||
        // Is firebug? http://stackoverflow.com/a/398120/376773
        // @ts-expect-error window.console.firebug and window.console.exception are not in the types
        (typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||
        // Is firefox >= v31?
        // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages
        (typeof navigator !== 'undefined' && (navigator.userAgent?.toLowerCase().match(/firefox\/(\d+)/) != null) && parseInt(RegExp.$1, 10) >= 31) ||
        // Double check webkit in userAgent just in case we are in a worker
        (typeof navigator !== 'undefined' && navigator.userAgent?.toLowerCase().match(/applewebkit\/(\d+)/));
}
/**
 * Colorize log arguments if enabled.
 */
function formatArgs(args) {
    args[0] = (this.useColors ? '%c' : '') +
        this.namespace +
        (this.useColors ? ' %c' : ' ') +
        args[0] +
        (this.useColors ? '%c ' : ' ') +
        '+' + ms(this.diff);
    if (!this.useColors) {
        return;
    }
    const c = 'color: ' + this.color;
    args.splice(1, 0, c, 'color: inherit');
    // The final "%c" is somewhat tricky, because there could be other
    // arguments passed either before or after the %c, so we need to
    // figure out the correct index to insert the CSS into
    let index = 0;
    let lastC = 0;
    args[0].replace(/%[a-zA-Z%]/g, (match) => {
        if (match === '%%') {
            return;
        }
        index++;
        if (match === '%c') {
            // We only are interested in the *last* %c
            // (the user may have provided their own)
            lastC = index;
        }
    });
    args.splice(lastC, 0, c);
}
/**
 * Invokes `console.debug()` when available.
 * No-op when `console.debug` is not a "function".
 * If `console.debug` is not available, falls back
 * to `console.log`.
 */
const log$b = console.debug ?? console.log ?? (() => { });
/**
 * Save `namespaces`.
 *
 * @param {string} namespaces
 */
function save(namespaces) {
    try {
        if (namespaces) {
            storage?.setItem('debug', namespaces);
        }
        else {
            storage?.removeItem('debug');
        }
    }
    catch (error) {
        // Swallow
        // XXX (@Qix-) should we be logging these?
    }
}
/**
 * Load `namespaces`.
 *
 * @returns {string} returns the previously persisted debug modes
 */
function load() {
    let r;
    try {
        r = storage?.getItem('debug');
    }
    catch (error) {
        // Swallow
        // XXX (@Qix-) should we be logging these?
    }
    // If debug isn't set in LS, and we're in Electron, try to load $DEBUG
    if (!r && typeof globalThis.process !== 'undefined' && 'env' in globalThis.process) {
        r = globalThis.process.env.DEBUG;
    }
    return r;
}
/**
 * Localstorage attempts to return the localstorage.
 *
 * This is necessary because safari throws
 * when a user disables cookies/localstorage
 * and you attempt to access it.
 */
function localstorage() {
    try {
        // TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context
        // The Browser also has localStorage in the global context.
        return localStorage;
    }
    catch (error) {
        // Swallow
        // XXX (@Qix-) should we be logging these?
    }
}
function setupFormatters(formatters) {
    /**
     * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.
     */
    formatters.j = function (v) {
        try {
            return JSON.stringify(v);
        }
        catch (error) {
            return '[UnexpectedJSONParseError]: ' + error.message;
        }
    };
}
var weald = setup({ formatArgs, save, load, useColors, setupFormatters, colors, storage, log: log$b });

/**
 * @packageDocumentation
 *
 * A logger for libp2p based on [weald](https://www.npmjs.com/package/weald), a TypeScript port of the venerable [debug](https://www.npmjs.com/package/debug) module.
 *
 * @example
 *
 * ```TypeScript
 * import { logger } from '@libp2p/logger'
 *
 * const log = logger('libp2p:my:component:name')
 *
 * try {
 *   // an operation
 *   log('something happened: %s', 'it was ok')
 * } catch (err) {
 *   log.error('something bad happened: %o', err)
 * }
 *
 * log('with this peer: %p', {})
 * log('and this base58btc: %b', Uint8Array.from([0, 1, 2, 3]))
 * log('and this base32: %t', Uint8Array.from([4, 5, 6, 7]))
 * ```
 *
 * ```console
 * $ DEBUG=libp2p:* node index.js
 * something happened: it was ok
 * something bad happened: <stack trace>
 * with this peer: 12D3Foo
 * with this base58btc: Qmfoo
 * with this base32: bafyfoo
 * ```
 */
// Add a formatter for converting to a base58 string
weald.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc.baseEncode(v);
};
// Add a formatter for converting to a base32 string
weald.formatters.t = (v) => {
    return v == null ? 'undefined' : base32$2.baseEncode(v);
};
// Add a formatter for converting to a base64 string
weald.formatters.m = (v) => {
    return v == null ? 'undefined' : base64.baseEncode(v);
};
// Add a formatter for stringifying peer ids
weald.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
weald.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
weald.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Multiaddrs
weald.formatters.a = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Errors
weald.formatters.e = (v) => {
    return v == null ? 'undefined' : notEmpty(v.stack) ?? notEmpty(v.message) ?? v.toString();
};
function createDisabledLogger(namespace) {
    const logger = () => { };
    logger.enabled = false;
    logger.color = '';
    logger.diff = 0;
    logger.log = () => { };
    logger.namespace = namespace;
    logger.destroy = () => true;
    logger.extend = () => logger;
    return logger;
}
/**
 * Create a component logger
 *
 * @example
 *
 * ```TypeScript
 * import { defaultLogger } from '@libp2p/logger'
 * import { peerIdFromString } from '@libp2p/peer-id'
 *
 * const logger = defaultLogger()
 *
 * const log = logger.forComponent('my-component')
 * log.info('hello world')
 * // logs "my-component hello world"
 * ```
 */
function defaultLogger() {
    return {
        forComponent(name) {
            return logger$2(name);
        }
    };
}
/**
 * Creates a logger for the passed component name.
 *
 * @example
 *
 * ```TypeScript
 * import { logger } from '@libp2p/logger'
 *
 * const log = logger('my-component')
 * log.info('hello world')
 * // logs "my-component hello world"
 * ```
 */
function logger$2(name) {
    // trace logging is a no-op by default
    let trace = createDisabledLogger(`${name}:trace`);
    // look at all the debug names and see if trace logging has explicitly been enabled
    if (weald.enabled(`${name}:trace`) && weald.names.map((r) => r.toString()).find((n) => n.includes(':trace')) != null) {
        trace = weald(`${name}:trace`);
    }
    return Object.assign(weald(name), {
        error: weald(`${name}:error`),
        trace
    });
}
function notEmpty(str) {
    if (str == null) {
        return;
    }
    str = str.trim();
    if (str.length === 0) {
        return;
    }
    return str;
}

/**
 * Calls the passed map function on every entry of the passed iterable iterator
 */
function mapIterable(iter, map) {
    const iterator = {
        [Symbol.iterator]: () => {
            return iterator;
        },
        next: () => {
            const next = iter.next();
            const val = next.value;
            if (next.done === true || val == null) {
                const result = {
                    done: true,
                    value: undefined
                };
                return result;
            }
            return {
                done: false,
                value: map(val)
            };
        }
    };
    return iterator;
}
function peerIdFromString(str) {
    const multihash = decode$3(base58btc.decode(`z${str}`));
    return peerIdFromMultihash(multihash);
}

/**
 * We can't use PeerIds as map keys because map keys are
 * compared using same-value-zero equality, so this is just
 * a map that stringifies the PeerIds before storing them.
 *
 * PeerIds cache stringified versions of themselves so this
 * should be a cheap operation.
 *
 * @example
 *
 * ```TypeScript
 * import { peerMap } from '@libp2p/peer-collections'
 *
 * const map = peerMap<string>()
 * map.set(peerId, 'value')
 * ```
 */
class PeerMap {
    map;
    constructor(map) {
        this.map = new Map();
        if (map != null) {
            for (const [key, value] of map.entries()) {
                this.map.set(key.toString(), { key, value });
            }
        }
    }
    [Symbol.iterator]() {
        return this.entries();
    }
    clear() {
        this.map.clear();
    }
    delete(peer) {
        return this.map.delete(peer.toString());
    }
    entries() {
        return mapIterable(this.map.entries(), (val) => {
            return [val[1].key, val[1].value];
        });
    }
    forEach(fn) {
        this.map.forEach((value, key) => {
            fn(value.value, value.key, this);
        });
    }
    get(peer) {
        return this.map.get(peer.toString())?.value;
    }
    has(peer) {
        return this.map.has(peer.toString());
    }
    set(peer, value) {
        this.map.set(peer.toString(), { key: peer, value });
    }
    keys() {
        return mapIterable(this.map.values(), (val) => {
            return val.key;
        });
    }
    values() {
        return mapIterable(this.map.values(), (val) => val.value);
    }
    get size() {
        return this.map.size;
    }
}

/**
 * We can't use PeerIds as set entries because set entries are
 * compared using same-value-zero equality, so this is just
 * a map that stringifies the PeerIds before storing them.
 *
 * PeerIds cache stringified versions of themselves so this
 * should be a cheap operation.
 *
 * @example
 *
 * ```TypeScript
 * import { peerSet } from '@libp2p/peer-collections'
 *
 * const set = peerSet()
 * set.add(peerId)
 * ```
 */
class PeerSet {
    set;
    constructor(set) {
        this.set = new Set();
        if (set != null) {
            for (const key of set) {
                this.set.add(key.toString());
            }
        }
    }
    get size() {
        return this.set.size;
    }
    [Symbol.iterator]() {
        return this.values();
    }
    add(peer) {
        this.set.add(peer.toString());
    }
    clear() {
        this.set.clear();
    }
    delete(peer) {
        this.set.delete(peer.toString());
    }
    entries() {
        return mapIterable(this.set.entries(), (val) => {
            const peerId = peerIdFromString(val[0]);
            return [peerId, peerId];
        });
    }
    forEach(predicate) {
        this.set.forEach((str) => {
            const peerId = peerIdFromString(str);
            predicate(peerId, peerId, this);
        });
    }
    has(peer) {
        return this.set.has(peer.toString());
    }
    values() {
        return mapIterable(this.set.values(), (val) => {
            return peerIdFromString(val);
        });
    }
    intersection(other) {
        const output = new PeerSet();
        for (const peerId of other) {
            if (this.has(peerId)) {
                output.add(peerId);
            }
        }
        return output;
    }
    difference(other) {
        const output = new PeerSet();
        for (const peerId of this) {
            if (!other.has(peerId)) {
                output.add(peerId);
            }
        }
        return output;
    }
    union(other) {
        const output = new PeerSet();
        for (const peerId of other) {
            output.add(peerId);
        }
        for (const peerId of this) {
            output.add(peerId);
        }
        return output;
    }
}

// FNV_PRIMES and FNV_OFFSETS from
// http://www.isthe.com/chongo/tech/comp/fnv/index.html#FNV-param

const FNV_PRIMES = {
	32: 16_777_619n,
	64: 1_099_511_628_211n,
	128: 309_485_009_821_345_068_724_781_371n,
	256: 374_144_419_156_711_147_060_143_317_175_368_453_031_918_731_002_211n,
	512: 35_835_915_874_844_867_368_919_076_489_095_108_449_946_327_955_754_392_558_399_825_615_420_669_938_882_575_126_094_039_892_345_713_852_759n,
	1024: 5_016_456_510_113_118_655_434_598_811_035_278_955_030_765_345_404_790_744_303_017_523_831_112_055_108_147_451_509_157_692_220_295_382_716_162_651_878_526_895_249_385_292_291_816_524_375_083_746_691_371_804_094_271_873_160_484_737_966_720_260_389_217_684_476_157_468_082_573n,
};

const FNV_OFFSETS = {
	32: 2_166_136_261n,
	64: 14_695_981_039_346_656_037n,
	128: 144_066_263_297_769_815_596_495_629_667_062_367_629n,
	256: 100_029_257_958_052_580_907_070_968_620_625_704_837_092_796_014_241_193_945_225_284_501_741_471_925_557n,
	512: 9_659_303_129_496_669_498_009_435_400_716_310_466_090_418_745_672_637_896_108_374_329_434_462_657_994_582_932_197_716_438_449_813_051_892_206_539_805_784_495_328_239_340_083_876_191_928_701_583_869_517_785n,
	1024: 14_197_795_064_947_621_068_722_070_641_403_218_320_880_622_795_441_933_960_878_474_914_617_582_723_252_296_732_303_717_722_150_864_096_521_202_355_549_365_628_174_669_108_571_814_760_471_015_076_148_029_755_969_804_077_320_157_692_458_563_003_215_304_957_150_157_403_644_460_363_550_505_412_711_285_966_361_610_267_868_082_893_823_963_790_439_336_411_086_884_584_107_735_010_676_915n,
};

const cachedEncoder = new globalThis.TextEncoder();

function fnv1aUint8Array(uint8Array, size) {
	const fnvPrime = FNV_PRIMES[size];
	let hash = FNV_OFFSETS[size];

	// eslint-disable-next-line unicorn/no-for-loop -- This is a performance-sensitive loop
	for (let index = 0; index < uint8Array.length; index++) {
		hash ^= BigInt(uint8Array[index]);
		hash = BigInt.asUintN(size, hash * fnvPrime);
	}

	return hash;
}

function fnv1aEncodeInto(string, size, utf8Buffer) {
	if (utf8Buffer.length === 0) {
		throw new Error('The `utf8Buffer` option must have a length greater than zero');
	}

	const fnvPrime = FNV_PRIMES[size];
	let hash = FNV_OFFSETS[size];
	let remaining = string;

	while (remaining.length > 0) {
		const result = cachedEncoder.encodeInto(remaining, utf8Buffer);
		remaining = remaining.slice(result.read);
		for (let index = 0; index < result.written; index++) {
			hash ^= BigInt(utf8Buffer[index]);
			hash = BigInt.asUintN(size, hash * fnvPrime);
		}
	}

	return hash;
}

function fnv1a$1(value, {size = 32, utf8Buffer} = {}) {
	if (!FNV_PRIMES[size]) {
		throw new Error('The `size` option must be one of 32, 64, 128, 256, 512, or 1024');
	}

	if (typeof value === 'string') {
		if (utf8Buffer) {
			return fnv1aEncodeInto(value, size, utf8Buffer);
		}

		value = cachedEncoder.encode(value);
	}

	return fnv1aUint8Array(value, size);
}

const fnv1a = {
    hash: (input) => {
        return Number(fnv1a$1(input, {
            size: 32
        }));
    },
    hashV: (input, seed) => {
        return numberToBuffer(fnv1a.hash(input, seed));
    }
};
function numberToBuffer(num) {
    let hex = num.toString(16);
    if (hex.length % 2 === 1) {
        hex = `0${hex}`;
    }
    return fromString(hex, 'base16');
}

const MAX_FINGERPRINT_SIZE = 64;
class Fingerprint {
    fp;
    h;
    seed;
    constructor(buf, hash, seed, fingerprintSize = 2) {
        if (fingerprintSize > MAX_FINGERPRINT_SIZE) {
            throw new TypeError('Invalid Fingerprint Size');
        }
        const fnv = hash.hashV(buf, seed);
        const fp = alloc$1(fingerprintSize);
        for (let i = 0; i < fp.length; i++) {
            fp[i] = fnv[i];
        }
        if (fp.length === 0) {
            fp[0] = 7;
        }
        this.fp = fp;
        this.h = hash;
        this.seed = seed;
    }
    hash() {
        return this.h.hash(this.fp, this.seed);
    }
    equals(other) {
        if (!(other?.fp instanceof Uint8Array)) {
            return false;
        }
        return equals(this.fp, other.fp);
    }
}

function getRandomInt(min, max) {
    return Math.floor(Math.random() * (max - min)) + min;
}

class Bucket {
    contents;
    constructor(size) {
        this.contents = new Array(size).fill(null);
    }
    has(fingerprint) {
        if (!(fingerprint instanceof Fingerprint)) {
            throw new TypeError('Invalid Fingerprint');
        }
        return this.contents.some((fp) => {
            return fingerprint.equals(fp);
        });
    }
    add(fingerprint) {
        if (!(fingerprint instanceof Fingerprint)) {
            throw new TypeError('Invalid Fingerprint');
        }
        for (let i = 0; i < this.contents.length; i++) {
            if (this.contents[i] == null) {
                this.contents[i] = fingerprint;
                return true;
            }
        }
        return true;
    }
    swap(fingerprint) {
        if (!(fingerprint instanceof Fingerprint)) {
            throw new TypeError('Invalid Fingerprint');
        }
        const i = getRandomInt(0, this.contents.length - 1);
        const current = this.contents[i];
        this.contents[i] = fingerprint;
        return current;
    }
    remove(fingerprint) {
        if (!(fingerprint instanceof Fingerprint)) {
            throw new TypeError('Invalid Fingerprint');
        }
        const found = this.contents.findIndex((fp) => {
            return fingerprint.equals(fp);
        });
        if (found > -1) {
            this.contents[found] = null;
            return true;
        }
        else {
            return false;
        }
    }
}

const maxCuckooCount = 500;
class CuckooFilter {
    bucketSize;
    filterSize;
    fingerprintSize;
    buckets;
    count;
    hash;
    seed;
    constructor(init) {
        this.filterSize = init.filterSize;
        this.bucketSize = init.bucketSize ?? 4;
        this.fingerprintSize = init.fingerprintSize ?? 2;
        this.count = 0;
        this.buckets = [];
        this.hash = init.hash ?? fnv1a;
        this.seed = init.seed ?? getRandomInt(0, Math.pow(2, 10));
    }
    add(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);
        const j = this.hash.hash(item, this.seed) % this.filterSize;
        const k = (j ^ fingerprint.hash()) % this.filterSize;
        if (this.buckets[j] == null) {
            this.buckets[j] = new Bucket(this.bucketSize);
        }
        if (this.buckets[k] == null) {
            this.buckets[k] = new Bucket(this.bucketSize);
        }
        if (this.buckets[j].add(fingerprint) || this.buckets[k].add(fingerprint)) {
            this.count++;
            return true;
        }
        const rand = [j, k];
        let i = rand[getRandomInt(0, rand.length - 1)];
        if (this.buckets[i] == null) {
            this.buckets[i] = new Bucket(this.bucketSize);
        }
        for (let n = 0; n < maxCuckooCount; n++) {
            const swapped = this.buckets[i].swap(fingerprint);
            if (swapped == null) {
                continue;
            }
            i = (i ^ swapped.hash()) % this.filterSize;
            if (this.buckets[i] == null) {
                this.buckets[i] = new Bucket(this.bucketSize);
            }
            if (this.buckets[i].add(swapped)) {
                this.count++;
                return true;
            }
            else {
                continue;
            }
        }
        return false;
    }
    has(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);
        const j = this.hash.hash(item, this.seed) % this.filterSize;
        const inJ = this.buckets[j]?.has(fingerprint) ?? false;
        if (inJ) {
            return inJ;
        }
        const k = (j ^ fingerprint.hash()) % this.filterSize;
        return this.buckets[k]?.has(fingerprint) ?? false;
    }
    remove(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);
        const j = this.hash.hash(item, this.seed) % this.filterSize;
        const inJ = this.buckets[j]?.remove(fingerprint) ?? false;
        if (inJ) {
            this.count--;
            return inJ;
        }
        const k = (j ^ fingerprint.hash()) % this.filterSize;
        const inK = this.buckets[k]?.remove(fingerprint) ?? false;
        if (inK) {
            this.count--;
        }
        return inK;
    }
    get reliable() {
        return Math.floor(100 * (this.count / this.filterSize)) <= 90;
    }
}
// max load constants, defined in the cuckoo paper
const MAX_LOAD = {
    1: 0.5,
    2: 0.84,
    4: 0.95,
    8: 0.98
};
function calculateBucketSize(errorRate = 0.001) {
    if (errorRate > 0.002) {
        return 2;
    }
    if (errorRate > 0.00001) {
        return 4;
    }
    return 8;
}
function optimize(maxItems, errorRate = 0.001) {
    // https://www.eecs.harvard.edu/~michaelm/postscripts/cuckoo-conext2014.pdf
    // Section 5.1 Optimal Bucket Size
    const bucketSize = calculateBucketSize(errorRate);
    const load = MAX_LOAD[bucketSize];
    // https://stackoverflow.com/questions/57555236/how-to-size-a-cuckoo-filter/57617208#57617208
    const filterSize = Math.round(maxItems / load);
    const fingerprintSize = Math.min(Math.ceil(Math.log2(1 / errorRate) + Math.log2(2 * bucketSize)), MAX_FINGERPRINT_SIZE);
    return {
        filterSize,
        bucketSize,
        fingerprintSize
    };
}

class ScalableCuckooFilter {
    filterSize;
    bucketSize;
    fingerprintSize;
    scale;
    filterSeries;
    hash;
    seed;
    constructor(init) {
        this.bucketSize = init.bucketSize ?? 4;
        this.filterSize = init.filterSize ?? (1 << 18) / this.bucketSize;
        this.fingerprintSize = init.fingerprintSize ?? 2;
        this.scale = init.scale ?? 2;
        this.hash = init.hash ?? fnv1a;
        this.seed = init.seed ?? getRandomInt(0, Math.pow(2, 10));
        this.filterSeries = [
            new CuckooFilter({
                filterSize: this.filterSize,
                bucketSize: this.bucketSize,
                fingerprintSize: this.fingerprintSize,
                hash: this.hash,
                seed: this.seed
            })
        ];
    }
    add(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        if (this.has(item)) {
            return true;
        }
        let current = this.filterSeries.find((cuckoo) => {
            return cuckoo.reliable;
        });
        if (current == null) {
            const curSize = this.filterSize * Math.pow(this.scale, this.filterSeries.length);
            current = new CuckooFilter({
                filterSize: curSize,
                bucketSize: this.bucketSize,
                fingerprintSize: this.fingerprintSize,
                hash: this.hash,
                seed: this.seed
            });
            this.filterSeries.push(current);
        }
        return current.add(item);
    }
    has(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        for (let i = 0; i < this.filterSeries.length; i++) {
            if (this.filterSeries[i].has(item)) {
                return true;
            }
        }
        return false;
    }
    remove(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        for (let i = 0; i < this.filterSeries.length; i++) {
            if (this.filterSeries[i].remove(item)) {
                return true;
            }
        }
        return false;
    }
    get count() {
        return this.filterSeries.reduce((acc, curr) => {
            return acc + curr.count;
        }, 0);
    }
}
function createScalableCuckooFilter(maxItems, errorRate = 0.001, options) {
    return new ScalableCuckooFilter({
        ...optimize(maxItems, errorRate),
        ...({})
    });
}

class TrackedPeerMap extends PeerMap {
    metric;
    constructor(init) {
        super();
        const { name, metrics } = init;
        this.metric = metrics.registerMetric(name);
        this.updateComponentMetric();
    }
    set(key, value) {
        super.set(key, value);
        this.updateComponentMetric();
        return this;
    }
    delete(key) {
        const deleted = super.delete(key);
        this.updateComponentMetric();
        return deleted;
    }
    clear() {
        super.clear();
        this.updateComponentMetric();
    }
    updateComponentMetric() {
        this.metric.update(this.size);
    }
}
/**
 * Creates a PeerMap that reports it's size to the libp2p Metrics service
 *
 * @example
 *
 * ```Typescript
 * import { trackedPeerMap } from '@libp2p/peer-collections'
 * import { createLibp2p } from 'libp2p'
 *
 * const libp2p = await createLibp2p()
 *
 * const list = trackedPeerMap({ name: 'my_metric_name', metrics: libp2p.metrics })
 * map.set(peerId, 'value')
 * ```
 */
function trackedPeerMap(config) {
    const { name, metrics } = config;
    let map;
    if (metrics != null) {
        map = new TrackedPeerMap({ name, metrics });
    }
    else {
        map = new PeerMap();
    }
    return map;
}

/**
 * @packageDocumentation
 *
 * A simple error class and options interface that seems to get copied from
 * project to project.
 *
 * @example Using `AbortError`
 *
 * ```JavaScript
 * import { AbortError } from 'abort-error'
 *
 * // a promise that will be settled later
 * const deferred = Promise.withResolvers()
 *
 * const signal = AbortSignal.timeout(1000)
 * signal.addEventListener('abort', () => {
 *   deferred.reject(new AbortError())
 * })
 * ```
 *
 * @example Using `AbortOptions`
 *
 * ```TypeScript
 * import type { AbortOptions } from 'abort-error'
 *
 * async function myFunction (options?: AbortOptions) {
 *   return fetch('https://example.com', {
 *     signal: options?.signal
 *   })
 * }
 * ```
 */
let AbortError$2 = class AbortError extends Error {
    static name = 'AbortError';
    name = 'AbortError';
    constructor(message = 'The operation was aborted', ...rest) {
        super(message, ...rest);
    }
};

/**
 * @packageDocumentation
 *
 * Race an event against an AbortSignal, taking care to remove any event
 * listeners that were added.
 *
 * @example Getting started
 *
 * ```TypeScript
 * import { raceEvent } from 'race-event'
 *
 * const controller = new AbortController()
 * const emitter = new EventTarget()
 *
 * setTimeout(() => {
 *   controller.abort()
 * }, 500)
 *
 * setTimeout(() => {
 *   // too late
 *   emitter.dispatchEvent(new CustomEvent('event'))
 * }, 1000)
 *
 * // throws an AbortError
 * const resolve = await raceEvent(emitter, 'event', controller.signal)
 * ```
 *
 * @example Aborting the promise with an error event
 *
 * ```TypeScript
 * import { raceEvent } from 'race-event'
 *
 * const emitter = new EventTarget()
 *
 * setTimeout(() => {
 *   emitter.dispatchEvent(new CustomEvent('failure', {
 *     detail: new Error('Oh no!')
 *   }))
 * }, 1000)
 *
 * // throws 'Oh no!' error
 * const resolve = await raceEvent(emitter, 'success', AbortSignal.timeout(5000), {
 *   errorEvent: 'failure'
 * })
 * ```
 *
 * @example Customising the thrown AbortError
 *
 * The error message and `.code` property of the thrown `AbortError` can be
 * specified by passing options:
 *
 * ```TypeScript
 * import { raceEvent } from 'race-event'
 *
 * const controller = new AbortController()
 * const emitter = new EventTarget()
 *
 * setTimeout(() => {
 *   controller.abort()
 * }, 500)
 *
 * // throws a Error: Oh no!
 * const resolve = await raceEvent(emitter, 'event', controller.signal, {
 *   errorMessage: 'Oh no!',
 *   errorCode: 'ERR_OH_NO'
 * })
 * ```
 *
 * @example Only resolving on specific events
 *
 * Where multiple events with the same type are emitted, a `filter` function can
 * be passed to only resolve on one of them:
 *
 * ```TypeScript
 * import { raceEvent } from 'race-event'
 *
 * const controller = new AbortController()
 * const emitter = new EventTarget()
 *
 * // throws a Error: Oh no!
 * const resolve = await raceEvent(emitter, 'event', controller.signal, {
 *   filter: (evt: Event) => {
 *     return evt.detail.foo === 'bar'
 *   }
 * })
 * ```
 *
 * @example Terminating early by throwing from the filter
 *
 * You can cause listening for the event to cease and all event listeners to be
 * removed by throwing from the filter:
 *
 * ```TypeScript
 * import { raceEvent } from 'race-event'
 *
 * const controller = new AbortController()
 * const emitter = new EventTarget()
 *
 * // throws Error: Cannot continue
 * const resolve = await raceEvent(emitter, 'event', controller.signal, {
 *   filter: (evt) => {
 *     if (...reasons) {
 *       throw new Error('Cannot continue')
 *     }
 *
 *     return true
 *   }
 * })
 * ```
 */
/**
 * An abort error class that extends error
 */
let AbortError$1 = class AbortError extends Error {
    type;
    code;
    constructor(message, code) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.name = 'AbortError';
        this.code = code ?? 'ABORT_ERR';
    }
};
/**
 * Race a promise against an abort signal
 */
async function raceEvent(emitter, eventName, signal, opts) {
    // create the error here so we have more context in the stack trace
    const error = new AbortError$1(opts?.errorMessage, opts?.errorCode);
    if (signal?.aborted === true) {
        return Promise.reject(error);
    }
    return new Promise((resolve, reject) => {
        function removeListeners() {
            signal?.removeEventListener('abort', abortListener);
            emitter.removeEventListener(eventName, eventListener);
            if (opts?.errorEvent != null) {
                emitter.removeEventListener(opts.errorEvent, errorEventListener);
            }
        }
        const eventListener = (evt) => {
            try {
                if (opts?.filter?.(evt) === false) {
                    return;
                }
            }
            catch (err) {
                removeListeners();
                reject(err);
                return;
            }
            removeListeners();
            resolve(evt);
        };
        const errorEventListener = (evt) => {
            removeListeners();
            reject(evt.detail);
        };
        const abortListener = () => {
            removeListeners();
            reject(error);
        };
        signal?.addEventListener('abort', abortListener);
        emitter.addEventListener(eventName, eventListener);
        if (opts?.errorEvent != null) {
            emitter.addEventListener(opts.errorEvent, errorEventListener);
        }
    });
}

class QueueFullError extends Error {
    static name = 'QueueFullError';
    constructor(message = 'The queue was full') {
        super(message);
        this.name = 'QueueFullError';
    }
}

let JobRecipient$1 = class JobRecipient {
    deferred;
    signal;
    constructor(signal) {
        this.signal = signal;
        this.deferred = Promise.withResolvers();
        this.onAbort = this.onAbort.bind(this);
        this.signal?.addEventListener('abort', this.onAbort);
    }
    onAbort() {
        this.deferred.reject(this.signal?.reason ?? new AbortError$2());
    }
    cleanup() {
        this.signal?.removeEventListener('abort', this.onAbort);
    }
};

/**
 * Returns a random string
 */
function randomId$1() {
    return `${(parseInt(String(Math.random() * 1e9), 10)).toString()}${Date.now()}`;
}
let Job$1 = class Job {
    id;
    fn;
    options;
    recipients;
    status;
    timeline;
    controller;
    constructor(fn, options) {
        this.id = randomId$1();
        this.status = 'queued';
        this.fn = fn;
        this.options = options;
        this.recipients = [];
        this.timeline = {
            created: Date.now()
        };
        this.controller = new AbortController();
        setMaxListeners(Infinity, this.controller.signal);
        this.onAbort = this.onAbort.bind(this);
    }
    abort(err) {
        this.controller.abort(err);
    }
    onAbort() {
        const allAborted = this.recipients.reduce((acc, curr) => {
            return acc && (curr.signal?.aborted === true);
        }, true);
        // if all recipients have aborted the job, actually abort the job
        if (allAborted) {
            this.controller.abort(new AbortError$2());
            this.cleanup();
        }
    }
    async join(options = {}) {
        const recipient = new JobRecipient$1(options.signal);
        this.recipients.push(recipient);
        options.signal?.addEventListener('abort', this.onAbort);
        return recipient.deferred.promise;
    }
    async run() {
        this.status = 'running';
        this.timeline.started = Date.now();
        try {
            this.controller.signal.throwIfAborted();
            const result = await raceSignal(this.fn({
                ...(this.options ?? {}),
                signal: this.controller.signal
            }), this.controller.signal);
            this.recipients.forEach(recipient => {
                recipient.deferred.resolve(result);
            });
            this.status = 'complete';
        }
        catch (err) {
            this.recipients.forEach(recipient => {
                recipient.deferred.reject(err);
            });
            this.status = 'errored';
        }
        finally {
            this.timeline.finished = Date.now();
            this.cleanup();
        }
    }
    cleanup() {
        this.recipients.forEach(recipient => {
            recipient.cleanup();
            recipient.signal?.removeEventListener('abort', this.onAbort);
        });
    }
};

/**
 * Returns a function wrapper that will only call the passed function once
 *
 * Important - the passed function should not throw or reject
 */
function debounce(func, wait) {
    let timeout;
    const output = function () {
        const later = function () {
            timeout = undefined;
            void func();
        };
        clearTimeout(timeout);
        timeout = setTimeout(later, wait);
    };
    output.start = () => { };
    output.stop = () => {
        clearTimeout(timeout);
    };
    return output;
}

/**
 * @packageDocumentation
 *
 * Based on `p-queue` but with access to the underlying queue, aborting a task
 * removes it from the queue and you can iterate over the queue results.
 *
 * @example
 *
 * ```ts
 * import all from 'it-all'
 * import { Queue } from 'it-queue'
 *
 * const queue = new Queue({
 *   concurrency: Infinity
 * })
 * void queue.add(async () => {
 *   return 'hello'
 * })
 * void queue.add(async () => {
 *   return 'world'
 * })
 *
 * const results = await all(queue)
 * // ['hello', 'world']
 *
 * // how many items are in the queue (includes running items)
 * console.info(queue.size)
 *
 * // how many items are running
 * console.info(queue.running)
 *
 * // how many items have not started running yet
 * console.info(queue.queued)
 * ```
 */
/**
 * Heavily influence by `p-queue` with the following differences:
 *
 * 1. Items remain at the head of the queue while they are running so `queue.size` includes `queue.pending` items - this is so interested parties can join the results of a queue item while it is running
 * 2. The options for a job are stored separately to the job in order for them to be modified while they are still in the queue
 * 3. If a job's abort signal fires before execution begins, it is removed from the queue immediately
 * 4. 'success'/'failure' events are emitted instead of 'error'/'complete'
 */
let Queue$1 = class Queue extends TypedEventEmitter {
    concurrency;
    maxSize;
    queue;
    pending;
    sort;
    autoStart;
    constructor(init = {}) {
        super();
        this.concurrency = init.concurrency ?? Number.POSITIVE_INFINITY;
        this.maxSize = init.maxSize ?? Number.POSITIVE_INFINITY;
        this.pending = 0;
        this.autoStart = init.autoStart ?? true;
        this.sort = init.sort;
        this.queue = [];
        this.emitEmpty = debounce(this.emitEmpty.bind(this), 1);
        this.emitIdle = debounce(this.emitIdle.bind(this), 1);
    }
    [Symbol.asyncIterator]() {
        return this.toGenerator();
    }
    emitEmpty() {
        if (this.size !== 0) {
            return;
        }
        this.safeDispatchEvent('empty');
    }
    emitIdle() {
        if (this.running !== 0) {
            return;
        }
        this.safeDispatchEvent('idle');
    }
    tryToStartAnother() {
        if (this.size === 0) {
            this.emitEmpty();
            if (this.running === 0) {
                this.emitIdle();
            }
            return false;
        }
        if (this.pending < this.concurrency) {
            let job;
            for (const j of this.queue) {
                if (j.status === 'queued') {
                    job = j;
                    break;
                }
            }
            if (job == null) {
                return false;
            }
            this.safeDispatchEvent('active');
            this.pending++;
            void job.run()
                .finally(() => {
                // remove the job from the queue
                for (let i = 0; i < this.queue.length; i++) {
                    if (this.queue[i] === job) {
                        this.queue.splice(i, 1);
                        break;
                    }
                }
                this.pending--;
                this.safeDispatchEvent('next');
                if (this.autoStart) {
                    this.tryToStartAnother();
                }
            });
            return true;
        }
        return false;
    }
    enqueue(job) {
        this.queue.push(job);
        if (this.sort != null) {
            this.queue.sort(this.sort);
        }
    }
    /**
     * Start the queue. If the `autoStart` parameter passed to the constructor was
     * not `false` this is a no-op
     */
    start() {
        if (this.autoStart !== false) {
            return;
        }
        this.autoStart = true;
        this.tryToStartAnother();
    }
    /**
     * Prevent further jobs from running - call `.start` to start the queue again
     */
    pause() {
        this.autoStart = false;
    }
    /**
     * Adds a sync or async task to the queue. Always returns a promise.
     */
    async add(fn, options) {
        options?.signal?.throwIfAborted();
        if (this.size === this.maxSize) {
            throw new QueueFullError();
        }
        const job = new Job$1(fn, options);
        this.enqueue(job);
        this.safeDispatchEvent('add');
        if (this.autoStart) {
            this.tryToStartAnother();
        }
        return job.join(options)
            .then(result => {
            this.safeDispatchEvent('success', { detail: { job, result } });
            return result;
        })
            .catch(err => {
            if (job.status === 'queued') {
                // job was aborted before it started - remove the job from the queue
                for (let i = 0; i < this.queue.length; i++) {
                    if (this.queue[i] === job) {
                        this.queue.splice(i, 1);
                        break;
                    }
                }
            }
            this.safeDispatchEvent('failure', { detail: { job, error: err } });
            throw err;
        });
    }
    /**
     * Clear the queue
     */
    clear() {
        this.queue.splice(0, this.queue.length);
    }
    /**
     * Abort all jobs in the queue and clear it
     */
    abort() {
        this.queue.forEach(job => {
            job.abort(new AbortError$2());
        });
        this.clear();
    }
    /**
     * Can be called multiple times. Useful if you for example add additional items at a later time.
     *
     * @returns A promise that settles when the queue becomes empty.
     */
    async onEmpty(options) {
        // Instantly resolve if the queue is empty
        if (this.size === 0) {
            return;
        }
        await raceEvent(this, 'empty', options?.signal);
    }
    /**
     * @returns A promise that settles when the queue size is less than the given
     * limit: `queue.size < limit`.
     *
     * If you want to avoid having the queue grow beyond a certain size you can
     * `await queue.onSizeLessThan()` before adding a new item.
     *
     * Note that this only limits the number of items waiting to start. There
     * could still be up to `concurrency` jobs already running that this call does
     * not include in its calculation.
     */
    async onSizeLessThan(limit, options) {
        // Instantly resolve if the queue is empty.
        if (this.size < limit) {
            return;
        }
        await raceEvent(this, 'next', options?.signal, {
            filter: () => this.size < limit
        });
    }
    /**
     * The difference with `.onEmpty` is that `.onIdle` guarantees that all work
     * from the queue has finished. `.onEmpty` merely signals that the queue is
     * empty, but it could mean that some promises haven't completed yet.
     *
     * @returns A promise that settles when the queue becomes empty, and all
     * promises have completed; `queue.size === 0 && queue.pending === 0`.
     */
    async onIdle(options) {
        // Instantly resolve if none pending and if nothing else is queued
        if (this.pending === 0 && this.size === 0) {
            return;
        }
        await raceEvent(this, 'idle', options?.signal);
    }
    /**
     * Size of the queue including running items
     */
    get size() {
        return this.queue.length;
    }
    /**
     * The number of queued items waiting to run.
     */
    get queued() {
        return this.queue.length - this.pending;
    }
    /**
     * The number of items currently running.
     */
    get running() {
        return this.pending;
    }
    /**
     * Returns an async generator that makes it easy to iterate over the results
     * of jobs added to the queue.
     *
     * The generator will end when the queue becomes idle, that is there are no
     * jobs running and no jobs that have yet to run.
     *
     * If you need to keep the queue open indefinitely, consider using it-pushable
     * instead.
     */
    async *toGenerator(options) {
        options?.signal?.throwIfAborted();
        const stream = pushable({
            objectMode: true
        });
        const cleanup = (err) => {
            if (err != null) {
                this.abort();
            }
            else {
                this.clear();
            }
            stream.end(err);
        };
        const onQueueJobComplete = (evt) => {
            if (evt.detail != null) {
                stream.push(evt.detail.result);
            }
        };
        const onQueueError = (evt) => {
            cleanup(evt.detail.error);
        };
        const onQueueIdle = () => {
            cleanup();
        };
        // clear the queue and throw if the query is aborted
        const onSignalAbort = () => {
            cleanup(new AbortError$2('Queue aborted'));
        };
        // add listeners
        this.addEventListener('success', onQueueJobComplete);
        this.addEventListener('failure', onQueueError);
        this.addEventListener('idle', onQueueIdle);
        options?.signal?.addEventListener('abort', onSignalAbort);
        try {
            yield* stream;
        }
        finally {
            // remove listeners
            this.removeEventListener('success', onQueueJobComplete);
            this.removeEventListener('failure', onQueueError);
            this.removeEventListener('idle', onQueueIdle);
            options?.signal?.removeEventListener('abort', onSignalAbort);
            // empty the queue for when the user has broken out of a loop early
            cleanup();
        }
    }
};

const WORKER_REQUEST_READ_LOCK = 'lock:worker:request-read';
const WORKER_ABORT_READ_LOCK_REQUEST = 'lock:worker:abort-read-request';
const WORKER_RELEASE_READ_LOCK = 'lock:worker:release-read';
const MASTER_GRANT_READ_LOCK = 'lock:master:grant-read';
const MASTER_READ_LOCK_ERROR = 'lock:master:error-read';
const WORKER_REQUEST_WRITE_LOCK = 'lock:worker:request-write';
const WORKER_ABORT_WRITE_LOCK_REQUEST = 'lock:worker:abort-write-request';
const WORKER_RELEASE_WRITE_LOCK = 'lock:worker:release-write';
const MASTER_GRANT_WRITE_LOCK = 'lock:master:grant-write';
const MASTER_WRITE_LOCK_ERROR = 'lock:master:error-write';
const WORKER_FINALIZE = 'lock:worker:finalize';
const BROADCAST_CHANNEL_NAME = 'mortice';
const defaultOptions$3 = {
    singleProcess: false
};

const handleChannelWorkerLockRequest = (emitter, channel, masterEvent, abortMasterEvent, requestType, abortType, errorType, releaseType, grantType) => {
    return (event) => {
        if (event.data == null) {
            return;
        }
        const requestEvent = {
            type: event.data.type,
            name: event.data.name,
            identifier: event.data.identifier
        };
        // worker is requesting lock
        if (requestEvent.type === requestType) {
            emitter.safeDispatchEvent(masterEvent, {
                detail: {
                    name: requestEvent.name,
                    identifier: requestEvent.identifier,
                    handler: async () => {
                        // grant lock to worker
                        channel.postMessage({
                            type: grantType,
                            name: requestEvent.name,
                            identifier: requestEvent.identifier
                        });
                        // wait for worker to finish
                        await new Promise((resolve) => {
                            const releaseEventListener = (event) => {
                                if (event?.data == null) {
                                    return;
                                }
                                const releaseEvent = {
                                    type: event.data.type,
                                    name: event.data.name,
                                    identifier: event.data.identifier
                                };
                                if (releaseEvent.type === releaseType && releaseEvent.identifier === requestEvent.identifier) {
                                    channel.removeEventListener('message', releaseEventListener);
                                    resolve();
                                }
                            };
                            channel.addEventListener('message', releaseEventListener);
                        });
                    },
                    onError: (err) => {
                        // send error to worker
                        channel.postMessage({
                            type: errorType,
                            name: requestEvent.name,
                            identifier: requestEvent.identifier,
                            error: {
                                message: err.message,
                                name: err.name,
                                stack: err.stack
                            }
                        });
                    }
                }
            });
        }
        // worker is no longer interested in requesting the lock
        if (requestEvent.type === abortType) {
            emitter.safeDispatchEvent(abortMasterEvent, {
                detail: {
                    name: requestEvent.name,
                    identifier: requestEvent.identifier
                }
            });
        }
        // worker is done with lock
        if (requestEvent.type === WORKER_FINALIZE) {
            emitter.safeDispatchEvent('finalizeRequest', {
                detail: {
                    name: requestEvent.name
                }
            });
        }
    };
};

const nanoid = (size = 10) => {
    return Math.random().toString().substring(2, size + 2);
};

class MorticeChannelWorker {
    name;
    channel;
    constructor(name) {
        this.name = name;
        this.channel = new BroadcastChannel(BROADCAST_CHANNEL_NAME);
    }
    readLock(options) {
        return this.sendRequest(WORKER_REQUEST_READ_LOCK, WORKER_ABORT_READ_LOCK_REQUEST, MASTER_GRANT_READ_LOCK, MASTER_READ_LOCK_ERROR, WORKER_RELEASE_READ_LOCK, options);
    }
    writeLock(options) {
        return this.sendRequest(WORKER_REQUEST_WRITE_LOCK, WORKER_ABORT_WRITE_LOCK_REQUEST, MASTER_GRANT_WRITE_LOCK, MASTER_WRITE_LOCK_ERROR, WORKER_RELEASE_WRITE_LOCK, options);
    }
    finalize() {
        this.channel.postMessage({
            type: WORKER_FINALIZE,
            name: this.name
        });
        this.channel.close();
    }
    async sendRequest(requestType, abortType, grantType, errorType, releaseType, options) {
        options?.signal?.throwIfAborted();
        const id = nanoid();
        this.channel.postMessage({
            type: requestType,
            identifier: id,
            name: this.name
        });
        return new Promise((resolve, reject) => {
            const abortListener = () => {
                this.channel.postMessage({
                    type: abortType,
                    identifier: id,
                    name: this.name
                });
            };
            options?.signal?.addEventListener('abort', abortListener, {
                once: true
            });
            const listener = (event) => {
                if (event.data?.identifier !== id) {
                    return;
                }
                if (event.data?.type === grantType) {
                    this.channel.removeEventListener('message', listener);
                    options?.signal?.removeEventListener('abort', abortListener);
                    // lock granted
                    resolve(() => {
                        // release lock
                        this.channel.postMessage({
                            type: releaseType,
                            identifier: id,
                            name: this.name
                        });
                    });
                }
                if (event.data.type === errorType) {
                    this.channel.removeEventListener('message', listener);
                    options?.signal?.removeEventListener('abort', abortListener);
                    // error while waiting for grant of lock
                    const err = new Error();
                    if (event.data.error != null) {
                        err.message = event.data.error.message;
                        err.name = event.data.error.name;
                        err.stack = event.data.error.stack;
                    }
                    reject(err);
                }
            };
            this.channel.addEventListener('message', listener);
        });
    }
}

var impl = (options) => {
    options = Object.assign({}, defaultOptions$3, options);
    const isPrimary = Boolean(globalThis.document) || options.singleProcess;
    if (isPrimary) {
        const channel = new BroadcastChannel(BROADCAST_CHANNEL_NAME);
        const emitter = new TypedEventEmitter();
        channel.addEventListener('message', handleChannelWorkerLockRequest(emitter, channel, 'requestReadLock', 'abortReadLockRequest', WORKER_REQUEST_READ_LOCK, WORKER_ABORT_READ_LOCK_REQUEST, MASTER_READ_LOCK_ERROR, WORKER_RELEASE_READ_LOCK, MASTER_GRANT_READ_LOCK));
        channel.addEventListener('message', handleChannelWorkerLockRequest(emitter, channel, 'requestWriteLock', 'abortWriteLockRequest', WORKER_REQUEST_WRITE_LOCK, WORKER_ABORT_WRITE_LOCK_REQUEST, MASTER_WRITE_LOCK_ERROR, WORKER_RELEASE_WRITE_LOCK, MASTER_GRANT_WRITE_LOCK));
        return emitter;
    }
    return new MorticeChannelWorker(options.name);
};

const mutexes = new Map();
let implementation;
function isMortice(obj) {
    return typeof obj?.readLock === 'function' && typeof obj?.writeLock === 'function';
}
function getImplementation(opts) {
    if (implementation == null) {
        implementation = impl(opts);
        if (!isMortice(implementation)) {
            const emitter = implementation;
            // we are master, set up worker requests
            emitter.addEventListener('requestReadLock', (event) => {
                const mutexName = event.detail.name;
                const identifier = event.detail.identifier;
                const mutex = mutexes.get(mutexName);
                if (mutex == null) {
                    return;
                }
                const abortController = new AbortController();
                const abortListener = (event) => {
                    if (event.detail.name !== mutexName || event.detail.identifier !== identifier) {
                        return;
                    }
                    abortController.abort();
                };
                emitter.addEventListener('abortReadLockRequest', abortListener);
                void mutex.readLock({
                    signal: abortController.signal
                })
                    .then(async (release) => {
                    await event.detail.handler()
                        .finally(() => {
                        release();
                    });
                })
                    .catch(err => {
                    event.detail.onError(err);
                })
                    .finally(() => {
                    emitter.removeEventListener('abortReadLockRequest', abortListener);
                });
            });
            emitter.addEventListener('requestWriteLock', (event) => {
                const mutexName = event.detail.name;
                const identifier = event.detail.identifier;
                const mutex = mutexes.get(mutexName);
                if (mutex == null) {
                    return;
                }
                const abortController = new AbortController();
                const abortListener = (event) => {
                    if (event.detail.name !== mutexName || event.detail.identifier !== identifier) {
                        return;
                    }
                    abortController.abort();
                };
                emitter.addEventListener('abortWriteLockRequest', abortListener);
                void mutex.writeLock({
                    signal: abortController.signal
                })
                    .then(async (release) => {
                    await event.detail.handler()
                        .finally(() => {
                        release();
                    });
                })
                    .catch(err => {
                    event.detail.onError(err);
                })
                    .finally(() => {
                    emitter.removeEventListener('abortWriteLockRequest', abortListener);
                });
            });
            emitter.addEventListener('finalizeRequest', (event) => {
                const mutexName = event.detail.name;
                const mutex = mutexes.get(mutexName);
                if (mutex == null) {
                    return;
                }
                mutex.finalize();
            });
        }
    }
    return implementation;
}
async function createReleasable(queue, options) {
    let res;
    let rej;
    const p = new Promise((resolve, reject) => {
        res = resolve;
        rej = reject;
    });
    const listener = () => {
        rej(new AbortError$2());
    };
    options?.signal?.addEventListener('abort', listener, {
        once: true
    });
    queue.add(async () => {
        await new Promise((resolve) => {
            res(() => {
                options?.signal?.removeEventListener('abort', listener);
                resolve();
            });
        });
    }, {
        signal: options?.signal
    })
        .catch((err) => {
        rej(err);
    });
    return p;
}
const createMutex = (name, options) => {
    let mutex = mutexes.get(name);
    if (mutex != null) {
        return mutex;
    }
    const implementation = getImplementation(options);
    // a Mortice instance will be returned if we are a worker, otherwise if we are
    // primary an event target will be returned that fires events when workers
    // request a lock
    if (isMortice(implementation)) {
        mutex = implementation;
        mutexes.set(name, mutex);
        return mutex;
    }
    const masterQueue = new Queue$1({
        concurrency: 1
    });
    let readQueue;
    mutex = {
        async readLock(opts) {
            // If there's already a read queue, just add the task to it
            if (readQueue != null) {
                return createReleasable(readQueue, opts);
            }
            // Create a new read queue
            readQueue = new Queue$1({
                concurrency: options.concurrency,
                autoStart: false
            });
            const localReadQueue = readQueue;
            // Add the task to the read queue
            const readPromise = createReleasable(readQueue, opts);
            void masterQueue.add(async () => {
                // Start the task only once the master queue has completed processing
                // any previous tasks
                localReadQueue.start();
                // Once all the tasks in the read queue have completed, remove it so
                // that the next read lock will occur after any write locks that were
                // started in the interim
                await localReadQueue.onIdle()
                    .then(() => {
                    if (readQueue === localReadQueue) {
                        readQueue = null;
                    }
                });
            });
            return readPromise;
        },
        async writeLock(opts) {
            // Remove the read queue reference, so that any later read locks will be
            // added to a new queue that starts after this write lock has been
            // released
            readQueue = null;
            return createReleasable(masterQueue, opts);
        },
        finalize: () => {
            mutexes.delete(name);
        },
        queue: masterQueue
    };
    mutexes.set(name, mutex);
    // if requested, finalize the lock once the last lock holder has released it
    if (options.autoFinalize === true) {
        masterQueue.addEventListener('idle', () => {
            mutex.finalize();
        }, {
            once: true
        });
    }
    return mutex;
};

/**
 * @packageDocumentation
 *
 * - Reads occur concurrently
 * - Writes occur one at a time
 * - No reads occur while a write operation is in progress
 * - Locks can be created with different names
 * - Reads/writes can time out
 *
 * @example
 *
 * ```ts
 * import mortice from 'mortice'
 * import delay from 'delay'
 *
 * // the lock name & options objects are both optional
 * const mutex = mortice()
 *
 * Promise.all([
 *   (async () => {
 *     const release = await mutex.readLock()
 *
 *     try {
 *       console.info('read 1')
 *     } finally {
 *       release()
 *     }
 *   })(),
 *   (async () => {
 *     const release = await mutex.readLock()
 *
 *     try {
 *       console.info('read 2')
 *     } finally {
 *       release()
 *     }
 *   })(),
 *   (async () => {
 *     const release = await mutex.writeLock()
 *
 *     try {
 *       await delay(1000)
 *
 *       console.info('write 1')
 *     } finally {
 *       release()
 *     }
 *   })(),
 *   (async () => {
 *     const release = await mutex.readLock()
 *
 *     try {
 *       console.info('read 3')
 *     } finally {
 *       release()
 *     }
 *   })()
 * ])
 * ```
 *
 *     read 1
 *     read 2
 *     <small pause>
 *     write 1
 *     read 3
 *
 * ## Clean up
 *
 * Mutexes are stored globally reference by name, this is so you can obtain the
 * same lock from different contexts, including workers.
 *
 * When a mutex is no longer required, the `.finalize` function should be called
 * to remove any internal references to it.
 *
 * ```ts
 * import mortice from 'mortice'
 *
 * const mutex = mortice()
 *
 * // ...some time later
 *
 * mutex.finalize()
 * ```
 *
 * ## Auto clean up
 *
 * If your app generates a lot of short-lived mutexes and you want to clean them
 * up after the last lock has been released, pass the `autoFinalize` option to
 * mortice in the owning context:
 *
 ```ts
 * import mortice from 'mortice'
 *
 * const mutex = mortice({
 *   autoFinalize: true
 * })
 *
 * const release = await mutex.readLock()
 * // ...some time later
 *
 * release()
 *
 * // mutex will be freed soon after
 * ```
 *
 * ## React native support
 *
 * This module should run on react native but it only supports single-process
 * concurrency as it's not clear to the author (disclaimer - not a react native
 * dev) what the officially supported process concurrency model is.
 *
 * Please open an issue if this is a feature you would like to see added.
 */
const defaultOptions$2 = {
    name: 'lock',
    concurrency: Infinity,
    singleProcess: false,
    autoFinalize: false
};
function createMortice(options) {
    const opts = Object.assign({}, defaultOptions$2, options);
    return createMutex(opts.name, opts);
}

const MAX_ADDRESS_AGE = 3_600_000;
const MAX_PEER_AGE = 21_600_000;

/* eslint-disable complexity */
var Peer;
(function (Peer) {
    (function (Peer$metadataEntry) {
        let _codec;
        Peer$metadataEntry.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.key != null && obj.key !== '')) {
                        w.uint32(10);
                        w.string(obj.key);
                    }
                    if ((obj.value != null && obj.value.byteLength > 0)) {
                        w.uint32(18);
                        w.bytes(obj.value);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length, opts = {}) => {
                    const obj = {
                        key: '',
                        value: alloc$1(0)
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1: {
                                obj.key = reader.string();
                                break;
                            }
                            case 2: {
                                obj.value = reader.bytes();
                                break;
                            }
                            default: {
                                reader.skipType(tag & 7);
                                break;
                            }
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        Peer$metadataEntry.encode = (obj) => {
            return encodeMessage(obj, Peer$metadataEntry.codec());
        };
        Peer$metadataEntry.decode = (buf, opts) => {
            return decodeMessage(buf, Peer$metadataEntry.codec(), opts);
        };
    })(Peer.Peer$metadataEntry || (Peer.Peer$metadataEntry = {}));
    (function (Peer$tagsEntry) {
        let _codec;
        Peer$tagsEntry.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.key != null && obj.key !== '')) {
                        w.uint32(10);
                        w.string(obj.key);
                    }
                    if (obj.value != null) {
                        w.uint32(18);
                        Tag.codec().encode(obj.value, w);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length, opts = {}) => {
                    const obj = {
                        key: ''
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1: {
                                obj.key = reader.string();
                                break;
                            }
                            case 2: {
                                obj.value = Tag.codec().decode(reader, reader.uint32(), {
                                    limits: opts.limits?.value
                                });
                                break;
                            }
                            default: {
                                reader.skipType(tag & 7);
                                break;
                            }
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        Peer$tagsEntry.encode = (obj) => {
            return encodeMessage(obj, Peer$tagsEntry.codec());
        };
        Peer$tagsEntry.decode = (buf, opts) => {
            return decodeMessage(buf, Peer$tagsEntry.codec(), opts);
        };
    })(Peer.Peer$tagsEntry || (Peer.Peer$tagsEntry = {}));
    let _codec;
    Peer.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.addresses != null) {
                    for (const value of obj.addresses) {
                        w.uint32(10);
                        Address.codec().encode(value, w);
                    }
                }
                if (obj.protocols != null) {
                    for (const value of obj.protocols) {
                        w.uint32(18);
                        w.string(value);
                    }
                }
                if (obj.publicKey != null) {
                    w.uint32(34);
                    w.bytes(obj.publicKey);
                }
                if (obj.peerRecordEnvelope != null) {
                    w.uint32(42);
                    w.bytes(obj.peerRecordEnvelope);
                }
                if (obj.metadata != null && obj.metadata.size !== 0) {
                    for (const [key, value] of obj.metadata.entries()) {
                        w.uint32(50);
                        Peer.Peer$metadataEntry.codec().encode({ key, value }, w);
                    }
                }
                if (obj.tags != null && obj.tags.size !== 0) {
                    for (const [key, value] of obj.tags.entries()) {
                        w.uint32(58);
                        Peer.Peer$tagsEntry.codec().encode({ key, value }, w);
                    }
                }
                if (obj.updated != null) {
                    w.uint32(64);
                    w.uint64Number(obj.updated);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    addresses: [],
                    protocols: [],
                    metadata: new Map(),
                    tags: new Map()
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            if (opts.limits?.addresses != null && obj.addresses.length === opts.limits.addresses) {
                                throw new MaxLengthError('Decode error - map field "addresses" had too many elements');
                            }
                            obj.addresses.push(Address.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.addresses$
                            }));
                            break;
                        }
                        case 2: {
                            if (opts.limits?.protocols != null && obj.protocols.length === opts.limits.protocols) {
                                throw new MaxLengthError('Decode error - map field "protocols" had too many elements');
                            }
                            obj.protocols.push(reader.string());
                            break;
                        }
                        case 4: {
                            obj.publicKey = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.peerRecordEnvelope = reader.bytes();
                            break;
                        }
                        case 6: {
                            if (opts.limits?.metadata != null && obj.metadata.size === opts.limits.metadata) {
                                throw new MaxSizeError('Decode error - map field "metadata" had too many elements');
                            }
                            const entry = Peer.Peer$metadataEntry.codec().decode(reader, reader.uint32());
                            obj.metadata.set(entry.key, entry.value);
                            break;
                        }
                        case 7: {
                            if (opts.limits?.tags != null && obj.tags.size === opts.limits.tags) {
                                throw new MaxSizeError('Decode error - map field "tags" had too many elements');
                            }
                            const entry = Peer.Peer$tagsEntry.codec().decode(reader, reader.uint32(), {
                                limits: {
                                    value: opts.limits?.tags$value
                                }
                            });
                            obj.tags.set(entry.key, entry.value);
                            break;
                        }
                        case 8: {
                            obj.updated = reader.uint64Number();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Peer.encode = (obj) => {
        return encodeMessage(obj, Peer.codec());
    };
    Peer.decode = (buf, opts) => {
        return decodeMessage(buf, Peer.codec(), opts);
    };
})(Peer || (Peer = {}));
var Address;
(function (Address) {
    let _codec;
    Address.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.multiaddr != null && obj.multiaddr.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.multiaddr);
                }
                if (obj.isCertified != null) {
                    w.uint32(16);
                    w.bool(obj.isCertified);
                }
                if (obj.observed != null) {
                    w.uint32(24);
                    w.uint64Number(obj.observed);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    multiaddr: alloc$1(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.multiaddr = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.isCertified = reader.bool();
                            break;
                        }
                        case 3: {
                            obj.observed = reader.uint64Number();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Address.encode = (obj) => {
        return encodeMessage(obj, Address.codec());
    };
    Address.decode = (buf, opts) => {
        return decodeMessage(buf, Address.codec(), opts);
    };
})(Address || (Address = {}));
var Tag;
(function (Tag) {
    let _codec;
    Tag.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.value != null && obj.value !== 0)) {
                    w.uint32(8);
                    w.uint32(obj.value);
                }
                if (obj.expiry != null) {
                    w.uint32(16);
                    w.uint64(obj.expiry);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    value: 0
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.value = reader.uint32();
                            break;
                        }
                        case 2: {
                            obj.expiry = reader.uint64();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Tag.encode = (obj) => {
        return encodeMessage(obj, Tag.codec());
    };
    Tag.decode = (buf, opts) => {
        return decodeMessage(buf, Tag.codec(), opts);
    };
})(Tag || (Tag = {}));

function populatePublicKey(peerId, protobuf) {
    if (peerId.publicKey != null || protobuf.publicKey == null) {
        return peerId;
    }
    let digest;
    if (peerId.type === 'RSA') {
        // avoid hashing public key
        digest = peerId.toMultihash();
    }
    const publicKey = publicKeyFromProtobuf(protobuf.publicKey, digest);
    return peerIdFromPublicKey(publicKey);
}
function bytesToPeer(peerId, buf, maxAddressAge) {
    const peer = Peer.decode(buf);
    return pbToPeer(peerId, peer, maxAddressAge);
}
function pbToPeer(peerId, peer, maxAddressAge) {
    const tags = new Map();
    // remove any expired tags
    const now = BigInt(Date.now());
    for (const [key, tag] of peer.tags.entries()) {
        if (tag.expiry != null && tag.expiry < now) {
            continue;
        }
        tags.set(key, tag);
    }
    return {
        ...peer,
        id: populatePublicKey(peerId, peer),
        addresses: peer.addresses
            // remove any expired multiaddrs
            .filter(({ observed }) => observed != null && observed > (Date.now() - maxAddressAge))
            .map(({ multiaddr: ma, isCertified }) => {
            return {
                multiaddr: multiaddr(ma),
                isCertified: isCertified ?? false
            };
        }),
        metadata: peer.metadata,
        peerRecordEnvelope: peer.peerRecordEnvelope ?? undefined,
        tags
    };
}

function peerEquals(peerA, peerB) {
    return addressesEqual(peerA.addresses, peerB.addresses) &&
        protocolsEqual(peerA.protocols, peerB.protocols) &&
        publicKeyEqual(peerA.publicKey, peerB.publicKey) &&
        peerRecordEnvelope(peerA.peerRecordEnvelope, peerB.peerRecordEnvelope) &&
        metadataEqual(peerA.metadata, peerB.metadata) &&
        tagsEqual(peerA.tags, peerB.tags);
}
function addressesEqual(addressesA, addressesB) {
    return compareArrays(addressesA, addressesB, (a, b) => {
        if (a.isCertified !== b.isCertified) {
            return false;
        }
        if (!equals(a.multiaddr, b.multiaddr)) {
            return false;
        }
        return true;
    });
}
function protocolsEqual(protocolsA, protocolsB) {
    return compareArrays(protocolsA, protocolsB, (a, b) => a === b);
}
function publicKeyEqual(publicKeyA, publicKeyB) {
    return compareOptionalUint8Arrays(publicKeyA, publicKeyB);
}
function peerRecordEnvelope(envelopeA, envelopeB) {
    return compareOptionalUint8Arrays(envelopeA, envelopeB);
}
function metadataEqual(metadataA, metadataB) {
    return compareMaps(metadataA, metadataB, (a, b) => equals(a, b));
}
function tagsEqual(metadataA, metadataB) {
    return compareMaps(metadataA, metadataB, (a, b) => a.value === b.value && a.expiry === b.expiry);
}
function compareOptionalUint8Arrays(arrA, arrB) {
    if (arrA == null && arrB == null) {
        return true;
    }
    if (arrA != null && arrB != null) {
        return equals(arrA, arrB);
    }
    return false;
}
function compareArrays(arrA, arrB, compare) {
    if (arrA.length !== arrB.length) {
        return false;
    }
    for (let i = 0; i < arrA.length; i++) {
        if (!compare(arrA[i], arrB[i])) {
            return false;
        }
    }
    return true;
}
function compareMaps(mapA, mapB, compare) {
    if (mapA.size !== mapB.size) {
        return false;
    }
    for (const [key, value] of mapA.entries()) {
        const valueB = mapB.get(key);
        if (valueB == null) {
            return false;
        }
        if (!compare(value, valueB)) {
            return false;
        }
    }
    return true;
}

const pathSepS = '/';
const pathSepB = new TextEncoder().encode(pathSepS);
const pathSep = pathSepB[0];
/**
 * A Key represents the unique identifier of an object.
 * Our Key scheme is inspired by file systems and Google App Engine key model.
 * Keys are meant to be unique across a system. Keys are hierarchical,
 * incorporating more and more specific namespaces. Thus keys can be deemed
 * 'children' or 'ancestors' of other keys:
 * - `new Key('/Comedy')`
 * - `new Key('/Comedy/MontyPython')`
 * Also, every namespace can be parametrized to embed relevant object
 * information. For example, the Key `name` (most specific namespace) could
 * include the object type:
 * - `new Key('/Comedy/MontyPython/Actor:JohnCleese')`
 * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop')`
 * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop/Character:Mousebender')`
 *
 */
class Key {
    _buf;
    /**
     * @param {string | Uint8Array} s
     * @param {boolean} [clean]
     */
    constructor(s, clean) {
        if (typeof s === 'string') {
            this._buf = fromString(s);
        }
        else if (s instanceof Uint8Array) {
            this._buf = s;
        }
        else {
            throw new Error('Invalid key, should be String of Uint8Array');
        }
        if (clean == null) {
            clean = true;
        }
        if (clean) {
            this.clean();
        }
        if (this._buf.byteLength === 0 || this._buf[0] !== pathSep) {
            throw new Error('Invalid key');
        }
    }
    /**
     * Convert to the string representation
     *
     * @param {import('uint8arrays/to-string').SupportedEncodings} [encoding] - The encoding to use.
     * @returns {string}
     */
    toString(encoding = 'utf8') {
        return toString(this._buf, encoding);
    }
    /**
     * Return the Uint8Array representation of the key
     *
     * @returns {Uint8Array}
     */
    uint8Array() {
        return this._buf;
    }
    /**
     * Return string representation of the key
     *
     * @returns {string}
     */
    get [Symbol.toStringTag]() {
        return `Key(${this.toString()})`;
    }
    /**
     * Constructs a key out of a namespace array.
     *
     * @param {Array<string>} list - The array of namespaces
     * @returns {Key}
     *
     * @example
     * ```js
     * Key.withNamespaces(['one', 'two'])
     * // => Key('/one/two')
     * ```
     */
    static withNamespaces(list) {
        return new Key(list.join(pathSepS));
    }
    /**
     * Returns a randomly (uuid) generated key.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * Key.random()
     * // => Key('/344502982398')
     * ```
     */
    static random() {
        return new Key(Math.random().toString().substring(2));
    }
    /**
     * @param {*} other
     */
    static asKey(other) {
        if (other instanceof Uint8Array || typeof other === 'string') {
            // we can create a key from this
            return new Key(other);
        }
        if (typeof other.uint8Array === 'function') {
            // this is an older version or may have crossed the esm/cjs boundary
            return new Key(other.uint8Array());
        }
        return null;
    }
    /**
     * Cleanup the current key
     *
     * @returns {void}
     */
    clean() {
        if (this._buf == null || this._buf.byteLength === 0) {
            this._buf = pathSepB;
        }
        if (this._buf[0] !== pathSep) {
            const bytes = new Uint8Array(this._buf.byteLength + 1);
            bytes.fill(pathSep, 0, 1);
            bytes.set(this._buf, 1);
            this._buf = bytes;
        }
        // normalize does not remove trailing slashes
        while (this._buf.byteLength > 1 && this._buf[this._buf.byteLength - 1] === pathSep) {
            this._buf = this._buf.subarray(0, -1);
        }
    }
    /**
     * Check if the given key is sorted lower than ourself.
     *
     * @param {Key} key - The other Key to check against
     * @returns {boolean}
     */
    less(key) {
        const list1 = this.list();
        const list2 = key.list();
        for (let i = 0; i < list1.length; i++) {
            if (list2.length < i + 1) {
                return false;
            }
            const c1 = list1[i];
            const c2 = list2[i];
            if (c1 < c2) {
                return true;
            }
            else if (c1 > c2) {
                return false;
            }
        }
        return list1.length < list2.length;
    }
    /**
     * Returns the key with all parts in reversed order.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').reverse()
     * // => Key('/Actor:JohnCleese/MontyPython/Comedy')
     * ```
     */
    reverse() {
        return Key.withNamespaces(this.list().slice().reverse());
    }
    /**
     * Returns the `namespaces` making up this Key.
     *
     * @returns {Array<string>}
     */
    namespaces() {
        return this.list();
    }
    /**
     * Returns the "base" namespace of this key.
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').baseNamespace()
     * // => 'Actor:JohnCleese'
     * ```
     */
    baseNamespace() {
        const ns = this.namespaces();
        return ns[ns.length - 1];
    }
    /**
     * Returns the `list` representation of this key.
     *
     * @returns {Array<string>}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').list()
     * // => ['Comedy', 'MontyPythong', 'Actor:JohnCleese']
     * ```
     */
    list() {
        return this.toString().split(pathSepS).slice(1);
    }
    /**
     * Returns the "type" of this key (value of last namespace).
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').type()
     * // => 'Actor'
     * ```
     */
    type() {
        return namespaceType(this.baseNamespace());
    }
    /**
     * Returns the "name" of this key (field of last namespace).
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').name()
     * // => 'JohnCleese'
     * ```
     */
    name() {
        return namespaceValue(this.baseNamespace());
    }
    /**
     * Returns an "instance" of this type key (appends value to namespace).
     *
     * @param {string} s - The string to append.
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor').instance('JohnClesse')
     * // => Key('/Comedy/MontyPython/Actor:JohnCleese')
     * ```
     */
    instance(s) {
        return new Key(this.toString() + ':' + s);
    }
    /**
     * Returns the "path" of this key (parent + type).
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').path()
     * // => Key('/Comedy/MontyPython/Actor')
     * ```
     */
    path() {
        let p = this.parent().toString();
        if (!p.endsWith(pathSepS)) {
            p += pathSepS;
        }
        p += this.type();
        return new Key(p);
    }
    /**
     * Returns the `parent` Key of this Key.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key("/Comedy/MontyPython/Actor:JohnCleese").parent()
     * // => Key("/Comedy/MontyPython")
     * ```
     */
    parent() {
        const list = this.list();
        if (list.length === 1) {
            return new Key(pathSepS);
        }
        return new Key(list.slice(0, -1).join(pathSepS));
    }
    /**
     * Returns the `child` Key of this Key.
     *
     * @param {Key} key - The child Key to add
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython').child(new Key('Actor:JohnCleese'))
     * // => Key('/Comedy/MontyPython/Actor:JohnCleese')
     * ```
     */
    child(key) {
        if (this.toString() === pathSepS) {
            return key;
        }
        else if (key.toString() === pathSepS) {
            return this;
        }
        return new Key(this.toString() + key.toString(), false);
    }
    /**
     * Returns whether this key is a prefix of `other`
     *
     * @param {Key} other - The other key to test against
     * @returns {boolean}
     *
     * @example
     * ```js
     * new Key('/Comedy').isAncestorOf('/Comedy/MontyPython')
     * // => true
     * ```
     */
    isAncestorOf(other) {
        if (other.toString() === this.toString()) {
            return false;
        }
        return other.toString().startsWith(this.toString());
    }
    /**
     * Returns whether this key is a contains another as prefix.
     *
     * @param {Key} other - The other Key to test against
     * @returns {boolean}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython').isDecendantOf('/Comedy')
     * // => true
     * ```
     */
    isDecendantOf(other) {
        if (other.toString() === this.toString()) {
            return false;
        }
        return this.toString().startsWith(other.toString());
    }
    /**
     * Checks if this key has only one namespace.
     *
     * @returns {boolean}
     */
    isTopLevel() {
        return this.list().length === 1;
    }
    /**
     * Concats one or more Keys into one new Key.
     *
     * @param {Array<Key>} keys - The array of keys to concatenate
     * @returns {Key}
     */
    concat(...keys) {
        return Key.withNamespaces([...this.namespaces(), ...flatten(keys.map(key => key.namespaces()))]);
    }
}
/**
 * The first component of a namespace. `foo` in `foo:bar`
 *
 * @param {string} ns
 * @returns {string}
 */
function namespaceType(ns) {
    const parts = ns.split(':');
    if (parts.length < 2) {
        return '';
    }
    return parts.slice(0, -1).join(':');
}
/**
 * The last component of a namespace, `baz` in `foo:bar:baz`.
 *
 * @param {string} ns
 * @returns {string}
 */
function namespaceValue(ns) {
    const parts = ns.split(':');
    return parts[parts.length - 1];
}
/**
 * Flatten array of arrays (only one level)
 *
 * @template T
 * @param {Array<any>} arr
 * @returns {T[]}
 */
function flatten(arr) {
    return ([]).concat(...arr);
}

const NAMESPACE_COMMON = '/peers/';
function peerIdToDatastoreKey(peerId) {
    if (!isPeerId(peerId) || peerId.type == null) {
        throw new InvalidParametersError$1('Invalid PeerId');
    }
    const b32key = peerId.toCID().toString();
    return new Key(`${NAMESPACE_COMMON}${b32key}`);
}

async function dedupeFilterAndSortAddresses(peerId, filter, addresses, existingAddresses, options) {
    const addressMap = new Map();
    for (const addr of addresses) {
        if (addr == null) {
            continue;
        }
        if (addr.multiaddr instanceof Uint8Array) {
            addr.multiaddr = multiaddr(addr.multiaddr);
        }
        if (!isMultiaddr(addr.multiaddr)) {
            throw new InvalidParametersError$1('Multiaddr was invalid');
        }
        if (!(await filter(peerId, addr.multiaddr, options))) {
            continue;
        }
        const isCertified = addr.isCertified ?? false;
        const maStr = addr.multiaddr.toString();
        const existingAddr = addressMap.get(maStr);
        if (existingAddr != null) {
            addr.isCertified = existingAddr.isCertified || isCertified;
        }
        else {
            addressMap.set(maStr, {
                multiaddr: addr.multiaddr,
                isCertified
            });
        }
    }
    return [...addressMap.values()]
        .sort((a, b) => {
        return a.multiaddr.toString().localeCompare(b.multiaddr.toString());
    })
        .map(({ isCertified, multiaddr: ma }) => {
        // strip the trailing peerId if it is present
        const addrPeer = ma.getPeerId();
        if (peerId.equals(addrPeer)) {
            ma = ma.decapsulate(multiaddr(`/p2p/${peerId}`));
        }
        return {
            isCertified,
            multiaddr: ma.bytes
        };
    });
}

/* eslint-disable complexity */
async function toPeerPB(peerId, data, strategy, options) {
    if (data == null) {
        throw new InvalidParametersError$1('Invalid PeerData');
    }
    if (data.publicKey != null && peerId.publicKey != null && !data.publicKey.equals(peerId.publicKey)) {
        throw new InvalidParametersError$1('publicKey bytes do not match peer id publicKey bytes');
    }
    const existingPeer = options.existingPeer?.peer;
    if (existingPeer != null && !peerId.equals(existingPeer.id)) {
        throw new InvalidParametersError$1('peer id did not match existing peer id');
    }
    let addresses = existingPeer?.addresses ?? [];
    let protocols = new Set(existingPeer?.protocols ?? []);
    let metadata = existingPeer?.metadata ?? new Map();
    let tags = existingPeer?.tags ?? new Map();
    let peerRecordEnvelope = existingPeer?.peerRecordEnvelope;
    // when patching, we replace the original fields with passed values
    if (strategy === 'patch') {
        if (data.multiaddrs != null || data.addresses != null) {
            addresses = [];
            if (data.multiaddrs != null) {
                addresses.push(...data.multiaddrs.map(multiaddr => ({
                    isCertified: false,
                    multiaddr
                })));
            }
            if (data.addresses != null) {
                addresses.push(...data.addresses);
            }
        }
        if (data.protocols != null) {
            protocols = new Set(data.protocols);
        }
        if (data.metadata != null) {
            const metadataEntries = data.metadata instanceof Map ? [...data.metadata.entries()] : Object.entries(data.metadata);
            metadata = createSortedMap(metadataEntries, {
                validate: validateMetadata
            });
        }
        if (data.tags != null) {
            const tagsEntries = data.tags instanceof Map ? [...data.tags.entries()] : Object.entries(data.tags);
            tags = createSortedMap(tagsEntries, {
                validate: validateTag,
                map: mapTag
            });
        }
        if (data.peerRecordEnvelope != null) {
            peerRecordEnvelope = data.peerRecordEnvelope;
        }
    }
    // when merging, we join the original fields with passed values
    if (strategy === 'merge') {
        if (data.multiaddrs != null) {
            addresses.push(...data.multiaddrs.map(multiaddr => ({
                isCertified: false,
                multiaddr
            })));
        }
        if (data.addresses != null) {
            addresses.push(...data.addresses);
        }
        if (data.protocols != null) {
            protocols = new Set([...protocols, ...data.protocols]);
        }
        if (data.metadata != null) {
            const metadataEntries = data.metadata instanceof Map ? [...data.metadata.entries()] : Object.entries(data.metadata);
            for (const [key, value] of metadataEntries) {
                if (value == null) {
                    metadata.delete(key);
                }
                else {
                    metadata.set(key, value);
                }
            }
            metadata = createSortedMap([...metadata.entries()], {
                validate: validateMetadata
            });
        }
        if (data.tags != null) {
            const tagsEntries = data.tags instanceof Map ? [...data.tags.entries()] : Object.entries(data.tags);
            const mergedTags = new Map(tags);
            for (const [key, value] of tagsEntries) {
                if (value == null) {
                    mergedTags.delete(key);
                }
                else {
                    mergedTags.set(key, value);
                }
            }
            tags = createSortedMap([...mergedTags.entries()], {
                validate: validateTag,
                map: mapTag
            });
        }
        if (data.peerRecordEnvelope != null) {
            peerRecordEnvelope = data.peerRecordEnvelope;
        }
    }
    let publicKey;
    if (existingPeer?.id.publicKey != null) {
        publicKey = publicKeyToProtobuf(existingPeer.id.publicKey);
    }
    else if (data.publicKey != null) {
        publicKey = publicKeyToProtobuf(data.publicKey);
    }
    else if (peerId.publicKey != null) {
        publicKey = publicKeyToProtobuf(peerId.publicKey);
    }
    const output = {
        addresses: await dedupeFilterAndSortAddresses(peerId, options.addressFilter ?? (async () => true), addresses, options.existingPeer?.peerPB.addresses, options),
        protocols: [...protocols.values()].sort((a, b) => {
            return a.localeCompare(b);
        }),
        metadata,
        tags,
        publicKey,
        peerRecordEnvelope
    };
    // add observed addresses to multiaddrs
    output.addresses.forEach(addr => {
        addr.observed = options.existingPeer?.peerPB.addresses?.find(addr => equals(addr.multiaddr, addr.multiaddr))?.observed ?? Date.now();
    });
    // Ed25519 and secp256k1 have their public key embedded in them so no need to duplicate it
    if (peerId.type !== 'RSA') {
        delete output.publicKey;
    }
    return output;
}
/**
 * In JS maps are ordered by insertion order so create a new map with the
 * keys inserted in alphabetical order.
 */
function createSortedMap(entries, options) {
    const output = new Map();
    for (const [key, value] of entries) {
        if (value == null) {
            continue;
        }
        options.validate(key, value);
    }
    for (const [key, value] of entries.sort(([a], [b]) => {
        return a.localeCompare(b);
    })) {
        if (value != null) {
            output.set(key, options.map?.(key, value) ?? value);
        }
    }
    return output;
}
function validateMetadata(key, value) {
    if (typeof key !== 'string') {
        throw new InvalidParametersError$1('Metadata key must be a string');
    }
    if (!(value instanceof Uint8Array)) {
        throw new InvalidParametersError$1('Metadata value must be a Uint8Array');
    }
}
function validateTag(key, tag) {
    if (typeof key !== 'string') {
        throw new InvalidParametersError$1('Tag name must be a string');
    }
    if (tag.value != null) {
        if (parseInt(`${tag.value}`, 10) !== tag.value) {
            throw new InvalidParametersError$1('Tag value must be an integer');
        }
        if (tag.value < 0 || tag.value > 100) {
            throw new InvalidParametersError$1('Tag value must be between 0-100');
        }
    }
    if (tag.ttl != null) {
        if (parseInt(`${tag.ttl}`, 10) !== tag.ttl) {
            throw new InvalidParametersError$1('Tag ttl must be an integer');
        }
        if (tag.ttl < 0) {
            throw new InvalidParametersError$1('Tag ttl must be between greater than 0');
        }
    }
}
function mapTag(key, tag) {
    let expiry;
    if (tag.expiry != null) {
        expiry = tag.expiry;
    }
    if (tag.ttl != null) {
        expiry = BigInt(Date.now() + Number(tag.ttl));
    }
    const output = {
        value: tag.value ?? 0
    };
    if (expiry != null) {
        output.expiry = expiry;
    }
    return output;
}

function keyToPeerId(key) {
    // /peers/${peer-id-as-libp2p-key-cid-string-in-base-32}
    const base32Str = key.toString().split('/')[2];
    const buf = CID.parse(base32Str, base32$2);
    return peerIdFromCID(buf);
}
function decodePeer(key, value, maxAddressAge) {
    const peerId = keyToPeerId(key);
    return bytesToPeer(peerId, value, maxAddressAge);
}
function mapQuery(query, maxAddressAge) {
    return {
        prefix: NAMESPACE_COMMON,
        filters: (query.filters ?? []).map(fn => ({ key, value }) => {
            return fn(decodePeer(key, value, maxAddressAge));
        }),
        orders: (query.orders ?? []).map(fn => (a, b) => {
            return fn(decodePeer(a.key, a.value, maxAddressAge), decodePeer(b.key, b.value, maxAddressAge));
        })
    };
}
class PersistentStore {
    peerId;
    datastore;
    locks;
    addressFilter;
    log;
    maxAddressAge;
    maxPeerAge;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:peer-store');
        this.peerId = components.peerId;
        this.datastore = components.datastore;
        this.addressFilter = init.addressFilter;
        this.locks = trackedPeerMap({
            name: 'libp2p_peer_store_locks',
            metrics: components.metrics
        });
        this.maxAddressAge = init.maxAddressAge ?? MAX_ADDRESS_AGE;
        this.maxPeerAge = init.maxPeerAge ?? MAX_PEER_AGE;
    }
    getLock(peerId) {
        let lock = this.locks.get(peerId);
        if (lock == null) {
            lock = {
                refs: 0,
                lock: createMortice({
                    name: peerId.toString(),
                    singleProcess: true
                })
            };
            this.locks.set(peerId, lock);
        }
        lock.refs++;
        return lock;
    }
    maybeRemoveLock(peerId, lock) {
        lock.refs--;
        if (lock.refs === 0) {
            lock.lock.finalize();
            this.locks.delete(peerId);
        }
    }
    async getReadLock(peerId, options) {
        const lock = this.getLock(peerId);
        try {
            const release = await lock.lock.readLock(options);
            return () => {
                release();
                this.maybeRemoveLock(peerId, lock);
            };
        }
        catch (err) {
            this.maybeRemoveLock(peerId, lock);
            throw err;
        }
    }
    async getWriteLock(peerId, options) {
        const lock = this.getLock(peerId);
        try {
            const release = await lock.lock.writeLock(options);
            return () => {
                release();
                this.maybeRemoveLock(peerId, lock);
            };
        }
        catch (err) {
            this.maybeRemoveLock(peerId, lock);
            throw err;
        }
    }
    async has(peerId, options) {
        try {
            await this.load(peerId, options);
            return true;
        }
        catch (err) {
            if (err.name !== 'NotFoundError') {
                throw err;
            }
        }
        return false;
    }
    async delete(peerId, options) {
        if (this.peerId.equals(peerId)) {
            return;
        }
        await this.datastore.delete(peerIdToDatastoreKey(peerId), options);
    }
    async load(peerId, options) {
        const key = peerIdToDatastoreKey(peerId);
        const buf = await this.datastore.get(key, options);
        const peer = Peer.decode(buf);
        if (this.#peerIsExpired(peerId, peer)) {
            await this.datastore.delete(key, options);
            throw new NotFoundError$1();
        }
        return pbToPeer(peerId, peer, this.peerId.equals(peerId) ? Infinity : this.maxAddressAge);
    }
    async save(peerId, data, options) {
        const existingPeer = await this.#findExistingPeer(peerId, options);
        const peerPb = await toPeerPB(peerId, data, 'patch', {
            ...options,
            addressFilter: this.addressFilter
        });
        return this.#saveIfDifferent(peerId, peerPb, existingPeer);
    }
    async patch(peerId, data, options) {
        const existingPeer = await this.#findExistingPeer(peerId, options);
        const peerPb = await toPeerPB(peerId, data, 'patch', {
            ...options,
            addressFilter: this.addressFilter,
            existingPeer
        });
        return this.#saveIfDifferent(peerId, peerPb, existingPeer);
    }
    async merge(peerId, data, options) {
        const existingPeer = await this.#findExistingPeer(peerId, options);
        const peerPb = await toPeerPB(peerId, data, 'merge', {
            addressFilter: this.addressFilter,
            existingPeer
        });
        return this.#saveIfDifferent(peerId, peerPb, existingPeer);
    }
    async *all(options) {
        for await (const { key, value } of this.datastore.query(mapQuery(options ?? {}, this.maxAddressAge), options)) {
            const peerId = keyToPeerId(key);
            // skip self peer if present
            if (peerId.equals(this.peerId)) {
                continue;
            }
            const peer = Peer.decode(value);
            // remove expired peer
            if (this.#peerIsExpired(peerId, peer)) {
                await this.datastore.delete(key, options);
                continue;
            }
            yield pbToPeer(peerId, peer, this.peerId.equals(peerId) ? Infinity : this.maxAddressAge);
        }
    }
    async #findExistingPeer(peerId, options) {
        try {
            const key = peerIdToDatastoreKey(peerId);
            const buf = await this.datastore.get(key, options);
            const peerPB = Peer.decode(buf);
            // remove expired peer
            if (this.#peerIsExpired(peerId, peerPB)) {
                await this.datastore.delete(key, options);
                throw new NotFoundError$1();
            }
            return {
                peerPB,
                peer: pbToPeer(peerId, peerPB, this.maxAddressAge)
            };
        }
        catch (err) {
            if (err.name !== 'NotFoundError') {
                this.log.error('invalid peer data found in peer store - %e', err);
            }
        }
    }
    async #saveIfDifferent(peerId, peer, existingPeer, options) {
        // record last update
        peer.updated = Date.now();
        const buf = Peer.encode(peer);
        await this.datastore.put(peerIdToDatastoreKey(peerId), buf, options);
        return {
            peer: pbToPeer(peerId, peer, this.maxAddressAge),
            previous: existingPeer?.peer,
            updated: existingPeer == null || !peerEquals(peer, existingPeer.peerPB)
        };
    }
    #peerIsExpired(peerId, peer) {
        if (peer.updated == null) {
            return true;
        }
        if (this.peerId.equals(peerId)) {
            return false;
        }
        const expired = peer.updated < (Date.now() - this.maxPeerAge);
        const minAddressObserved = Date.now() - this.maxAddressAge;
        const addrs = peer.addresses.filter(addr => {
            return addr.observed != null && addr.observed > minAddressObserved;
        });
        return expired && addrs.length === 0;
    }
}

/**
 * @packageDocumentation
 *
 * The peer store is where libp2p stores data about the peers it has encountered on the network.
 */
/**
 * An implementation of PeerStore that stores data in a Datastore
 */
class PersistentPeerStore {
    store;
    events;
    peerId;
    log;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:peer-store');
        this.events = components.events;
        this.peerId = components.peerId;
        this.store = new PersistentStore(components, init);
    }
    [Symbol.toStringTag] = '@libp2p/peer-store';
    async forEach(fn, query) {
        for await (const peer of this.store.all(query)) {
            fn(peer);
        }
    }
    async all(query) {
        return all$1(this.store.all(query));
    }
    async delete(peerId, options) {
        const release = await this.store.getReadLock(peerId, options);
        try {
            await this.store.delete(peerId, options);
        }
        finally {
            release();
        }
    }
    async has(peerId, options) {
        const release = await this.store.getReadLock(peerId, options);
        try {
            return await this.store.has(peerId, options);
        }
        finally {
            this.log.trace('has release read lock');
            release?.();
        }
    }
    async get(peerId, options) {
        const release = await this.store.getReadLock(peerId, options);
        try {
            return await this.store.load(peerId, options);
        }
        finally {
            release?.();
        }
    }
    async getInfo(peerId, options) {
        const peer = await this.get(peerId, options);
        return {
            id: peer.id,
            multiaddrs: peer.addresses.map(({ multiaddr }) => multiaddr)
        };
    }
    async save(id, data, options) {
        const release = await this.store.getWriteLock(id, options);
        try {
            const result = await this.store.save(id, data, options);
            this.#emitIfUpdated(id, result);
            return result.peer;
        }
        finally {
            release?.();
        }
    }
    async patch(id, data, options) {
        const release = await this.store.getWriteLock(id, options);
        try {
            const result = await this.store.patch(id, data, options);
            this.#emitIfUpdated(id, result);
            return result.peer;
        }
        finally {
            release?.();
        }
    }
    async merge(id, data, options) {
        const release = await this.store.getWriteLock(id, options);
        try {
            const result = await this.store.merge(id, data, options);
            this.#emitIfUpdated(id, result);
            return result.peer;
        }
        finally {
            release?.();
        }
    }
    async consumePeerRecord(buf, arg1, arg2) {
        const expectedPeer = isPeerId(arg1) ? arg1 : isPeerId(arg1?.expectedPeer) ? arg1.expectedPeer : undefined;
        const options = isPeerId(arg1) ? arg2 : arg1 === undefined ? arg2 : arg1;
        const envelope = await RecordEnvelope.openAndCertify(buf, PeerRecord.DOMAIN, options);
        const peerId = peerIdFromCID(envelope.publicKey.toCID());
        if (expectedPeer?.equals(peerId) === false) {
            this.log('envelope peer id was not the expected peer id - expected: %p received: %p', expectedPeer, peerId);
            return false;
        }
        const peerRecord = PeerRecord.createFromProtobuf(envelope.payload);
        let peer;
        try {
            peer = await this.get(peerId, options);
        }
        catch (err) {
            if (err.name !== 'NotFoundError') {
                throw err;
            }
        }
        // ensure seq is greater than, or equal to, the last received
        if (peer?.peerRecordEnvelope != null) {
            const storedEnvelope = RecordEnvelope.createFromProtobuf(peer.peerRecordEnvelope);
            const storedRecord = PeerRecord.createFromProtobuf(storedEnvelope.payload);
            if (storedRecord.seqNumber >= peerRecord.seqNumber) {
                this.log('sequence number was lower or equal to existing sequence number - stored: %d received: %d', storedRecord.seqNumber, peerRecord.seqNumber);
                return false;
            }
        }
        await this.patch(peerRecord.peerId, {
            peerRecordEnvelope: buf,
            addresses: peerRecord.multiaddrs.map(multiaddr => ({
                isCertified: true,
                multiaddr
            }))
        }, options);
        return true;
    }
    #emitIfUpdated(id, result) {
        if (!result.updated) {
            return;
        }
        if (this.peerId.equals(id)) {
            this.events.safeDispatchEvent('self:peer:update', { detail: result });
        }
        else {
            this.events.safeDispatchEvent('peer:update', { detail: result });
        }
    }
}
function persistentPeerStore(components, init = {}) {
    return new PersistentPeerStore(components, init);
}

class NotFoundError extends Error {
    static name = 'NotFoundError';
    static code = 'ERR_NOT_FOUND';
    name = NotFoundError.name;
    code = NotFoundError.code;
    constructor(message = 'Not Found') {
        super(message);
    }
}

/**
 * @packageDocumentation
 *
 * Lets you look at the contents of an async iterator and decide what to do
 *
 * @example
 *
 * ```javascript
 * import peekable from 'it-peekable'
 *
 * // This can also be an iterator, generator, etc
 * const values = [0, 1, 2, 3, 4]
 *
 * const it = peekable(value)
 *
 * const first = it.peek()
 *
 * console.info(first) // 0
 *
 * it.push(first)
 *
 * console.info([...it])
 * // [ 0, 1, 2, 3, 4 ]
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import peekable from 'it-peekable'
 *
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const it = peekable(values())
 *
 * const first = await it.peek()
 *
 * console.info(first) // 0
 *
 * it.push(first)
 *
 * console.info(await all(it))
 * // [ 0, 1, 2, 3, 4 ]
 * ```
 */
function peekable(iterable) {
    // @ts-expect-error can't use Symbol.asyncIterator to index iterable since it might be Iterable
    const [iterator, symbol] = iterable[Symbol.asyncIterator] != null
        // @ts-expect-error can't use Symbol.asyncIterator to index iterable since it might be Iterable
        ? [iterable[Symbol.asyncIterator](), Symbol.asyncIterator]
        // @ts-expect-error can't use Symbol.iterator to index iterable since it might be AsyncIterable
        : [iterable[Symbol.iterator](), Symbol.iterator];
    const queue = [];
    // @ts-expect-error can't use symbol to index peekable
    return {
        peek: () => {
            return iterator.next();
        },
        push: (value) => {
            queue.push(value);
        },
        next: () => {
            if (queue.length > 0) {
                return {
                    done: false,
                    value: queue.shift()
                };
            }
            return iterator.next();
        },
        [symbol]() {
            return this;
        }
    };
}

/**
 * @packageDocumentation
 *
 * Filter values out of an (async)iterable
 *
 * @example
 *
 * ```javascript
 * import all from 'it-all'
 * import filter from 'it-filter'
 *
 * // This can also be an iterator, generator, etc
 * const values = [0, 1, 2, 3, 4]
 *
 * const fn = (val, index) => val > 2 // Return boolean to keep item
 *
 * const arr = all(filter(values, fn))
 *
 * console.info(arr) // 3, 4
 * ```
 *
 * Async sources and filter functions must be awaited:
 *
 * ```javascript
 * import all from 'it-all'
 * import filter from 'it-filter'
 *
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const fn = async val => (val, index) > 2 // Return boolean or promise of boolean to keep item
 *
 * const arr = await all(filter(values, fn))
 *
 * console.info(arr) // 3, 4
 * ```
 */
function isAsyncIterable$3(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function filter(source, fn) {
    let index = 0;
    if (isAsyncIterable$3(source)) {
        return (async function* () {
            for await (const entry of source) {
                if (await fn(entry, index++)) {
                    yield entry;
                }
            }
        })();
    }
    // if mapping function returns a promise we have to return an async generator
    const peekable$1 = peekable(source);
    const { value, done } = peekable$1.next();
    if (done === true) {
        return (function* () { }());
    }
    const res = fn(value, index++);
    // @ts-expect-error .then is not present on O
    if (typeof res.then === 'function') {
        return (async function* () {
            if (await res) {
                yield value;
            }
            for (const entry of peekable$1) {
                if (await fn(entry, index++)) {
                    yield entry;
                }
            }
        })();
    }
    const func = fn;
    return (function* () {
        if (res === true) {
            yield value;
        }
        for (const entry of peekable$1) {
            if (func(entry, index++)) {
                yield entry;
            }
        }
    })();
}

/**
 * @packageDocumentation
 *
 * Consumes all values from an (async)iterable and returns them sorted by the passed sort function.
 *
 * @example
 *
 * ```javascript
 * import sort from 'it-sort'
 * import all from 'it-all'
 *
 * const sorter = (a, b) => {
 *   return a.localeCompare(b)
 * }
 *
 * // This can also be an iterator, generator, etc
 * const values = ['foo', 'bar']
 *
 * const arr = all(sort(values, sorter))
 *
 * console.info(arr) // 'bar', 'foo'
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import sort from 'it-sort'
 * import all from 'it-all'
 *
 * const sorter = (a, b) => {
 *   return a.localeCompare(b)
 * }
 *
 * const values = async function * () {
 *   yield * ['foo', 'bar']
 * }
 *
 * const arr = await all(sort(values, sorter))
 *
 * console.info(arr) // 'bar', 'foo'
 * ```
 */
function isAsyncIterable$2(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function sort(source, sorter) {
    if (isAsyncIterable$2(source)) {
        return (async function* () {
            const arr = await all$1(source);
            yield* arr.sort(sorter);
        })();
    }
    return (function* () {
        const arr = all$1(source);
        yield* arr.sort(sorter);
    })();
}

/**
 * @packageDocumentation
 *
 * For when you only want a few values out of an (async)iterable.
 *
 * @example
 *
 * ```javascript
 * import take from 'it-take'
 * import all from 'it-all'
 *
 * // This can also be an iterator, generator, etc
 * const values = [0, 1, 2, 3, 4]
 *
 * const arr = all(take(values, 2))
 *
 * console.info(arr) // 0, 1
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import take from 'it-take'
 * import all from 'it-all'
 *
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const arr = await all(take(values(), 2))
 *
 * console.info(arr) // 0, 1
 * ```
 */
function isAsyncIterable$1(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function take(source, limit) {
    if (isAsyncIterable$1(source)) {
        return (async function* () {
            let items = 0;
            if (limit < 1) {
                return;
            }
            for await (const entry of source) {
                yield entry;
                items++;
                if (items === limit) {
                    return;
                }
            }
        })();
    }
    return (function* () {
        let items = 0;
        if (limit < 1) {
            return;
        }
        for (const entry of source) {
            yield entry;
            items++;
            if (items === limit) {
                return;
            }
        }
    })();
}

class BaseDatastore {
    put(key, val, options) {
        return Promise.reject(new Error('.put is not implemented'));
    }
    get(key, options) {
        return Promise.reject(new Error('.get is not implemented'));
    }
    has(key, options) {
        return Promise.reject(new Error('.has is not implemented'));
    }
    delete(key, options) {
        return Promise.reject(new Error('.delete is not implemented'));
    }
    async *putMany(source, options = {}) {
        for await (const { key, value } of source) {
            await this.put(key, value, options);
            yield key;
        }
    }
    async *getMany(source, options = {}) {
        for await (const key of source) {
            yield {
                key,
                value: await this.get(key, options)
            };
        }
    }
    async *deleteMany(source, options = {}) {
        for await (const key of source) {
            await this.delete(key, options);
            yield key;
        }
    }
    batch() {
        let puts = [];
        let dels = [];
        return {
            put(key, value) {
                puts.push({ key, value });
            },
            delete(key) {
                dels.push(key);
            },
            commit: async (options) => {
                await drain(this.putMany(puts, options));
                puts = [];
                await drain(this.deleteMany(dels, options));
                dels = [];
            }
        };
    }
    /**
     * Extending classes should override `query` or implement this method
     */
    // eslint-disable-next-line require-yield
    async *_all(q, options) {
        throw new Error('._all is not implemented');
    }
    /**
     * Extending classes should override `queryKeys` or implement this method
     */
    // eslint-disable-next-line require-yield
    async *_allKeys(q, options) {
        throw new Error('._allKeys is not implemented');
    }
    query(q, options) {
        let it = this._all(q, options);
        if (q.prefix != null) {
            const prefix = q.prefix;
            it = filter(it, (e) => e.key.toString().startsWith(prefix));
        }
        if (Array.isArray(q.filters)) {
            it = q.filters.reduce((it, f) => filter(it, f), it);
        }
        if (Array.isArray(q.orders)) {
            it = q.orders.reduce((it, f) => sort(it, f), it);
        }
        if (q.offset != null) {
            let i = 0;
            const offset = q.offset;
            it = filter(it, () => i++ >= offset);
        }
        if (q.limit != null) {
            it = take(it, q.limit);
        }
        return it;
    }
    queryKeys(q, options) {
        let it = this._allKeys(q, options);
        if (q.prefix != null) {
            const prefix = q.prefix;
            it = filter(it, (key) => key.toString().startsWith(prefix));
        }
        if (Array.isArray(q.filters)) {
            it = q.filters.reduce((it, f) => filter(it, f), it);
        }
        if (Array.isArray(q.orders)) {
            it = q.orders.reduce((it, f) => sort(it, f), it);
        }
        if (q.offset != null) {
            const offset = q.offset;
            let i = 0;
            it = filter(it, () => i++ >= offset);
        }
        if (q.limit != null) {
            it = take(it, q.limit);
        }
        return it;
    }
}

class MemoryDatastore extends BaseDatastore {
    data;
    constructor() {
        super();
        this.data = new Map();
    }
    put(key, val, options) {
        options?.signal?.throwIfAborted();
        this.data.set(key.toString(), val);
        return key;
    }
    get(key, options) {
        options?.signal?.throwIfAborted();
        const result = this.data.get(key.toString());
        if (result == null) {
            throw new NotFoundError();
        }
        return result;
    }
    has(key, options) {
        options?.signal?.throwIfAborted();
        return this.data.has(key.toString());
    }
    delete(key, options) {
        options?.signal?.throwIfAborted();
        this.data.delete(key.toString());
    }
    *_all(q, options) {
        options?.signal?.throwIfAborted();
        for (const [key, value] of this.data.entries()) {
            yield { key: new Key(key), value };
            options?.signal?.throwIfAborted();
        }
    }
    *_allKeys(q, options) {
        options?.signal?.throwIfAborted();
        for (const key of this.data.keys()) {
            yield new Key(key);
            options?.signal?.throwIfAborted();
        }
    }
}

class TrackedMap extends Map {
    metric;
    constructor(init) {
        super();
        const { name, metrics } = init;
        this.metric = metrics.registerMetric(name);
        this.updateComponentMetric();
    }
    set(key, value) {
        super.set(key, value);
        this.updateComponentMetric();
        return this;
    }
    delete(key) {
        const deleted = super.delete(key);
        this.updateComponentMetric();
        return deleted;
    }
    clear() {
        super.clear();
        this.updateComponentMetric();
    }
    updateComponentMetric() {
        this.metric.update(this.size);
    }
}
function trackedMap(config) {
    const { name, metrics } = config;
    let map;
    if (metrics != null) {
        map = new TrackedMap({ name, metrics });
    }
    else {
        map = new Map();
    }
    return map;
}

const MAX_DATE = 8_640_000_000_000_000;
const CODEC_TLS = 0x01c0;
const CODEC_SNI = 0x01c1;
const CODEC_DNS = 0x35;
const CODEC_DNS4 = 0x36;
const CODEC_DNS6 = 0x37;
const CODEC_DNSADDR = 0x38;
class DNSMappings {
    log;
    mappings;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:address-manager:dns-mappings');
        this.mappings = trackedMap({
            name: 'libp2p_address_manager_dns_mappings',
            metrics: components.metrics
        });
    }
    has(ma) {
        const host = this.findHost(ma);
        for (const mapping of this.mappings.values()) {
            if (mapping.domain === host) {
                return true;
            }
        }
        return false;
    }
    add(domain, addresses) {
        addresses.forEach(ip => {
            this.log('add DNS mapping %s to %s', ip, domain);
            // we are only confident if this is an local domain mapping, otherwise
            // we will require external validation
            const verified = isPrivateIp(ip) === true;
            this.mappings.set(ip, {
                domain,
                verified,
                expires: verified ? MAX_DATE - Date.now() : 0,
                lastVerified: verified ? MAX_DATE - Date.now() : undefined
            });
        });
    }
    remove(ma) {
        const host = this.findHost(ma);
        let wasConfident = false;
        for (const [ip, mapping] of this.mappings.entries()) {
            if (mapping.domain === host) {
                this.log('removing %s to %s DNS mapping %e', ip, mapping.domain, new Error('where'));
                this.mappings.delete(ip);
                wasConfident = wasConfident || mapping.verified;
            }
        }
        return wasConfident;
    }
    getAll(addresses) {
        const dnsMappedAddresses = [];
        for (let i = 0; i < addresses.length; i++) {
            const address = addresses[i];
            const tuples = address.multiaddr.stringTuples();
            const host = tuples[0][1];
            if (host == null) {
                continue;
            }
            for (const [ip, mapping] of this.mappings.entries()) {
                if (host !== ip) {
                    continue;
                }
                // insert SNI tuple after TLS tuple, if one is present
                const mappedIp = this.maybeAddSNITuple(tuples, mapping.domain);
                if (mappedIp) {
                    // remove the address and replace it with the version that includes
                    // the SNI tuple
                    addresses.splice(i, 1);
                    i--;
                    dnsMappedAddresses.push({
                        multiaddr: multiaddr(`/${tuples.map(tuple => {
                            return [
                                protocols(tuple[0]).name,
                                tuple[1]
                            ].join('/');
                        }).join('/')}`),
                        verified: mapping.verified,
                        type: 'dns-mapping',
                        expires: mapping.expires,
                        lastVerified: mapping.lastVerified
                    });
                }
            }
        }
        return dnsMappedAddresses;
    }
    maybeAddSNITuple(tuples, domain) {
        for (let j = 0; j < tuples.length; j++) {
            if (tuples[j][0] === CODEC_TLS && tuples[j + 1]?.[0] !== CODEC_SNI) {
                tuples.splice(j + 1, 0, [CODEC_SNI, domain]);
                return true;
            }
        }
        return false;
    }
    confirm(ma, ttl) {
        const host = this.findHost(ma);
        let startingConfidence = false;
        for (const [ip, mapping] of this.mappings.entries()) {
            if (mapping.domain === host) {
                this.log('marking %s to %s DNS mapping as verified', ip, mapping.domain);
                startingConfidence = mapping.verified;
                mapping.verified = true;
                mapping.expires = Date.now() + ttl;
                mapping.lastVerified = Date.now();
            }
        }
        return startingConfidence;
    }
    unconfirm(ma, ttl) {
        const host = this.findHost(ma);
        let wasConfident = false;
        for (const [ip, mapping] of this.mappings.entries()) {
            if (mapping.domain === host) {
                this.log('removing verification of %s to %s DNS mapping', ip, mapping.domain);
                wasConfident = wasConfident || mapping.verified;
                mapping.verified = false;
                mapping.expires = Date.now() + ttl;
            }
        }
        return wasConfident;
    }
    findHost(ma) {
        for (const tuple of ma.stringTuples()) {
            if (tuple[0] === CODEC_SNI) {
                return tuple[1];
            }
            if (tuple[0] === CODEC_DNS || tuple[0] === CODEC_DNS4 || tuple[0] === CODEC_DNS6 || tuple[0] === CODEC_DNSADDR) {
                return tuple[1];
            }
        }
    }
}

const CODEC_IP4$1 = 0x04;
const CODEC_IP6$1 = 0x29;
const CODEC_TCP = 0x06;
const CODEC_UDP = 0x0111;
class IPMappings {
    log;
    mappings;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:address-manager:ip-mappings');
        this.mappings = trackedMap({
            name: 'libp2p_address_manager_ip_mappings',
            metrics: components.metrics
        });
    }
    has(ma) {
        const tuples = ma.stringTuples();
        for (const mappings of this.mappings.values()) {
            for (const mapping of mappings) {
                if (mapping.externalIp === tuples[0][1]) {
                    return true;
                }
            }
        }
        return false;
    }
    add(internalIp, internalPort, externalIp, externalPort = internalPort, protocol = 'tcp') {
        const key = `${internalIp}-${internalPort}-${protocol}`;
        const mappings = this.mappings.get(key) ?? [];
        const mapping = {
            internalIp,
            internalPort,
            externalIp,
            externalPort,
            externalFamily: isIPv4(externalIp) ? 4 : 6,
            protocol,
            verified: false,
            expires: 0
        };
        mappings.push(mapping);
        this.mappings.set(key, mappings);
    }
    remove(ma) {
        const tuples = ma.stringTuples();
        const host = tuples[0][1] ?? '';
        const protocol = tuples[1][0] === CODEC_TCP ? 'tcp' : 'udp';
        const port = parseInt(tuples[1][1] ?? '0');
        let wasConfident = false;
        for (const [key, mappings] of this.mappings.entries()) {
            for (let i = 0; i < mappings.length; i++) {
                const mapping = mappings[i];
                if (mapping.externalIp === host && mapping.externalPort === port && mapping.protocol === protocol) {
                    this.log('removing %s:%s to %s:%s %s IP mapping', mapping.externalIp, mapping.externalPort, host, port, protocol);
                    wasConfident = wasConfident || mapping.verified;
                    mappings.splice(i, 1);
                    i--;
                }
            }
            if (mappings.length === 0) {
                this.mappings.delete(key);
            }
        }
        return wasConfident;
    }
    getAll(addresses) {
        const ipMappedAddresses = [];
        for (const { multiaddr: ma } of addresses) {
            const tuples = ma.stringTuples();
            let tuple;
            // see if the internal host/port/protocol tuple has been mapped externally
            if ((tuples[0][0] === CODEC_IP4$1 || tuples[0][0] === CODEC_IP6$1) && tuples[1][0] === CODEC_TCP) {
                tuple = `${tuples[0][1]}-${tuples[1][1]}-tcp`;
            }
            else if ((tuples[0][0] === CODEC_IP4$1 || tuples[0][0] === CODEC_IP6$1) && tuples[1][0] === CODEC_UDP) {
                tuple = `${tuples[0][1]}-${tuples[1][1]}-udp`;
            }
            if (tuple == null) {
                continue;
            }
            const mappings = this.mappings.get(tuple);
            if (mappings == null) {
                continue;
            }
            for (const mapping of mappings) {
                tuples[0][0] = mapping.externalFamily === 4 ? CODEC_IP4$1 : CODEC_IP6$1;
                tuples[0][1] = mapping.externalIp;
                tuples[1][1] = `${mapping.externalPort}`;
                ipMappedAddresses.push({
                    multiaddr: multiaddr(`/${tuples.map(tuple => {
                        return [
                            protocols(tuple[0]).name,
                            tuple[1]
                        ].join('/');
                    }).join('/')}`),
                    verified: mapping.verified,
                    type: 'ip-mapping',
                    expires: mapping.expires,
                    lastVerified: mapping.lastVerified
                });
            }
        }
        return ipMappedAddresses;
    }
    confirm(ma, ttl) {
        const tuples = ma.stringTuples();
        const host = tuples[0][1];
        let startingConfidence = false;
        for (const mappings of this.mappings.values()) {
            for (const mapping of mappings) {
                if (mapping.externalIp === host) {
                    this.log('marking %s to %s IP mapping as verified', mapping.internalIp, mapping.externalIp);
                    startingConfidence = mapping.verified;
                    mapping.verified = true;
                    mapping.expires = Date.now() + ttl;
                    mapping.lastVerified = Date.now();
                }
            }
        }
        return startingConfidence;
    }
    unconfirm(ma, ttl) {
        const tuples = ma.stringTuples();
        const host = tuples[0][1] ?? '';
        const protocol = tuples[1][0] === CODEC_TCP ? 'tcp' : 'udp';
        const port = parseInt(tuples[1][1] ?? '0');
        let wasConfident = false;
        for (const mappings of this.mappings.values()) {
            for (let i = 0; i < mappings.length; i++) {
                const mapping = mappings[i];
                if (mapping.externalIp === host && mapping.externalPort === port && mapping.protocol === protocol) {
                    this.log('removing verification of %s:%s to %s:%s %s IP mapping', mapping.externalIp, mapping.externalPort, host, port, protocol);
                    wasConfident = wasConfident || mapping.verified;
                    mapping.verified = false;
                    mapping.expires = Date.now() + ttl;
                }
            }
        }
        return wasConfident;
    }
}

/**
 * Check if a given multiaddr is a link-local address
 */
function isLinkLocal(ma) {
    try {
        for (const { code, value } of ma.getComponents()) {
            if (code === CODE_IP6ZONE) {
                continue;
            }
            if (value == null) {
                continue;
            }
            if (code === CODE_IP4) {
                return value.startsWith('169.254.');
            }
            if (code === CODE_IP6) {
                return value.toLowerCase().startsWith('fe80');
            }
        }
    }
    catch {
    }
    return false;
}

const defaultValues$2 = {
    maxObservedAddresses: 10
};
class ObservedAddresses {
    log;
    addresses;
    maxObservedAddresses;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:address-manager:observed-addresses');
        this.addresses = trackedMap({
            name: 'libp2p_address_manager_observed_addresses',
            metrics: components.metrics
        });
        this.maxObservedAddresses = init.maxObservedAddresses ?? defaultValues$2.maxObservedAddresses;
    }
    has(ma) {
        return this.addresses.has(ma.toString());
    }
    removePrefixed(prefix) {
        for (const key of this.addresses.keys()) {
            if (key.toString().startsWith(prefix)) {
                this.addresses.delete(key);
            }
        }
    }
    add(ma) {
        if (this.addresses.size === this.maxObservedAddresses) {
            return;
        }
        if (isPrivate(ma) || isLinkLocal(ma)) {
            return;
        }
        this.log('adding observed address %a', ma);
        this.addresses.set(ma.toString(), {
            verified: false,
            expires: 0
        });
    }
    getAll() {
        return Array.from(this.addresses)
            .map(([ma, metadata]) => ({
            multiaddr: multiaddr(ma),
            verified: metadata.verified,
            type: 'observed',
            expires: metadata.expires,
            lastVerified: metadata.lastVerified
        }));
    }
    remove(ma) {
        const startingConfidence = this.addresses.get(ma.toString())?.verified ?? false;
        this.log('removing observed address %a', ma);
        this.addresses.delete(ma.toString());
        return startingConfidence;
    }
    confirm(ma, ttl) {
        const addrString = ma.toString();
        const metadata = this.addresses.get(addrString) ?? {
            verified: false,
            expires: Date.now() + ttl,
            lastVerified: Date.now()
        };
        const startingConfidence = metadata.verified;
        metadata.verified = true;
        metadata.expires = Date.now() + ttl;
        metadata.lastVerified = Date.now();
        this.log('marking observed address %a as verified', addrString);
        this.addresses.set(addrString, metadata);
        return startingConfidence;
    }
}

const NETWORK_CODECS = [
    CODE_IP4,
    CODE_IP6,
    CODE_DNS,
    CODE_DNS4,
    CODE_DNS6,
    CODE_DNSADDR
];
/**
 * Check if a given multiaddr is a network address
 */
function isNetworkAddress(ma) {
    try {
        for (const { code } of ma.getComponents()) {
            if (code === CODE_IP6ZONE) {
                continue;
            }
            return NETWORK_CODECS.includes(code);
        }
    }
    catch {
    }
    return false;
}

const defaultValues$1 = {
    maxObservedAddresses: 10
};
class TransportAddresses {
    log;
    addresses;
    maxObservedAddresses;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:address-manager:observed-addresses');
        this.addresses = trackedMap({
            name: 'libp2p_address_manager_transport_addresses',
            metrics: components.metrics
        });
        this.maxObservedAddresses = init.maxObservedAddresses ?? defaultValues$1.maxObservedAddresses;
    }
    get(multiaddr, ttl) {
        if (isPrivate(multiaddr)) {
            return {
                multiaddr,
                verified: true,
                type: 'transport',
                expires: Date.now() + ttl,
                lastVerified: Date.now()
            };
        }
        const key = this.toKey(multiaddr);
        let metadata = this.addresses.get(key);
        if (metadata == null) {
            metadata = {
                verified: !isNetworkAddress(multiaddr),
                expires: 0
            };
            this.addresses.set(key, metadata);
        }
        return {
            multiaddr,
            verified: metadata.verified,
            type: 'transport',
            expires: metadata.expires,
            lastVerified: metadata.lastVerified
        };
    }
    has(ma) {
        const key = this.toKey(ma);
        return this.addresses.has(key);
    }
    remove(ma) {
        const key = this.toKey(ma);
        const startingConfidence = this.addresses.get(key)?.verified ?? false;
        this.log('removing observed address %a', ma);
        this.addresses.delete(key);
        return startingConfidence;
    }
    confirm(ma, ttl) {
        const key = this.toKey(ma);
        const metadata = this.addresses.get(key) ?? {
            verified: false,
            expires: 0,
            lastVerified: 0
        };
        const startingConfidence = metadata.verified;
        metadata.verified = true;
        metadata.expires = Date.now() + ttl;
        metadata.lastVerified = Date.now();
        this.addresses.set(key, metadata);
        return startingConfidence;
    }
    unconfirm(ma, ttl) {
        const key = this.toKey(ma);
        const metadata = this.addresses.get(key) ?? {
            verified: false,
            expires: 0
        };
        const startingConfidence = metadata.verified;
        metadata.verified = false;
        metadata.expires = Date.now() + ttl;
        this.addresses.set(key, metadata);
        return startingConfidence;
    }
    toKey(ma) {
        if (isNetworkAddress(ma)) {
            // only works for dns/ip based addresses
            const options = ma.toOptions();
            return `${options.host}-${options.port}-${options.transport}`;
        }
        return ma.toString();
    }
}

/* eslint-disable complexity */
const ONE_MINUTE = 60_000;
const defaultValues = {
    addressVerificationTTL: ONE_MINUTE * 10,
    addressVerificationRetry: ONE_MINUTE * 5
};
const defaultAddressFilter = (addrs) => addrs;
/**
 * If the passed multiaddr contains the passed peer id, remove it
 */
function stripPeerId(ma, peerId) {
    const observedPeerIdStr = ma.getPeerId();
    // strip our peer id if it has been passed
    if (observedPeerIdStr != null) {
        const observedPeerId = peerIdFromString$1(observedPeerIdStr);
        // use same encoding for comparison
        if (observedPeerId.equals(peerId)) {
            ma = ma.decapsulate(multiaddr(`/p2p/${peerId.toString()}`));
        }
    }
    return ma;
}
class AddressManager {
    log;
    components;
    // this is an array to allow for duplicates, e.g. multiples of `/ip4/0.0.0.0/tcp/0`
    listen;
    announce;
    appendAnnounce;
    announceFilter;
    observed;
    dnsMappings;
    ipMappings;
    transportAddresses;
    observedAddressFilter;
    addressVerificationTTL;
    addressVerificationRetry;
    /**
     * Responsible for managing the peer addresses.
     * Peers can specify their listen and announce addresses.
     * The listen addresses will be used by the libp2p transports to listen for new connections,
     * while the announce addresses will be used for the peer addresses' to other peers in the network.
     */
    constructor(components, init = {}) {
        const { listen = [], announce = [], appendAnnounce = [] } = init;
        this.components = components;
        this.log = components.logger.forComponent('libp2p:address-manager');
        this.listen = listen.map(ma => ma.toString());
        this.announce = new Set(announce.map(ma => ma.toString()));
        this.appendAnnounce = new Set(appendAnnounce.map(ma => ma.toString()));
        this.observed = new ObservedAddresses(components, init);
        this.dnsMappings = new DNSMappings(components, init);
        this.ipMappings = new IPMappings(components, init);
        this.transportAddresses = new TransportAddresses(components, init);
        this.announceFilter = init.announceFilter ?? defaultAddressFilter;
        this.observedAddressFilter = createScalableCuckooFilter(1024);
        this.addressVerificationTTL = init.addressVerificationTTL ?? defaultValues.addressVerificationTTL;
        this.addressVerificationRetry = init.addressVerificationRetry ?? defaultValues.addressVerificationRetry;
        // this method gets called repeatedly on startup when transports start listening so
        // debounce it so we don't cause multiple self:peer:update events to be emitted
        this._updatePeerStoreAddresses = debounce$1(this._updatePeerStoreAddresses.bind(this), 1000);
        // update our stored addresses when new transports listen
        components.events.addEventListener('transport:listening', () => {
            this._updatePeerStoreAddresses();
        });
        // update our stored addresses when existing transports stop listening
        components.events.addEventListener('transport:close', () => {
            this._updatePeerStoreAddresses();
        });
    }
    [Symbol.toStringTag] = '@libp2p/address-manager';
    _updatePeerStoreAddresses() {
        // if announce addresses have been configured, ensure they make it into our peer
        // record for things like identify
        const addrs = this.getAddresses()
            .map(ma => {
            // strip our peer id if it is present
            if (ma.getPeerId() === this.components.peerId.toString()) {
                return ma.decapsulate(`/p2p/${this.components.peerId.toString()}`);
            }
            return ma;
        });
        this.components.peerStore.patch(this.components.peerId, {
            multiaddrs: addrs
        })
            .catch(err => {
            this.log.error('error updating addresses', err);
        });
    }
    /**
     * Get peer listen multiaddrs
     */
    getListenAddrs() {
        return Array.from(this.listen).map((a) => multiaddr(a));
    }
    /**
     * Get peer announcing multiaddrs
     */
    getAnnounceAddrs() {
        return Array.from(this.announce).map((a) => multiaddr(a));
    }
    /**
     * Get peer announcing multiaddrs
     */
    getAppendAnnounceAddrs() {
        return Array.from(this.appendAnnounce).map((a) => multiaddr(a));
    }
    /**
     * Get observed multiaddrs
     */
    getObservedAddrs() {
        return this.observed.getAll().map(addr => addr.multiaddr);
    }
    /**
     * Add peer observed addresses
     */
    addObservedAddr(addr) {
        const tuples = addr.stringTuples();
        const socketAddress = `${tuples[0][1]}:${tuples[1][1]}`;
        // ignore if this address if it's been observed before
        if (this.observedAddressFilter.has(socketAddress)) {
            return;
        }
        this.observedAddressFilter.add(socketAddress);
        addr = stripPeerId(addr, this.components.peerId);
        // ignore observed address if it is an IP mapping
        if (this.ipMappings.has(addr)) {
            return;
        }
        // ignore observed address if it is a DNS mapping
        if (this.dnsMappings.has(addr)) {
            return;
        }
        this.observed.add(addr);
    }
    confirmObservedAddr(addr, options) {
        addr = stripPeerId(addr, this.components.peerId);
        let startingConfidence = true;
        if (options?.type === 'transport' || this.transportAddresses.has(addr)) {
            const transportStartingConfidence = this.transportAddresses.confirm(addr, options?.ttl ?? this.addressVerificationTTL);
            if (!transportStartingConfidence && startingConfidence) {
                startingConfidence = false;
            }
        }
        if (options?.type === 'dns-mapping' || this.dnsMappings.has(addr)) {
            const dnsMappingStartingConfidence = this.dnsMappings.confirm(addr, options?.ttl ?? this.addressVerificationTTL);
            if (!dnsMappingStartingConfidence && startingConfidence) {
                startingConfidence = false;
            }
        }
        if (options?.type === 'ip-mapping' || this.ipMappings.has(addr)) {
            const ipMappingStartingConfidence = this.ipMappings.confirm(addr, options?.ttl ?? this.addressVerificationTTL);
            if (!ipMappingStartingConfidence && startingConfidence) {
                startingConfidence = false;
            }
        }
        if (options?.type === 'observed' || this.observed.has(addr)) {
            // try to match up observed address with local transport listener
            if (this.maybeUpgradeToIPMapping(addr)) {
                this.ipMappings.confirm(addr, options?.ttl ?? this.addressVerificationTTL);
                startingConfidence = false;
            }
            else {
                const observedStartingConfidence = this.observed.confirm(addr, options?.ttl ?? this.addressVerificationTTL);
                if (!observedStartingConfidence && startingConfidence) {
                    startingConfidence = false;
                }
            }
        }
        // only trigger the 'self:peer:update' event if our confidence in an address has changed
        if (!startingConfidence) {
            this._updatePeerStoreAddresses();
        }
    }
    removeObservedAddr(addr, options) {
        addr = stripPeerId(addr, this.components.peerId);
        if (this.observed.has(addr)) {
            this.observed.remove(addr);
        }
        if (this.transportAddresses.has(addr)) {
            this.transportAddresses.unconfirm(addr, options?.ttl ?? this.addressVerificationRetry);
        }
        if (this.dnsMappings.has(addr)) {
            this.dnsMappings.unconfirm(addr, options?.ttl ?? this.addressVerificationRetry);
        }
        if (this.ipMappings.has(addr)) {
            this.ipMappings.unconfirm(addr, options?.ttl ?? this.addressVerificationRetry);
        }
    }
    getAddresses() {
        const addresses = new Set();
        const multiaddrs = this.getAddressesWithMetadata()
            .filter(addr => {
            if (!addr.verified) {
                return false;
            }
            const maStr = addr.multiaddr.toString();
            if (addresses.has(maStr)) {
                return false;
            }
            addresses.add(maStr);
            return true;
        })
            .map(address => address.multiaddr);
        // filter addressees before returning
        return this.announceFilter(multiaddrs.map(str => {
            const ma = multiaddr(str);
            const lastComponent = ma.getComponents().pop();
            if (lastComponent?.value === this.components.peerId.toString()) {
                return ma;
            }
            return ma.encapsulate(`/p2p/${this.components.peerId.toString()}`);
        }));
    }
    getAddressesWithMetadata() {
        const announceMultiaddrs = this.getAnnounceAddrs();
        if (announceMultiaddrs.length > 0) {
            // allow transports to add certhashes and other runtime information
            this.components.transportManager.getListeners().forEach(listener => {
                listener.updateAnnounceAddrs(announceMultiaddrs);
            });
            return announceMultiaddrs.map(multiaddr => ({
                multiaddr,
                verified: true,
                type: 'announce',
                expires: Date.now() + this.addressVerificationTTL,
                lastVerified: Date.now()
            }));
        }
        let addresses = [];
        // add transport addresses
        addresses = addresses.concat(this.components.transportManager.getAddrs()
            .map(multiaddr => this.transportAddresses.get(multiaddr, this.addressVerificationTTL)));
        const appendAnnounceMultiaddrs = this.getAppendAnnounceAddrs();
        // add append announce addresses
        if (appendAnnounceMultiaddrs.length > 0) {
            // allow transports to add certhashes and other runtime information
            this.components.transportManager.getListeners().forEach(listener => {
                listener.updateAnnounceAddrs(appendAnnounceMultiaddrs);
            });
            addresses = addresses.concat(appendAnnounceMultiaddrs.map(multiaddr => ({
                multiaddr,
                verified: true,
                type: 'announce',
                expires: Date.now() + this.addressVerificationTTL,
                lastVerified: Date.now()
            })));
        }
        // add observed addresses
        addresses = addresses.concat(this.observed.getAll());
        // add ip mapped addresses
        addresses = addresses.concat(this.ipMappings.getAll(addresses));
        // add ip->domain mappings, must be done after IP mappings
        addresses = addresses.concat(this.dnsMappings.getAll(addresses));
        return addresses;
    }
    addDNSMapping(domain, addresses) {
        this.dnsMappings.add(domain, addresses);
    }
    removeDNSMapping(domain) {
        if (this.dnsMappings.remove(multiaddr(`/dns/${domain}`))) {
            this._updatePeerStoreAddresses();
        }
    }
    addPublicAddressMapping(internalIp, internalPort, externalIp, externalPort = internalPort, protocol = 'tcp') {
        this.ipMappings.add(internalIp, internalPort, externalIp, externalPort, protocol);
        // remove duplicate observed addresses
        this.observed.removePrefixed(`/ip${isIPv4(externalIp) ? 4 : 6}/${externalIp}/${protocol}/${externalPort}`);
    }
    removePublicAddressMapping(internalIp, internalPort, externalIp, externalPort = internalPort, protocol = 'tcp') {
        if (this.ipMappings.remove(multiaddr(`/ip${isIPv4(externalIp) ? 4 : 6}/${externalIp}/${protocol}/${externalPort}`))) {
            this._updatePeerStoreAddresses();
        }
    }
    /**
     * Where an external service (router, gateway, etc) is forwarding traffic to
     * us, attempt to add an IP mapping for the external address - this will
     * include the observed mapping in the address list where we also have a DNS
     * mapping for the external IP.
     *
     * Returns true if we added a new mapping
     */
    maybeUpgradeToIPMapping(ma) {
        // this address is already mapped
        if (this.ipMappings.has(ma)) {
            return false;
        }
        const maOptions = ma.toOptions();
        // only public IPv4 addresses
        if (maOptions.family === 6 || maOptions.host === '127.0.0.1' || isPrivateIp(maOptions.host) === true) {
            return false;
        }
        const listeners = this.components.transportManager.getListeners();
        const transportMatchers = [
            (ma) => WebSockets$1.exactMatch(ma) || WebSocketsSecure.exactMatch(ma),
            (ma) => TCP.exactMatch(ma),
            (ma) => QUICV1.exactMatch(ma)
        ];
        for (const matcher of transportMatchers) {
            // is the incoming address the same type as the matcher
            if (!matcher(ma)) {
                continue;
            }
            // get the listeners for this transport
            const transportListeners = listeners.filter(listener => {
                return listener.getAddrs().filter(ma => {
                    // only IPv4 addresses of the matcher type
                    return ma.toOptions().family === 4 && matcher(ma);
                }).length > 0;
            });
            // because the NAT mapping could be forwarding different external ports to
            // internal ones, we can only be sure enough to add a mapping if there is
            // a single listener
            if (transportListeners.length !== 1) {
                continue;
            }
            // we have one listener which listens on one port so whatever the external
            // NAT port mapping is, it should be for this listener
            const linkLocalAddr = transportListeners[0].getAddrs().filter(ma => {
                return ma.toOptions().host !== '127.0.0.1';
            }).pop();
            if (linkLocalAddr == null) {
                continue;
            }
            const linkLocalOptions = linkLocalAddr.toOptions();
            // upgrade observed address to IP mapping
            this.observed.remove(ma);
            this.ipMappings.add(linkLocalOptions.host, linkLocalOptions.port, maOptions.host, maOptions.port, maOptions.transport);
            return true;
        }
        return false;
    }
}

var messages;
(function (messages) {
    messages["NOT_STARTED_YET"] = "The libp2p node is not started yet";
    messages["NOT_FOUND"] = "Not found";
})(messages || (messages = {}));
class MissingServiceError extends Error {
    constructor(message = 'Missing service') {
        super(message);
        this.name = 'MissingServiceError';
    }
}
class UnmetServiceDependenciesError extends Error {
    constructor(message = 'Unmet service dependencies') {
        super(message);
        this.name = 'UnmetServiceDependenciesError';
    }
}
class NoContentRoutersError extends Error {
    constructor(message = 'No content routers available') {
        super(message);
        this.name = 'NoContentRoutersError';
    }
}
class NoPeerRoutersError extends Error {
    constructor(message = 'No peer routers available') {
        super(message);
        this.name = 'NoPeerRoutersError';
    }
}
class QueriedForSelfError extends Error {
    constructor(message = 'Should not try to find self') {
        super(message);
        this.name = 'QueriedForSelfError';
    }
}
class UnhandledProtocolError extends Error {
    constructor(message = 'Unhandled protocol error') {
        super(message);
        this.name = 'UnhandledProtocolError';
    }
}
class DuplicateProtocolHandlerError extends Error {
    constructor(message = 'Duplicate protocol handler error') {
        super(message);
        this.name = 'DuplicateProtocolHandlerError';
    }
}
class DialDeniedError extends Error {
    constructor(message = 'Dial denied error') {
        super(message);
        this.name = 'DialDeniedError';
    }
}
class UnsupportedListenAddressError extends Error {
    constructor(message = 'No transport was configured to listen on this address') {
        super(message);
        this.name = 'UnsupportedListenAddressError';
    }
}
class UnsupportedListenAddressesError extends Error {
    constructor(message = 'Configured listen addresses could not be listened on') {
        super(message);
        this.name = 'UnsupportedListenAddressesError';
    }
}
class NoValidAddressesError extends Error {
    constructor(message = 'No valid addresses') {
        super(message);
        this.name = 'NoValidAddressesError';
    }
}
class ConnectionInterceptedError extends Error {
    constructor(message = 'Connection intercepted') {
        super(message);
        this.name = 'ConnectionInterceptedError';
    }
}
class ConnectionDeniedError extends Error {
    constructor(message = 'Connection denied') {
        super(message);
        this.name = 'ConnectionDeniedError';
    }
}
class MuxerUnavailableError extends Error {
    constructor(message = 'Stream is not multiplexed') {
        super(message);
        this.name = 'MuxerUnavailableError';
    }
}
class EncryptionFailedError extends Error {
    constructor(message = 'Encryption failed') {
        super(message);
        this.name = 'EncryptionFailedError';
    }
}
class TransportUnavailableError extends Error {
    constructor(message = 'Transport unavailable') {
        super(message);
        this.name = 'TransportUnavailableError';
    }
}

class DefaultComponents {
    components = {};
    _started = false;
    constructor(init = {}) {
        this.components = {};
        for (const [key, value] of Object.entries(init)) {
            this.components[key] = value;
        }
        if (this.components.logger == null) {
            this.components.logger = defaultLogger();
        }
    }
    isStarted() {
        return this._started;
    }
    async _invokeStartableMethod(methodName) {
        await Promise.all(Object.values(this.components)
            .filter(obj => isStartable(obj))
            .map(async (startable) => {
            await startable[methodName]?.();
        }));
    }
    async beforeStart() {
        await this._invokeStartableMethod('beforeStart');
    }
    async start() {
        await this._invokeStartableMethod('start');
        this._started = true;
    }
    async afterStart() {
        await this._invokeStartableMethod('afterStart');
    }
    async beforeStop() {
        await this._invokeStartableMethod('beforeStop');
    }
    async stop() {
        await this._invokeStartableMethod('stop');
        this._started = false;
    }
    async afterStop() {
        await this._invokeStartableMethod('afterStop');
    }
}
const OPTIONAL_SERVICES = [
    'metrics',
    'connectionProtector',
    'dns'
];
const NON_SERVICE_PROPERTIES = [
    'components',
    'isStarted',
    'beforeStart',
    'start',
    'afterStart',
    'beforeStop',
    'stop',
    'afterStop',
    'then',
    '_invokeStartableMethod'
];
function defaultComponents(init = {}) {
    const components = new DefaultComponents(init);
    const proxy = new Proxy(components, {
        get(target, prop, receiver) {
            if (typeof prop === 'string' && !NON_SERVICE_PROPERTIES.includes(prop)) {
                const service = components.components[prop];
                if (service == null && !OPTIONAL_SERVICES.includes(prop)) {
                    throw new MissingServiceError(`${prop} not set`);
                }
                return service;
            }
            return Reflect.get(target, prop, receiver);
        },
        set(target, prop, value) {
            if (typeof prop === 'string') {
                components.components[prop] = value;
            }
            else {
                Reflect.set(target, prop, value);
            }
            return true;
        }
    });
    // @ts-expect-error component keys are proxied
    return proxy;
}
function checkServiceDependencies(components) {
    const serviceCapabilities = {};
    for (const service of Object.values(components.components)) {
        for (const capability of getServiceCapabilities(service)) {
            serviceCapabilities[capability] = true;
        }
    }
    for (const service of Object.values(components.components)) {
        for (const capability of getServiceDependencies(service)) {
            if (serviceCapabilities[capability] !== true) {
                throw new UnmetServiceDependenciesError(`Service "${getServiceName(service)}" required capability "${capability}" but it was not provided by any component, you may need to add additional configuration when creating your node.`);
            }
        }
    }
}
function getServiceCapabilities(service) {
    if (Array.isArray(service?.[serviceCapabilities])) {
        return service[serviceCapabilities];
    }
    return [];
}
function getServiceDependencies(service) {
    if (Array.isArray(service?.[serviceDependencies])) {
        return service[serviceDependencies];
    }
    return [];
}
function getServiceName(service) {
    return service?.[Symbol.toStringTag] ?? service?.toString() ?? 'unknown';
}

const CODEC_IP4 = 0x04;
const CODEC_IP6 = 0x29;
/**
 * Returns a connection gater that disallows dialling private addresses or
 * insecure websockets by default.
 *
 * Browsers are severely limited in their resource usage so don't waste time
 * trying to dial undialable addresses, and they also print verbose error
 * messages when making connections over insecure transports which causes
 * confusion.
 */
function connectionGater(gater = {}) {
    return {
        denyDialPeer: async () => false,
        denyDialMultiaddr: async (multiaddr) => {
            // do not connect to insecure websockets by default
            if (WebSockets$1.matches(multiaddr)) {
                return false;
            }
            const tuples = multiaddr.stringTuples();
            // do not connect to private addresses by default
            if (tuples[0][0] === CODEC_IP4 || tuples[0][0] === CODEC_IP6) {
                return Boolean(isPrivateIp(`${tuples[0][1]}`));
            }
            return false;
        },
        denyInboundConnection: async () => false,
        denyOutboundConnection: async () => false,
        denyInboundEncryptedConnection: async () => false,
        denyOutboundEncryptedConnection: async () => false,
        denyInboundUpgradedConnection: async () => false,
        denyOutboundUpgradedConnection: async () => false,
        filterMultiaddrForPeer: async () => true,
        ...gater
    };
}

/**
 * Extracts a PeerId and/or multiaddr from the passed PeerId or Multiaddr or an
 * array of Multiaddrs
 */
function getPeerAddress(peer) {
    if (isPeerId(peer)) {
        return { peerId: peer, multiaddrs: [] };
    }
    let multiaddrs = Array.isArray(peer) ? peer : [peer];
    let peerId;
    if (multiaddrs.length > 0) {
        const peerIdStr = multiaddrs[0].getPeerId();
        peerId = peerIdStr == null ? undefined : peerIdFromString$1(peerIdStr);
        // ensure PeerId is either not set or is consistent
        multiaddrs.forEach(ma => {
            if (!isMultiaddr(ma)) {
                throw new InvalidMultiaddrError$1('Invalid multiaddr');
            }
            const maPeerIdStr = ma.getPeerId();
            if (maPeerIdStr == null) {
                if (peerId != null) {
                    throw new InvalidParametersError$1('Multiaddrs must all have the same peer id or have no peer id');
                }
            }
            else {
                const maPeerId = peerIdFromString$1(maPeerIdStr);
                if (peerId?.equals(maPeerId) !== true) {
                    throw new InvalidParametersError$1('Multiaddrs must all have the same peer id or have no peer id');
                }
            }
        });
    }
    // ignore any `/p2p/Qmfoo`-style addresses as we will include the peer id in
    // the returned value of this function
    multiaddrs = multiaddrs.filter(ma => {
        return !PEER_ID.exactMatch(ma);
    });
    return {
        peerId,
        multiaddrs
    };
}

/**
 * Close the passed stream, falling back to aborting the stream if closing
 * cleanly fails.
 */
/**
 * These are speculative protocols that are run automatically on connection open
 * so are usually not the reason the connection was opened.
 *
 * Consequently when requested it should be safe to close connections that only
 * have these protocol streams open.
 */
const DEFAULT_CLOSABLE_PROTOCOLS = [
    // identify
    '/ipfs/id/1.0.0',
    // identify-push
    '/ipfs/id/push/1.0.0',
    // autonat
    '/libp2p/autonat/1.0.0',
    // dcutr
    '/libp2p/dcutr'
];
/**
 * Close the passed connection if it has no streams, or only closable protocol
 * streams, falling back to aborting the connection if closing it cleanly fails.
 */
async function safelyCloseConnectionIfUnused(connection, options) {
    const streamProtocols = connection?.streams?.map(stream => stream.protocol) ?? [];
    const closableProtocols = options?.closableProtocols ?? DEFAULT_CLOSABLE_PROTOCOLS;
    // if the connection has protocols not in the closable protocols list, do not
    // close the connection
    if (streamProtocols.filter(proto => proto != null && !closableProtocols.includes(proto)).length > 0) {
        return;
    }
    try {
        await connection?.close(options);
    }
    catch (err) {
        connection?.abort(err);
    }
}

/**
 * Recursively resolve DNSADDR multiaddrs
 */
async function resolveMultiaddrs(ma, options) {
    // check multiaddr resolvers
    let resolvable = false;
    for (const key of resolvers.keys()) {
        resolvable = ma.protoNames().includes(key);
        if (resolvable) {
            break;
        }
    }
    // return multiaddr if it is not resolvable
    if (!resolvable) {
        return [ma];
    }
    const output = await ma.resolve(options);
    options.log('resolved %s to', ma, output.map(ma => ma.toString()));
    return output;
}
/**
 * Converts a multiaddr string or object to an IpNet object.
 * If the multiaddr doesn't include /ipcidr, it will encapsulate with the appropriate CIDR:
 * - /ipcidr/32 for IPv4
 * - /ipcidr/128 for IPv6
 *
 * @param {string | Multiaddr} ma - The multiaddr string or object to convert.
 * @returns {IpNet} The converted IpNet object.
 * @throws {Error} Throws an error if the multiaddr is not valid.
 */
function multiaddrToIpNet(ma) {
    try {
        let parsedMa;
        if (typeof ma === 'string') {
            parsedMa = multiaddr(ma);
        }
        else {
            parsedMa = ma;
        }
        // Check if /ipcidr is already present
        if (!parsedMa.protoNames().includes('ipcidr')) {
            const isIPv6 = parsedMa.protoNames().includes('ip6');
            const cidr = isIPv6 ? '/ipcidr/128' : '/ipcidr/32';
            parsedMa = parsedMa.encapsulate(cidr);
        }
        return convertToIpNet(parsedMa);
    }
    catch (error) {
        throw new Error(`Can't convert to IpNet, Invalid multiaddr format: ${ma}`);
    }
}

/**
 * If we go over the max connections limit, choose some connections to close
 */
class ConnectionPruner {
    connectionManager;
    peerStore;
    allow;
    events;
    log;
    constructor(components, init = {}) {
        this.allow = (init.allow ?? []).map(ma => multiaddrToIpNet(ma));
        this.connectionManager = components.connectionManager;
        this.peerStore = components.peerStore;
        this.events = components.events;
        this.log = components.logger.forComponent('libp2p:connection-manager:connection-pruner');
        this.maybePruneConnections = this.maybePruneConnections.bind(this);
    }
    start() {
        this.events.addEventListener('connection:open', this.maybePruneConnections);
    }
    stop() {
        this.events.removeEventListener('connection:open', this.maybePruneConnections);
    }
    maybePruneConnections() {
        this._maybePruneConnections()
            .catch(err => {
            this.log.error('error while pruning connections %e', err);
        });
    }
    /**
     * If we have more connections than our maximum, select some excess connections
     * to prune based on peer value
     */
    async _maybePruneConnections() {
        const connections = this.connectionManager.getConnections();
        const numConnections = connections.length;
        const maxConnections = this.connectionManager.getMaxConnections();
        this.log('checking max connections limit %d/%d', numConnections, maxConnections);
        if (numConnections <= maxConnections) {
            return;
        }
        const peerValues = new PeerMap();
        // work out peer values
        for (const connection of connections) {
            const remotePeer = connection.remotePeer;
            if (peerValues.has(remotePeer)) {
                continue;
            }
            peerValues.set(remotePeer, 0);
            try {
                const peer = await this.peerStore.get(remotePeer);
                // sum all tag values
                peerValues.set(remotePeer, [...peer.tags.values()].reduce((acc, curr) => {
                    return acc + curr.value;
                }, 0));
            }
            catch (err) {
                if (err.name !== 'NotFoundError') {
                    this.log.error('error loading peer tags', err);
                }
            }
        }
        const sortedConnections = this.sortConnections(connections, peerValues);
        // close some connections
        const toPrune = Math.max(numConnections - maxConnections, 0);
        const toClose = [];
        for (const connection of sortedConnections) {
            this.log('too many connections open - closing a connection to %p', connection.remotePeer);
            // check allow list
            const connectionInAllowList = this.allow.some((ipNet) => {
                return ipNet.contains(connection.remoteAddr.nodeAddress().address);
            });
            // Connections in the allow list should be excluded from pruning
            if (!connectionInAllowList) {
                toClose.push(connection);
            }
            if (toClose.length === toPrune) {
                break;
            }
        }
        // close connections
        await Promise.all(toClose.map(async (connection) => {
            await safelyCloseConnectionIfUnused(connection, {
                signal: AbortSignal.timeout(1000)
            });
        }));
        // despatch prune event
        this.events.safeDispatchEvent('connection:prune', { detail: toClose });
    }
    sortConnections(connections, peerValues) {
        return connections
            // sort by connection age, newest to oldest
            .sort((a, b) => {
            const connectionALifespan = a.timeline.open;
            const connectionBLifespan = b.timeline.open;
            if (connectionALifespan < connectionBLifespan) {
                return 1;
            }
            if (connectionALifespan > connectionBLifespan) {
                return -1;
            }
            return 0;
        })
            // sort by direction, incoming first then outgoing
            .sort((a, b) => {
            if (a.direction === 'outbound' && b.direction === 'inbound') {
                return 1;
            }
            if (a.direction === 'inbound' && b.direction === 'outbound') {
                return -1;
            }
            return 0;
        })
            // sort by number of streams, lowest to highest
            .sort((a, b) => {
            if (a.streams.length > b.streams.length) {
                return 1;
            }
            if (a.streams.length < b.streams.length) {
                return -1;
            }
            return 0;
        })
            // sort by tag value, lowest to highest
            .sort((a, b) => {
            const peerAValue = peerValues.get(a.remotePeer) ?? 0;
            const peerBValue = peerValues.get(b.remotePeer) ?? 0;
            if (peerAValue > peerBValue) {
                return 1;
            }
            if (peerAValue < peerBValue) {
                return -1;
            }
            return 0;
        });
    }
}

/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#dialTimeout
 */
const DIAL_TIMEOUT = 10_000;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#inboundUpgradeTimeout
 */
const INBOUND_UPGRADE_TIMEOUT = 10_000;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#protocolNegotiationTimeout
 */
const PROTOCOL_NEGOTIATION_TIMEOUT = 10_000;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxPeerAddrsToDial
 */
const MAX_PEER_ADDRS_TO_DIAL = 25;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#inboundConnectionThreshold
 */
const INBOUND_CONNECTION_THRESHOLD = 5;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxIncomingPendingConnections
 */
const MAX_INCOMING_PENDING_CONNECTIONS = 10;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxParallelReconnects
 */
const MAX_PARALLEL_RECONNECTS = 5;
/**
 * Store as part of the peer store metadata for a given peer, the value for this
 * key is a timestamp of the last time a dial attempt failed with the timestamp
 * stored as a string.
 *
 * Used to insure we do not endlessly try to auto dial peers we have recently
 * failed to dial.
 */
const LAST_DIAL_FAILURE_KEY = 'last-dial-failure';
/**
 * Store as part of the peer store metadata for a given peer, the value for this
 * key is a timestamp of the last time a dial attempt succeeded with the
 * timestamp stored as a string.
 */
const LAST_DIAL_SUCCESS_KEY = 'last-dial-success';
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxDialQueueLength
 */
const MAX_DIAL_QUEUE_LENGTH = 500;

/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxConnections
 */
const MAX_CONNECTIONS = 100;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxParallelDials
 */
const MAX_PARALLEL_DIALS = 50;

class JobRecipient {
    deferred;
    signal;
    constructor(signal) {
        this.signal = signal;
        this.deferred = pDefer();
        this.onAbort = this.onAbort.bind(this);
        this.signal?.addEventListener('abort', this.onAbort);
    }
    onAbort() {
        this.deferred.reject(this.signal?.reason ?? new AbortError$4());
    }
    cleanup() {
        this.signal?.removeEventListener('abort', this.onAbort);
    }
}

/**
 * Returns a random string
 */
function randomId() {
    return `${(parseInt(String(Math.random() * 1e9), 10)).toString()}${Date.now()}`;
}
class Job {
    id;
    fn;
    options;
    recipients;
    status;
    timeline;
    controller;
    constructor(fn, options) {
        this.id = randomId();
        this.status = 'queued';
        this.fn = fn;
        this.options = options;
        this.recipients = [];
        this.timeline = {
            created: Date.now()
        };
        this.controller = new AbortController();
        setMaxListeners(Infinity, this.controller.signal);
        this.onAbort = this.onAbort.bind(this);
    }
    abort(err) {
        this.controller.abort(err);
    }
    onAbort() {
        const allAborted = this.recipients.reduce((acc, curr) => {
            return acc && (curr.signal?.aborted === true);
        }, true);
        // if all recipients have aborted the job, actually abort the job
        if (allAborted) {
            this.controller.abort(new AbortError$4());
            this.cleanup();
        }
    }
    async join(options = {}) {
        const recipient = new JobRecipient(options.signal);
        this.recipients.push(recipient);
        options.signal?.addEventListener('abort', this.onAbort);
        return recipient.deferred.promise;
    }
    async run() {
        this.status = 'running';
        this.timeline.started = Date.now();
        try {
            this.controller.signal.throwIfAborted();
            const result = await raceSignal(this.fn({
                ...(this.options ?? {}),
                signal: this.controller.signal
            }), this.controller.signal);
            this.recipients.forEach(recipient => {
                recipient.deferred.resolve(result);
            });
            this.status = 'complete';
        }
        catch (err) {
            this.recipients.forEach(recipient => {
                recipient.deferred.reject(err);
            });
            this.status = 'errored';
        }
        finally {
            this.timeline.finished = Date.now();
            this.cleanup();
        }
    }
    cleanup() {
        this.recipients.forEach(recipient => {
            recipient.cleanup();
            recipient.signal?.removeEventListener('abort', this.onAbort);
        });
    }
}

/**
 * Heavily influence by `p-queue` with the following differences:
 *
 * 1. Items remain at the head of the queue while they are running so `queue.size` includes `queue.pending` items - this is so interested parties can join the results of a queue item while it is running
 * 2. The options for a job are stored separately to the job in order for them to be modified while they are still in the queue
 */
class Queue extends TypedEventEmitter {
    concurrency;
    maxSize;
    queue;
    pending;
    sort;
    constructor(init = {}) {
        super();
        this.concurrency = init.concurrency ?? Number.POSITIVE_INFINITY;
        this.maxSize = init.maxSize ?? Number.POSITIVE_INFINITY;
        this.pending = 0;
        if (init.metricName != null) {
            init.metrics?.registerMetricGroup(init.metricName, {
                calculate: () => {
                    return {
                        size: this.queue.length,
                        running: this.pending,
                        queued: this.queue.length - this.pending
                    };
                }
            });
        }
        this.sort = init.sort;
        this.queue = [];
        this.emitEmpty = debounce$1(this.emitEmpty.bind(this), 1);
        this.emitIdle = debounce$1(this.emitIdle.bind(this), 1);
    }
    emitEmpty() {
        if (this.size !== 0) {
            return;
        }
        this.safeDispatchEvent('empty');
    }
    emitIdle() {
        if (this.running !== 0) {
            return;
        }
        this.safeDispatchEvent('idle');
    }
    tryToStartAnother() {
        if (this.size === 0) {
            this.emitEmpty();
            if (this.running === 0) {
                this.emitIdle();
            }
            return false;
        }
        if (this.pending < this.concurrency) {
            let job;
            for (const j of this.queue) {
                if (j.status === 'queued') {
                    job = j;
                    break;
                }
            }
            if (job == null) {
                return false;
            }
            this.safeDispatchEvent('active');
            this.pending++;
            void job.run()
                .finally(() => {
                // remove the job from the queue
                for (let i = 0; i < this.queue.length; i++) {
                    if (this.queue[i] === job) {
                        this.queue.splice(i, 1);
                        break;
                    }
                }
                this.pending--;
                this.tryToStartAnother();
                this.safeDispatchEvent('next');
            });
            return true;
        }
        return false;
    }
    enqueue(job) {
        this.queue.push(job);
        if (this.sort != null) {
            this.queue.sort(this.sort);
        }
    }
    /**
     * Adds a sync or async task to the queue. Always returns a promise.
     */
    async add(fn, options) {
        options?.signal?.throwIfAborted();
        if (this.size === this.maxSize) {
            throw new QueueFullError$1();
        }
        const job = new Job(fn, options);
        this.enqueue(job);
        this.safeDispatchEvent('add');
        this.tryToStartAnother();
        return job.join(options)
            .then(result => {
            this.safeDispatchEvent('completed', { detail: result });
            this.safeDispatchEvent('success', { detail: { job, result } });
            return result;
        })
            .catch(err => {
            if (job.status === 'queued') {
                // job was aborted before it started - remove the job from the queue
                for (let i = 0; i < this.queue.length; i++) {
                    if (this.queue[i] === job) {
                        this.queue.splice(i, 1);
                        break;
                    }
                }
            }
            this.safeDispatchEvent('error', { detail: err });
            this.safeDispatchEvent('failure', { detail: { job, error: err } });
            throw err;
        });
    }
    /**
     * Clear the queue
     */
    clear() {
        this.queue.splice(0, this.queue.length);
    }
    /**
     * Abort all jobs in the queue and clear it
     */
    abort() {
        this.queue.forEach(job => {
            job.abort(new AbortError$4());
        });
        this.clear();
    }
    /**
     * Can be called multiple times. Useful if you for example add additional items at a later time.
     *
     * @returns A promise that settles when the queue becomes empty.
     */
    async onEmpty(options) {
        // Instantly resolve if the queue is empty
        if (this.size === 0) {
            return;
        }
        await raceEvent(this, 'empty', options?.signal);
    }
    /**
     * @returns A promise that settles when the queue size is less than the given
     * limit: `queue.size < limit`.
     *
     * If you want to avoid having the queue grow beyond a certain size you can
     * `await queue.onSizeLessThan()` before adding a new item.
     *
     * Note that this only limits the number of items waiting to start. There
     * could still be up to `concurrency` jobs already running that this call does
     * not include in its calculation.
     */
    async onSizeLessThan(limit, options) {
        // Instantly resolve if the queue is empty.
        if (this.size < limit) {
            return;
        }
        await raceEvent(this, 'next', options?.signal, {
            filter: () => this.size < limit
        });
    }
    /**
     * The difference with `.onEmpty` is that `.onIdle` guarantees that all work
     * from the queue has finished. `.onEmpty` merely signals that the queue is
     * empty, but it could mean that some promises haven't completed yet.
     *
     * @returns A promise that settles when the queue becomes empty, and all
     * promises have completed; `queue.size === 0 && queue.pending === 0`.
     */
    async onIdle(options) {
        // Instantly resolve if none pending and if nothing else is queued
        if (this.pending === 0 && this.size === 0) {
            return;
        }
        await raceEvent(this, 'idle', options?.signal);
    }
    /**
     * Size of the queue including running items
     */
    get size() {
        return this.queue.length;
    }
    /**
     * The number of queued items waiting to run.
     */
    get queued() {
        return this.queue.length - this.pending;
    }
    /**
     * The number of items currently running.
     */
    get running() {
        return this.pending;
    }
    /**
     * Returns an async generator that makes it easy to iterate over the results
     * of jobs added to the queue.
     *
     * The generator will end when the queue becomes idle, that is there are no
     * jobs running and no jobs that have yet to run.
     *
     * If you need to keep the queue open indefinitely, consider using it-pushable
     * instead.
     */
    async *toGenerator(options) {
        options?.signal?.throwIfAborted();
        const stream = pushable({
            objectMode: true
        });
        const cleanup = (err) => {
            if (err != null) {
                this.abort();
            }
            else {
                this.clear();
            }
            stream.end(err);
        };
        const onQueueJobComplete = (evt) => {
            if (evt.detail != null) {
                stream.push(evt.detail);
            }
        };
        const onQueueError = (evt) => {
            cleanup(evt.detail);
        };
        const onQueueIdle = () => {
            cleanup();
        };
        // clear the queue and throw if the query is aborted
        const onSignalAbort = () => {
            cleanup(new AbortError$4('Queue aborted'));
        };
        // add listeners
        this.addEventListener('completed', onQueueJobComplete);
        this.addEventListener('error', onQueueError);
        this.addEventListener('idle', onQueueIdle);
        options?.signal?.addEventListener('abort', onSignalAbort);
        try {
            yield* stream;
        }
        finally {
            // remove listeners
            this.removeEventListener('completed', onQueueJobComplete);
            this.removeEventListener('error', onQueueError);
            this.removeEventListener('idle', onQueueIdle);
            options?.signal?.removeEventListener('abort', onSignalAbort);
            // empty the queue for when the user has broken out of a loop early
            cleanup();
        }
    }
}

class PriorityQueue extends Queue {
    constructor(init = {}) {
        super({
            ...init,
            sort: (a, b) => {
                if (a.options.priority > b.options.priority) {
                    return -1;
                }
                if (a.options.priority < b.options.priority) {
                    return 1;
                }
                return 0;
            }
        });
    }
}

/**
 * Takes an array of AbortSignals and returns a single signal.
 * If any signals are aborted, the returned signal will be aborted.
 */
function anySignal(signals) {
    const controller = new globalThis.AbortController();
    function onAbort() {
        controller.abort();
        for (const signal of signals) {
            if (signal?.removeEventListener != null) {
                signal.removeEventListener('abort', onAbort);
            }
        }
    }
    for (const signal of signals) {
        if (signal?.aborted === true) {
            onAbort();
            break;
        }
        if (signal?.addEventListener != null) {
            signal.addEventListener('abort', onAbort);
        }
    }
    function clear() {
        for (const signal of signals) {
            if (signal?.removeEventListener != null) {
                signal.removeEventListener('abort', onAbort);
            }
        }
    }
    const signal = controller.signal;
    signal.clear = clear;
    return signal;
}

/**
 * Check if a given ip address is a loopback address
 */
function isLoopbackAddr(ip) {
    return /^127\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/i.test(ip) ||
        /^::1$/.test(ip);
}

/**
 * Check if a given multiaddr is a loopback address.
 */
function isLoopback(ma) {
    if (!isIpBased(ma)) {
        // not an IP based multiaddr, cannot be private
        return false;
    }
    const { address } = ma.nodeAddress();
    return isLoopbackAddr(address);
}

/**
 * Sorts addresses by order of reliability, where they have presented the fewest
 * problems:
 *
 * TCP -> WebSockets/Secure -> WebRTC -> WebRTCDirect -> WebTransport
 */
// eslint-disable-next-line complexity
function reliableTransportsFirst(a, b) {
    const isATcp = TCP.exactMatch(a.multiaddr);
    const isBTcp = TCP.exactMatch(b.multiaddr);
    if (isATcp && !isBTcp) {
        return -1;
    }
    if (!isATcp && isBTcp) {
        return 1;
    }
    const isAWebSocketSecure = WebSocketsSecure.exactMatch(a.multiaddr);
    const isBWebSocketSecure = WebSocketsSecure.exactMatch(b.multiaddr);
    if (isAWebSocketSecure && !isBWebSocketSecure) {
        return -1;
    }
    if (!isAWebSocketSecure && isBWebSocketSecure) {
        return 1;
    }
    const isAWebSocket = WebSockets$1.exactMatch(a.multiaddr);
    const isBWebSocket = WebSockets$1.exactMatch(b.multiaddr);
    if (isAWebSocket && !isBWebSocket) {
        return -1;
    }
    if (!isAWebSocket && isBWebSocket) {
        return 1;
    }
    const isAWebRTC = WebRTC.exactMatch(a.multiaddr);
    const isBWebRTC = WebRTC.exactMatch(b.multiaddr);
    if (isAWebRTC && !isBWebRTC) {
        return -1;
    }
    if (!isAWebRTC && isBWebRTC) {
        return 1;
    }
    const isAWebRTCDirect = WebRTCDirect.exactMatch(a.multiaddr);
    const isBWebRTCDirect = WebRTCDirect.exactMatch(b.multiaddr);
    if (isAWebRTCDirect && !isBWebRTCDirect) {
        return -1;
    }
    if (!isAWebRTCDirect && isBWebRTCDirect) {
        return 1;
    }
    const isAWebTransport = WebTransport.exactMatch(a.multiaddr);
    const isBWebTransport = WebTransport.exactMatch(b.multiaddr);
    if (isAWebTransport && !isBWebTransport) {
        return -1;
    }
    if (!isAWebTransport && isBWebTransport) {
        return 1;
    }
    // ... everything else
    return 0;
}
/**
 * Compare function for array.sort() that moves loopback addresses to the end
 * of the array.
 */
function loopbackAddressLast(a, b) {
    const isALoopback = isLoopback(a.multiaddr);
    const isBLoopback = isLoopback(b.multiaddr);
    if (isALoopback && !isBLoopback) {
        return 1;
    }
    else if (!isALoopback && isBLoopback) {
        return -1;
    }
    return 0;
}
/**
 * Compare function for array.sort() that moves public addresses to the start
 * of the array.
 */
function publicAddressesFirst(a, b) {
    const isAPrivate = isPrivate(a.multiaddr);
    const isBPrivate = isPrivate(b.multiaddr);
    if (isAPrivate && !isBPrivate) {
        return 1;
    }
    else if (!isAPrivate && isBPrivate) {
        return -1;
    }
    return 0;
}
/**
 * Compare function for array.sort() that moves certified addresses to the start
 * of the array.
 */
function certifiedAddressesFirst(a, b) {
    if (a.isCertified && !b.isCertified) {
        return -1;
    }
    else if (!a.isCertified && b.isCertified) {
        return 1;
    }
    return 0;
}
/**
 * Compare function for array.sort() that moves circuit relay addresses to the
 * end of the array.
 */
function circuitRelayAddressesLast(a, b) {
    const isACircuit = Circuit.exactMatch(a.multiaddr);
    const isBCircuit = Circuit.exactMatch(b.multiaddr);
    if (isACircuit && !isBCircuit) {
        return 1;
    }
    else if (!isACircuit && isBCircuit) {
        return -1;
    }
    return 0;
}
function defaultAddressSorter(addresses) {
    return addresses
        .sort(reliableTransportsFirst)
        .sort(certifiedAddressesFirst)
        .sort(circuitRelayAddressesLast)
        .sort(publicAddressesFirst)
        .sort(loopbackAddressLast);
}

/* eslint-disable max-depth */
const defaultOptions$1 = {
    maxParallelDials: MAX_PARALLEL_DIALS,
    maxDialQueueLength: MAX_DIAL_QUEUE_LENGTH,
    maxPeerAddrsToDial: MAX_PEER_ADDRS_TO_DIAL,
    dialTimeout: DIAL_TIMEOUT};
class DialQueue {
    queue;
    components;
    addressSorter;
    maxPeerAddrsToDial;
    maxDialQueueLength;
    dialTimeout;
    shutDownController;
    connections;
    log;
    constructor(components, init = {}) {
        this.addressSorter = init.addressSorter;
        this.maxPeerAddrsToDial = init.maxPeerAddrsToDial ?? defaultOptions$1.maxPeerAddrsToDial;
        this.maxDialQueueLength = init.maxDialQueueLength ?? defaultOptions$1.maxDialQueueLength;
        this.dialTimeout = init.dialTimeout ?? defaultOptions$1.dialTimeout;
        this.connections = init.connections ?? new PeerMap();
        this.log = components.logger.forComponent('libp2p:connection-manager:dial-queue');
        this.components = components;
        this.shutDownController = new AbortController();
        setMaxListeners(Infinity, this.shutDownController.signal);
        for (const [key, value] of Object.entries(init.resolvers ?? {})) {
            resolvers.set(key, value);
        }
        // controls dial concurrency
        this.queue = new PriorityQueue({
            concurrency: init.maxParallelDials ?? defaultOptions$1.maxParallelDials,
            metricName: 'libp2p_dial_queue',
            metrics: components.metrics
        });
        // a started job errored
        this.queue.addEventListener('error', (event) => {
            if (event.detail?.name !== AbortError$4.name) {
                this.log.error('error in dial queue - %e', event.detail);
            }
        });
    }
    start() {
        this.shutDownController = new AbortController();
        setMaxListeners(Infinity, this.shutDownController.signal);
    }
    /**
     * Clears any pending dials
     */
    stop() {
        this.shutDownController.abort();
        this.queue.abort();
    }
    /**
     * Connects to a given peer, multiaddr or list of multiaddrs.
     *
     * If a peer is passed, all known multiaddrs will be tried. If a multiaddr or
     * multiaddrs are passed only those will be dialled.
     *
     * Where a list of multiaddrs is passed, if any contain a peer id then all
     * multiaddrs in the list must contain the same peer id.
     *
     * The dial to the first address that is successfully able to upgrade a
     * connection will be used, all other dials will be aborted when that happens.
     */
    async dial(peerIdOrMultiaddr, options = {}) {
        const { peerId, multiaddrs } = getPeerAddress(peerIdOrMultiaddr);
        // make sure we don't have an existing connection to any of the addresses we
        // are about to dial
        const existingConnection = Array.from(this.connections.values()).flat().find(conn => {
            if (options.force === true) {
                return false;
            }
            if (conn.remotePeer.equals(peerId)) {
                return true;
            }
            return multiaddrs.find(addr => {
                return addr.equals(conn.remoteAddr);
            });
        });
        if (existingConnection?.status === 'open') {
            this.log('already connected to %a', existingConnection.remoteAddr);
            options.onProgress?.(new CustomProgressEvent('dial-queue:already-connected'));
            return existingConnection;
        }
        // ready to dial, all async work finished - make sure we don't have any
        // pending dials in progress for this peer or set of multiaddrs
        const existingDial = this.queue.queue.find(job => {
            if (peerId?.equals(job.options.peerId) === true) {
                return true;
            }
            // does the dial contain any of the target multiaddrs?
            const addresses = job.options.multiaddrs;
            if (addresses == null) {
                return false;
            }
            for (const multiaddr of multiaddrs) {
                if (addresses.has(multiaddr.toString())) {
                    return true;
                }
            }
            return false;
        });
        if (existingDial != null) {
            this.log('joining existing dial target for %p', peerId);
            // add all multiaddrs to the dial target
            for (const multiaddr of multiaddrs) {
                existingDial.options.multiaddrs.add(multiaddr.toString());
            }
            options.onProgress?.(new CustomProgressEvent('dial-queue:already-in-dial-queue'));
            return existingDial.join(options);
        }
        if (this.queue.size >= this.maxDialQueueLength) {
            throw new DialError('Dial queue is full');
        }
        this.log('creating dial target for %p', peerId, multiaddrs.map(ma => ma.toString()));
        options.onProgress?.(new CustomProgressEvent('dial-queue:add-to-dial-queue'));
        return this.queue.add(async (options) => {
            options.onProgress?.(new CustomProgressEvent('dial-queue:start-dial'));
            // create abort conditions - need to do this before `calculateMultiaddrs` as
            // we may be about to resolve a dns addr which can time out
            const signal = anySignal([
                this.shutDownController.signal,
                options.signal
            ]);
            try {
                return await this.dialPeer(options, signal);
            }
            finally {
                // clean up abort signals/controllers
                signal.clear();
            }
        }, {
            peerId,
            priority: options.priority ?? DEFAULT_DIAL_PRIORITY,
            multiaddrs: new Set(multiaddrs.map(ma => ma.toString())),
            signal: options.signal ?? AbortSignal.timeout(this.dialTimeout),
            onProgress: options.onProgress
        });
    }
    async dialPeer(options, signal) {
        const peerId = options.peerId;
        const multiaddrs = options.multiaddrs;
        const failedMultiaddrs = new Set();
        // if we have no multiaddrs, only a peer id, set a flag so we will look the
        // peer up in the peer routing to obtain multiaddrs
        let forcePeerLookup = options.multiaddrs.size === 0;
        let dialed = 0;
        let dialIteration = 0;
        const errors = [];
        this.log('starting dial to %p', peerId);
        // repeat this operation in case addresses are added to the dial while we
        // resolve multiaddrs, etc
        while (forcePeerLookup || multiaddrs.size > 0) {
            dialIteration++;
            // only perform peer lookup once
            forcePeerLookup = false;
            // the addresses we will dial
            const addrsToDial = [];
            // copy the addresses into a new set
            const addrs = new Set(options.multiaddrs);
            // empty the old set - subsequent dial attempts for the same peer id may
            // add more addresses to try
            multiaddrs.clear();
            this.log('calculating addrs to dial %p from %s', peerId, [...addrs]);
            // load addresses from address book, resolve and dnsaddrs, filter
            // undialables, add peer IDs, etc
            const calculatedAddrs = await this.calculateMultiaddrs(peerId, addrs, {
                ...options,
                signal
            });
            for (const addr of calculatedAddrs) {
                // skip any addresses we have previously failed to dial
                if (failedMultiaddrs.has(addr.multiaddr.toString())) {
                    this.log.trace('skipping previously failed multiaddr %a while dialing %p', addr.multiaddr, peerId);
                    continue;
                }
                addrsToDial.push(addr);
            }
            this.log('%s dial to %p with %s', dialIteration === 1 ? 'starting' : 'continuing', peerId, addrsToDial.map(ma => ma.multiaddr.toString()));
            options?.onProgress?.(new CustomProgressEvent('dial-queue:calculated-addresses', addrsToDial));
            for (const address of addrsToDial) {
                if (dialed === this.maxPeerAddrsToDial) {
                    this.log('dialed maxPeerAddrsToDial (%d) addresses for %p, not trying any others', dialed, options.peerId);
                    throw new DialError('Peer had more than maxPeerAddrsToDial');
                }
                dialed++;
                try {
                    // try to dial the address
                    const conn = await this.components.transportManager.dial(address.multiaddr, {
                        ...options,
                        signal
                    });
                    this.log('dial to %a succeeded', address.multiaddr);
                    // record the successful dial and the address
                    try {
                        await this.components.peerStore.merge(conn.remotePeer, {
                            multiaddrs: [
                                conn.remoteAddr
                            ],
                            metadata: {
                                [LAST_DIAL_SUCCESS_KEY]: fromString(Date.now().toString())
                            }
                        });
                    }
                    catch (err) {
                        this.log.error('could not update last dial failure key for %p', peerId, err);
                    }
                    // dial successful, return the connection
                    return conn;
                }
                catch (err) {
                    this.log.error('dial failed to %a', address.multiaddr, err);
                    // ensure we don't dial it again in this attempt
                    failedMultiaddrs.add(address.multiaddr.toString());
                    if (peerId != null) {
                        // record the failed dial
                        try {
                            await this.components.peerStore.merge(peerId, {
                                metadata: {
                                    [LAST_DIAL_FAILURE_KEY]: fromString(Date.now().toString())
                                }
                            });
                        }
                        catch (err) {
                            this.log.error('could not update last dial failure key for %p', peerId, err);
                        }
                    }
                    // the user/dial timeout/shutdown controller signal aborted
                    if (signal.aborted) {
                        throw new TimeoutError$1(err.message);
                    }
                    errors.push(err);
                }
            }
        }
        if (errors.length === 1) {
            throw errors[0];
        }
        throw new AggregateError(errors, 'All multiaddr dials failed');
    }
    // eslint-disable-next-line complexity
    async calculateMultiaddrs(peerId, multiaddrs = new Set(), options = {}) {
        const addrs = [...multiaddrs].map(ma => ({
            multiaddr: multiaddr(ma),
            isCertified: false
        }));
        // if a peer id or multiaddr(s) with a peer id, make sure it isn't our peer id and that we are allowed to dial it
        if (peerId != null) {
            if (this.components.peerId.equals(peerId)) {
                throw new DialError('Tried to dial self');
            }
            if ((await this.components.connectionGater.denyDialPeer?.(peerId)) === true) {
                throw new DialDeniedError('The dial request is blocked by gater.allowDialPeer');
            }
            // if just a peer id was passed, load available multiaddrs for this peer
            // from the peer store
            if (addrs.length === 0) {
                this.log('loading multiaddrs for %p', peerId);
                try {
                    const peer = await this.components.peerStore.get(peerId);
                    addrs.push(...peer.addresses);
                    this.log('loaded multiaddrs for %p', peerId, addrs.map(({ multiaddr }) => multiaddr.toString()));
                }
                catch (err) {
                    if (err.name !== 'NotFoundError') {
                        throw err;
                    }
                }
            }
            // if we still don't have any addresses for this peer, or the only
            // addresses we have are without any routing information (e.g.
            // `/p2p/Qmfoo`), try a lookup using the peer routing
            if (addrs.length === 0) {
                this.log('looking up multiaddrs for %p in the peer routing', peerId);
                try {
                    const peerInfo = await this.components.peerRouting.findPeer(peerId, options);
                    this.log('found multiaddrs for %p in the peer routing', peerId, addrs.map(({ multiaddr }) => multiaddr.toString()));
                    addrs.push(...peerInfo.multiaddrs.map(multiaddr => ({
                        multiaddr,
                        isCertified: false
                    })));
                }
                catch (err) {
                    if (err.name === 'NoPeerRoutersError') {
                        this.log('no peer routers configured', peerId);
                    }
                    else {
                        this.log.error('looking up multiaddrs for %p in the peer routing failed - %e', peerId, err);
                    }
                }
            }
        }
        // resolve addresses - this can result in a one-to-many translation when
        // dnsaddrs are resolved
        let resolvedAddresses = (await Promise.all(addrs.map(async (addr) => {
            const result = await resolveMultiaddrs(addr.multiaddr, {
                dns: this.components.dns,
                ...options,
                log: this.log
            });
            if (result.length === 1 && result[0].equals(addr.multiaddr)) {
                return addr;
            }
            return result.map(multiaddr => ({
                multiaddr,
                isCertified: false
            }));
        })))
            .flat();
        // ensure the peer id is appended to the multiaddr
        if (peerId != null) {
            const peerIdMultiaddr = `/p2p/${peerId.toString()}`;
            resolvedAddresses = resolvedAddresses.map(addr => {
                const lastComponent = addr.multiaddr.getComponents().pop();
                // append peer id to multiaddr if it is not already present
                if (lastComponent?.name !== 'p2p') {
                    return {
                        multiaddr: addr.multiaddr.encapsulate(peerIdMultiaddr),
                        isCertified: addr.isCertified
                    };
                }
                return addr;
            });
        }
        const filteredAddrs = resolvedAddresses.filter(addr => {
            // filter out any multiaddrs that we do not have transports for
            if (this.components.transportManager.dialTransportForMultiaddr(addr.multiaddr) == null) {
                return false;
            }
            // if the resolved multiaddr has a PeerID but it's the wrong one, ignore it
            // - this can happen with addresses like bootstrap.libp2p.io that resolve
            // to multiple different peers
            const addrPeerId = addr.multiaddr.getPeerId();
            if (peerId != null && addrPeerId != null) {
                return peerId.equals(addrPeerId);
            }
            return true;
        });
        // deduplicate addresses
        const dedupedAddrs = new Map();
        for (const addr of filteredAddrs) {
            const maStr = addr.multiaddr.toString();
            const existing = dedupedAddrs.get(maStr);
            if (existing != null) {
                existing.isCertified = existing.isCertified || addr.isCertified || false;
                continue;
            }
            dedupedAddrs.set(maStr, addr);
        }
        const dedupedMultiaddrs = [...dedupedAddrs.values()];
        // make sure we actually have some addresses to dial
        if (dedupedMultiaddrs.length === 0) {
            throw new NoValidAddressesError('The dial request has no valid addresses');
        }
        const gatedAddrs = [];
        for (const addr of dedupedMultiaddrs) {
            if (this.components.connectionGater.denyDialMultiaddr != null && await this.components.connectionGater.denyDialMultiaddr(addr.multiaddr)) {
                continue;
            }
            gatedAddrs.push(addr);
        }
        const sortedGatedAddrs = this.addressSorter == null ? defaultAddressSorter(gatedAddrs) : gatedAddrs.sort(this.addressSorter);
        // make sure we actually have some addresses to dial
        if (sortedGatedAddrs.length === 0) {
            throw new DialDeniedError('The connection gater denied all addresses in the dial request');
        }
        this.log.trace('addresses for %p before filtering', peerId ?? 'unknown peer', resolvedAddresses.map(({ multiaddr }) => multiaddr.toString()));
        this.log.trace('addresses for %p after filtering', peerId ?? 'unknown peer', sortedGatedAddrs.map(({ multiaddr }) => multiaddr.toString()));
        return sortedGatedAddrs;
    }
    async isDialable(multiaddr, options = {}) {
        if (!Array.isArray(multiaddr)) {
            multiaddr = [multiaddr];
        }
        try {
            const addresses = await this.calculateMultiaddrs(undefined, new Set(multiaddr.map(ma => ma.toString())), options);
            if (options.runOnLimitedConnection === false) {
                // return true if any resolved multiaddrs are not relay addresses
                return addresses.find(addr => {
                    return !Circuit.matches(addr.multiaddr);
                }) != null;
            }
            return true;
        }
        catch (err) {
            this.log.trace('error calculating if multiaddr(s) were dialable', err);
        }
        return false;
    }
}

/**
 * Extends Queue to add support for querying queued jobs by peer id
 */
class PeerQueue extends Queue {
    has(peerId) {
        return this.find(peerId) != null;
    }
    find(peerId) {
        return this.queue.find(job => {
            return peerId.equals(job.options.peerId);
        });
    }
}

var retry$2 = {};

function RetryOperation(timeouts, options) {
  // Compatibility for the old (timeouts, retryForever) signature
  if (typeof options === 'boolean') {
    options = { forever: options };
  }

  this._originalTimeouts = JSON.parse(JSON.stringify(timeouts));
  this._timeouts = timeouts;
  this._options = options || {};
  this._maxRetryTime = options && options.maxRetryTime || Infinity;
  this._fn = null;
  this._errors = [];
  this._attempts = 1;
  this._operationTimeout = null;
  this._operationTimeoutCb = null;
  this._timeout = null;
  this._operationStart = null;
  this._timer = null;

  if (this._options.forever) {
    this._cachedTimeouts = this._timeouts.slice(0);
  }
}
var retry_operation = RetryOperation;

RetryOperation.prototype.reset = function() {
  this._attempts = 1;
  this._timeouts = this._originalTimeouts.slice(0);
};

RetryOperation.prototype.stop = function() {
  if (this._timeout) {
    clearTimeout(this._timeout);
  }
  if (this._timer) {
    clearTimeout(this._timer);
  }

  this._timeouts       = [];
  this._cachedTimeouts = null;
};

RetryOperation.prototype.retry = function(err) {
  if (this._timeout) {
    clearTimeout(this._timeout);
  }

  if (!err) {
    return false;
  }
  var currentTime = new Date().getTime();
  if (err && currentTime - this._operationStart >= this._maxRetryTime) {
    this._errors.push(err);
    this._errors.unshift(new Error('RetryOperation timeout occurred'));
    return false;
  }

  this._errors.push(err);

  var timeout = this._timeouts.shift();
  if (timeout === undefined) {
    if (this._cachedTimeouts) {
      // retry forever, only keep last error
      this._errors.splice(0, this._errors.length - 1);
      timeout = this._cachedTimeouts.slice(-1);
    } else {
      return false;
    }
  }

  var self = this;
  this._timer = setTimeout(function() {
    self._attempts++;

    if (self._operationTimeoutCb) {
      self._timeout = setTimeout(function() {
        self._operationTimeoutCb(self._attempts);
      }, self._operationTimeout);

      if (self._options.unref) {
          self._timeout.unref();
      }
    }

    self._fn(self._attempts);
  }, timeout);

  if (this._options.unref) {
      this._timer.unref();
  }

  return true;
};

RetryOperation.prototype.attempt = function(fn, timeoutOps) {
  this._fn = fn;

  if (timeoutOps) {
    if (timeoutOps.timeout) {
      this._operationTimeout = timeoutOps.timeout;
    }
    if (timeoutOps.cb) {
      this._operationTimeoutCb = timeoutOps.cb;
    }
  }

  var self = this;
  if (this._operationTimeoutCb) {
    this._timeout = setTimeout(function() {
      self._operationTimeoutCb();
    }, self._operationTimeout);
  }

  this._operationStart = new Date().getTime();

  this._fn(this._attempts);
};

RetryOperation.prototype.try = function(fn) {
  console.log('Using RetryOperation.try() is deprecated');
  this.attempt(fn);
};

RetryOperation.prototype.start = function(fn) {
  console.log('Using RetryOperation.start() is deprecated');
  this.attempt(fn);
};

RetryOperation.prototype.start = RetryOperation.prototype.try;

RetryOperation.prototype.errors = function() {
  return this._errors;
};

RetryOperation.prototype.attempts = function() {
  return this._attempts;
};

RetryOperation.prototype.mainError = function() {
  if (this._errors.length === 0) {
    return null;
  }

  var counts = {};
  var mainError = null;
  var mainErrorCount = 0;

  for (var i = 0; i < this._errors.length; i++) {
    var error = this._errors[i];
    var message = error.message;
    var count = (counts[message] || 0) + 1;

    counts[message] = count;

    if (count >= mainErrorCount) {
      mainError = error;
      mainErrorCount = count;
    }
  }

  return mainError;
};

(function (exports) {
	var RetryOperation = retry_operation;

	exports.operation = function(options) {
	  var timeouts = exports.timeouts(options);
	  return new RetryOperation(timeouts, {
	      forever: options && (options.forever || options.retries === Infinity),
	      unref: options && options.unref,
	      maxRetryTime: options && options.maxRetryTime
	  });
	};

	exports.timeouts = function(options) {
	  if (options instanceof Array) {
	    return [].concat(options);
	  }

	  var opts = {
	    retries: 10,
	    factor: 2,
	    minTimeout: 1 * 1000,
	    maxTimeout: Infinity,
	    randomize: false
	  };
	  for (var key in options) {
	    opts[key] = options[key];
	  }

	  if (opts.minTimeout > opts.maxTimeout) {
	    throw new Error('minTimeout is greater than maxTimeout');
	  }

	  var timeouts = [];
	  for (var i = 0; i < opts.retries; i++) {
	    timeouts.push(this.createTimeout(i, opts));
	  }

	  if (options && options.forever && !timeouts.length) {
	    timeouts.push(this.createTimeout(i, opts));
	  }

	  // sort the array numerically ascending
	  timeouts.sort(function(a,b) {
	    return a - b;
	  });

	  return timeouts;
	};

	exports.createTimeout = function(attempt, opts) {
	  var random = (opts.randomize)
	    ? (Math.random() + 1)
	    : 1;

	  var timeout = Math.round(random * Math.max(opts.minTimeout, 1) * Math.pow(opts.factor, attempt));
	  timeout = Math.min(timeout, opts.maxTimeout);

	  return timeout;
	};

	exports.wrap = function(obj, options, methods) {
	  if (options instanceof Array) {
	    methods = options;
	    options = null;
	  }

	  if (!methods) {
	    methods = [];
	    for (var key in obj) {
	      if (typeof obj[key] === 'function') {
	        methods.push(key);
	      }
	    }
	  }

	  for (var i = 0; i < methods.length; i++) {
	    var method   = methods[i];
	    var original = obj[method];

	    obj[method] = function retryWrapper(original) {
	      var op       = exports.operation(options);
	      var args     = Array.prototype.slice.call(arguments, 1);
	      var callback = args.pop();

	      args.push(function(err) {
	        if (op.retry(err)) {
	          return;
	        }
	        if (err) {
	          arguments[0] = op.mainError();
	        }
	        callback.apply(this, arguments);
	      });

	      op.attempt(function() {
	        original.apply(obj, args);
	      });
	    }.bind(obj, original);
	    obj[method].options = options;
	  }
	}; 
} (retry$2));

var retry = retry$2;

var retry$1 = /*@__PURE__*/getDefaultExportFromCjs(retry);

const objectToString = Object.prototype.toString;

const isError = value => objectToString.call(value) === '[object Error]';

const errorMessages = new Set([
	'network error', // Chrome
	'Failed to fetch', // Chrome
	'NetworkError when attempting to fetch resource.', // Firefox
	'The Internet connection appears to be offline.', // Safari 16
	'Load failed', // Safari 17+
	'Network request failed', // `cross-fetch`
	'fetch failed', // Undici (Node.js)
	'terminated', // Undici (Node.js)
]);

function isNetworkError(error) {
	const isValid = error
		&& isError(error)
		&& error.name === 'TypeError'
		&& typeof error.message === 'string';

	if (!isValid) {
		return false;
	}

	// We do an extra check for Safari 17+ as it has a very generic error message.
	// Network errors in Safari have no stack.
	if (error.message === 'Load failed') {
		return error.stack === undefined;
	}

	return errorMessages.has(error.message);
}

class AbortError extends Error {
	constructor(message) {
		super();

		if (message instanceof Error) {
			this.originalError = message;
			({message} = message);
		} else {
			this.originalError = new Error(message);
			this.originalError.stack = this.stack;
		}

		this.name = 'AbortError';
		this.message = message;
	}
}

const decorateErrorWithCounts = (error, attemptNumber, options) => {
	// Minus 1 from attemptNumber because the first attempt does not count as a retry
	const retriesLeft = options.retries - (attemptNumber - 1);

	error.attemptNumber = attemptNumber;
	error.retriesLeft = retriesLeft;
	return error;
};

async function pRetry(input, options) {
	return new Promise((resolve, reject) => {
		options = {...options};
		options.onFailedAttempt ??= () => {};
		options.shouldRetry ??= () => true;
		options.retries ??= 10;

		const operation = retry$1.operation(options);

		const abortHandler = () => {
			operation.stop();
			reject(options.signal?.reason);
		};

		if (options.signal && !options.signal.aborted) {
			options.signal.addEventListener('abort', abortHandler, {once: true});
		}

		const cleanUp = () => {
			options.signal?.removeEventListener('abort', abortHandler);
			operation.stop();
		};

		operation.attempt(async attemptNumber => {
			try {
				const result = await input(attemptNumber);
				cleanUp();
				resolve(result);
			} catch (error) {
				try {
					if (!(error instanceof Error)) {
						throw new TypeError(`Non-error was thrown: "${error}". You should only throw errors.`);
					}

					if (error instanceof AbortError) {
						throw error.originalError;
					}

					if (error instanceof TypeError && !isNetworkError(error)) {
						throw error;
					}

					decorateErrorWithCounts(error, attemptNumber, options);

					if (!(await options.shouldRetry(error))) {
						operation.stop();
						reject(error);
					}

					await options.onFailedAttempt(error);

					if (!operation.retry(error)) {
						throw operation.mainError();
					}
				} catch (finalError) {
					decorateErrorWithCounts(finalError, attemptNumber, options);
					cleanUp();
					reject(finalError);
				}
			}
		});
	});
}

/**
 * When peers tagged with `KEEP_ALIVE` disconnect, this component attempts to
 * redial them
 */
class ReconnectQueue {
    log;
    queue;
    started;
    peerStore;
    retries;
    retryInterval;
    backoffFactor;
    connectionManager;
    events;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:reconnect-queue');
        this.peerStore = components.peerStore;
        this.connectionManager = components.connectionManager;
        this.queue = new PeerQueue({
            concurrency: init.maxParallelReconnects ?? MAX_PARALLEL_RECONNECTS,
            metricName: 'libp2p_reconnect_queue',
            metrics: components.metrics
        });
        this.started = false;
        this.retries = init.retries ?? 5;
        this.backoffFactor = init.backoffFactor;
        this.retryInterval = init.retryInterval;
        this.events = components.events;
        components.events.addEventListener('peer:disconnect', (evt) => {
            this.maybeReconnect(evt.detail)
                .catch(err => {
                this.log.error('failed to maybe reconnect to %p - %e', evt.detail, err);
            });
        });
    }
    async maybeReconnect(peerId) {
        if (!this.started) {
            return;
        }
        const peer = await this.peerStore.get(peerId);
        if (!hasKeepAliveTag(peer)) {
            return;
        }
        if (this.queue.has(peerId)) {
            return;
        }
        this.queue.add(async (options) => {
            await pRetry(async (attempt) => {
                if (!this.started) {
                    return;
                }
                try {
                    await this.connectionManager.openConnection(peerId, {
                        signal: options?.signal
                    });
                }
                catch (err) {
                    this.log('reconnecting to %p attempt %d of %d failed - %e', peerId, attempt, this.retries, err);
                    throw err;
                }
            }, {
                signal: options?.signal,
                retries: this.retries,
                factor: this.backoffFactor,
                minTimeout: this.retryInterval
            });
        }, {
            peerId
        })
            .catch(async (err) => {
            this.log.error('failed to reconnect to %p - %e', peerId, err);
            const tags = {};
            [...peer.tags.keys()].forEach(key => {
                if (key.startsWith(KEEP_ALIVE)) {
                    tags[key] = undefined;
                }
            });
            await this.peerStore.merge(peerId, {
                tags
            });
            this.events.safeDispatchEvent('peer:reconnect-failure', {
                detail: peerId
            });
        })
            .catch(async (err) => {
            this.log.error('failed to remove keep-alive tag from %p - %e', peerId, err);
        });
    }
    start() {
        this.started = true;
    }
    async afterStart() {
        // re-connect to any peers with the KEEP_ALIVE tag
        void Promise.resolve()
            .then(async () => {
            const keepAlivePeers = await this.peerStore.all({
                filters: [
                    (peer) => hasKeepAliveTag(peer)
                ]
            });
            await Promise.all(keepAlivePeers.map(async (peer) => {
                await this.connectionManager.openConnection(peer.id)
                    .catch(err => {
                    this.log.error(err);
                });
            }));
        })
            .catch(err => {
            this.log.error(err);
        });
    }
    stop() {
        this.started = false;
        this.queue.abort();
    }
}
function hasKeepAliveTag(peer) {
    for (const tag of peer.tags.keys()) {
        if (tag.startsWith(KEEP_ALIVE)) {
            return true;
        }
    }
    return false;
}

const DEFAULT_DIAL_PRIORITY = 50;
const defaultOptions = {
    maxConnections: MAX_CONNECTIONS,
    inboundConnectionThreshold: INBOUND_CONNECTION_THRESHOLD,
    maxIncomingPendingConnections: MAX_INCOMING_PENDING_CONNECTIONS
};
/**
 * Responsible for managing known connections.
 */
class DefaultConnectionManager {
    started;
    connections;
    allow;
    deny;
    maxIncomingPendingConnections;
    incomingPendingConnections;
    outboundPendingConnections;
    maxConnections;
    dialQueue;
    reconnectQueue;
    connectionPruner;
    inboundConnectionRateLimiter;
    peerStore;
    metrics;
    events;
    log;
    peerId;
    constructor(components, init = {}) {
        this.maxConnections = init.maxConnections ?? defaultOptions.maxConnections;
        if (this.maxConnections < 1) {
            throw new InvalidParametersError$1('Connection Manager maxConnections must be greater than 0');
        }
        /**
         * Map of connections per peer
         */
        this.connections = new PeerMap();
        this.started = false;
        this.peerId = components.peerId;
        this.peerStore = components.peerStore;
        this.metrics = components.metrics;
        this.events = components.events;
        this.log = components.logger.forComponent('libp2p:connection-manager');
        this.onConnect = this.onConnect.bind(this);
        this.onDisconnect = this.onDisconnect.bind(this);
        // allow/deny lists
        this.allow = (init.allow ?? []).map(str => multiaddrToIpNet(str));
        this.deny = (init.deny ?? []).map(str => multiaddrToIpNet(str));
        this.incomingPendingConnections = 0;
        this.maxIncomingPendingConnections = init.maxIncomingPendingConnections ?? defaultOptions.maxIncomingPendingConnections;
        this.outboundPendingConnections = 0;
        // controls individual peers trying to dial us too quickly
        this.inboundConnectionRateLimiter = new RateLimiter({
            points: init.inboundConnectionThreshold ?? defaultOptions.inboundConnectionThreshold,
            duration: 1
        });
        // controls what happens when we have too many connections
        this.connectionPruner = new ConnectionPruner({
            connectionManager: this,
            peerStore: components.peerStore,
            events: components.events,
            logger: components.logger
        }, {
            allow: init.allow?.map(a => multiaddr(a))
        });
        this.dialQueue = new DialQueue(components, {
            addressSorter: init.addressSorter,
            maxParallelDials: init.maxParallelDials ?? MAX_PARALLEL_DIALS,
            maxDialQueueLength: init.maxDialQueueLength ?? MAX_DIAL_QUEUE_LENGTH,
            maxPeerAddrsToDial: init.maxPeerAddrsToDial ?? MAX_PEER_ADDRS_TO_DIAL,
            dialTimeout: init.dialTimeout ?? DIAL_TIMEOUT,
            resolvers: init.resolvers ?? {
                dnsaddr: dnsaddrResolver
            },
            connections: this.connections
        });
        this.reconnectQueue = new ReconnectQueue({
            events: components.events,
            peerStore: components.peerStore,
            logger: components.logger,
            connectionManager: this
        }, {
            retries: init.reconnectRetries,
            retryInterval: init.reconnectRetryInterval,
            backoffFactor: init.reconnectBackoffFactor,
            maxParallelReconnects: init.maxParallelReconnects
        });
    }
    [Symbol.toStringTag] = '@libp2p/connection-manager';
    /**
     * Starts the Connection Manager. If Metrics are not enabled on libp2p
     * only event loop and connection limits will be monitored.
     */
    async start() {
        // track inbound/outbound connections
        this.metrics?.registerMetricGroup('libp2p_connection_manager_connections', {
            calculate: () => {
                const metric = {
                    inbound: 0,
                    'inbound pending': this.incomingPendingConnections,
                    outbound: 0,
                    'outbound pending': this.outboundPendingConnections
                };
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        metric[conn.direction]++;
                    }
                }
                return metric;
            }
        });
        // track total number of streams per protocol
        this.metrics?.registerMetricGroup('libp2p_protocol_streams_total', {
            label: 'protocol',
            calculate: () => {
                const metric = {};
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        for (const stream of conn.streams) {
                            const key = `${stream.direction} ${stream.protocol ?? 'unnegotiated'}`;
                            metric[key] = (metric[key] ?? 0) + 1;
                        }
                    }
                }
                return metric;
            }
        });
        // track 90th percentile of streams per protocol
        this.metrics?.registerMetricGroup('libp2p_connection_manager_protocol_streams_per_connection_90th_percentile', {
            label: 'protocol',
            calculate: () => {
                const allStreams = {};
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        const streams = {};
                        for (const stream of conn.streams) {
                            const key = `${stream.direction} ${stream.protocol ?? 'unnegotiated'}`;
                            streams[key] = (streams[key] ?? 0) + 1;
                        }
                        for (const [protocol, count] of Object.entries(streams)) {
                            allStreams[protocol] = allStreams[protocol] ?? [];
                            allStreams[protocol].push(count);
                        }
                    }
                }
                const metric = {};
                for (let [protocol, counts] of Object.entries(allStreams)) {
                    counts = counts.sort((a, b) => a - b);
                    const index = Math.floor(counts.length * 0.9);
                    metric[protocol] = counts[index];
                }
                return metric;
            }
        });
        this.events.addEventListener('connection:open', this.onConnect);
        this.events.addEventListener('connection:close', this.onDisconnect);
        await start(this.dialQueue, this.reconnectQueue, this.connectionPruner);
        this.started = true;
        this.log('started');
    }
    /**
     * Stops the Connection Manager
     */
    async stop() {
        this.events.removeEventListener('connection:open', this.onConnect);
        this.events.removeEventListener('connection:close', this.onDisconnect);
        await stop(this.reconnectQueue, this.dialQueue, this.connectionPruner);
        // Close all connections we're tracking
        const tasks = [];
        for (const connectionList of this.connections.values()) {
            for (const connection of connectionList) {
                tasks.push((async () => {
                    try {
                        await connection.close();
                    }
                    catch (err) {
                        this.log.error(err);
                    }
                })());
            }
        }
        this.log('closing %d connections', tasks.length);
        await Promise.all(tasks);
        this.connections.clear();
        this.log('stopped');
    }
    getMaxConnections() {
        return this.maxConnections;
    }
    setMaxConnections(maxConnections) {
        if (this.maxConnections < 1) {
            throw new InvalidParametersError$1('Connection Manager maxConnections must be greater than 0');
        }
        let needsPrune = false;
        if (maxConnections < this.maxConnections) {
            needsPrune = true;
        }
        this.maxConnections = maxConnections;
        if (needsPrune) {
            this.connectionPruner.maybePruneConnections();
        }
    }
    onConnect(evt) {
        void this._onConnect(evt).catch(err => {
            this.log.error(err);
        });
    }
    /**
     * Tracks the incoming connection and check the connection limit
     */
    async _onConnect(evt) {
        const { detail: connection } = evt;
        if (!this.started) {
            // This can happen when we are in the process of shutting down the node
            await connection.close();
            return;
        }
        if (connection.status !== 'open') {
            // this can happen when the remote closes the connection immediately after
            // opening
            return;
        }
        const peerId = connection.remotePeer;
        const isNewPeer = !this.connections.has(peerId);
        const storedConns = this.connections.get(peerId) ?? [];
        storedConns.push(connection);
        this.connections.set(peerId, storedConns);
        // only need to store RSA public keys, all other types are embedded in the peer id
        if (peerId.publicKey != null && peerId.type === 'RSA') {
            await this.peerStore.patch(peerId, {
                publicKey: peerId.publicKey
            });
        }
        if (isNewPeer) {
            this.events.safeDispatchEvent('peer:connect', { detail: connection.remotePeer });
        }
    }
    /**
     * Removes the connection from tracking
     */
    onDisconnect(evt) {
        const { detail: connection } = evt;
        const peerId = connection.remotePeer;
        const peerConns = this.connections.get(peerId) ?? [];
        // remove closed connection
        const filteredPeerConns = peerConns.filter(conn => conn.id !== connection.id);
        // update peer connections
        this.connections.set(peerId, filteredPeerConns);
        if (filteredPeerConns.length === 0) {
            // trigger disconnect event if no connections remain
            this.log('onDisconnect remove all connections for peer %p', peerId);
            this.connections.delete(peerId);
            // broadcast disconnect event
            this.events.safeDispatchEvent('peer:disconnect', { detail: connection.remotePeer });
        }
    }
    getConnections(peerId) {
        if (peerId != null) {
            return this.connections.get(peerId) ?? [];
        }
        let conns = [];
        for (const c of this.connections.values()) {
            conns = conns.concat(c);
        }
        return conns;
    }
    getConnectionsMap() {
        return this.connections;
    }
    async openConnection(peerIdOrMultiaddr, options = {}) {
        if (!this.started) {
            throw new NotStartedError('Not started');
        }
        this.outboundPendingConnections++;
        try {
            options.signal?.throwIfAborted();
            const { peerId } = getPeerAddress(peerIdOrMultiaddr);
            if (this.peerId.equals(peerId)) {
                throw new InvalidPeerIdError('Can not dial self');
            }
            if (peerId != null && options.force !== true) {
                this.log('dial %p', peerId);
                const existingConnection = this.getConnections(peerId)
                    .find(conn => conn.limits == null);
                if (existingConnection != null) {
                    this.log('had an existing non-limited connection to %p', peerId);
                    options.onProgress?.(new CustomProgressEvent('dial-queue:already-connected'));
                    return existingConnection;
                }
            }
            const connection = await this.dialQueue.dial(peerIdOrMultiaddr, {
                ...options,
                priority: options.priority ?? DEFAULT_DIAL_PRIORITY
            });
            if (connection.status !== 'open') {
                throw new ConnectionClosedError('Remote closed connection during opening');
            }
            let peerConnections = this.connections.get(connection.remotePeer);
            if (peerConnections == null) {
                peerConnections = [];
                this.connections.set(connection.remotePeer, peerConnections);
            }
            // we get notified of connections via the Upgrader emitting "connection"
            // events, double check we aren't already tracking this connection before
            // storing it
            let trackedConnection = false;
            for (const conn of peerConnections) {
                if (conn.id === connection.id) {
                    trackedConnection = true;
                }
                // make sure we don't already have a connection to this multiaddr
                if (options.force !== true && conn.id !== connection.id && conn.remoteAddr.equals(connection.remoteAddr)) {
                    connection.abort(new InvalidMultiaddrError$1('Duplicate multiaddr connection'));
                    // return the existing connection
                    return conn;
                }
            }
            if (!trackedConnection) {
                peerConnections.push(connection);
            }
            return connection;
        }
        finally {
            this.outboundPendingConnections--;
        }
    }
    async closeConnections(peerId, options = {}) {
        const connections = this.connections.get(peerId) ?? [];
        await Promise.all(connections.map(async (connection) => {
            try {
                await connection.close(options);
            }
            catch (err) {
                connection.abort(err);
            }
        }));
    }
    async acceptIncomingConnection(maConn) {
        // check deny list
        const denyConnection = this.deny.some(ma => {
            return ma.contains(maConn.remoteAddr.nodeAddress().address);
        });
        if (denyConnection) {
            this.log('connection from %a refused - connection remote address was in deny list', maConn.remoteAddr);
            return false;
        }
        // check allow list
        const allowConnection = this.allow.some(ipNet => {
            return ipNet.contains(maConn.remoteAddr.nodeAddress().address);
        });
        if (allowConnection) {
            this.incomingPendingConnections++;
            return true;
        }
        // check pending connections
        if (this.incomingPendingConnections === this.maxIncomingPendingConnections) {
            this.log('connection from %a refused - incomingPendingConnections exceeded by host', maConn.remoteAddr);
            return false;
        }
        if (maConn.remoteAddr.isThinWaistAddress()) {
            const host = maConn.remoteAddr.nodeAddress().address;
            try {
                await this.inboundConnectionRateLimiter.consume(host, 1);
            }
            catch {
                this.log('connection from %a refused - inboundConnectionThreshold exceeded by host %s', maConn.remoteAddr, host);
                return false;
            }
        }
        if (this.getConnections().length < this.maxConnections) {
            this.incomingPendingConnections++;
            return true;
        }
        this.log('connection from %a refused - maxConnections exceeded', maConn.remoteAddr);
        return false;
    }
    afterUpgradeInbound() {
        this.incomingPendingConnections--;
    }
    getDialQueue() {
        const statusMap = {
            queued: 'queued',
            running: 'active',
            errored: 'error',
            complete: 'success'
        };
        return this.dialQueue.queue.queue.map(job => {
            return {
                id: job.id,
                status: statusMap[job.status],
                peerId: job.options.peerId,
                multiaddrs: [...job.options.multiaddrs].map(ma => multiaddr(ma))
            };
        });
    }
    async isDialable(multiaddr, options = {}) {
        return this.dialQueue.isDialable(multiaddr, options);
    }
}

/**
 * Implements exponential moving average. Ported from `moving-average`.
 *
 * @see https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average
 * @see https://www.npmjs.com/package/moving-average
 */
class MovingAverage {
    movingAverage;
    variance;
    deviation;
    forecast;
    timeSpan;
    previousTime;
    constructor(timeSpan) {
        this.timeSpan = timeSpan;
        this.movingAverage = 0;
        this.variance = 0;
        this.deviation = 0;
        this.forecast = 0;
    }
    alpha(t, pt) {
        return 1 - (Math.exp(-(t - pt) / this.timeSpan));
    }
    push(value, time = Date.now()) {
        if (this.previousTime != null) {
            // calculate moving average
            const a = this.alpha(time, this.previousTime);
            const diff = value - this.movingAverage;
            const incr = a * diff;
            this.movingAverage = a * value + (1 - a) * this.movingAverage;
            // calculate variance & deviation
            this.variance = (1 - a) * (this.variance + diff * incr);
            this.deviation = Math.sqrt(this.variance);
            // calculate forecast
            this.forecast = this.movingAverage + a * diff;
        }
        else {
            this.movingAverage = value;
        }
        this.previousTime = time;
    }
}

const DEFAULT_TIMEOUT_MULTIPLIER = 1.2;
const DEFAULT_FAILURE_MULTIPLIER = 2;
const DEFAULT_MIN_TIMEOUT = 5_000;
const DEFAULT_MAX_TIMEOUT = 60_000;
const DEFAULT_INTERVAL = 5_000;
class AdaptiveTimeout {
    success;
    failure;
    next;
    metric;
    timeoutMultiplier;
    failureMultiplier;
    minTimeout;
    maxTimeout;
    constructor(init = {}) {
        const interval = init.interval ?? DEFAULT_INTERVAL;
        this.success = new MovingAverage(interval);
        this.failure = new MovingAverage(interval);
        this.next = new MovingAverage(interval);
        this.failureMultiplier = init.failureMultiplier ?? DEFAULT_FAILURE_MULTIPLIER;
        this.timeoutMultiplier = init.timeoutMultiplier ?? DEFAULT_TIMEOUT_MULTIPLIER;
        this.minTimeout = init.minTimeout ?? DEFAULT_MIN_TIMEOUT;
        this.maxTimeout = init.maxTimeout ?? DEFAULT_MAX_TIMEOUT;
        if (init.metricName != null) {
            this.metric = init.metrics?.registerMetricGroup(init.metricName);
        }
    }
    getTimeoutSignal(options = {}) {
        // calculate timeout for individual peers based on moving average of
        // previous successful requests
        let timeout = Math.round(this.next.movingAverage * (options.timeoutFactor ?? this.timeoutMultiplier));
        if (timeout < this.minTimeout) {
            timeout = this.minTimeout;
        }
        if (timeout > this.maxTimeout) {
            timeout = this.maxTimeout;
        }
        const sendTimeout = AbortSignal.timeout(timeout);
        const timeoutSignal = anySignal([options.signal, sendTimeout]);
        timeoutSignal.start = Date.now();
        timeoutSignal.timeout = timeout;
        return timeoutSignal;
    }
    cleanUp(signal) {
        const time = Date.now() - signal.start;
        if (signal.aborted) {
            this.failure.push(time);
            this.next.push(time * this.failureMultiplier);
            this.metric?.update({
                failureMovingAverage: this.failure.movingAverage,
                failureDeviation: this.failure.deviation,
                failureForecast: this.failure.forecast,
                failureVariance: this.failure.variance,
                failure: time
            });
        }
        else {
            this.success.push(time);
            this.next.push(time);
            this.metric?.update({
                successMovingAverage: this.success.movingAverage,
                successDeviation: this.success.deviation,
                successForecast: this.success.forecast,
                successVariance: this.success.variance,
                success: time
            });
        }
    }
}

const DEFAULT_PING_INTERVAL_MS = 10000;
const PROTOCOL_VERSION = '1.0.0';
const PROTOCOL_NAME = 'ping';
const PROTOCOL_PREFIX = 'ipfs';
const PING_LENGTH = 32;
const DEFAULT_ABORT_CONNECTION_ON_PING_FAILURE = true;
class ConnectionMonitor {
    protocol;
    components;
    log;
    heartbeatInterval;
    pingIntervalMs;
    abortController;
    timeout;
    abortConnectionOnPingFailure;
    constructor(components, init = {}) {
        this.components = components;
        this.protocol = `/${init.protocolPrefix ?? PROTOCOL_PREFIX}/${PROTOCOL_NAME}/${PROTOCOL_VERSION}`;
        this.log = components.logger.forComponent('libp2p:connection-monitor');
        this.pingIntervalMs = init.pingInterval ?? DEFAULT_PING_INTERVAL_MS;
        this.abortConnectionOnPingFailure = init.abortConnectionOnPingFailure ?? DEFAULT_ABORT_CONNECTION_ON_PING_FAILURE;
        this.timeout = new AdaptiveTimeout({
            ...(init.pingTimeout ?? {}),
            metrics: components.metrics,
            metricName: 'libp2p_connection_monitor_ping_time_milliseconds'
        });
    }
    [Symbol.toStringTag] = '@libp2p/connection-monitor';
    [serviceCapabilities] = [
        '@libp2p/connection-monitor'
    ];
    start() {
        this.abortController = new AbortController();
        setMaxListeners(Infinity, this.abortController.signal);
        this.heartbeatInterval = setInterval(() => {
            this.components.connectionManager.getConnections().forEach(conn => {
                Promise.resolve().then(async () => {
                    let start = Date.now();
                    try {
                        const signal = this.timeout.getTimeoutSignal({
                            signal: this.abortController?.signal
                        });
                        const stream = await conn.newStream(this.protocol, {
                            signal,
                            runOnLimitedConnection: true
                        });
                        const bs = byteStream(stream);
                        start = Date.now();
                        await Promise.all([
                            bs.write(randomBytes(PING_LENGTH), {
                                signal
                            }),
                            bs.read({
                                bytes: PING_LENGTH,
                                signal
                            })
                        ]);
                        conn.rtt = Date.now() - start;
                        await bs.unwrap().close({
                            signal
                        });
                    }
                    catch (err) {
                        if (err.name !== 'UnsupportedProtocolError') {
                            throw err;
                        }
                        // protocol was unsupported, but that's ok as it means the remote
                        // peer was still alive. We ran multistream-select which means two
                        // round trips (e.g. 1x for the mss header, then another for the
                        // protocol) so divide the time it took by two
                        conn.rtt = (Date.now() - start) / 2;
                    }
                })
                    .catch(err => {
                    this.log.error('error during heartbeat', err);
                    if (this.abortConnectionOnPingFailure) {
                        this.log.error('aborting connection due to ping failure');
                        conn.abort(err);
                    }
                    else {
                        this.log('connection ping failed, but not aborting due to abortConnectionOnPingFailure flag');
                    }
                });
            });
        }, this.pingIntervalMs);
    }
    stop() {
        this.abortController?.abort();
        if (this.heartbeatInterval != null) {
            clearInterval(this.heartbeatInterval);
        }
    }
}

class CompoundContentRouting {
    routers;
    started;
    components;
    constructor(components, init) {
        this.routers = init.routers ?? [];
        this.started = false;
        this.components = components;
        this.findProviders = components.metrics?.traceFunction('libp2p.contentRouting.findProviders', this.findProviders.bind(this), {
            optionsIndex: 1,
            getAttributesFromArgs: ([cid], attrs) => {
                return {
                    ...attrs,
                    cid: cid.toString()
                };
            },
            getAttributesFromYieldedValue: (value, attrs) => {
                return {
                    ...attrs,
                    providers: [...(Array.isArray(attrs.providers) ? attrs.providers : []), value.id.toString()]
                };
            }
        }) ?? this.findProviders;
        this.provide = components.metrics?.traceFunction('libp2p.contentRouting.provide', this.provide.bind(this), {
            optionsIndex: 1,
            getAttributesFromArgs: ([cid], attrs) => {
                return {
                    ...attrs,
                    cid: cid.toString()
                };
            }
        }) ?? this.provide;
        this.cancelReprovide = components.metrics?.traceFunction('libp2p.contentRouting.cancelReprovide', this.cancelReprovide.bind(this), {
            optionsIndex: 1,
            getAttributesFromArgs: ([cid], attrs) => {
                return {
                    ...attrs,
                    cid: cid.toString()
                };
            }
        }) ?? this.cancelReprovide;
        this.put = components.metrics?.traceFunction('libp2p.contentRouting.put', this.put.bind(this), {
            optionsIndex: 2,
            getAttributesFromArgs: ([key]) => {
                return {
                    key: toString(key, 'base36')
                };
            }
        }) ?? this.put;
        this.get = components.metrics?.traceFunction('libp2p.contentRouting.get', this.get.bind(this), {
            optionsIndex: 1,
            getAttributesFromArgs: ([key]) => {
                return {
                    key: toString(key, 'base36')
                };
            }
        }) ?? this.get;
    }
    [Symbol.toStringTag] = '@libp2p/content-routing';
    isStarted() {
        return this.started;
    }
    async start() {
        this.started = true;
    }
    async stop() {
        this.started = false;
    }
    /**
     * Iterates over all content routers in parallel to find providers of the given key
     */
    async *findProviders(key, options = {}) {
        if (this.routers.length === 0) {
            throw new NoContentRoutersError('No content routers available');
        }
        const self = this;
        const seen = new PeerSet();
        for await (const peer of merge$1(...self.routers
            .filter(router => router.findProviders instanceof Function)
            .map(router => router.findProviders(key, options)))) {
            // the peer was yielded by a content router without multiaddrs and we
            // failed to load them
            if (peer == null) {
                continue;
            }
            // store the addresses for the peer if found
            if (peer.multiaddrs.length > 0) {
                await this.components.peerStore.merge(peer.id, {
                    multiaddrs: peer.multiaddrs
                }, options);
            }
            // deduplicate peers
            if (seen.has(peer.id)) {
                continue;
            }
            seen.add(peer.id);
            yield peer;
        }
    }
    /**
     * Iterates over all content routers in parallel to notify it is
     * a provider of the given key
     */
    async provide(key, options = {}) {
        if (this.routers.length === 0) {
            throw new NoContentRoutersError('No content routers available');
        }
        await Promise.all(this.routers
            .filter(router => router.provide instanceof Function)
            .map(async (router) => {
            await router.provide(key, options);
        }));
    }
    async cancelReprovide(key, options = {}) {
        if (this.routers.length === 0) {
            throw new NoContentRoutersError('No content routers available');
        }
        await Promise.all(this.routers
            .filter(router => router.cancelReprovide instanceof Function)
            .map(async (router) => {
            await router.cancelReprovide(key, options);
        }));
    }
    /**
     * Store the given key/value pair in the available content routings
     */
    async put(key, value, options) {
        if (!this.isStarted()) {
            throw new NotStartedError();
        }
        await Promise.all(this.routers
            .filter(router => router.put instanceof Function)
            .map(async (router) => {
            await router.put(key, value, options);
        }));
    }
    /**
     * Get the value to the given key.
     * Times out after 1 minute by default.
     */
    async get(key, options) {
        if (!this.isStarted()) {
            throw new NotStartedError();
        }
        return Promise.any(this.routers
            .filter(router => router.get instanceof Function)
            .map(async (router) => {
            return router.get(key, options);
        }));
    }
}

class DefaultPeerRouting {
    log;
    peerId;
    peerStore;
    routers;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:peer-routing');
        this.peerId = components.peerId;
        this.peerStore = components.peerStore;
        this.routers = init.routers ?? [];
        this.findPeer = components.metrics?.traceFunction('libp2p.peerRouting.findPeer', this.findPeer.bind(this), {
            optionsIndex: 1,
            getAttributesFromArgs: ([peer], attrs) => {
                return {
                    ...attrs,
                    peer: peer.toString()
                };
            }
        }) ?? this.findPeer;
        this.getClosestPeers = components.metrics?.traceFunction('libp2p.peerRouting.getClosestPeers', this.getClosestPeers.bind(this), {
            optionsIndex: 1,
            getAttributesFromArgs: ([key], attrs) => {
                return {
                    ...attrs,
                    key: toString(key, 'base36')
                };
            },
            getAttributesFromYieldedValue: (value, attrs) => {
                return {
                    ...attrs,
                    peers: [...(Array.isArray(attrs.peers) ? attrs.peers : []), value.id.toString()]
                };
            }
        }) ?? this.getClosestPeers;
    }
    [Symbol.toStringTag] = '@libp2p/peer-routing';
    /**
     * Iterates over all peer routers in parallel to find the given peer
     */
    async findPeer(id, options) {
        if (this.routers.length === 0) {
            throw new NoPeerRoutersError('No peer routers available');
        }
        if (id.toString() === this.peerId.toString()) {
            throw new QueriedForSelfError('Should not try to find self');
        }
        const self = this;
        const source = merge$1(...this.routers
            .filter(router => router.findPeer instanceof Function)
            .map(router => (async function* () {
            try {
                yield await router.findPeer(id, options);
            }
            catch (err) {
                self.log.error(err);
            }
        })()));
        for await (const peer of source) {
            if (peer == null) {
                continue;
            }
            // store the addresses for the peer if found
            if (peer.multiaddrs.length > 0) {
                await this.peerStore.merge(peer.id, {
                    multiaddrs: peer.multiaddrs
                }, options);
            }
            return peer;
        }
        throw new NotFoundError$1();
    }
    /**
     * Attempt to find the closest peers on the network to the given key
     */
    async *getClosestPeers(key, options = {}) {
        if (this.routers.length === 0) {
            throw new NoPeerRoutersError('No peer routers available');
        }
        const self = this;
        const seen = createScalableCuckooFilter(1024);
        for await (const peer of parallel(async function* () {
            const source = merge$1(...self.routers
                .filter(router => router.getClosestPeers instanceof Function)
                .map(router => router.getClosestPeers(key, options)));
            for await (let peer of source) {
                yield async () => {
                    // find multiaddrs if they are missing
                    if (peer.multiaddrs.length === 0) {
                        try {
                            peer = await self.findPeer(peer.id, {
                                ...options,
                                useCache: false
                            });
                        }
                        catch (err) {
                            self.log.error('could not find peer multiaddrs', err);
                            return;
                        }
                    }
                    return peer;
                };
            }
        }())) {
            if (peer == null) {
                continue;
            }
            // store the addresses for the peer if found
            if (peer.multiaddrs.length > 0) {
                await this.peerStore.merge(peer.id, {
                    multiaddrs: peer.multiaddrs
                }, options);
            }
            // deduplicate peers
            if (seen.has(peer.id.toMultihash().bytes)) {
                continue;
            }
            seen.add(peer.id.toMultihash().bytes);
            yield peer;
        }
    }
}

class RandomWalk extends TypedEventEmitter {
    peerRouting;
    log;
    walking;
    walkers;
    shutdownController;
    walkController;
    needNext;
    constructor(components) {
        super();
        this.log = components.logger.forComponent('libp2p:random-walk');
        this.peerRouting = components.peerRouting;
        this.walkers = 0;
        this.walking = false;
        // stops any in-progress walks when the node is shut down
        this.shutdownController = new AbortController();
        setMaxListeners(Infinity, this.shutdownController.signal);
    }
    [Symbol.toStringTag] = '@libp2p/random-walk';
    start() {
        this.shutdownController = new AbortController();
        setMaxListeners(Infinity, this.shutdownController.signal);
    }
    stop() {
        this.shutdownController.abort();
    }
    async *walk(options) {
        if (!this.walking) {
            // start the query that causes walk:peer events to be emitted
            this.startWalk();
        }
        this.walkers++;
        const signal = anySignal([this.shutdownController.signal, options?.signal]);
        try {
            while (true) {
                // if another consumer has paused the query, start it again
                this.needNext?.resolve();
                this.needNext = pDefer();
                // wait for a walk:peer or walk:error event
                const event = await raceEvent(this, 'walk:peer', signal, {
                    errorEvent: 'walk:error'
                });
                yield event.detail;
            }
        }
        finally {
            signal.clear();
            this.walkers--;
            // stop the walk if no more consumers are interested
            if (this.walkers === 0) {
                this.walkController?.abort();
                this.walkController = undefined;
            }
        }
    }
    startWalk() {
        this.walking = true;
        // the signal for this controller will be aborted if no more random peers
        // are required
        this.walkController = new AbortController();
        setMaxListeners(Infinity, this.walkController.signal);
        const signal = anySignal([this.walkController.signal, this.shutdownController.signal]);
        const start = Date.now();
        let found = 0;
        Promise.resolve().then(async () => {
            this.log('start walk');
            // find peers until no more consumers are interested
            while (this.walkers > 0) {
                try {
                    const data = randomBytes(32);
                    let s = Date.now();
                    for await (const peer of this.peerRouting.getClosestPeers(data, { signal })) {
                        if (signal.aborted) {
                            this.log('aborting walk');
                        }
                        signal.throwIfAborted();
                        this.log('found peer %p after %dms for %d walkers', peer.id, Date.now() - s, this.walkers);
                        found++;
                        this.safeDispatchEvent('walk:peer', {
                            detail: peer
                        });
                        // if we only have one consumer, pause the query until they request
                        // another random peer or they signal they are no longer interested
                        if (this.walkers === 1 && this.needNext != null) {
                            this.log('wait for need next');
                            await raceSignal(this.needNext.promise, signal);
                        }
                        s = Date.now();
                    }
                    this.log('walk iteration for %b and %d walkers finished, found %d peers', data, this.walkers, found);
                }
                catch (err) {
                    this.log.error('random walk errored', err);
                    this.safeDispatchEvent('walk:error', {
                        detail: err
                    });
                }
            }
            this.log('no walkers left, ended walk');
        })
            .catch(err => {
            this.log.error('random walk errored', err);
        })
            .finally(() => {
            this.log('finished walk, found %d peers after %dms', found, Date.now() - start);
            this.walking = false;
        });
    }
}

const DEFAULT_MAX_INBOUND_STREAMS = 32;
const DEFAULT_MAX_OUTBOUND_STREAMS = 64;
/**
 * Responsible for notifying registered protocols of events in the network.
 */
class Registrar {
    log;
    topologies;
    handlers;
    components;
    constructor(components) {
        this.components = components;
        this.log = components.logger.forComponent('libp2p:registrar');
        this.topologies = new Map();
        components.metrics?.registerMetricGroup('libp2p_registrar_topologies', {
            calculate: () => {
                const output = {};
                for (const [key, value] of this.topologies) {
                    output[key] = value.size;
                }
                return output;
            }
        });
        this.handlers = trackedMap({
            name: 'libp2p_registrar_protocol_handlers',
            metrics: components.metrics
        });
        this._onDisconnect = this._onDisconnect.bind(this);
        this._onPeerUpdate = this._onPeerUpdate.bind(this);
        this._onPeerIdentify = this._onPeerIdentify.bind(this);
        this.components.events.addEventListener('peer:disconnect', this._onDisconnect);
        this.components.events.addEventListener('peer:update', this._onPeerUpdate);
        this.components.events.addEventListener('peer:identify', this._onPeerIdentify);
    }
    [Symbol.toStringTag] = '@libp2p/registrar';
    getProtocols() {
        return Array.from(new Set([
            ...this.handlers.keys()
        ])).sort();
    }
    getHandler(protocol) {
        const handler = this.handlers.get(protocol);
        if (handler == null) {
            throw new UnhandledProtocolError(`No handler registered for protocol ${protocol}`);
        }
        return handler;
    }
    getTopologies(protocol) {
        const topologies = this.topologies.get(protocol);
        if (topologies == null) {
            return [];
        }
        return [
            ...topologies.values()
        ];
    }
    /**
     * Registers the `handler` for each protocol
     */
    async handle(protocol, handler, opts) {
        if (this.handlers.has(protocol) && opts?.force !== true) {
            throw new DuplicateProtocolHandlerError(`Handler already registered for protocol ${protocol}`);
        }
        const options = mergeOptions.bind({ ignoreUndefined: true })({
            maxInboundStreams: DEFAULT_MAX_INBOUND_STREAMS,
            maxOutboundStreams: DEFAULT_MAX_OUTBOUND_STREAMS
        }, opts);
        this.handlers.set(protocol, {
            handler,
            options
        });
        // Add new protocol to self protocols in the peer store
        await this.components.peerStore.merge(this.components.peerId, {
            protocols: [protocol]
        }, opts);
    }
    /**
     * Removes the handler for each protocol. The protocol
     * will no longer be supported on streams.
     */
    async unhandle(protocols, options) {
        const protocolList = Array.isArray(protocols) ? protocols : [protocols];
        protocolList.forEach(protocol => {
            this.handlers.delete(protocol);
        });
        // Update self protocols in the peer store
        await this.components.peerStore.patch(this.components.peerId, {
            protocols: this.getProtocols()
        }, options);
    }
    /**
     * Register handlers for a set of multicodecs given
     */
    async register(protocol, topology) {
        if (topology == null) {
            throw new InvalidParametersError$1('invalid topology');
        }
        // Create topology
        const id = `${(Math.random() * 1e9).toString(36)}${Date.now()}`;
        let topologies = this.topologies.get(protocol);
        if (topologies == null) {
            topologies = new Map();
            this.topologies.set(protocol, topologies);
        }
        topologies.set(id, topology);
        return id;
    }
    /**
     * Unregister topology
     */
    unregister(id) {
        for (const [protocol, topologies] of this.topologies.entries()) {
            if (topologies.has(id)) {
                topologies.delete(id);
                if (topologies.size === 0) {
                    this.topologies.delete(protocol);
                }
            }
        }
    }
    /**
     * Remove a disconnected peer from the record
     */
    _onDisconnect(evt) {
        const remotePeer = evt.detail;
        const options = {
            signal: AbortSignal.timeout(5_000)
        };
        void this.components.peerStore.get(remotePeer, options)
            .then(peer => {
            for (const protocol of peer.protocols) {
                const topologies = this.topologies.get(protocol);
                if (topologies == null) {
                    // no topologies are interested in this protocol
                    continue;
                }
                for (const topology of topologies.values()) {
                    if (topology.filter?.has(remotePeer) === false) {
                        continue;
                    }
                    topology.filter?.remove(remotePeer);
                    topology.onDisconnect?.(remotePeer);
                }
            }
        })
            .catch(err => {
            if (err.name === 'NotFoundError') {
                // peer has not completed identify so they are not in the peer store
                return;
            }
            this.log.error('could not inform topologies of disconnecting peer %p', remotePeer, err);
        });
    }
    /**
     * When a peer is updated, if they have removed supported protocols notify any
     * topologies interested in the removed protocols.
     */
    _onPeerUpdate(evt) {
        const { peer, previous } = evt.detail;
        const removed = (previous?.protocols ?? []).filter(protocol => !peer.protocols.includes(protocol));
        for (const protocol of removed) {
            const topologies = this.topologies.get(protocol);
            if (topologies == null) {
                // no topologies are interested in this protocol
                continue;
            }
            for (const topology of topologies.values()) {
                if (topology.filter?.has(peer.id) === false) {
                    continue;
                }
                topology.filter?.remove(peer.id);
                topology.onDisconnect?.(peer.id);
            }
        }
    }
    /**
     * After identify has completed and we have received the list of supported
     * protocols, notify any topologies interested in those protocols.
     */
    _onPeerIdentify(evt) {
        const protocols = evt.detail.protocols;
        const connection = evt.detail.connection;
        const peerId = evt.detail.peerId;
        for (const protocol of protocols) {
            const topologies = this.topologies.get(protocol);
            if (topologies == null) {
                // no topologies are interested in this protocol
                continue;
            }
            for (const topology of topologies.values()) {
                if (connection.limits != null && topology.notifyOnLimitedConnection !== true) {
                    continue;
                }
                if (topology.filter?.has(peerId) === true) {
                    continue;
                }
                topology.filter?.add(peerId);
                topology.onConnect?.(peerId, connection);
            }
        }
    }
}

class DefaultTransportManager {
    log;
    components;
    transports;
    listeners;
    faultTolerance;
    started;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:transports');
        this.components = components;
        this.started = false;
        this.transports = trackedMap({
            name: 'libp2p_transport_manager_transports',
            metrics: this.components.metrics
        });
        this.listeners = trackedMap({
            name: 'libp2p_transport_manager_listeners',
            metrics: this.components.metrics
        });
        this.faultTolerance = init.faultTolerance ?? FaultTolerance.FATAL_ALL;
    }
    [Symbol.toStringTag] = '@libp2p/transport-manager';
    /**
     * Adds a `Transport` to the manager
     */
    add(transport) {
        const tag = transport[Symbol.toStringTag];
        if (tag == null) {
            throw new InvalidParametersError$1('Transport must have a valid tag');
        }
        if (this.transports.has(tag)) {
            throw new InvalidParametersError$1(`There is already a transport with the tag ${tag}`);
        }
        this.log('adding transport %s', tag);
        this.transports.set(tag, transport);
        if (!this.listeners.has(tag)) {
            this.listeners.set(tag, []);
        }
    }
    isStarted() {
        return this.started;
    }
    start() {
        this.started = true;
    }
    async afterStart() {
        // Listen on the provided transports for the provided addresses
        const addrs = this.components.addressManager.getListenAddrs();
        await this.listen(addrs);
    }
    /**
     * Stops all listeners
     */
    async stop() {
        const tasks = [];
        for (const [key, listeners] of this.listeners) {
            this.log('closing listeners for %s', key);
            while (listeners.length > 0) {
                const listener = listeners.pop();
                if (listener == null) {
                    continue;
                }
                tasks.push(listener.close());
            }
        }
        await Promise.all(tasks);
        this.log('all listeners closed');
        for (const key of this.listeners.keys()) {
            this.listeners.set(key, []);
        }
        this.started = false;
    }
    /**
     * Dials the given Multiaddr over it's supported transport
     */
    async dial(ma, options) {
        const transport = this.dialTransportForMultiaddr(ma);
        if (transport == null) {
            throw new TransportUnavailableError(`No transport available for address ${String(ma)}`);
        }
        options?.onProgress?.(new CustomProgressEvent('transport-manager:selected-transport', transport[Symbol.toStringTag]));
        // @ts-expect-error the transport has a typed onProgress option but we
        // can't predict what transport implementation we selected so all we can
        // do is pass the onProgress handler in and hope for the best
        return transport.dial(ma, {
            ...options,
            upgrader: this.components.upgrader
        });
    }
    /**
     * Returns all Multiaddr's the listeners are using
     */
    getAddrs() {
        let addrs = [];
        for (const listeners of this.listeners.values()) {
            for (const listener of listeners) {
                addrs = [...addrs, ...listener.getAddrs()];
            }
        }
        return addrs;
    }
    /**
     * Returns all the transports instances
     */
    getTransports() {
        return Array.of(...this.transports.values());
    }
    /**
     * Returns all the listener instances
     */
    getListeners() {
        return Array.of(...this.listeners.values()).flat();
    }
    /**
     * Finds a transport that matches the given Multiaddr
     */
    dialTransportForMultiaddr(ma) {
        for (const transport of this.transports.values()) {
            const addrs = transport.dialFilter([ma]);
            if (addrs.length > 0) {
                return transport;
            }
        }
    }
    /**
     * Finds a transport that matches the given Multiaddr
     */
    listenTransportForMultiaddr(ma) {
        for (const transport of this.transports.values()) {
            const addrs = transport.listenFilter([ma]);
            if (addrs.length > 0) {
                return transport;
            }
        }
    }
    /**
     * Starts listeners for each listen Multiaddr
     */
    async listen(addrs) {
        if (!this.isStarted()) {
            throw new NotStartedError('Not started');
        }
        if (addrs == null || addrs.length === 0) {
            this.log('no addresses were provided for listening, this node is dial only');
            return;
        }
        // track IPv4/IPv6 results - if we succeed on IPv4 but all IPv6 attempts
        // fail then we are probably on a network without IPv6 support
        const listenStats = {
            errors: new Map(),
            ipv4: {
                success: 0,
                attempts: 0
            },
            ipv6: {
                success: 0,
                attempts: 0
            }
        };
        addrs.forEach(ma => {
            listenStats.errors.set(ma.toString(), new UnsupportedListenAddressError());
        });
        const tasks = [];
        for (const [key, transport] of this.transports.entries()) {
            const supportedAddrs = transport.listenFilter(addrs);
            // For each supported multiaddr, create a listener
            for (const addr of supportedAddrs) {
                this.log('creating listener for %s on %a', key, addr);
                const listener = transport.createListener({
                    upgrader: this.components.upgrader
                });
                let listeners = this.listeners.get(key) ?? [];
                if (listeners == null) {
                    listeners = [];
                    this.listeners.set(key, listeners);
                }
                listeners.push(listener);
                // Track listen/close events
                listener.addEventListener('listening', () => {
                    this.components.events.safeDispatchEvent('transport:listening', {
                        detail: listener
                    });
                });
                listener.addEventListener('close', () => {
                    const index = listeners.findIndex(l => l === listener);
                    // remove the listener
                    listeners.splice(index, 1);
                    this.components.events.safeDispatchEvent('transport:close', {
                        detail: listener
                    });
                });
                // track IPv4/IPv6 support
                if (IP4.matches(addr)) {
                    listenStats.ipv4.attempts++;
                }
                else if (IP6.matches(addr)) {
                    listenStats.ipv6.attempts++;
                }
                // We need to attempt to listen on everything
                tasks.push(listener.listen(addr)
                    .then(() => {
                    listenStats.errors.delete(addr.toString());
                    if (IP4.matches(addr)) {
                        listenStats.ipv4.success++;
                    }
                    if (IP6.matches(addr)) {
                        listenStats.ipv6.success++;
                    }
                }, (err) => {
                    this.log.error('transport %s could not listen on address %a - %e', key, addr, err);
                    listenStats.errors.set(addr.toString(), err);
                    throw err;
                }));
            }
        }
        const results = await Promise.allSettled(tasks);
        // listening on all addresses, all good
        if (results.length > 0 && results.every(res => res.status === 'fulfilled')) {
            return;
        }
        // detect lack of IPv6 support on the current network - if we tried to
        // listen on IPv4 and IPv6 addresses, and all IPv4 addresses succeeded but
        // all IPv6 addresses fail, then we can assume there's no IPv6 here
        if (this.ipv6Unsupported(listenStats)) {
            this.log('all IPv4 addresses succeed but all IPv6 failed');
            return;
        }
        if (this.faultTolerance === FaultTolerance.NO_FATAL) {
            // ok to be dial-only
            this.log('failed to listen on any address but fault tolerance allows this');
            return;
        }
        // if a configured address was not able to be listened on, throw an error
        throw new UnsupportedListenAddressesError(`Some configured addresses failed to be listened on, you may need to remove one or more listen addresses from your configuration or set \`transportManager.faultTolerance\` to NO_FATAL:\n${[...listenStats.errors.entries()].map(([addr, err]) => {
            return `
  ${addr}: ${`${err.stack ?? err}`.split('\n').join('\n  ')}
`;
        }).join('')}`);
    }
    ipv6Unsupported(listenStats) {
        if (listenStats.ipv4.attempts === 0 || listenStats.ipv6.attempts === 0) {
            return false;
        }
        const allIpv4Succeeded = listenStats.ipv4.attempts === listenStats.ipv4.success;
        const allIpv6Failed = listenStats.ipv6.success === 0;
        return allIpv4Succeeded && allIpv6Failed;
    }
    /**
     * Removes the given transport from the manager.
     * If a transport has any running listeners, they will be closed.
     */
    async remove(key) {
        const listeners = this.listeners.get(key) ?? [];
        this.log.trace('removing transport %s', key);
        // Close any running listeners
        const tasks = [];
        this.log.trace('closing listeners for %s', key);
        while (listeners.length > 0) {
            const listener = listeners.pop();
            if (listener == null) {
                continue;
            }
            tasks.push(listener.close());
        }
        await Promise.all(tasks);
        this.transports.delete(key);
        this.listeners.delete(key);
    }
    /**
     * Removes all transports from the manager.
     * If any listeners are running, they will be closed.
     *
     * @async
     */
    async removeAll() {
        const tasks = [];
        for (const key of this.transports.keys()) {
            tasks.push(this.remove(key));
        }
        await Promise.all(tasks);
    }
}

const PROTOCOL_ID = '/multistream/1.0.0';
// Conforming to go-libp2p
// See https://github.com/multiformats/go-multistream/blob/master/multistream.go#L297
const MAX_PROTOCOL_LENGTH = 1024;

const NewLine = fromString('\n');
/**
 * `write` encodes and writes a single buffer
 */
async function write(writer, buffer, options) {
    await writer.write(buffer, options);
}
/**
 * `writeAll` behaves like `write`, except it encodes an array of items as a single write
 */
async function writeAll(writer, buffers, options) {
    await writer.writeV(buffers, options);
}
/**
 * Read a length-prefixed buffer from the passed stream, stripping the final newline character
 */
async function read(reader, options) {
    const buf = await reader.read(options);
    if (buf.byteLength === 0 || buf.get(buf.byteLength - 1) !== NewLine[0]) {
        options.log.error('Invalid mss message - missing newline', buf);
        throw new InvalidMessageError('Missing newline');
    }
    return buf.sublist(0, -1); // Remove newline
}
/**
 * Read a length-prefixed string from the passed stream, stripping the final newline character
 */
async function readString(reader, options) {
    const buf = await read(reader, options);
    return toString(buf.subarray());
}

/**
 * Negotiate a protocol to use from a list of protocols.
 *
 * @param stream - A duplex iterable stream to dial on
 * @param protocols - A list of protocols (or single protocol) to negotiate with. Protocols are attempted in order until a match is made.
 * @param options - An options object containing an AbortSignal and an optional boolean `writeBytes` - if this is true, `Uint8Array`s will be written into `duplex`, otherwise `Uint8ArrayList`s will
 * @returns A stream for the selected protocol and the protocol that was selected from the list of protocols provided to `select`.
 * @example
 *
 * ```TypeScript
 * import { pipe } from 'it-pipe'
 * import * as mss from '@libp2p/multistream-select'
 * import { Mplex } from '@libp2p/mplex'
 *
 * const muxer = new Mplex()
 * const muxedStream = muxer.newStream()
 *
 * // mss.select(protocol(s))
 * // Select from one of the passed protocols (in priority order)
 * // Returns selected stream and protocol
 * const { stream: dhtStream, protocol } = await mss.select(muxedStream, [
 *   // This might just be different versions of DHT, but could be different implementations
 *   '/ipfs-dht/2.0.0', // Most of the time this will probably just be one item.
 *   '/ipfs-dht/1.0.0'
 * ])
 *
 * // Typically this stream will be passed back to the caller of libp2p.dialProtocol
 * //
 * // ...it might then do something like this:
 * // try {
 * //   await pipe(
 * //     [uint8ArrayFromString('Some DHT data')]
 * //     dhtStream,
 * //     async source => {
 * //       for await (const chunk of source)
 * //         // DHT response data
 * //     }
 * //   )
 * // } catch (err) {
 * //   // Error in stream
 * // }
 * ```
 */
async function select(stream, protocols, options) {
    protocols = Array.isArray(protocols) ? [...protocols] : [protocols];
    if (protocols.length === 1 && options.negotiateFully === false) {
        return optimisticSelect(stream, protocols[0], options);
    }
    const lp = lpStream(stream, {
        ...options,
        maxDataLength: MAX_PROTOCOL_LENGTH
    });
    const protocol = protocols.shift();
    if (protocol == null) {
        throw new Error('At least one protocol must be specified');
    }
    options.log.trace('select: write ["%s", "%s"]', PROTOCOL_ID, protocol);
    const p1 = fromString(`${PROTOCOL_ID}\n`);
    const p2 = fromString(`${protocol}\n`);
    await writeAll(lp, [p1, p2], options);
    options.log.trace('select: reading multistream-select header');
    let response = await readString(lp, options);
    options.log.trace('select: read "%s"', response);
    // Read the protocol response if we got the protocolId in return
    if (response === PROTOCOL_ID) {
        options.log.trace('select: reading protocol response');
        response = await readString(lp, options);
        options.log.trace('select: read "%s"', response);
    }
    // We're done
    if (response === protocol) {
        return { stream: lp.unwrap(), protocol };
    }
    // We haven't gotten a valid ack, try the other protocols
    for (const protocol of protocols) {
        options.log.trace('select: write "%s"', protocol);
        await write(lp, fromString(`${protocol}\n`), options);
        options.log.trace('select: reading protocol response');
        const response = await readString(lp, options);
        options.log.trace('select: read "%s" for "%s"', response, protocol);
        if (response === protocol) {
            return { stream: lp.unwrap(), protocol };
        }
    }
    throw new UnsupportedProtocolError('protocol selection failed');
}
/**
 * Optimistically negotiates a protocol.
 *
 * It *does not* block writes waiting for the other end to respond. Instead, it
 * simply assumes the negotiation went successfully and starts writing data.
 *
 * Use when it is known that the receiver supports the desired protocol.
 */
function optimisticSelect(stream, protocol, options) {
    const originalSink = stream.sink.bind(stream);
    const originalSource = stream.source;
    let negotiated = false;
    let negotiating = false;
    const doneNegotiating = pDefer();
    let sentProtocol = false;
    let sendingProtocol = false;
    const doneSendingProtocol = pDefer();
    let readProtocol = false;
    let readingProtocol = false;
    const doneReadingProtocol = pDefer();
    const lp = lpStream({
        sink: originalSink,
        source: originalSource
    }, {
        ...options,
        maxDataLength: MAX_PROTOCOL_LENGTH
    });
    stream.sink = async (source) => {
        const { sink } = lp.unwrap();
        await sink(async function* () {
            let sentData = false;
            for await (const buf of source) {
                // started reading before the source yielded, wait for protocol send
                if (sendingProtocol) {
                    await doneSendingProtocol.promise;
                }
                // writing before reading, send the protocol and the first chunk of data
                if (!sentProtocol) {
                    sendingProtocol = true;
                    options.log.trace('optimistic: write ["%s", "%s", data(%d)] in sink', PROTOCOL_ID, protocol, buf.byteLength);
                    const protocolString = `${protocol}\n`;
                    // send protocols in first chunk of data written to transport
                    yield new Uint8ArrayList(Uint8Array.from([19]), // length of PROTOCOL_ID plus newline
                    fromString(`${PROTOCOL_ID}\n`), encode$8(protocolString.length), fromString(protocolString), buf).subarray();
                    options.log.trace('optimistic: wrote ["%s", "%s", data(%d)] in sink', PROTOCOL_ID, protocol, buf.byteLength);
                    sentProtocol = true;
                    sendingProtocol = false;
                    doneSendingProtocol.resolve();
                    // read the negotiation response but don't block more sending
                    negotiate()
                        .catch(err => {
                        options.log.error('could not finish optimistic protocol negotiation of %s', protocol, err);
                    });
                }
                else {
                    yield buf;
                }
                sentData = true;
            }
            // special case - the source passed to the sink has ended but we didn't
            // negotiated the protocol yet so do it now
            if (!sentData) {
                await negotiate();
            }
        }());
    };
    async function negotiate() {
        if (negotiating) {
            options.log.trace('optimistic: already negotiating %s stream', protocol);
            await doneNegotiating.promise;
            return;
        }
        negotiating = true;
        try {
            // we haven't sent the protocol yet, send it now
            if (!sentProtocol) {
                options.log.trace('optimistic: doing send protocol for %s stream', protocol);
                await doSendProtocol();
            }
            // if we haven't read the protocol response yet, do it now
            if (!readProtocol) {
                options.log.trace('optimistic: doing read protocol for %s stream', protocol);
                await doReadProtocol();
            }
        }
        finally {
            negotiating = false;
            negotiated = true;
            doneNegotiating.resolve();
        }
    }
    async function doSendProtocol() {
        if (sendingProtocol) {
            await doneSendingProtocol.promise;
            return;
        }
        sendingProtocol = true;
        try {
            options.log.trace('optimistic: write ["%s", "%s", data] in source', PROTOCOL_ID, protocol);
            await lp.writeV([
                fromString(`${PROTOCOL_ID}\n`),
                fromString(`${protocol}\n`)
            ]);
            options.log.trace('optimistic: wrote ["%s", "%s", data] in source', PROTOCOL_ID, protocol);
        }
        finally {
            sentProtocol = true;
            sendingProtocol = false;
            doneSendingProtocol.resolve();
        }
    }
    async function doReadProtocol() {
        if (readingProtocol) {
            await doneReadingProtocol.promise;
            return;
        }
        readingProtocol = true;
        try {
            options.log.trace('optimistic: reading multistream select header');
            let response = await readString(lp, options);
            options.log.trace('optimistic: read multistream select header "%s"', response);
            if (response === PROTOCOL_ID) {
                response = await readString(lp, options);
            }
            options.log.trace('optimistic: read protocol "%s", expecting "%s"', response, protocol);
            if (response !== protocol) {
                throw new UnsupportedProtocolError('protocol selection failed');
            }
        }
        finally {
            readProtocol = true;
            readingProtocol = false;
            doneReadingProtocol.resolve();
        }
    }
    stream.source = (async function* () {
        // make sure we've done protocol negotiation before we read stream data
        await negotiate();
        options.log.trace('optimistic: reading data from "%s" stream', protocol);
        yield* lp.unwrap().source;
    })();
    if (stream.closeRead != null) {
        const originalCloseRead = stream.closeRead.bind(stream);
        stream.closeRead = async (opts) => {
            // we need to read & write to negotiate the protocol so ensure we've done
            // this before closing the readable end of the stream
            if (!negotiated) {
                await negotiate().catch(err => {
                    options.log.error('could not negotiate protocol before close read', err);
                });
            }
            // protocol has been negotiated, ok to close the readable end
            await originalCloseRead(opts);
        };
    }
    if (stream.closeWrite != null) {
        const originalCloseWrite = stream.closeWrite.bind(stream);
        stream.closeWrite = async (opts) => {
            // we need to read & write to negotiate the protocol so ensure we've done
            // this before closing the writable end of the stream
            if (!negotiated) {
                await negotiate().catch(err => {
                    options.log.error('could not negotiate protocol before close write', err);
                });
            }
            // protocol has been negotiated, ok to close the writable end
            await originalCloseWrite(opts);
        };
    }
    if (stream.close != null) {
        const originalClose = stream.close.bind(stream);
        stream.close = async (opts) => {
            // if we are in the process of negotiation, let it finish before closing
            // because we may have unsent early data
            const tasks = [];
            if (sendingProtocol) {
                tasks.push(doneSendingProtocol.promise);
            }
            if (readingProtocol) {
                tasks.push(doneReadingProtocol.promise);
            }
            if (tasks.length > 0) {
                // let the in-flight protocol negotiation finish gracefully
                await raceSignal(Promise.all(tasks), opts?.signal);
            }
            else {
                // no protocol negotiation attempt has occurred so don't start one
                negotiated = true;
                negotiating = false;
                doneNegotiating.resolve();
            }
            // protocol has been negotiated, ok to close the writable end
            await originalClose(opts);
        };
    }
    return {
        stream,
        protocol
    };
}

// Maximum length of the length section of the message
// Maximum length of the data section of the message
const MAX_DATA_LENGTH = 1024 * 1024 * 4;

/**
 * The reported length of the next data message was not a positive integer
 */
/**
 * The reported length of the next data message was larger than the configured
 * max allowable value
 */
class InvalidDataLengthError extends Error {
    name = 'InvalidDataLengthError';
    code = 'ERR_MSG_DATA_TOO_LONG';
}

function isAsyncIterable(thing) {
    return thing[Symbol.asyncIterator] != null;
}

// Helper function to validate the chunk size against maxDataLength
function validateMaxDataLength(chunk, maxDataLength) {
    if (chunk.byteLength > maxDataLength) {
        throw new InvalidDataLengthError('Message length too long');
    }
}
const defaultEncoder = (length) => {
    const lengthLength = encodingLength$1(length);
    const lengthBuf = allocUnsafe(lengthLength);
    encode$8(length, lengthBuf);
    defaultEncoder.bytes = lengthLength;
    return lengthBuf;
};
defaultEncoder.bytes = 0;
function encode$1(source, options) {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    const maxDataLength = options?.maxDataLength ?? MAX_DATA_LENGTH;
    function* maybeYield(chunk) {
        validateMaxDataLength(chunk, maxDataLength);
        // length + data
        const length = encodeLength(chunk.byteLength);
        // yield only Uint8Arrays
        if (length instanceof Uint8Array) {
            yield length;
        }
        else {
            yield* length;
        }
        // yield only Uint8Arrays
        if (chunk instanceof Uint8Array) {
            yield chunk;
        }
        else {
            yield* chunk;
        }
    }
    if (isAsyncIterable(source)) {
        return (async function* () {
            for await (const chunk of source) {
                yield* maybeYield(chunk);
            }
        })();
    }
    return (function* () {
        for (const chunk of source) {
            yield* maybeYield(chunk);
        }
    })();
}
encode$1.single = (chunk, options) => {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    const maxDataLength = options?.maxDataLength ?? MAX_DATA_LENGTH;
    validateMaxDataLength(chunk, maxDataLength);
    return new Uint8ArrayList(encodeLength(chunk.byteLength), chunk);
};

/* eslint max-depth: ["error", 6] */
var ReadMode;
(function (ReadMode) {
    ReadMode[ReadMode["LENGTH"] = 0] = "LENGTH";
    ReadMode[ReadMode["DATA"] = 1] = "DATA";
})(ReadMode || (ReadMode = {}));

/**
 * Handle multistream protocol selections for the given list of protocols.
 *
 * Note that after a protocol is handled `listener` can no longer be used.
 *
 * @param stream - A duplex iterable stream to listen on
 * @param protocols - A list of protocols (or single protocol) that this listener is able to speak.
 * @param options - an options object containing an AbortSignal and an optional boolean `writeBytes` - if this is true, `Uint8Array`s will be written into `duplex`, otherwise `Uint8ArrayList`s will
 * @returns A stream for the selected protocol and the protocol that was selected from the list of protocols provided to `select`
 * @example
 *
 * ```TypeScript
 * import { pipe } from 'it-pipe'
 * import * as mss from '@libp2p/multistream-select'
 * import { Mplex } from '@libp2p/mplex'
 *
 * const muxer = new Mplex({
 *   async onStream (muxedStream) {
 *   // mss.handle(handledProtocols)
 *   // Returns selected stream and protocol
 *   const { stream, protocol } = await mss.handle(muxedStream, [
 *     '/ipfs-dht/1.0.0',
 *     '/ipfs-bitswap/1.0.0'
 *   ])
 *
 *   // Typically here we'd call the handler function that was registered in
 *   // libp2p for the given protocol:
 *   // e.g. handlers[protocol].handler(stream)
 *   //
 *   // If protocol was /ipfs-dht/1.0.0 it might do something like this:
 *   // try {
 *   //   await pipe(
 *   //     dhtStream,
 *   //     source => (async function * () {
 *   //       for await (const chunk of source)
 *   //         // Incoming DHT data -> process and yield to respond
 *   //     })(),
 *   //     dhtStream
 *   //   )
 *   // } catch (err) {
 *   //   // Error in stream
 *   // }
 *   }
 * })
 * ```
 */
async function handle(stream, protocols, options) {
    protocols = Array.isArray(protocols) ? protocols : [protocols];
    options.log.trace('handle: available protocols %s', protocols);
    const lp = lpStream(stream, {
        ...options,
        maxDataLength: MAX_PROTOCOL_LENGTH,
        maxLengthLength: 2 // 2 bytes is enough to length-prefix MAX_PROTOCOL_LENGTH
    });
    while (true) {
        options.log.trace('handle: reading incoming string');
        const protocol = await readString(lp, options);
        options.log.trace('handle: read "%s"', protocol);
        if (protocol === PROTOCOL_ID) {
            options.log.trace('handle: respond with "%s" for "%s"', PROTOCOL_ID, protocol);
            await write(lp, fromString(`${PROTOCOL_ID}\n`), options);
            options.log.trace('handle: responded with "%s" for "%s"', PROTOCOL_ID, protocol);
            continue;
        }
        if (protocols.includes(protocol)) {
            options.log.trace('handle: respond with "%s" for "%s"', protocol, protocol);
            await write(lp, fromString(`${protocol}\n`), options);
            options.log.trace('handle: responded with "%s" for "%s"', protocol, protocol);
            return { stream: lp.unwrap(), protocol };
        }
        if (protocol === 'ls') {
            // <varint-msg-len><varint-proto-name-len><proto-name>\n<varint-proto-name-len><proto-name>\n\n
            const protos = new Uint8ArrayList(...protocols.map(p => encode$1.single(fromString(`${p}\n`))), fromString('\n'));
            options.log.trace('handle: respond with "%s" for %s', protocols, protocol);
            await write(lp, protos, options);
            options.log.trace('handle: responded with "%s" for %s', protocols, protocol);
            continue;
        }
        options.log.trace('handle: respond with "na" for "%s"', protocol);
        await write(lp, fromString('na\n'), options);
        options.log('handle: responded with "na" for "%s"', protocol);
    }
}

const CLOSE_TIMEOUT = 500;
/**
 * An implementation of the js-libp2p connection.
 * Any libp2p transport should use an upgrader to return this connection.
 */
class ConnectionImpl {
    /**
     * Connection identifier.
     */
    id;
    /**
     * Observed multiaddr of the remote peer
     */
    remoteAddr;
    /**
     * Remote peer id
     */
    remotePeer;
    direction;
    timeline;
    multiplexer;
    encryption;
    status;
    limits;
    log;
    /**
     * User provided tags
     *
     */
    tags;
    /**
     * Reference to the new stream function of the multiplexer
     */
    _newStream;
    /**
     * Reference to the close function of the raw connection
     */
    _close;
    _abort;
    /**
     * Reference to the getStreams function of the muxer
     */
    _getStreams;
    /**
     * An implementation of the js-libp2p connection.
     * Any libp2p transport should use an upgrader to return this connection.
     */
    constructor(init) {
        const { remoteAddr, remotePeer, newStream, close, abort, getStreams } = init;
        this.id = `${(parseInt(String(Math.random() * 1e9))).toString(36)}${Date.now()}`;
        this.remoteAddr = remoteAddr;
        this.remotePeer = remotePeer;
        this.direction = init.direction;
        this.status = 'open';
        this.timeline = init.timeline;
        this.multiplexer = init.multiplexer;
        this.encryption = init.encryption;
        this.limits = init.limits;
        this.log = init.logger.forComponent(`libp2p:connection:${this.direction}:${this.id}`);
        if (this.remoteAddr.getPeerId() == null) {
            this.remoteAddr = this.remoteAddr.encapsulate(`/p2p/${this.remotePeer}`);
        }
        this._newStream = newStream;
        this._close = close;
        this._abort = abort;
        this._getStreams = getStreams;
        this.tags = [];
    }
    [Symbol.toStringTag] = 'Connection';
    [connectionSymbol] = true;
    /**
     * Get all the streams of the muxer
     */
    get streams() {
        return this._getStreams();
    }
    /**
     * Create a new stream from this connection
     */
    async newStream(protocols, options) {
        if (this.status === 'closing') {
            throw new ConnectionClosingError('the connection is being closed');
        }
        if (this.status === 'closed') {
            throw new ConnectionClosedError('the connection is closed');
        }
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        if (this.limits != null && options?.runOnLimitedConnection !== true) {
            throw new LimitedConnectionError('Cannot open protocol stream on limited connection');
        }
        const stream = await this._newStream(protocols, options);
        stream.direction = 'outbound';
        return stream;
    }
    /**
     * Close the connection
     */
    async close(options = {}) {
        if (this.status === 'closed' || this.status === 'closing') {
            return;
        }
        this.log('closing connection to %a', this.remoteAddr);
        this.status = 'closing';
        if (options.signal == null) {
            const signal = AbortSignal.timeout(CLOSE_TIMEOUT);
            options = {
                ...options,
                signal
            };
        }
        try {
            this.log.trace('closing underlying transport');
            // close raw connection
            await this._close(options);
            this.log.trace('updating timeline with close time');
            this.status = 'closed';
            this.timeline.close = Date.now();
        }
        catch (err) {
            this.log.error('error encountered during graceful close of connection to %a', this.remoteAddr, err);
            this.abort(err);
        }
    }
    abort(err) {
        if (this.status === 'closed') {
            return;
        }
        this.log.error('aborting connection to %a due to error', this.remoteAddr, err);
        this.status = 'closing';
        // Abort raw connection
        this._abort(err);
        this.status = 'closed';
        this.timeline.close = Date.now();
    }
}
function createConnection(init) {
    return new ConnectionImpl(init);
}

function findIncomingStreamLimit(protocol, registrar) {
    try {
        const { options } = registrar.getHandler(protocol);
        return options.maxInboundStreams;
    }
    catch (err) {
        if (err.name !== 'UnhandledProtocolError') {
            throw err;
        }
    }
    return DEFAULT_MAX_INBOUND_STREAMS;
}
function findOutgoingStreamLimit(protocol, registrar, options = {}) {
    try {
        const { options } = registrar.getHandler(protocol);
        if (options.maxOutboundStreams != null) {
            return options.maxOutboundStreams;
        }
    }
    catch (err) {
        if (err.name !== 'UnhandledProtocolError') {
            throw err;
        }
    }
    return options.maxOutboundStreams ?? DEFAULT_MAX_OUTBOUND_STREAMS;
}
function countStreams(protocol, direction, connection) {
    let streamCount = 0;
    connection.streams.forEach(stream => {
        if (stream.direction === direction && stream.protocol === protocol) {
            streamCount++;
        }
    });
    return streamCount;
}
class Upgrader {
    components;
    connectionEncrypters;
    streamMuxers;
    inboundUpgradeTimeout;
    inboundStreamProtocolNegotiationTimeout;
    outboundStreamProtocolNegotiationTimeout;
    events;
    metrics;
    constructor(components, init) {
        this.components = components;
        this.connectionEncrypters = trackedMap({
            name: 'libp2p_upgrader_connection_encrypters',
            metrics: this.components.metrics
        });
        init.connectionEncrypters.forEach(encrypter => {
            this.connectionEncrypters.set(encrypter.protocol, encrypter);
        });
        this.streamMuxers = trackedMap({
            name: 'libp2p_upgrader_stream_multiplexers',
            metrics: this.components.metrics
        });
        init.streamMuxers.forEach(muxer => {
            this.streamMuxers.set(muxer.protocol, muxer);
        });
        this.inboundUpgradeTimeout = init.inboundUpgradeTimeout ?? INBOUND_UPGRADE_TIMEOUT;
        this.inboundStreamProtocolNegotiationTimeout = init.inboundStreamProtocolNegotiationTimeout ?? PROTOCOL_NEGOTIATION_TIMEOUT;
        this.outboundStreamProtocolNegotiationTimeout = init.outboundStreamProtocolNegotiationTimeout ?? PROTOCOL_NEGOTIATION_TIMEOUT;
        this.events = components.events;
        this.metrics = {
            dials: components.metrics?.registerCounterGroup('libp2p_connection_manager_dials_total'),
            errors: components.metrics?.registerCounterGroup('libp2p_connection_manager_dial_errors_total'),
            inboundErrors: components.metrics?.registerCounterGroup('libp2p_connection_manager_dials_inbound_errors_total'),
            outboundErrors: components.metrics?.registerCounterGroup('libp2p_connection_manager_dials_outbound_errors_total')
        };
    }
    [Symbol.toStringTag] = '@libp2p/upgrader';
    async shouldBlockConnection(method, ...args) {
        const denyOperation = this.components.connectionGater[method];
        if (denyOperation == null) {
            return;
        }
        const result = await denyOperation.apply(this.components.connectionGater, args);
        if (result === true) {
            throw new ConnectionInterceptedError(`The multiaddr connection is blocked by gater.${method}`);
        }
    }
    createInboundAbortSignal(signal) {
        const output = anySignal([
            AbortSignal.timeout(this.inboundUpgradeTimeout),
            signal
        ]);
        return output;
    }
    /**
     * Upgrades an inbound connection
     */
    async upgradeInbound(maConn, opts) {
        let accepted = false;
        // always apply upgrade timeout for incoming upgrades
        const signal = this.createInboundAbortSignal(opts.signal);
        try {
            this.metrics.dials?.increment({
                inbound: true
            });
            accepted = await raceSignal(this.components.connectionManager.acceptIncomingConnection(maConn), signal);
            if (!accepted) {
                throw new ConnectionDeniedError('Connection denied');
            }
            await raceSignal(this.shouldBlockConnection('denyInboundConnection', maConn), signal);
            await this._performUpgrade(maConn, 'inbound', {
                ...opts,
                signal
            });
        }
        catch (err) {
            this.metrics.errors?.increment({
                inbound: true
            });
            this.metrics.inboundErrors?.increment({
                [err.name ?? 'Error']: true
            });
            throw err;
        }
        finally {
            signal.clear();
            if (accepted) {
                this.components.connectionManager.afterUpgradeInbound();
            }
        }
    }
    /**
     * Upgrades an outbound connection
     */
    async upgradeOutbound(maConn, opts) {
        try {
            this.metrics.dials?.increment({
                outbound: true
            });
            const idStr = maConn.remoteAddr.getPeerId();
            let remotePeerId;
            if (idStr != null) {
                remotePeerId = peerIdFromString$1(idStr);
                await raceSignal(this.shouldBlockConnection('denyOutboundConnection', remotePeerId, maConn), opts.signal);
            }
            let direction = 'outbound';
            // act as the multistream-select server if we are not to be the initiator
            if (opts.initiator === false) {
                direction = 'inbound';
            }
            return await this._performUpgrade(maConn, direction, opts);
        }
        catch (err) {
            this.metrics.errors?.increment({
                outbound: true
            });
            this.metrics.outboundErrors?.increment({
                [err.name ?? 'Error']: true
            });
            throw err;
        }
    }
    async _performUpgrade(maConn, direction, opts) {
        let encryptedConn;
        let remotePeer;
        let upgradedConn;
        let muxerFactory;
        let cryptoProtocol;
        this.components.metrics?.trackMultiaddrConnection(maConn);
        maConn.log.trace('starting the %s connection upgrade', direction);
        // Protect
        let protectedConn = maConn;
        if (opts?.skipProtection !== true) {
            const protector = this.components.connectionProtector;
            if (protector != null) {
                maConn.log('protecting the %s connection', direction);
                protectedConn = await protector.protect(maConn, opts);
            }
        }
        try {
            // Encrypt the connection
            encryptedConn = protectedConn;
            if (opts?.skipEncryption !== true) {
                opts?.onProgress?.(new CustomProgressEvent(`upgrader:encrypt-${direction}-connection`));
                ({
                    conn: encryptedConn,
                    remotePeer,
                    protocol: cryptoProtocol,
                    streamMuxer: muxerFactory
                } = await (direction === 'inbound'
                    ? this._encryptInbound(protectedConn, opts)
                    : this._encryptOutbound(protectedConn, opts)));
                const maConn = {
                    ...protectedConn,
                    ...encryptedConn
                };
                await this.shouldBlockConnection(direction === 'inbound' ? 'denyInboundEncryptedConnection' : 'denyOutboundEncryptedConnection', remotePeer, maConn);
            }
            else {
                const idStr = maConn.remoteAddr.getPeerId();
                if (idStr == null) {
                    throw new InvalidMultiaddrError$1(`${direction} connection that skipped encryption must have a peer id`);
                }
                const remotePeerId = peerIdFromString$1(idStr);
                cryptoProtocol = 'native';
                remotePeer = remotePeerId;
            }
            // this can happen if we dial a multiaddr without a peer id, we only find
            // out the identity of the remote after the connection is encrypted
            if (remotePeer.equals(this.components.peerId)) {
                const err = new InvalidPeerIdError('Can not dial self');
                maConn.abort(err);
                throw err;
            }
            upgradedConn = encryptedConn;
            if (opts?.muxerFactory != null) {
                muxerFactory = opts.muxerFactory;
            }
            else if (muxerFactory == null && this.streamMuxers.size > 0) {
                opts?.onProgress?.(new CustomProgressEvent(`upgrader:multiplex-${direction}-connection`));
                // Multiplex the connection
                const multiplexed = await (direction === 'inbound'
                    ? this._multiplexInbound({
                        ...protectedConn,
                        ...encryptedConn
                    }, this.streamMuxers, opts)
                    : this._multiplexOutbound({
                        ...protectedConn,
                        ...encryptedConn
                    }, this.streamMuxers, opts));
                muxerFactory = multiplexed.muxerFactory;
                upgradedConn = multiplexed.stream;
            }
        }
        catch (err) {
            maConn.log.error('failed to upgrade inbound connection %s %a - %e', direction === 'inbound' ? 'from' : 'to', maConn.remoteAddr, err);
            throw err;
        }
        await this.shouldBlockConnection(direction === 'inbound' ? 'denyInboundUpgradedConnection' : 'denyOutboundUpgradedConnection', remotePeer, maConn);
        maConn.log('successfully upgraded %s connection', direction);
        return this._createConnection({
            cryptoProtocol,
            direction,
            maConn,
            upgradedConn,
            muxerFactory,
            remotePeer,
            limits: opts?.limits
        });
    }
    /**
     * A convenience method for generating a new `Connection`
     */
    _createConnection(opts) {
        const { cryptoProtocol, direction, maConn, upgradedConn, remotePeer, muxerFactory, limits } = opts;
        let muxer;
        let newStream;
        let connection; // eslint-disable-line prefer-const
        if (muxerFactory != null) {
            // Create the muxer
            muxer = muxerFactory.createStreamMuxer({
                direction,
                // Run anytime a remote stream is created
                onIncomingStream: muxedStream => {
                    if (connection == null) {
                        return;
                    }
                    const signal = AbortSignal.timeout(this.inboundStreamProtocolNegotiationTimeout);
                    void Promise.resolve()
                        .then(async () => {
                        const protocols = this.components.registrar.getProtocols();
                        const { stream, protocol } = await handle(muxedStream, protocols, {
                            signal,
                            log: muxedStream.log,
                            yieldBytes: false
                        });
                        if (connection == null) {
                            return;
                        }
                        connection.log('incoming stream opened on %s', protocol);
                        const incomingLimit = findIncomingStreamLimit(protocol, this.components.registrar);
                        const streamCount = countStreams(protocol, 'inbound', connection);
                        if (streamCount === incomingLimit) {
                            const err = new TooManyInboundProtocolStreamsError(`Too many inbound protocol streams for protocol "${protocol}" - limit ${incomingLimit}`);
                            muxedStream.abort(err);
                            throw err;
                        }
                        // after the handshake the returned stream can have early data so override
                        // the source/sink
                        muxedStream.source = stream.source;
                        muxedStream.sink = stream.sink;
                        muxedStream.protocol = protocol;
                        // allow closing the write end of a not-yet-negotiated stream
                        if (stream.closeWrite != null) {
                            muxedStream.closeWrite = stream.closeWrite;
                        }
                        // allow closing the read end of a not-yet-negotiated stream
                        if (stream.closeRead != null) {
                            muxedStream.closeRead = stream.closeRead;
                        }
                        // make sure we don't try to negotiate a stream we are closing
                        if (stream.close != null) {
                            muxedStream.close = stream.close;
                        }
                        // If a protocol stream has been successfully negotiated and is to be passed to the application,
                        // the peer store should ensure that the peer is registered with that protocol
                        await this.components.peerStore.merge(remotePeer, {
                            protocols: [protocol]
                        }, {
                            signal
                        });
                        this.components.metrics?.trackProtocolStream(muxedStream, connection);
                        this._onStream({ connection, stream: muxedStream, protocol });
                    })
                        .catch(async (err) => {
                        connection.log.error('error handling incoming stream id %s - %e', muxedStream.id, err);
                        if (muxedStream.timeline.close == null) {
                            await muxedStream.close({
                                signal
                            })
                                .catch(err => muxedStream.abort(err));
                        }
                    });
                }
            });
            newStream = async (protocols, options = {}) => {
                if (muxer == null) {
                    throw new MuxerUnavailableError('Connection is not multiplexed');
                }
                connection.log.trace('starting new stream for protocols %s', protocols);
                const muxedStream = await muxer.newStream();
                connection.log.trace('started new stream %s for protocols %s', muxedStream.id, protocols);
                try {
                    if (options.signal == null) {
                        muxedStream.log('no abort signal was passed while trying to negotiate protocols %s falling back to default timeout', protocols);
                        const signal = AbortSignal.timeout(this.outboundStreamProtocolNegotiationTimeout);
                        setMaxListeners(Infinity, signal);
                        options = {
                            ...options,
                            signal
                        };
                    }
                    muxedStream.log.trace('selecting protocol from protocols %s', protocols);
                    const { stream, protocol } = await select(muxedStream, protocols, {
                        ...options,
                        log: muxedStream.log,
                        yieldBytes: true
                    });
                    muxedStream.log.trace('selected protocol %s', protocol);
                    const outgoingLimit = findOutgoingStreamLimit(protocol, this.components.registrar, options);
                    const streamCount = countStreams(protocol, 'outbound', connection);
                    if (streamCount >= outgoingLimit) {
                        const err = new TooManyOutboundProtocolStreamsError(`Too many outbound protocol streams for protocol "${protocol}" - ${streamCount}/${outgoingLimit}`);
                        muxedStream.abort(err);
                        throw err;
                    }
                    // If a protocol stream has been successfully negotiated and is to be passed to the application,
                    // the peer store should ensure that the peer is registered with that protocol
                    await this.components.peerStore.merge(remotePeer, {
                        protocols: [protocol]
                    });
                    // after the handshake the returned stream can have early data so override
                    // the source/sink
                    muxedStream.source = stream.source;
                    muxedStream.sink = stream.sink;
                    muxedStream.protocol = protocol;
                    // allow closing the write end of a not-yet-negotiated stream
                    if (stream.closeWrite != null) {
                        muxedStream.closeWrite = stream.closeWrite;
                    }
                    // allow closing the read end of a not-yet-negotiated stream
                    if (stream.closeRead != null) {
                        muxedStream.closeRead = stream.closeRead;
                    }
                    // make sure we don't try to negotiate a stream we are closing
                    if (stream.close != null) {
                        muxedStream.close = stream.close;
                    }
                    this.components.metrics?.trackProtocolStream(muxedStream, connection);
                    return muxedStream;
                }
                catch (err) {
                    connection.log.error('could not create new outbound stream on connection %s %a for protocols %s - %e', direction === 'inbound' ? 'from' : 'to', opts.maConn.remoteAddr, protocols, err);
                    if (muxedStream.timeline.close == null) {
                        muxedStream.abort(err);
                    }
                    throw err;
                }
            };
            // Pipe all data through the muxer
            void Promise.all([
                muxer.sink(upgradedConn.source),
                upgradedConn.sink(muxer.source)
            ]).catch(err => {
                connection.log.error('error piping data through muxer - %e', err);
            });
        }
        const _timeline = maConn.timeline;
        maConn.timeline = new Proxy(_timeline, {
            set: (...args) => {
                if (args[1] === 'close' && args[2] != null && _timeline.close == null) {
                    // Wait for close to finish before notifying of the closure
                    (async () => {
                        try {
                            if (connection.status === 'open') {
                                await connection.close();
                            }
                        }
                        catch (err) {
                            connection.log.error('error closing connection after timeline close %e', err);
                        }
                        finally {
                            this.events.safeDispatchEvent('connection:close', {
                                detail: connection
                            });
                        }
                    })().catch(err => {
                        connection.log.error('error thrown while dispatching connection:close event %e', err);
                    });
                }
                return Reflect.set(...args);
            }
        });
        maConn.timeline.upgraded = Date.now();
        const errConnectionNotMultiplexed = () => {
            throw new MuxerUnavailableError('Connection is not multiplexed');
        };
        // Create the connection
        connection = createConnection({
            remoteAddr: maConn.remoteAddr,
            remotePeer,
            status: 'open',
            direction,
            timeline: maConn.timeline,
            multiplexer: muxer?.protocol,
            encryption: cryptoProtocol,
            limits,
            logger: this.components.logger,
            newStream: newStream ?? errConnectionNotMultiplexed,
            getStreams: () => {
                return muxer?.streams ?? [];
            },
            close: async (options) => {
                // ensure remaining streams are closed gracefully
                await muxer?.close(options);
                // close the underlying transport
                await maConn.close(options);
            },
            abort: (err) => {
                maConn.abort(err);
                // ensure remaining streams are aborted
                muxer?.abort(err);
            }
        });
        this.events.safeDispatchEvent('connection:open', {
            detail: connection
        });
        // @ts-expect-error nah
        connection.__maConnTimeline = _timeline;
        return connection;
    }
    /**
     * Routes incoming streams to the correct handler
     */
    _onStream(opts) {
        const { connection, stream, protocol } = opts;
        const { handler, options } = this.components.registrar.getHandler(protocol);
        if (connection.limits != null && options.runOnLimitedConnection !== true) {
            throw new LimitedConnectionError('Cannot open protocol stream on limited connection');
        }
        handler({ connection, stream });
    }
    /**
     * Attempts to encrypt the incoming `connection` with the provided `cryptos`
     */
    async _encryptInbound(connection, options) {
        const protocols = Array.from(this.connectionEncrypters.keys());
        try {
            const { stream, protocol } = await handle(connection, protocols, {
                ...options,
                log: connection.log
            });
            const encrypter = this.connectionEncrypters.get(protocol);
            if (encrypter == null) {
                throw new EncryptionFailedError(`no crypto module found for ${protocol}`);
            }
            connection.log('encrypting inbound connection to %a using %s', connection.remoteAddr, protocol);
            return {
                ...await encrypter.secureInbound(stream, options),
                protocol
            };
        }
        catch (err) {
            connection.log.error('encrypting inbound connection from %a failed', connection.remoteAddr, err);
            throw new EncryptionFailedError(err.message);
        }
    }
    /**
     * Attempts to encrypt the given `connection` with the provided connection encrypters.
     * The first `ConnectionEncrypter` module to succeed will be used
     */
    async _encryptOutbound(connection, options) {
        const protocols = Array.from(this.connectionEncrypters.keys());
        try {
            connection.log.trace('selecting encrypter from %s', protocols);
            const { stream, protocol } = await select(connection, protocols, {
                ...options,
                log: connection.log,
                yieldBytes: true
            });
            const encrypter = this.connectionEncrypters.get(protocol);
            if (encrypter == null) {
                throw new EncryptionFailedError(`no crypto module found for ${protocol}`);
            }
            connection.log('encrypting outbound connection to %a using %s', connection.remoteAddr, protocol);
            return {
                ...await encrypter.secureOutbound(stream, options),
                protocol
            };
        }
        catch (err) {
            connection.log.error('encrypting outbound connection to %a failed', connection.remoteAddr, err);
            throw new EncryptionFailedError(err.message);
        }
    }
    /**
     * Selects one of the given muxers via multistream-select. That
     * muxer will be used for all future streams on the connection.
     */
    async _multiplexOutbound(connection, muxers, options) {
        const protocols = Array.from(muxers.keys());
        connection.log('outbound selecting muxer %s', protocols);
        try {
            connection.log.trace('selecting stream muxer from %s', protocols);
            const { stream, protocol } = await select(connection, protocols, {
                ...options,
                log: connection.log,
                yieldBytes: true
            });
            connection.log('selected %s as muxer protocol', protocol);
            const muxerFactory = muxers.get(protocol);
            return { stream, muxerFactory };
        }
        catch (err) {
            connection.log.error('error multiplexing outbound connection', err);
            throw new MuxerUnavailableError(String(err));
        }
    }
    /**
     * Registers support for one of the given muxers via multistream-select. The
     * selected muxer will be used for all future streams on the connection.
     */
    async _multiplexInbound(connection, muxers, options) {
        const protocols = Array.from(muxers.keys());
        connection.log('inbound handling muxers %s', protocols);
        try {
            const { stream, protocol } = await handle(connection, protocols, {
                ...options,
                log: connection.log
            });
            const muxerFactory = muxers.get(protocol);
            return { stream, muxerFactory };
        }
        catch (err) {
            connection.log.error('error multiplexing inbound connection', err);
            throw new MuxerUnavailableError(String(err));
        }
    }
    getConnectionEncrypters() {
        return this.connectionEncrypters;
    }
    getStreamMuxers() {
        return this.streamMuxers;
    }
}

const version$3 = '2.8.11';
const name = 'js-libp2p';

function userAgent(name$1, version) {
    return `${name$1 ?? name}/${version ?? version$3} browser/${globalThis.navigator.userAgent}`;
}

class Libp2p extends TypedEventEmitter {
    peerId;
    peerStore;
    contentRouting;
    peerRouting;
    metrics;
    services;
    logger;
    status;
    components;
    log;
    // eslint-disable-next-line complexity
    constructor(init) {
        super();
        this.status = 'stopped';
        // event bus - components can listen to this emitter to be notified of system events
        // and also cause them to be emitted
        const events = new TypedEventEmitter();
        const originalDispatch = events.dispatchEvent.bind(events);
        events.dispatchEvent = (evt) => {
            const internalResult = originalDispatch(evt);
            const externalResult = this.dispatchEvent(new CustomEvent(evt.type, { detail: evt.detail }));
            return internalResult || externalResult;
        };
        this.peerId = init.peerId;
        this.logger = init.logger ?? defaultLogger();
        this.log = this.logger.forComponent('libp2p');
        // @ts-expect-error {} may not be of type T
        this.services = {};
        const nodeInfoName = init.nodeInfo?.name ?? name;
        const nodeInfoVersion = init.nodeInfo?.version ?? version$3;
        // @ts-expect-error defaultComponents is missing component types added later
        const components = this.components = defaultComponents({
            peerId: init.peerId,
            privateKey: init.privateKey,
            nodeInfo: {
                name: nodeInfoName,
                version: nodeInfoVersion,
                userAgent: init.nodeInfo?.userAgent ?? userAgent(nodeInfoName, nodeInfoVersion)
            },
            logger: this.logger,
            events,
            datastore: init.datastore ?? new MemoryDatastore(),
            connectionGater: connectionGater(init.connectionGater),
            dns: init.dns
        });
        // Create Metrics
        if (init.metrics != null) {
            this.metrics = this.configureComponent('metrics', init.metrics(this.components));
        }
        this.peerStore = this.configureComponent('peerStore', persistentPeerStore(components, {
            addressFilter: this.components.connectionGater.filterMultiaddrForPeer,
            ...init.peerStore
        }));
        components.events.addEventListener('peer:update', evt => {
            // if there was no peer previously in the peer store this is a new peer
            if (evt.detail.previous == null) {
                const peerInfo = {
                    id: evt.detail.peer.id,
                    multiaddrs: evt.detail.peer.addresses.map(a => a.multiaddr)
                };
                components.events.safeDispatchEvent('peer:discovery', { detail: peerInfo });
            }
        });
        // Set up connection protector if configured
        if (init.connectionProtector != null) {
            this.configureComponent('connectionProtector', init.connectionProtector(components));
        }
        // Set up the Upgrader
        this.components.upgrader = new Upgrader(this.components, {
            connectionEncrypters: (init.connectionEncrypters ?? []).map((fn, index) => this.configureComponent(`connection-encryption-${index}`, fn(this.components))),
            streamMuxers: (init.streamMuxers ?? []).map((fn, index) => this.configureComponent(`stream-muxers-${index}`, fn(this.components))),
            inboundUpgradeTimeout: init.connectionManager?.inboundUpgradeTimeout,
            inboundStreamProtocolNegotiationTimeout: init.connectionManager?.inboundStreamProtocolNegotiationTimeout ?? init.connectionManager?.protocolNegotiationTimeout,
            outboundStreamProtocolNegotiationTimeout: init.connectionManager?.outboundStreamProtocolNegotiationTimeout ?? init.connectionManager?.protocolNegotiationTimeout
        });
        // Setup the transport manager
        this.configureComponent('transportManager', new DefaultTransportManager(this.components, init.transportManager));
        // Create the Connection Manager
        this.configureComponent('connectionManager', new DefaultConnectionManager(this.components, init.connectionManager));
        if (init.connectionMonitor?.enabled !== false) {
            // Create the Connection Monitor if not disabled
            this.configureComponent('connectionMonitor', new ConnectionMonitor(this.components, init.connectionMonitor));
        }
        // Create the Registrar
        this.configureComponent('registrar', new Registrar(this.components));
        // Addresses {listen, announce, noAnnounce}
        this.configureComponent('addressManager', new AddressManager(this.components, init.addresses));
        // Peer routers
        const peerRouters = (init.peerRouters ?? []).map((fn, index) => this.configureComponent(`peer-router-${index}`, fn(this.components)));
        this.peerRouting = this.components.peerRouting = this.configureComponent('peerRouting', new DefaultPeerRouting(this.components, {
            routers: peerRouters
        }));
        // Content routers
        const contentRouters = (init.contentRouters ?? []).map((fn, index) => this.configureComponent(`content-router-${index}`, fn(this.components)));
        this.contentRouting = this.components.contentRouting = this.configureComponent('contentRouting', new CompoundContentRouting(this.components, {
            routers: contentRouters
        }));
        // Random walk
        this.configureComponent('randomWalk', new RandomWalk(this.components));
        (init.peerDiscovery ?? []).forEach((fn, index) => {
            const service = this.configureComponent(`peer-discovery-${index}`, fn(this.components));
            service.addEventListener('peer', (evt) => {
                this.#onDiscoveryPeer(evt);
            });
        });
        // Transport modules
        init.transports?.forEach((fn, index) => {
            this.components.transportManager.add(this.configureComponent(`transport-${index}`, fn(this.components)));
        });
        // User defined modules
        if (init.services != null) {
            for (const name of Object.keys(init.services)) {
                const createService = init.services[name];
                const service = createService(this.components);
                if (service == null) {
                    this.log.error('service factory %s returned null or undefined instance', name);
                    continue;
                }
                this.services[name] = service;
                this.configureComponent(name, service);
                if (service[contentRoutingSymbol] != null) {
                    this.log('registering service %s for content routing', name);
                    contentRouters.push(service[contentRoutingSymbol]);
                }
                if (service[peerRoutingSymbol] != null) {
                    this.log('registering service %s for peer routing', name);
                    peerRouters.push(service[peerRoutingSymbol]);
                }
                if (service[peerDiscoverySymbol] != null) {
                    this.log('registering service %s for peer discovery', name);
                    service[peerDiscoverySymbol].addEventListener?.('peer', (evt) => {
                        this.#onDiscoveryPeer(evt);
                    });
                }
            }
        }
        // Ensure all services have their required dependencies
        checkServiceDependencies(components);
    }
    configureComponent(name, component) {
        if (component == null) {
            this.log.error('component %s was null or undefined', name);
        }
        // @ts-expect-error cannot assign props
        this.components[name] = component;
        return component;
    }
    /**
     * Starts the libp2p node and all its subsystems
     */
    async start() {
        if (this.status !== 'stopped') {
            return;
        }
        this.status = 'starting';
        this.log('libp2p is starting');
        try {
            await this.components.beforeStart?.();
            await this.components.start();
            await this.components.afterStart?.();
            this.status = 'started';
            this.safeDispatchEvent('start', { detail: this });
            this.log('libp2p has started');
        }
        catch (err) {
            this.log.error('An error occurred starting libp2p', err);
            // set status to 'started' so this.stop() will stop any running components
            this.status = 'started';
            await this.stop();
            throw err;
        }
    }
    /**
     * Stop the libp2p node by closing its listeners and open connections
     */
    async stop() {
        if (this.status !== 'started') {
            return;
        }
        this.log('libp2p is stopping');
        this.status = 'stopping';
        await this.components.beforeStop?.();
        await this.components.stop();
        await this.components.afterStop?.();
        this.status = 'stopped';
        this.safeDispatchEvent('stop', { detail: this });
        this.log('libp2p has stopped');
    }
    getConnections(peerId) {
        return this.components.connectionManager.getConnections(peerId);
    }
    getDialQueue() {
        return this.components.connectionManager.getDialQueue();
    }
    getPeers() {
        const peerSet = new PeerSet();
        for (const conn of this.components.connectionManager.getConnections()) {
            peerSet.add(conn.remotePeer);
        }
        return Array.from(peerSet);
    }
    async dial(peer, options = {}) {
        return this.components.connectionManager.openConnection(peer, {
            // ensure any userland dials take top priority in the queue
            priority: 75,
            ...options
        });
    }
    async dialProtocol(peer, protocols, options = {}) {
        if (protocols == null) {
            throw new InvalidParametersError$1('no protocols were provided to open a stream');
        }
        protocols = Array.isArray(protocols) ? protocols : [protocols];
        if (protocols.length === 0) {
            throw new InvalidParametersError$1('no protocols were provided to open a stream');
        }
        const connection = await this.dial(peer, options);
        return connection.newStream(protocols, options);
    }
    getMultiaddrs() {
        return this.components.addressManager.getAddresses();
    }
    getProtocols() {
        return this.components.registrar.getProtocols();
    }
    async hangUp(peer, options = {}) {
        if (isMultiaddr(peer)) {
            peer = peerIdFromString$1(peer.getPeerId() ?? '');
        }
        await this.components.connectionManager.closeConnections(peer, options);
    }
    async getPublicKey(peer, options = {}) {
        this.log('getPublicKey %p', peer);
        if (peer.publicKey != null) {
            return peer.publicKey;
        }
        try {
            const peerInfo = await this.peerStore.get(peer, options);
            if (peerInfo.id.publicKey != null) {
                return peerInfo.id.publicKey;
            }
        }
        catch (err) {
            if (err.name !== 'NotFoundError') {
                throw err;
            }
        }
        const peerKey = concat([
            fromString('/pk/'),
            peer.toMultihash().bytes
        ]);
        // search any available content routing methods
        const bytes = await this.contentRouting.get(peerKey, options);
        // ensure the returned key is valid
        const publicKey = publicKeyFromProtobuf(bytes);
        await this.peerStore.patch(peer, {
            publicKey
        }, options);
        return publicKey;
    }
    async handle(protocols, handler, options) {
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        await Promise.all(protocols.map(async (protocol) => {
            await this.components.registrar.handle(protocol, handler, options);
        }));
    }
    async unhandle(protocols, options) {
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        await Promise.all(protocols.map(async (protocol) => {
            await this.components.registrar.unhandle(protocol, options);
        }));
    }
    async register(protocol, topology, options) {
        return this.components.registrar.register(protocol, topology, options);
    }
    unregister(id) {
        this.components.registrar.unregister(id);
    }
    async isDialable(multiaddr, options = {}) {
        return this.components.connectionManager.isDialable(multiaddr, options);
    }
    /**
     * Called whenever peer discovery services emit `peer` events and adds peers
     * to the peer store.
     */
    #onDiscoveryPeer(evt) {
        const { detail: peer } = evt;
        if (peer.id.toString() === this.peerId.toString()) {
            this.log.error('peer discovery mechanism discovered self');
            return;
        }
        void this.components.peerStore.merge(peer.id, {
            multiaddrs: peer.multiaddrs
        })
            .catch(err => { this.log.error(err); });
    }
}

/**
 * @packageDocumentation
 *
 * Use the `createLibp2p` function to create a libp2p node.
 *
 * @example
 *
 * ```typescript
 * import { createLibp2p } from 'libp2p'
 *
 * const node = await createLibp2p({
 *   // ...other options
 * })
 * ```
 */
/**
 * Returns a new instance of the Libp2p interface, generating a new PeerId
 * if one is not passed as part of the options.
 *
 * The node will be started unless `start: false` is passed as an option.
 *
 * @example
 *
 * ```TypeScript
 * import { createLibp2p } from 'libp2p'
 * import { tcp } from '@libp2p/tcp'
 * import { mplex } from '@libp2p/mplex'
 * import { noise } from '@chainsafe/libp2p-noise'
 * import { yamux } from '@chainsafe/libp2p-yamux'
 *
 * // specify options
 * const options = {
 *   transports: [tcp()],
 *   streamMuxers: [yamux(), mplex()],
 *   connectionEncrypters: [noise()]
 * }
 *
 * // create libp2p
 * const libp2p = await createLibp2p(options)
 * ```
 */
async function createLibp2p(options = {}) {
    options.privateKey ??= await generateKeyPair();
    const node = new Libp2p({
        ...await validateConfig(options),
        peerId: peerIdFromPrivateKey(options.privateKey)
    });
    if (options.start !== false) {
        await node.start();
    }
    return node;
}

function isTestEnvironment() {
    try {
        return "production" === "test";
    }
    catch (_e) {
        // process variable is not defined in PROD environment
        return false;
    }
}

/**
 * The ENR tree for the different fleets.
 * SANDBOX and TEST fleets are for The Waku Network.
 */
const enrTree = {
    SANDBOX: "enrtree://AIRVQ5DDA4FFWLRBCHJWUWOO6X6S4ZTZ5B667LQ6AJU6PEYDLRD5O@sandbox.waku.nodes.status.im",
    TEST: "enrtree://AOGYWMBYOUIMOENHXCHILPKY3ZRFEULMFI4DOM442QSZ73TT2A7VI@test.waku.nodes.status.im"
};
const DEFAULT_BOOTSTRAP_TAG_NAME = Tags.BOOTSTRAP;
const DEFAULT_BOOTSTRAP_TAG_VALUE = 50;
const DEFAULT_BOOTSTRAP_TAG_TTL = 100_000_000;
const DEFAULT_NODE_REQUIREMENTS = {
    store: 1,
    filter: 2,
    lightPush: 2
};

// Maximum encoded size of an ENR
const ERR_INVALID_ID = "Invalid record id";
// The maximum length of byte size of a multiaddr to encode in the `multiaddr` field
// The size is a big endian 16-bit unsigned integer
const MULTIADDR_LENGTH_SIZE = 2;

var _nodeResolve_empty = {};

var nodeCrypto = /*#__PURE__*/Object.freeze({
    __proto__: null,
    default: _nodeResolve_empty
});

/*! noble-secp256k1 - MIT License (c) 2019 Paul Miller (paulmillr.com) */
const _0n = BigInt(0);
const _1n = BigInt(1);
const _2n = BigInt(2);
const _3n = BigInt(3);
const _8n = BigInt(8);
const CURVE = Object.freeze({
    a: _0n,
    b: BigInt(7),
    P: BigInt('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f'),
    n: BigInt('0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141'),
    h: _1n,
    Gx: BigInt('55066263022277343669578718895168534326250603453777594175500187360389116729240'),
    Gy: BigInt('32670510020758816978083085130507043184471273380659243275938904335757337482424'),
    beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
});
const divNearest = (a, b) => (a + b / _2n) / b;
const endo = {
    beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
    splitScalar(k) {
        const { n } = CURVE;
        const a1 = BigInt('0x3086d221a7d46bcde86c90e49284eb15');
        const b1 = -_1n * BigInt('0xe4437ed6010e88286f547fa90abfe4c3');
        const a2 = BigInt('0x114ca50f7a8e2f3f657c1108d9d44cfd8');
        const b2 = a1;
        const POW_2_128 = BigInt('0x100000000000000000000000000000000');
        const c1 = divNearest(b2 * k, n);
        const c2 = divNearest(-b1 * k, n);
        let k1 = mod(k - c1 * a1 - c2 * a2, n);
        let k2 = mod(-c1 * b1 - c2 * b2, n);
        const k1neg = k1 > POW_2_128;
        const k2neg = k2 > POW_2_128;
        if (k1neg)
            k1 = n - k1;
        if (k2neg)
            k2 = n - k2;
        if (k1 > POW_2_128 || k2 > POW_2_128) {
            throw new Error('splitScalarEndo: Endomorphism failed, k=' + k);
        }
        return { k1neg, k1, k2neg, k2 };
    },
};
const fieldLen = 32;
const groupLen = 32;
const hashLen = 32;
const compressedLen = fieldLen + 1;
const uncompressedLen = 2 * fieldLen + 1;
function weierstrass(x) {
    const { a, b } = CURVE;
    const x2 = mod(x * x);
    const x3 = mod(x2 * x);
    return mod(x3 + a * x + b);
}
const USE_ENDOMORPHISM = CURVE.a === _0n;
class ShaError extends Error {
    constructor(message) {
        super(message);
    }
}
function assertJacPoint(other) {
    if (!(other instanceof JacobianPoint))
        throw new TypeError('JacobianPoint expected');
}
class JacobianPoint {
    constructor(x, y, z) {
        this.x = x;
        this.y = y;
        this.z = z;
    }
    static fromAffine(p) {
        if (!(p instanceof Point)) {
            throw new TypeError('JacobianPoint#fromAffine: expected Point');
        }
        if (p.equals(Point.ZERO))
            return JacobianPoint.ZERO;
        return new JacobianPoint(p.x, p.y, _1n);
    }
    static toAffineBatch(points) {
        const toInv = invertBatch(points.map((p) => p.z));
        return points.map((p, i) => p.toAffine(toInv[i]));
    }
    static normalizeZ(points) {
        return JacobianPoint.toAffineBatch(points).map(JacobianPoint.fromAffine);
    }
    equals(other) {
        assertJacPoint(other);
        const { x: X1, y: Y1, z: Z1 } = this;
        const { x: X2, y: Y2, z: Z2 } = other;
        const Z1Z1 = mod(Z1 * Z1);
        const Z2Z2 = mod(Z2 * Z2);
        const U1 = mod(X1 * Z2Z2);
        const U2 = mod(X2 * Z1Z1);
        const S1 = mod(mod(Y1 * Z2) * Z2Z2);
        const S2 = mod(mod(Y2 * Z1) * Z1Z1);
        return U1 === U2 && S1 === S2;
    }
    negate() {
        return new JacobianPoint(this.x, mod(-this.y), this.z);
    }
    double() {
        const { x: X1, y: Y1, z: Z1 } = this;
        const A = mod(X1 * X1);
        const B = mod(Y1 * Y1);
        const C = mod(B * B);
        const x1b = X1 + B;
        const D = mod(_2n * (mod(x1b * x1b) - A - C));
        const E = mod(_3n * A);
        const F = mod(E * E);
        const X3 = mod(F - _2n * D);
        const Y3 = mod(E * (D - X3) - _8n * C);
        const Z3 = mod(_2n * Y1 * Z1);
        return new JacobianPoint(X3, Y3, Z3);
    }
    add(other) {
        assertJacPoint(other);
        const { x: X1, y: Y1, z: Z1 } = this;
        const { x: X2, y: Y2, z: Z2 } = other;
        if (X2 === _0n || Y2 === _0n)
            return this;
        if (X1 === _0n || Y1 === _0n)
            return other;
        const Z1Z1 = mod(Z1 * Z1);
        const Z2Z2 = mod(Z2 * Z2);
        const U1 = mod(X1 * Z2Z2);
        const U2 = mod(X2 * Z1Z1);
        const S1 = mod(mod(Y1 * Z2) * Z2Z2);
        const S2 = mod(mod(Y2 * Z1) * Z1Z1);
        const H = mod(U2 - U1);
        const r = mod(S2 - S1);
        if (H === _0n) {
            if (r === _0n) {
                return this.double();
            }
            else {
                return JacobianPoint.ZERO;
            }
        }
        const HH = mod(H * H);
        const HHH = mod(H * HH);
        const V = mod(U1 * HH);
        const X3 = mod(r * r - HHH - _2n * V);
        const Y3 = mod(r * (V - X3) - S1 * HHH);
        const Z3 = mod(Z1 * Z2 * H);
        return new JacobianPoint(X3, Y3, Z3);
    }
    subtract(other) {
        return this.add(other.negate());
    }
    multiplyUnsafe(scalar) {
        const P0 = JacobianPoint.ZERO;
        if (typeof scalar === 'bigint' && scalar === _0n)
            return P0;
        let n = normalizeScalar(scalar);
        if (n === _1n)
            return this;
        if (!USE_ENDOMORPHISM) {
            let p = P0;
            let d = this;
            while (n > _0n) {
                if (n & _1n)
                    p = p.add(d);
                d = d.double();
                n >>= _1n;
            }
            return p;
        }
        let { k1neg, k1, k2neg, k2 } = endo.splitScalar(n);
        let k1p = P0;
        let k2p = P0;
        let d = this;
        while (k1 > _0n || k2 > _0n) {
            if (k1 & _1n)
                k1p = k1p.add(d);
            if (k2 & _1n)
                k2p = k2p.add(d);
            d = d.double();
            k1 >>= _1n;
            k2 >>= _1n;
        }
        if (k1neg)
            k1p = k1p.negate();
        if (k2neg)
            k2p = k2p.negate();
        k2p = new JacobianPoint(mod(k2p.x * endo.beta), k2p.y, k2p.z);
        return k1p.add(k2p);
    }
    precomputeWindow(W) {
        const windows = USE_ENDOMORPHISM ? 128 / W + 1 : 256 / W + 1;
        const points = [];
        let p = this;
        let base = p;
        for (let window = 0; window < windows; window++) {
            base = p;
            points.push(base);
            for (let i = 1; i < 2 ** (W - 1); i++) {
                base = base.add(p);
                points.push(base);
            }
            p = base.double();
        }
        return points;
    }
    wNAF(n, affinePoint) {
        if (!affinePoint && this.equals(JacobianPoint.BASE))
            affinePoint = Point.BASE;
        const W = (affinePoint && affinePoint._WINDOW_SIZE) || 1;
        if (256 % W) {
            throw new Error('Point#wNAF: Invalid precomputation window, must be power of 2');
        }
        let precomputes = affinePoint && pointPrecomputes.get(affinePoint);
        if (!precomputes) {
            precomputes = this.precomputeWindow(W);
            if (affinePoint && W !== 1) {
                precomputes = JacobianPoint.normalizeZ(precomputes);
                pointPrecomputes.set(affinePoint, precomputes);
            }
        }
        let p = JacobianPoint.ZERO;
        let f = JacobianPoint.BASE;
        const windows = 1 + (USE_ENDOMORPHISM ? 128 / W : 256 / W);
        const windowSize = 2 ** (W - 1);
        const mask = BigInt(2 ** W - 1);
        const maxNumber = 2 ** W;
        const shiftBy = BigInt(W);
        for (let window = 0; window < windows; window++) {
            const offset = window * windowSize;
            let wbits = Number(n & mask);
            n >>= shiftBy;
            if (wbits > windowSize) {
                wbits -= maxNumber;
                n += _1n;
            }
            const offset1 = offset;
            const offset2 = offset + Math.abs(wbits) - 1;
            const cond1 = window % 2 !== 0;
            const cond2 = wbits < 0;
            if (wbits === 0) {
                f = f.add(constTimeNegate(cond1, precomputes[offset1]));
            }
            else {
                p = p.add(constTimeNegate(cond2, precomputes[offset2]));
            }
        }
        return { p, f };
    }
    multiply(scalar, affinePoint) {
        let n = normalizeScalar(scalar);
        let point;
        let fake;
        if (USE_ENDOMORPHISM) {
            const { k1neg, k1, k2neg, k2 } = endo.splitScalar(n);
            let { p: k1p, f: f1p } = this.wNAF(k1, affinePoint);
            let { p: k2p, f: f2p } = this.wNAF(k2, affinePoint);
            k1p = constTimeNegate(k1neg, k1p);
            k2p = constTimeNegate(k2neg, k2p);
            k2p = new JacobianPoint(mod(k2p.x * endo.beta), k2p.y, k2p.z);
            point = k1p.add(k2p);
            fake = f1p.add(f2p);
        }
        else {
            const { p, f } = this.wNAF(n, affinePoint);
            point = p;
            fake = f;
        }
        return JacobianPoint.normalizeZ([point, fake])[0];
    }
    toAffine(invZ) {
        const { x, y, z } = this;
        const is0 = this.equals(JacobianPoint.ZERO);
        if (invZ == null)
            invZ = is0 ? _8n : invert(z);
        const iz1 = invZ;
        const iz2 = mod(iz1 * iz1);
        const iz3 = mod(iz2 * iz1);
        const ax = mod(x * iz2);
        const ay = mod(y * iz3);
        const zz = mod(z * iz1);
        if (is0)
            return Point.ZERO;
        if (zz !== _1n)
            throw new Error('invZ was invalid');
        return new Point(ax, ay);
    }
}
JacobianPoint.BASE = new JacobianPoint(CURVE.Gx, CURVE.Gy, _1n);
JacobianPoint.ZERO = new JacobianPoint(_0n, _1n, _0n);
function constTimeNegate(condition, item) {
    const neg = item.negate();
    return condition ? neg : item;
}
const pointPrecomputes = new WeakMap();
class Point {
    constructor(x, y) {
        this.x = x;
        this.y = y;
    }
    _setWindowSize(windowSize) {
        this._WINDOW_SIZE = windowSize;
        pointPrecomputes.delete(this);
    }
    hasEvenY() {
        return this.y % _2n === _0n;
    }
    static fromCompressedHex(bytes) {
        const isShort = bytes.length === 32;
        const x = bytesToNumber(isShort ? bytes : bytes.subarray(1));
        if (!isValidFieldElement(x))
            throw new Error('Point is not on curve');
        const y2 = weierstrass(x);
        let y = sqrtMod(y2);
        const isYOdd = (y & _1n) === _1n;
        if (isShort) {
            if (isYOdd)
                y = mod(-y);
        }
        else {
            const isFirstByteOdd = (bytes[0] & 1) === 1;
            if (isFirstByteOdd !== isYOdd)
                y = mod(-y);
        }
        const point = new Point(x, y);
        point.assertValidity();
        return point;
    }
    static fromUncompressedHex(bytes) {
        const x = bytesToNumber(bytes.subarray(1, fieldLen + 1));
        const y = bytesToNumber(bytes.subarray(fieldLen + 1, fieldLen * 2 + 1));
        const point = new Point(x, y);
        point.assertValidity();
        return point;
    }
    static fromHex(hex) {
        const bytes = ensureBytes(hex);
        const len = bytes.length;
        const header = bytes[0];
        if (len === fieldLen)
            return this.fromCompressedHex(bytes);
        if (len === compressedLen && (header === 0x02 || header === 0x03)) {
            return this.fromCompressedHex(bytes);
        }
        if (len === uncompressedLen && header === 0x04)
            return this.fromUncompressedHex(bytes);
        throw new Error(`Point.fromHex: received invalid point. Expected 32-${compressedLen} compressed bytes or ${uncompressedLen} uncompressed bytes, not ${len}`);
    }
    static fromPrivateKey(privateKey) {
        return Point.BASE.multiply(normalizePrivateKey(privateKey));
    }
    static fromSignature(msgHash, signature, recovery) {
        const { r, s } = normalizeSignature(signature);
        if (![0, 1, 2, 3].includes(recovery))
            throw new Error('Cannot recover: invalid recovery bit');
        const h = truncateHash(ensureBytes(msgHash));
        const { n } = CURVE;
        const radj = recovery === 2 || recovery === 3 ? r + n : r;
        const rinv = invert(radj, n);
        const u1 = mod(-h * rinv, n);
        const u2 = mod(s * rinv, n);
        const prefix = recovery & 1 ? '03' : '02';
        const R = Point.fromHex(prefix + numTo32bStr(radj));
        const Q = Point.BASE.multiplyAndAddUnsafe(R, u1, u2);
        if (!Q)
            throw new Error('Cannot recover signature: point at infinify');
        Q.assertValidity();
        return Q;
    }
    toRawBytes(isCompressed = false) {
        return hexToBytes(this.toHex(isCompressed));
    }
    toHex(isCompressed = false) {
        const x = numTo32bStr(this.x);
        if (isCompressed) {
            const prefix = this.hasEvenY() ? '02' : '03';
            return `${prefix}${x}`;
        }
        else {
            return `04${x}${numTo32bStr(this.y)}`;
        }
    }
    toHexX() {
        return this.toHex(true).slice(2);
    }
    toRawX() {
        return this.toRawBytes(true).slice(1);
    }
    assertValidity() {
        const msg = 'Point is not on elliptic curve';
        const { x, y } = this;
        if (!isValidFieldElement(x) || !isValidFieldElement(y))
            throw new Error(msg);
        const left = mod(y * y);
        const right = weierstrass(x);
        if (mod(left - right) !== _0n)
            throw new Error(msg);
    }
    equals(other) {
        return this.x === other.x && this.y === other.y;
    }
    negate() {
        return new Point(this.x, mod(-this.y));
    }
    double() {
        return JacobianPoint.fromAffine(this).double().toAffine();
    }
    add(other) {
        return JacobianPoint.fromAffine(this).add(JacobianPoint.fromAffine(other)).toAffine();
    }
    subtract(other) {
        return this.add(other.negate());
    }
    multiply(scalar) {
        return JacobianPoint.fromAffine(this).multiply(scalar, this).toAffine();
    }
    multiplyAndAddUnsafe(Q, a, b) {
        const P = JacobianPoint.fromAffine(this);
        const aP = a === _0n || a === _1n || this !== Point.BASE ? P.multiplyUnsafe(a) : P.multiply(a);
        const bQ = JacobianPoint.fromAffine(Q).multiplyUnsafe(b);
        const sum = aP.add(bQ);
        return sum.equals(JacobianPoint.ZERO) ? undefined : sum.toAffine();
    }
}
Point.BASE = new Point(CURVE.Gx, CURVE.Gy);
Point.ZERO = new Point(_0n, _0n);
function sliceDER(s) {
    return Number.parseInt(s[0], 16) >= 8 ? '00' + s : s;
}
function parseDERInt(data) {
    if (data.length < 2 || data[0] !== 0x02) {
        throw new Error(`Invalid signature integer tag: ${bytesToHex(data)}`);
    }
    const len = data[1];
    const res = data.subarray(2, len + 2);
    if (!len || res.length !== len) {
        throw new Error(`Invalid signature integer: wrong length`);
    }
    if (res[0] === 0x00 && res[1] <= 0x7f) {
        throw new Error('Invalid signature integer: trailing length');
    }
    return { data: bytesToNumber(res), left: data.subarray(len + 2) };
}
function parseDERSignature(data) {
    if (data.length < 2 || data[0] != 0x30) {
        throw new Error(`Invalid signature tag: ${bytesToHex(data)}`);
    }
    if (data[1] !== data.length - 2) {
        throw new Error('Invalid signature: incorrect length');
    }
    const { data: r, left: sBytes } = parseDERInt(data.subarray(2));
    const { data: s, left: rBytesLeft } = parseDERInt(sBytes);
    if (rBytesLeft.length) {
        throw new Error(`Invalid signature: left bytes after parsing: ${bytesToHex(rBytesLeft)}`);
    }
    return { r, s };
}
class Signature {
    constructor(r, s) {
        this.r = r;
        this.s = s;
        this.assertValidity();
    }
    static fromCompact(hex) {
        const arr = isBytes$1(hex);
        const name = 'Signature.fromCompact';
        if (typeof hex !== 'string' && !arr)
            throw new TypeError(`${name}: Expected string or Uint8Array`);
        const str = arr ? bytesToHex(hex) : hex;
        if (str.length !== 128)
            throw new Error(`${name}: Expected 64-byte hex`);
        return new Signature(hexToNumber(str.slice(0, 64)), hexToNumber(str.slice(64, 128)));
    }
    static fromDER(hex) {
        const arr = isBytes$1(hex);
        if (typeof hex !== 'string' && !arr)
            throw new TypeError(`Signature.fromDER: Expected string or Uint8Array`);
        const { r, s } = parseDERSignature(arr ? hex : hexToBytes(hex));
        return new Signature(r, s);
    }
    static fromHex(hex) {
        return this.fromDER(hex);
    }
    assertValidity() {
        const { r, s } = this;
        if (!isWithinCurveOrder(r))
            throw new Error('Invalid Signature: r must be 0 < r < n');
        if (!isWithinCurveOrder(s))
            throw new Error('Invalid Signature: s must be 0 < s < n');
    }
    hasHighS() {
        const HALF = CURVE.n >> _1n;
        return this.s > HALF;
    }
    normalizeS() {
        return this.hasHighS() ? new Signature(this.r, mod(-this.s, CURVE.n)) : this;
    }
    toDERRawBytes() {
        return hexToBytes(this.toDERHex());
    }
    toDERHex() {
        const sHex = sliceDER(numberToHexUnpadded(this.s));
        const rHex = sliceDER(numberToHexUnpadded(this.r));
        const sHexL = sHex.length / 2;
        const rHexL = rHex.length / 2;
        const sLen = numberToHexUnpadded(sHexL);
        const rLen = numberToHexUnpadded(rHexL);
        const length = numberToHexUnpadded(rHexL + sHexL + 4);
        return `30${length}02${rLen}${rHex}02${sLen}${sHex}`;
    }
    toRawBytes() {
        return this.toDERRawBytes();
    }
    toHex() {
        return this.toDERHex();
    }
    toCompactRawBytes() {
        return hexToBytes(this.toCompactHex());
    }
    toCompactHex() {
        return numTo32bStr(this.r) + numTo32bStr(this.s);
    }
}
function isBytes$1(a) {
    return a instanceof Uint8Array || (ArrayBuffer.isView(a) && a.constructor.name === 'Uint8Array');
}
function abytes(item) {
    if (!isBytes$1(item))
        throw new Error('Uint8Array expected');
}
function concatBytes(...arrays) {
    arrays.every(abytes);
    if (arrays.length === 1)
        return arrays[0];
    const length = arrays.reduce((a, arr) => a + arr.length, 0);
    const result = new Uint8Array(length);
    for (let i = 0, pad = 0; i < arrays.length; i++) {
        const arr = arrays[i];
        result.set(arr, pad);
        pad += arr.length;
    }
    return result;
}
const hexes = Array.from({ length: 256 }, (_, i) => i.toString(16).padStart(2, '0'));
function bytesToHex(bytes) {
    abytes(bytes);
    let hex = '';
    for (let i = 0; i < bytes.length; i++) {
        hex += hexes[bytes[i]];
    }
    return hex;
}
const asciis = { _0: 48, _9: 57, A: 65, F: 70, a: 97, f: 102 };
function asciiToBase16(ch) {
    if (ch >= asciis._0 && ch <= asciis._9)
        return ch - asciis._0;
    if (ch >= asciis.A && ch <= asciis.F)
        return ch - (asciis.A - 10);
    if (ch >= asciis.a && ch <= asciis.f)
        return ch - (asciis.a - 10);
    return;
}
function hexToBytes(hex) {
    if (typeof hex !== 'string')
        throw new Error('hex string expected, got ' + typeof hex);
    const hl = hex.length;
    const al = hl / 2;
    if (hl % 2)
        throw new Error('hex string expected, got unpadded hex of length ' + hl);
    const array = new Uint8Array(al);
    for (let ai = 0, hi = 0; ai < al; ai++, hi += 2) {
        const n1 = asciiToBase16(hex.charCodeAt(hi));
        const n2 = asciiToBase16(hex.charCodeAt(hi + 1));
        if (n1 === undefined || n2 === undefined) {
            const char = hex[hi] + hex[hi + 1];
            throw new Error('hex string expected, got non-hex character "' + char + '" at index ' + hi);
        }
        array[ai] = n1 * 16 + n2;
    }
    return array;
}
const POW_2_256 = BigInt('0x10000000000000000000000000000000000000000000000000000000000000000');
function numTo32bStr(num) {
    if (typeof num !== 'bigint')
        throw new Error('Expected bigint');
    if (!(_0n <= num && num < POW_2_256))
        throw new Error('Expected number 0 <= n < 2^256');
    return num.toString(16).padStart(64, '0');
}
function numTo32b(num) {
    const b = hexToBytes(numTo32bStr(num));
    if (b.length !== 32)
        throw new Error('Error: expected 32 bytes');
    return b;
}
function numberToHexUnpadded(num) {
    const hex = num.toString(16);
    return hex.length & 1 ? `0${hex}` : hex;
}
function hexToNumber(hex) {
    if (typeof hex !== 'string') {
        throw new TypeError('hexToNumber: expected string, got ' + typeof hex);
    }
    return BigInt(`0x${hex}`);
}
function bytesToNumber(bytes) {
    return hexToNumber(bytesToHex(bytes));
}
function ensureBytes(hex) {
    return isBytes$1(hex) ? Uint8Array.from(hex) : hexToBytes(hex);
}
function normalizeScalar(num) {
    if (typeof num === 'number' && Number.isSafeInteger(num) && num > 0)
        return BigInt(num);
    if (typeof num === 'bigint' && isWithinCurveOrder(num))
        return num;
    throw new TypeError('Expected valid private scalar: 0 < scalar < curve.n');
}
function mod(a, b = CURVE.P) {
    const result = a % b;
    return result >= _0n ? result : b + result;
}
function pow2(x, power) {
    const { P } = CURVE;
    let res = x;
    while (power-- > _0n) {
        res *= res;
        res %= P;
    }
    return res;
}
function sqrtMod(x) {
    const { P } = CURVE;
    const _6n = BigInt(6);
    const _11n = BigInt(11);
    const _22n = BigInt(22);
    const _23n = BigInt(23);
    const _44n = BigInt(44);
    const _88n = BigInt(88);
    const b2 = (x * x * x) % P;
    const b3 = (b2 * b2 * x) % P;
    const b6 = (pow2(b3, _3n) * b3) % P;
    const b9 = (pow2(b6, _3n) * b3) % P;
    const b11 = (pow2(b9, _2n) * b2) % P;
    const b22 = (pow2(b11, _11n) * b11) % P;
    const b44 = (pow2(b22, _22n) * b22) % P;
    const b88 = (pow2(b44, _44n) * b44) % P;
    const b176 = (pow2(b88, _88n) * b88) % P;
    const b220 = (pow2(b176, _44n) * b44) % P;
    const b223 = (pow2(b220, _3n) * b3) % P;
    const t1 = (pow2(b223, _23n) * b22) % P;
    const t2 = (pow2(t1, _6n) * b2) % P;
    const rt = pow2(t2, _2n);
    const xc = (rt * rt) % P;
    if (xc !== x)
        throw new Error('Cannot find square root');
    return rt;
}
function invert(number, modulo = CURVE.P) {
    if (number === _0n || modulo <= _0n) {
        throw new Error(`invert: expected positive integers, got n=${number} mod=${modulo}`);
    }
    let a = mod(number, modulo);
    let b = modulo;
    let x = _0n, u = _1n;
    while (a !== _0n) {
        const q = b / a;
        const r = b % a;
        const m = x - u * q;
        b = a, a = r, x = u, u = m;
    }
    const gcd = b;
    if (gcd !== _1n)
        throw new Error('invert: does not exist');
    return mod(x, modulo);
}
function invertBatch(nums, p = CURVE.P) {
    const scratch = new Array(nums.length);
    const lastMultiplied = nums.reduce((acc, num, i) => {
        if (num === _0n)
            return acc;
        scratch[i] = acc;
        return mod(acc * num, p);
    }, _1n);
    const inverted = invert(lastMultiplied, p);
    nums.reduceRight((acc, num, i) => {
        if (num === _0n)
            return acc;
        scratch[i] = mod(acc * scratch[i], p);
        return mod(acc * num, p);
    }, inverted);
    return scratch;
}
function bits2int_2(bytes) {
    const delta = bytes.length * 8 - groupLen * 8;
    const num = bytesToNumber(bytes);
    return delta > 0 ? num >> BigInt(delta) : num;
}
function truncateHash(hash, truncateOnly = false) {
    const h = bits2int_2(hash);
    if (truncateOnly)
        return h;
    const { n } = CURVE;
    return h >= n ? h - n : h;
}
let _sha256Sync;
let _hmacSha256Sync;
class HmacDrbg {
    constructor(hashLen, qByteLen) {
        this.hashLen = hashLen;
        this.qByteLen = qByteLen;
        if (typeof hashLen !== 'number' || hashLen < 2)
            throw new Error('hashLen must be a number');
        if (typeof qByteLen !== 'number' || qByteLen < 2)
            throw new Error('qByteLen must be a number');
        this.v = new Uint8Array(hashLen).fill(1);
        this.k = new Uint8Array(hashLen).fill(0);
        this.counter = 0;
    }
    hmac(...values) {
        return utils.hmacSha256(this.k, ...values);
    }
    hmacSync(...values) {
        return _hmacSha256Sync(this.k, ...values);
    }
    checkSync() {
        if (typeof _hmacSha256Sync !== 'function')
            throw new ShaError('hmacSha256Sync needs to be set');
    }
    incr() {
        if (this.counter >= 1000)
            throw new Error('Tried 1,000 k values for sign(), all were invalid');
        this.counter += 1;
    }
    async reseed(seed = new Uint8Array()) {
        this.k = await this.hmac(this.v, Uint8Array.from([0x00]), seed);
        this.v = await this.hmac(this.v);
        if (seed.length === 0)
            return;
        this.k = await this.hmac(this.v, Uint8Array.from([0x01]), seed);
        this.v = await this.hmac(this.v);
    }
    reseedSync(seed = new Uint8Array()) {
        this.checkSync();
        this.k = this.hmacSync(this.v, Uint8Array.from([0x00]), seed);
        this.v = this.hmacSync(this.v);
        if (seed.length === 0)
            return;
        this.k = this.hmacSync(this.v, Uint8Array.from([0x01]), seed);
        this.v = this.hmacSync(this.v);
    }
    async generate() {
        this.incr();
        let len = 0;
        const out = [];
        while (len < this.qByteLen) {
            this.v = await this.hmac(this.v);
            const sl = this.v.slice();
            out.push(sl);
            len += this.v.length;
        }
        return concatBytes(...out);
    }
    generateSync() {
        this.checkSync();
        this.incr();
        let len = 0;
        const out = [];
        while (len < this.qByteLen) {
            this.v = this.hmacSync(this.v);
            const sl = this.v.slice();
            out.push(sl);
            len += this.v.length;
        }
        return concatBytes(...out);
    }
}
function isWithinCurveOrder(num) {
    return _0n < num && num < CURVE.n;
}
function isValidFieldElement(num) {
    return _0n < num && num < CURVE.P;
}
function kmdToSig(kBytes, m, d, lowS = true) {
    const { n } = CURVE;
    const k = truncateHash(kBytes, true);
    if (!isWithinCurveOrder(k))
        return;
    const kinv = invert(k, n);
    const q = Point.BASE.multiply(k);
    const r = mod(q.x, n);
    if (r === _0n)
        return;
    const s = mod(kinv * mod(m + d * r, n), n);
    if (s === _0n)
        return;
    let sig = new Signature(r, s);
    let recovery = (q.x === sig.r ? 0 : 2) | Number(q.y & _1n);
    if (lowS && sig.hasHighS()) {
        sig = sig.normalizeS();
        recovery ^= 1;
    }
    return { sig, recovery };
}
function normalizePrivateKey(key) {
    let num;
    if (typeof key === 'bigint') {
        num = key;
    }
    else if (typeof key === 'number' && Number.isSafeInteger(key) && key > 0) {
        num = BigInt(key);
    }
    else if (typeof key === 'string') {
        if (key.length !== 2 * groupLen)
            throw new Error('Expected 32 bytes of private key');
        num = hexToNumber(key);
    }
    else if (isBytes$1(key)) {
        if (key.length !== groupLen)
            throw new Error('Expected 32 bytes of private key');
        num = bytesToNumber(key);
    }
    else {
        throw new TypeError('Expected valid private key');
    }
    if (!isWithinCurveOrder(num))
        throw new Error('Expected private key: 0 < key < n');
    return num;
}
function normalizePublicKey(publicKey) {
    if (publicKey instanceof Point) {
        publicKey.assertValidity();
        return publicKey;
    }
    else {
        return Point.fromHex(publicKey);
    }
}
function normalizeSignature(signature) {
    if (signature instanceof Signature) {
        signature.assertValidity();
        return signature;
    }
    try {
        return Signature.fromDER(signature);
    }
    catch (error) {
        return Signature.fromCompact(signature);
    }
}
function bits2int(bytes) {
    const slice = bytes.length > fieldLen ? bytes.slice(0, fieldLen) : bytes;
    return bytesToNumber(slice);
}
function bits2octets(bytes) {
    const z1 = bits2int(bytes);
    const z2 = mod(z1, CURVE.n);
    return int2octets(z2 < _0n ? z1 : z2);
}
function int2octets(num) {
    return numTo32b(num);
}
function initSigArgs(msgHash, privateKey, extraEntropy) {
    if (msgHash == null)
        throw new Error(`sign: expected valid message hash, not "${msgHash}"`);
    const h1 = ensureBytes(msgHash);
    const d = normalizePrivateKey(privateKey);
    const seedArgs = [int2octets(d), bits2octets(h1)];
    if (extraEntropy != null) {
        if (extraEntropy === true)
            extraEntropy = utils.randomBytes(fieldLen);
        const e = ensureBytes(extraEntropy);
        if (e.length !== fieldLen)
            throw new Error(`sign: Expected ${fieldLen} bytes of extra data`);
        seedArgs.push(e);
    }
    const seed = concatBytes(...seedArgs);
    const m = bits2int(h1);
    return { seed, m, d };
}
function finalizeSig(recSig, opts) {
    const { sig, recovery } = recSig;
    const { der, recovered } = Object.assign({ canonical: true, der: true }, opts);
    const hashed = der ? sig.toDERRawBytes() : sig.toCompactRawBytes();
    return recovered ? [hashed, recovery] : hashed;
}
async function sign$1(msgHash, privKey, opts = {}) {
    const { seed, m, d } = initSigArgs(msgHash, privKey, opts.extraEntropy);
    const drbg = new HmacDrbg(hashLen, groupLen);
    await drbg.reseed(seed);
    let sig;
    while (!(sig = kmdToSig(await drbg.generate(), m, d, opts.canonical)))
        await drbg.reseed();
    return finalizeSig(sig, opts);
}
const vopts = { strict: true };
function verify(signature, msgHash, publicKey, opts = vopts) {
    let sig;
    try {
        sig = normalizeSignature(signature);
        msgHash = ensureBytes(msgHash);
    }
    catch (error) {
        return false;
    }
    const { r, s } = sig;
    if (opts.strict && sig.hasHighS())
        return false;
    const h = truncateHash(msgHash);
    let P;
    try {
        P = normalizePublicKey(publicKey);
    }
    catch (error) {
        return false;
    }
    const { n } = CURVE;
    const sinv = invert(s, n);
    const u1 = mod(h * sinv, n);
    const u2 = mod(r * sinv, n);
    const R = Point.BASE.multiplyAndAddUnsafe(P, u1, u2);
    if (!R)
        return false;
    const v = mod(R.x, n);
    return v === r;
}
Point.BASE._setWindowSize(8);
const crypto$1 = {
    node: nodeCrypto,
    web: typeof self === 'object' && 'crypto' in self ? self.crypto : undefined,
};
const TAGGED_HASH_PREFIXES = {};
const utils = {
    bytesToHex,
    hexToBytes,
    concatBytes,
    mod,
    invert,
    isValidPrivateKey(privateKey) {
        try {
            normalizePrivateKey(privateKey);
            return true;
        }
        catch (error) {
            return false;
        }
    },
    _bigintTo32Bytes: numTo32b,
    _normalizePrivateKey: normalizePrivateKey,
    hashToPrivateKey: (hash) => {
        hash = ensureBytes(hash);
        const minLen = groupLen + 8;
        if (hash.length < minLen || hash.length > 1024) {
            throw new Error(`Expected valid bytes of private key as per FIPS 186`);
        }
        const num = mod(bytesToNumber(hash), CURVE.n - _1n) + _1n;
        return numTo32b(num);
    },
    randomBytes: (bytesLength = 32) => {
        if (crypto$1.web) {
            return crypto$1.web.getRandomValues(new Uint8Array(bytesLength));
        }
        else if (crypto$1.node) {
            const { randomBytes } = crypto$1.node;
            return Uint8Array.from(randomBytes(bytesLength));
        }
        else {
            throw new Error("The environment doesn't have randomBytes function");
        }
    },
    randomPrivateKey: () => utils.hashToPrivateKey(utils.randomBytes(groupLen + 8)),
    precompute(windowSize = 8, point = Point.BASE) {
        const cached = point === Point.BASE ? point : new Point(point.x, point.y);
        cached._setWindowSize(windowSize);
        cached.multiply(_3n);
        return cached;
    },
    sha256: async (...messages) => {
        if (crypto$1.web) {
            const buffer = await crypto$1.web.subtle.digest('SHA-256', concatBytes(...messages));
            return new Uint8Array(buffer);
        }
        else if (crypto$1.node) {
            const { createHash } = crypto$1.node;
            const hash = createHash('sha256');
            messages.forEach((m) => hash.update(m));
            return Uint8Array.from(hash.digest());
        }
        else {
            throw new Error("The environment doesn't have sha256 function");
        }
    },
    hmacSha256: async (key, ...messages) => {
        if (crypto$1.web) {
            const ckey = await crypto$1.web.subtle.importKey('raw', key, { name: 'HMAC', hash: { name: 'SHA-256' } }, false, ['sign']);
            const message = concatBytes(...messages);
            const buffer = await crypto$1.web.subtle.sign('HMAC', ckey, message);
            return new Uint8Array(buffer);
        }
        else if (crypto$1.node) {
            const { createHmac } = crypto$1.node;
            const hash = createHmac('sha256', key);
            messages.forEach((m) => hash.update(m));
            return Uint8Array.from(hash.digest());
        }
        else {
            throw new Error("The environment doesn't have hmac-sha256 function");
        }
    },
    sha256Sync: undefined,
    hmacSha256Sync: undefined,
    taggedHash: async (tag, ...messages) => {
        let tagP = TAGGED_HASH_PREFIXES[tag];
        if (tagP === undefined) {
            const tagH = await utils.sha256(Uint8Array.from(tag, (c) => c.charCodeAt(0)));
            tagP = concatBytes(tagH, tagH);
            TAGGED_HASH_PREFIXES[tag] = tagP;
        }
        return utils.sha256(tagP, ...messages);
    },
    taggedHashSync: (tag, ...messages) => {
        if (typeof _sha256Sync !== 'function')
            throw new ShaError('sha256Sync is undefined, you need to set it');
        let tagP = TAGGED_HASH_PREFIXES[tag];
        if (tagP === undefined) {
            const tagH = _sha256Sync(Uint8Array.from(tag, (c) => c.charCodeAt(0)));
            tagP = concatBytes(tagH, tagH);
            TAGGED_HASH_PREFIXES[tag] = tagP;
        }
        return _sha256Sync(tagP, ...messages);
    },
    _JacobianPoint: JacobianPoint,
};
Object.defineProperties(utils, {
    sha256Sync: {
        configurable: false,
        get() {
            return _sha256Sync;
        },
        set(val) {
            if (!_sha256Sync)
                _sha256Sync = val;
        },
    },
    hmacSha256Sync: {
        configurable: false,
        get() {
            return _hmacSha256Sync;
        },
        set(val) {
            if (!_hmacSha256Sync)
                _hmacSha256Sync = val;
        },
    },
});

var sha3$1 = {exports: {}};

/**
 * [js-sha3]{@link https://github.com/emn178/js-sha3}
 *
 * @version 0.9.3
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2015-2023
 * @license MIT
 */

(function (module) {
	/*jslint bitwise: true */
	(function () {

	  var INPUT_ERROR = 'input is invalid type';
	  var FINALIZE_ERROR = 'finalize already called';
	  var WINDOW = typeof window === 'object';
	  var root = WINDOW ? window : {};
	  if (root.JS_SHA3_NO_WINDOW) {
	    WINDOW = false;
	  }
	  var WEB_WORKER = !WINDOW && typeof self === 'object';
	  var NODE_JS = !root.JS_SHA3_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;
	  if (NODE_JS) {
	    root = commonjsGlobal;
	  } else if (WEB_WORKER) {
	    root = self;
	  }
	  var COMMON_JS = !root.JS_SHA3_NO_COMMON_JS && 'object' === 'object' && module.exports;
	  var ARRAY_BUFFER = !root.JS_SHA3_NO_ARRAY_BUFFER && typeof ArrayBuffer !== 'undefined';
	  var HEX_CHARS = '0123456789abcdef'.split('');
	  var SHAKE_PADDING = [31, 7936, 2031616, 520093696];
	  var CSHAKE_PADDING = [4, 1024, 262144, 67108864];
	  var KECCAK_PADDING = [1, 256, 65536, 16777216];
	  var PADDING = [6, 1536, 393216, 100663296];
	  var SHIFT = [0, 8, 16, 24];
	  var RC = [1, 0, 32898, 0, 32906, 2147483648, 2147516416, 2147483648, 32907, 0, 2147483649,
	    0, 2147516545, 2147483648, 32777, 2147483648, 138, 0, 136, 0, 2147516425, 0,
	    2147483658, 0, 2147516555, 0, 139, 2147483648, 32905, 2147483648, 32771,
	    2147483648, 32770, 2147483648, 128, 2147483648, 32778, 0, 2147483658, 2147483648,
	    2147516545, 2147483648, 32896, 2147483648, 2147483649, 0, 2147516424, 2147483648];
	  var BITS = [224, 256, 384, 512];
	  var SHAKE_BITS = [128, 256];
	  var OUTPUT_TYPES = ['hex', 'buffer', 'arrayBuffer', 'array', 'digest'];
	  var CSHAKE_BYTEPAD = {
	    '128': 168,
	    '256': 136
	  };


	  var isArray = root.JS_SHA3_NO_NODE_JS || !Array.isArray
	    ? function (obj) {
	        return Object.prototype.toString.call(obj) === '[object Array]';
	      }
	    : Array.isArray;

	  var isView = (ARRAY_BUFFER && (root.JS_SHA3_NO_ARRAY_BUFFER_IS_VIEW || !ArrayBuffer.isView))
	    ? function (obj) {
	        return typeof obj === 'object' && obj.buffer && obj.buffer.constructor === ArrayBuffer;
	      }
	    : ArrayBuffer.isView;

	  // [message: string, isString: bool]
	  var formatMessage = function (message) {
	    var type = typeof message;
	    if (type === 'string') {
	      return [message, true];
	    }
	    if (type !== 'object' || message === null) {
	      throw new Error(INPUT_ERROR);
	    }
	    if (ARRAY_BUFFER && message.constructor === ArrayBuffer) {
	      return [new Uint8Array(message), false];
	    }
	    if (!isArray(message) && !isView(message)) {
	      throw new Error(INPUT_ERROR);
	    }
	    return [message, false];
	  };

	  var empty = function (message) {
	    return formatMessage(message)[0].length === 0;
	  };

	  var cloneArray = function (array) {
	    var newArray = [];
	    for (var i = 0; i < array.length; ++i) {
	      newArray[i] = array[i];
	    }
	    return newArray;
	  };

	  var createOutputMethod = function (bits, padding, outputType) {
	    return function (message) {
	      return new Keccak(bits, padding, bits).update(message)[outputType]();
	    };
	  };

	  var createShakeOutputMethod = function (bits, padding, outputType) {
	    return function (message, outputBits) {
	      return new Keccak(bits, padding, outputBits).update(message)[outputType]();
	    };
	  };

	  var createCshakeOutputMethod = function (bits, padding, outputType) {
	    return function (message, outputBits, n, s) {
	      return methods['cshake' + bits].update(message, outputBits, n, s)[outputType]();
	    };
	  };

	  var createKmacOutputMethod = function (bits, padding, outputType) {
	    return function (key, message, outputBits, s) {
	      return methods['kmac' + bits].update(key, message, outputBits, s)[outputType]();
	    };
	  };

	  var createOutputMethods = function (method, createMethod, bits, padding) {
	    for (var i = 0; i < OUTPUT_TYPES.length; ++i) {
	      var type = OUTPUT_TYPES[i];
	      method[type] = createMethod(bits, padding, type);
	    }
	    return method;
	  };

	  var createMethod = function (bits, padding) {
	    var method = createOutputMethod(bits, padding, 'hex');
	    method.create = function () {
	      return new Keccak(bits, padding, bits);
	    };
	    method.update = function (message) {
	      return method.create().update(message);
	    };
	    return createOutputMethods(method, createOutputMethod, bits, padding);
	  };

	  var createShakeMethod = function (bits, padding) {
	    var method = createShakeOutputMethod(bits, padding, 'hex');
	    method.create = function (outputBits) {
	      return new Keccak(bits, padding, outputBits);
	    };
	    method.update = function (message, outputBits) {
	      return method.create(outputBits).update(message);
	    };
	    return createOutputMethods(method, createShakeOutputMethod, bits, padding);
	  };

	  var createCshakeMethod = function (bits, padding) {
	    var w = CSHAKE_BYTEPAD[bits];
	    var method = createCshakeOutputMethod(bits, padding, 'hex');
	    method.create = function (outputBits, n, s) {
	      if (empty(n) && empty(s)) {
	        return methods['shake' + bits].create(outputBits);
	      } else {
	        return new Keccak(bits, padding, outputBits).bytepad([n, s], w);
	      }
	    };
	    method.update = function (message, outputBits, n, s) {
	      return method.create(outputBits, n, s).update(message);
	    };
	    return createOutputMethods(method, createCshakeOutputMethod, bits, padding);
	  };

	  var createKmacMethod = function (bits, padding) {
	    var w = CSHAKE_BYTEPAD[bits];
	    var method = createKmacOutputMethod(bits, padding, 'hex');
	    method.create = function (key, outputBits, s) {
	      return new Kmac(bits, padding, outputBits).bytepad(['KMAC', s], w).bytepad([key], w);
	    };
	    method.update = function (key, message, outputBits, s) {
	      return method.create(key, outputBits, s).update(message);
	    };
	    return createOutputMethods(method, createKmacOutputMethod, bits, padding);
	  };

	  var algorithms = [
	    { name: 'keccak', padding: KECCAK_PADDING, bits: BITS, createMethod: createMethod },
	    { name: 'sha3', padding: PADDING, bits: BITS, createMethod: createMethod },
	    { name: 'shake', padding: SHAKE_PADDING, bits: SHAKE_BITS, createMethod: createShakeMethod },
	    { name: 'cshake', padding: CSHAKE_PADDING, bits: SHAKE_BITS, createMethod: createCshakeMethod },
	    { name: 'kmac', padding: CSHAKE_PADDING, bits: SHAKE_BITS, createMethod: createKmacMethod }
	  ];

	  var methods = {}, methodNames = [];

	  for (var i = 0; i < algorithms.length; ++i) {
	    var algorithm = algorithms[i];
	    var bits = algorithm.bits;
	    for (var j = 0; j < bits.length; ++j) {
	      var methodName = algorithm.name + '_' + bits[j];
	      methodNames.push(methodName);
	      methods[methodName] = algorithm.createMethod(bits[j], algorithm.padding);
	      if (algorithm.name !== 'sha3') {
	        var newMethodName = algorithm.name + bits[j];
	        methodNames.push(newMethodName);
	        methods[newMethodName] = methods[methodName];
	      }
	    }
	  }

	  function Keccak(bits, padding, outputBits) {
	    this.blocks = [];
	    this.s = [];
	    this.padding = padding;
	    this.outputBits = outputBits;
	    this.reset = true;
	    this.finalized = false;
	    this.block = 0;
	    this.start = 0;
	    this.blockCount = (1600 - (bits << 1)) >> 5;
	    this.byteCount = this.blockCount << 2;
	    this.outputBlocks = outputBits >> 5;
	    this.extraBytes = (outputBits & 31) >> 3;

	    for (var i = 0; i < 50; ++i) {
	      this.s[i] = 0;
	    }
	  }

	  Keccak.prototype.update = function (message) {
	    if (this.finalized) {
	      throw new Error(FINALIZE_ERROR);
	    }
	    var result = formatMessage(message);
	    message = result[0];
	    var isString = result[1];
	    var blocks = this.blocks, byteCount = this.byteCount, length = message.length,
	      blockCount = this.blockCount, index = 0, s = this.s, i, code;

	    while (index < length) {
	      if (this.reset) {
	        this.reset = false;
	        blocks[0] = this.block;
	        for (i = 1; i < blockCount + 1; ++i) {
	          blocks[i] = 0;
	        }
	      }
	      if (isString) {
	        for (i = this.start; index < length && i < byteCount; ++index) {
	          code = message.charCodeAt(index);
	          if (code < 0x80) {
	            blocks[i >> 2] |= code << SHIFT[i++ & 3];
	          } else if (code < 0x800) {
	            blocks[i >> 2] |= (0xc0 | (code >> 6)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          } else if (code < 0xd800 || code >= 0xe000) {
	            blocks[i >> 2] |= (0xe0 | (code >> 12)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          } else {
	            code = 0x10000 + (((code & 0x3ff) << 10) | (message.charCodeAt(++index) & 0x3ff));
	            blocks[i >> 2] |= (0xf0 | (code >> 18)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 12) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          }
	        }
	      } else {
	        for (i = this.start; index < length && i < byteCount; ++index) {
	          blocks[i >> 2] |= message[index] << SHIFT[i++ & 3];
	        }
	      }
	      this.lastByteIndex = i;
	      if (i >= byteCount) {
	        this.start = i - byteCount;
	        this.block = blocks[blockCount];
	        for (i = 0; i < blockCount; ++i) {
	          s[i] ^= blocks[i];
	        }
	        f(s);
	        this.reset = true;
	      } else {
	        this.start = i;
	      }
	    }
	    return this;
	  };

	  Keccak.prototype.encode = function (x, right) {
	    var o = x & 255, n = 1;
	    var bytes = [o];
	    x = x >> 8;
	    o = x & 255;
	    while (o > 0) {
	      bytes.unshift(o);
	      x = x >> 8;
	      o = x & 255;
	      ++n;
	    }
	    if (right) {
	      bytes.push(n);
	    } else {
	      bytes.unshift(n);
	    }
	    this.update(bytes);
	    return bytes.length;
	  };

	  Keccak.prototype.encodeString = function (str) {
	    var result = formatMessage(str);
	    str = result[0];
	    var isString = result[1];
	    var bytes = 0, length = str.length;
	    if (isString) {
	      for (var i = 0; i < str.length; ++i) {
	        var code = str.charCodeAt(i);
	        if (code < 0x80) {
	          bytes += 1;
	        } else if (code < 0x800) {
	          bytes += 2;
	        } else if (code < 0xd800 || code >= 0xe000) {
	          bytes += 3;
	        } else {
	          code = 0x10000 + (((code & 0x3ff) << 10) | (str.charCodeAt(++i) & 0x3ff));
	          bytes += 4;
	        }
	      }
	    } else {
	      bytes = length;
	    }
	    bytes += this.encode(bytes * 8);
	    this.update(str);
	    return bytes;
	  };

	  Keccak.prototype.bytepad = function (strs, w) {
	    var bytes = this.encode(w);
	    for (var i = 0; i < strs.length; ++i) {
	      bytes += this.encodeString(strs[i]);
	    }
	    var paddingBytes = (w - bytes % w) % w;
	    var zeros = [];
	    zeros.length = paddingBytes;
	    this.update(zeros);
	    return this;
	  };

	  Keccak.prototype.finalize = function () {
	    if (this.finalized) {
	      return;
	    }
	    this.finalized = true;
	    var blocks = this.blocks, i = this.lastByteIndex, blockCount = this.blockCount, s = this.s;
	    blocks[i >> 2] |= this.padding[i & 3];
	    if (this.lastByteIndex === this.byteCount) {
	      blocks[0] = blocks[blockCount];
	      for (i = 1; i < blockCount + 1; ++i) {
	        blocks[i] = 0;
	      }
	    }
	    blocks[blockCount - 1] |= 0x80000000;
	    for (i = 0; i < blockCount; ++i) {
	      s[i] ^= blocks[i];
	    }
	    f(s);
	  };

	  Keccak.prototype.toString = Keccak.prototype.hex = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var hex = '', block;
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        block = s[i];
	        hex += HEX_CHARS[(block >> 4) & 0x0F] + HEX_CHARS[block & 0x0F] +
	          HEX_CHARS[(block >> 12) & 0x0F] + HEX_CHARS[(block >> 8) & 0x0F] +
	          HEX_CHARS[(block >> 20) & 0x0F] + HEX_CHARS[(block >> 16) & 0x0F] +
	          HEX_CHARS[(block >> 28) & 0x0F] + HEX_CHARS[(block >> 24) & 0x0F];
	      }
	      if (j % blockCount === 0) {
	        s = cloneArray(s);
	        f(s);
	        i = 0;
	      }
	    }
	    if (extraBytes) {
	      block = s[i];
	      hex += HEX_CHARS[(block >> 4) & 0x0F] + HEX_CHARS[block & 0x0F];
	      if (extraBytes > 1) {
	        hex += HEX_CHARS[(block >> 12) & 0x0F] + HEX_CHARS[(block >> 8) & 0x0F];
	      }
	      if (extraBytes > 2) {
	        hex += HEX_CHARS[(block >> 20) & 0x0F] + HEX_CHARS[(block >> 16) & 0x0F];
	      }
	    }
	    return hex;
	  };

	  Keccak.prototype.arrayBuffer = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var bytes = this.outputBits >> 3;
	    var buffer;
	    if (extraBytes) {
	      buffer = new ArrayBuffer((outputBlocks + 1) << 2);
	    } else {
	      buffer = new ArrayBuffer(bytes);
	    }
	    var array = new Uint32Array(buffer);
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        array[j] = s[i];
	      }
	      if (j % blockCount === 0) {
	        s = cloneArray(s);
	        f(s);
	      }
	    }
	    if (extraBytes) {
	      array[j] = s[i];
	      buffer = buffer.slice(0, bytes);
	    }
	    return buffer;
	  };

	  Keccak.prototype.buffer = Keccak.prototype.arrayBuffer;

	  Keccak.prototype.digest = Keccak.prototype.array = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var array = [], offset, block;
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        offset = j << 2;
	        block = s[i];
	        array[offset] = block & 0xFF;
	        array[offset + 1] = (block >> 8) & 0xFF;
	        array[offset + 2] = (block >> 16) & 0xFF;
	        array[offset + 3] = (block >> 24) & 0xFF;
	      }
	      if (j % blockCount === 0) {
	        s = cloneArray(s);
	        f(s);
	      }
	    }
	    if (extraBytes) {
	      offset = j << 2;
	      block = s[i];
	      array[offset] = block & 0xFF;
	      if (extraBytes > 1) {
	        array[offset + 1] = (block >> 8) & 0xFF;
	      }
	      if (extraBytes > 2) {
	        array[offset + 2] = (block >> 16) & 0xFF;
	      }
	    }
	    return array;
	  };

	  function Kmac(bits, padding, outputBits) {
	    Keccak.call(this, bits, padding, outputBits);
	  }

	  Kmac.prototype = new Keccak();

	  Kmac.prototype.finalize = function () {
	    this.encode(this.outputBits, true);
	    return Keccak.prototype.finalize.call(this);
	  };

	  var f = function (s) {
	    var h, l, n, c0, c1, c2, c3, c4, c5, c6, c7, c8, c9,
	      b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, b10, b11, b12, b13, b14, b15, b16, b17,
	      b18, b19, b20, b21, b22, b23, b24, b25, b26, b27, b28, b29, b30, b31, b32, b33,
	      b34, b35, b36, b37, b38, b39, b40, b41, b42, b43, b44, b45, b46, b47, b48, b49;
	    for (n = 0; n < 48; n += 2) {
	      c0 = s[0] ^ s[10] ^ s[20] ^ s[30] ^ s[40];
	      c1 = s[1] ^ s[11] ^ s[21] ^ s[31] ^ s[41];
	      c2 = s[2] ^ s[12] ^ s[22] ^ s[32] ^ s[42];
	      c3 = s[3] ^ s[13] ^ s[23] ^ s[33] ^ s[43];
	      c4 = s[4] ^ s[14] ^ s[24] ^ s[34] ^ s[44];
	      c5 = s[5] ^ s[15] ^ s[25] ^ s[35] ^ s[45];
	      c6 = s[6] ^ s[16] ^ s[26] ^ s[36] ^ s[46];
	      c7 = s[7] ^ s[17] ^ s[27] ^ s[37] ^ s[47];
	      c8 = s[8] ^ s[18] ^ s[28] ^ s[38] ^ s[48];
	      c9 = s[9] ^ s[19] ^ s[29] ^ s[39] ^ s[49];

	      h = c8 ^ ((c2 << 1) | (c3 >>> 31));
	      l = c9 ^ ((c3 << 1) | (c2 >>> 31));
	      s[0] ^= h;
	      s[1] ^= l;
	      s[10] ^= h;
	      s[11] ^= l;
	      s[20] ^= h;
	      s[21] ^= l;
	      s[30] ^= h;
	      s[31] ^= l;
	      s[40] ^= h;
	      s[41] ^= l;
	      h = c0 ^ ((c4 << 1) | (c5 >>> 31));
	      l = c1 ^ ((c5 << 1) | (c4 >>> 31));
	      s[2] ^= h;
	      s[3] ^= l;
	      s[12] ^= h;
	      s[13] ^= l;
	      s[22] ^= h;
	      s[23] ^= l;
	      s[32] ^= h;
	      s[33] ^= l;
	      s[42] ^= h;
	      s[43] ^= l;
	      h = c2 ^ ((c6 << 1) | (c7 >>> 31));
	      l = c3 ^ ((c7 << 1) | (c6 >>> 31));
	      s[4] ^= h;
	      s[5] ^= l;
	      s[14] ^= h;
	      s[15] ^= l;
	      s[24] ^= h;
	      s[25] ^= l;
	      s[34] ^= h;
	      s[35] ^= l;
	      s[44] ^= h;
	      s[45] ^= l;
	      h = c4 ^ ((c8 << 1) | (c9 >>> 31));
	      l = c5 ^ ((c9 << 1) | (c8 >>> 31));
	      s[6] ^= h;
	      s[7] ^= l;
	      s[16] ^= h;
	      s[17] ^= l;
	      s[26] ^= h;
	      s[27] ^= l;
	      s[36] ^= h;
	      s[37] ^= l;
	      s[46] ^= h;
	      s[47] ^= l;
	      h = c6 ^ ((c0 << 1) | (c1 >>> 31));
	      l = c7 ^ ((c1 << 1) | (c0 >>> 31));
	      s[8] ^= h;
	      s[9] ^= l;
	      s[18] ^= h;
	      s[19] ^= l;
	      s[28] ^= h;
	      s[29] ^= l;
	      s[38] ^= h;
	      s[39] ^= l;
	      s[48] ^= h;
	      s[49] ^= l;

	      b0 = s[0];
	      b1 = s[1];
	      b32 = (s[11] << 4) | (s[10] >>> 28);
	      b33 = (s[10] << 4) | (s[11] >>> 28);
	      b14 = (s[20] << 3) | (s[21] >>> 29);
	      b15 = (s[21] << 3) | (s[20] >>> 29);
	      b46 = (s[31] << 9) | (s[30] >>> 23);
	      b47 = (s[30] << 9) | (s[31] >>> 23);
	      b28 = (s[40] << 18) | (s[41] >>> 14);
	      b29 = (s[41] << 18) | (s[40] >>> 14);
	      b20 = (s[2] << 1) | (s[3] >>> 31);
	      b21 = (s[3] << 1) | (s[2] >>> 31);
	      b2 = (s[13] << 12) | (s[12] >>> 20);
	      b3 = (s[12] << 12) | (s[13] >>> 20);
	      b34 = (s[22] << 10) | (s[23] >>> 22);
	      b35 = (s[23] << 10) | (s[22] >>> 22);
	      b16 = (s[33] << 13) | (s[32] >>> 19);
	      b17 = (s[32] << 13) | (s[33] >>> 19);
	      b48 = (s[42] << 2) | (s[43] >>> 30);
	      b49 = (s[43] << 2) | (s[42] >>> 30);
	      b40 = (s[5] << 30) | (s[4] >>> 2);
	      b41 = (s[4] << 30) | (s[5] >>> 2);
	      b22 = (s[14] << 6) | (s[15] >>> 26);
	      b23 = (s[15] << 6) | (s[14] >>> 26);
	      b4 = (s[25] << 11) | (s[24] >>> 21);
	      b5 = (s[24] << 11) | (s[25] >>> 21);
	      b36 = (s[34] << 15) | (s[35] >>> 17);
	      b37 = (s[35] << 15) | (s[34] >>> 17);
	      b18 = (s[45] << 29) | (s[44] >>> 3);
	      b19 = (s[44] << 29) | (s[45] >>> 3);
	      b10 = (s[6] << 28) | (s[7] >>> 4);
	      b11 = (s[7] << 28) | (s[6] >>> 4);
	      b42 = (s[17] << 23) | (s[16] >>> 9);
	      b43 = (s[16] << 23) | (s[17] >>> 9);
	      b24 = (s[26] << 25) | (s[27] >>> 7);
	      b25 = (s[27] << 25) | (s[26] >>> 7);
	      b6 = (s[36] << 21) | (s[37] >>> 11);
	      b7 = (s[37] << 21) | (s[36] >>> 11);
	      b38 = (s[47] << 24) | (s[46] >>> 8);
	      b39 = (s[46] << 24) | (s[47] >>> 8);
	      b30 = (s[8] << 27) | (s[9] >>> 5);
	      b31 = (s[9] << 27) | (s[8] >>> 5);
	      b12 = (s[18] << 20) | (s[19] >>> 12);
	      b13 = (s[19] << 20) | (s[18] >>> 12);
	      b44 = (s[29] << 7) | (s[28] >>> 25);
	      b45 = (s[28] << 7) | (s[29] >>> 25);
	      b26 = (s[38] << 8) | (s[39] >>> 24);
	      b27 = (s[39] << 8) | (s[38] >>> 24);
	      b8 = (s[48] << 14) | (s[49] >>> 18);
	      b9 = (s[49] << 14) | (s[48] >>> 18);

	      s[0] = b0 ^ (~b2 & b4);
	      s[1] = b1 ^ (~b3 & b5);
	      s[10] = b10 ^ (~b12 & b14);
	      s[11] = b11 ^ (~b13 & b15);
	      s[20] = b20 ^ (~b22 & b24);
	      s[21] = b21 ^ (~b23 & b25);
	      s[30] = b30 ^ (~b32 & b34);
	      s[31] = b31 ^ (~b33 & b35);
	      s[40] = b40 ^ (~b42 & b44);
	      s[41] = b41 ^ (~b43 & b45);
	      s[2] = b2 ^ (~b4 & b6);
	      s[3] = b3 ^ (~b5 & b7);
	      s[12] = b12 ^ (~b14 & b16);
	      s[13] = b13 ^ (~b15 & b17);
	      s[22] = b22 ^ (~b24 & b26);
	      s[23] = b23 ^ (~b25 & b27);
	      s[32] = b32 ^ (~b34 & b36);
	      s[33] = b33 ^ (~b35 & b37);
	      s[42] = b42 ^ (~b44 & b46);
	      s[43] = b43 ^ (~b45 & b47);
	      s[4] = b4 ^ (~b6 & b8);
	      s[5] = b5 ^ (~b7 & b9);
	      s[14] = b14 ^ (~b16 & b18);
	      s[15] = b15 ^ (~b17 & b19);
	      s[24] = b24 ^ (~b26 & b28);
	      s[25] = b25 ^ (~b27 & b29);
	      s[34] = b34 ^ (~b36 & b38);
	      s[35] = b35 ^ (~b37 & b39);
	      s[44] = b44 ^ (~b46 & b48);
	      s[45] = b45 ^ (~b47 & b49);
	      s[6] = b6 ^ (~b8 & b0);
	      s[7] = b7 ^ (~b9 & b1);
	      s[16] = b16 ^ (~b18 & b10);
	      s[17] = b17 ^ (~b19 & b11);
	      s[26] = b26 ^ (~b28 & b20);
	      s[27] = b27 ^ (~b29 & b21);
	      s[36] = b36 ^ (~b38 & b30);
	      s[37] = b37 ^ (~b39 & b31);
	      s[46] = b46 ^ (~b48 & b40);
	      s[47] = b47 ^ (~b49 & b41);
	      s[8] = b8 ^ (~b0 & b2);
	      s[9] = b9 ^ (~b1 & b3);
	      s[18] = b18 ^ (~b10 & b12);
	      s[19] = b19 ^ (~b11 & b13);
	      s[28] = b28 ^ (~b20 & b22);
	      s[29] = b29 ^ (~b21 & b23);
	      s[38] = b38 ^ (~b30 & b32);
	      s[39] = b39 ^ (~b31 & b33);
	      s[48] = b48 ^ (~b40 & b42);
	      s[49] = b49 ^ (~b41 & b43);

	      s[0] ^= RC[n];
	      s[1] ^= RC[n + 1];
	    }
	  };

	  if (COMMON_JS) {
	    module.exports = methods;
	  } else {
	    for (i = 0; i < methodNames.length; ++i) {
	      root[methodNames[i]] = methods[methodNames[i]];
	    }
	  }
	})(); 
} (sha3$1));

var sha3Exports = sha3$1.exports;
var sha3 = /*@__PURE__*/getDefaultExportFromCjs(sha3Exports);

function keccak256(input) {
    return new Uint8Array(sha3.keccak256.arrayBuffer(input));
}
/**
 * Verify an ECDSA signature.
 */
function verifySignature(signature, message, publicKey) {
    try {
        const _signature = Signature.fromCompact(signature.slice(0, 64));
        return verify(_signature, message, publicKey);
    }
    catch {
        return false;
    }
}

function multiaddrFromFields(ipFamily, protocol, ipBytes, protocolBytes) {
    let ma = multiaddr("/" + ipFamily + "/" + convertToString(ipFamily, ipBytes));
    ma = ma.encapsulate(multiaddr("/" + protocol + "/" + convertToString(protocol, protocolBytes)));
    return ma;
}

function locationMultiaddrFromEnrFields(enr, protocol) {
    switch (protocol) {
        case "udp":
            return (locationMultiaddrFromEnrFields(enr, "udp4") ||
                locationMultiaddrFromEnrFields(enr, "udp6"));
        case "tcp":
            return (locationMultiaddrFromEnrFields(enr, "tcp4") ||
                locationMultiaddrFromEnrFields(enr, "tcp6"));
    }
    const isIpv6 = protocol.endsWith("6");
    const ipVal = enr.get(isIpv6 ? "ip6" : "ip");
    if (!ipVal)
        return;
    const protoName = protocol.slice(0, 3);
    let protoVal;
    switch (protoName) {
        case "udp":
            protoVal = isIpv6 ? enr.get("udp6") : enr.get("udp");
            break;
        case "tcp":
            protoVal = isIpv6 ? enr.get("tcp6") : enr.get("tcp");
            break;
        default:
            return;
    }
    if (!protoVal)
        return;
    return multiaddrFromFields(isIpv6 ? "ip6" : "ip4", protoName, ipVal, protoVal);
}

const ERR_TYPE_NOT_IMPLEMENTED = "Keypair type not implemented";
function createPeerIdFromPublicKey(publicKey) {
    const pubKey = publicKeyFromRaw(publicKey);
    if (pubKey.type !== "secp256k1") {
        throw new Error(ERR_TYPE_NOT_IMPLEMENTED);
    }
    return peerIdFromPublicKey(pubKey);
}

function decodeMultiaddrs(bytes) {
    const multiaddrs = [];
    let index = 0;
    while (index < bytes.length) {
        const sizeDataView = new DataView(bytes.buffer, index, MULTIADDR_LENGTH_SIZE);
        const size = sizeDataView.getUint16(0);
        index += MULTIADDR_LENGTH_SIZE;
        const multiaddrBytes = bytes.slice(index, index + size);
        index += size;
        multiaddrs.push(multiaddr(multiaddrBytes));
    }
    return multiaddrs;
}
function encodeMultiaddrs(multiaddrs) {
    const totalLength = multiaddrs.reduce((acc, ma) => acc + MULTIADDR_LENGTH_SIZE + ma.bytes.length, 0);
    const bytes = new Uint8Array(totalLength);
    const dataView = new DataView(bytes.buffer);
    let index = 0;
    multiaddrs.forEach((multiaddr) => {
        if (multiaddr.getPeerId())
            throw new Error("`multiaddr` field MUST not contain peer id");
        // Prepend the size of the next entry
        dataView.setUint16(index, multiaddr.bytes.length);
        index += MULTIADDR_LENGTH_SIZE;
        bytes.set(multiaddr.bytes, index);
        index += multiaddr.bytes.length;
    });
    return bytes;
}

function encodeWaku2(protocols) {
    let byte = 0;
    if (protocols.lightPush)
        byte += 1;
    byte = byte << 1;
    if (protocols.filter)
        byte += 1;
    byte = byte << 1;
    if (protocols.store)
        byte += 1;
    byte = byte << 1;
    if (protocols.relay)
        byte += 1;
    return byte;
}
function decodeWaku2(byte) {
    const waku2 = {
        relay: false,
        store: false,
        filter: false,
        lightPush: false
    };
    if (byte % 2)
        waku2.relay = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.store = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.filter = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.lightPush = true;
    return waku2;
}

class RawEnr extends Map {
    seq;
    signature;
    constructor(kvs = {}, seq = BigInt(1), signature) {
        super(Object.entries(kvs));
        this.seq = seq;
        this.signature = signature;
    }
    set(k, v) {
        this.signature = undefined;
        this.seq++;
        return super.set(k, v);
    }
    get id() {
        const id = this.get("id");
        if (!id)
            throw new Error("id not found.");
        return bytesToUtf8(id);
    }
    get publicKey() {
        switch (this.id) {
            case "v4":
                return this.get("secp256k1");
            default:
                throw new Error(ERR_INVALID_ID);
        }
    }
    get rs() {
        const rs = this.get("rs");
        if (!rs)
            return undefined;
        return decodeRelayShard(rs);
    }
    get rsv() {
        const rsv = this.get("rsv");
        if (!rsv)
            return undefined;
        return decodeRelayShard(rsv);
    }
    get ip() {
        return getStringValue(this, "ip", "ip4");
    }
    set ip(ip) {
        setStringValue(this, "ip", "ip4", ip);
    }
    get tcp() {
        return getNumberAsStringValue(this, "tcp", "tcp");
    }
    set tcp(port) {
        setNumberAsStringValue(this, "tcp", "tcp", port);
    }
    get udp() {
        return getNumberAsStringValue(this, "udp", "udp");
    }
    set udp(port) {
        setNumberAsStringValue(this, "udp", "udp", port);
    }
    get ip6() {
        return getStringValue(this, "ip6", "ip6");
    }
    set ip6(ip) {
        setStringValue(this, "ip6", "ip6", ip);
    }
    get tcp6() {
        return getNumberAsStringValue(this, "tcp6", "tcp");
    }
    set tcp6(port) {
        setNumberAsStringValue(this, "tcp6", "tcp", port);
    }
    get udp6() {
        return getNumberAsStringValue(this, "udp6", "udp");
    }
    set udp6(port) {
        setNumberAsStringValue(this, "udp6", "udp", port);
    }
    /**
     * Get the `multiaddrs` field from ENR.
     *
     * This field is used to store multiaddresses that cannot be stored with the current ENR pre-defined keys.
     * These can be a multiaddresses that include encapsulation (e.g. wss) or do not use `ip4` nor `ip6` for the host
     * address (e.g. `dns4`, `dnsaddr`, etc)..
     *
     * If the peer information only contains information that can be represented with the ENR pre-defined keys
     * (ip, tcp, etc) then the usage of { @link ENR.getLocationMultiaddr } should be preferred.
     *
     * The multiaddresses stored in this field are expected to be location multiaddresses, ie, peer id less.
     */
    get multiaddrs() {
        const raw = this.get("multiaddrs");
        if (raw)
            return decodeMultiaddrs(raw);
        return;
    }
    /**
     * Set the `multiaddrs` field on the ENR.
     *
     * This field is used to store multiaddresses that cannot be stored with the current ENR pre-defined keys.
     * These can be a multiaddresses that include encapsulation (e.g. wss) or do not use `ip4` nor `ip6` for the host
     * address (e.g. `dns4`, `dnsaddr`, etc)..
     *
     * If the peer information only contains information that can be represented with the ENR pre-defined keys
     * (ip, tcp, etc) then the usage of { @link ENR.setLocationMultiaddr } should be preferred.
     * The multiaddresses stored in this field must be location multiaddresses,
     * ie, without a peer id.
     */
    set multiaddrs(multiaddrs) {
        deleteUndefined(this, "multiaddrs", multiaddrs, encodeMultiaddrs);
    }
    /**
     * Get the `waku2` field from ENR.
     */
    get waku2() {
        const raw = this.get("waku2");
        if (raw)
            return decodeWaku2(raw[0]);
        return;
    }
    /**
     * Set the `waku2` field on the ENR.
     */
    set waku2(waku2) {
        deleteUndefined(this, "waku2", waku2, (w) => new Uint8Array([encodeWaku2(w)]));
    }
}
function getStringValue(map, key, proto) {
    const raw = map.get(key);
    if (!raw)
        return;
    return convertToString(proto, raw);
}
function getNumberAsStringValue(map, key, proto) {
    const raw = map.get(key);
    if (!raw)
        return;
    return Number(convertToString(proto, raw));
}
function setStringValue(map, key, proto, value) {
    deleteUndefined(map, key, value, convertToBytes.bind({}, proto));
}
function setNumberAsStringValue(map, key, proto, value) {
    setStringValue(map, key, proto, value?.toString(10));
}
function deleteUndefined(map, key, value, transform) {
    if (value !== undefined) {
        map.set(key, transform(value));
    }
    else {
        map.delete(key);
    }
}

async function sign(privKey, msg) {
    return sign$1(keccak256(msg), privKey, {
        der: false
    });
}
function nodeId(pubKey) {
    const publicKey = Point.fromHex(pubKey);
    const uncompressedPubkey = publicKey.toRawBytes(false);
    return bytesToHex$1(keccak256(uncompressedPubkey.slice(1)));
}

const log$a = new Logger$1("enr");
var TransportProtocol;
(function (TransportProtocol) {
    TransportProtocol["TCP"] = "tcp";
    TransportProtocol["UDP"] = "udp";
})(TransportProtocol || (TransportProtocol = {}));
var TransportProtocolPerIpVersion;
(function (TransportProtocolPerIpVersion) {
    TransportProtocolPerIpVersion["TCP4"] = "tcp4";
    TransportProtocolPerIpVersion["UDP4"] = "udp4";
    TransportProtocolPerIpVersion["TCP6"] = "tcp6";
    TransportProtocolPerIpVersion["UDP6"] = "udp6";
})(TransportProtocolPerIpVersion || (TransportProtocolPerIpVersion = {}));
class ENR extends RawEnr {
    static RECORD_PREFIX = "enr:";
    peerId;
    static create(kvs = {}, seq = BigInt(1), signature) {
        const enr = new ENR(kvs, seq, signature);
        try {
            const publicKey = enr.publicKey;
            if (publicKey) {
                enr.peerId = createPeerIdFromPublicKey(publicKey);
            }
        }
        catch (e) {
            log$a.error("Could not calculate peer id for ENR", e);
        }
        return enr;
    }
    get nodeId() {
        switch (this.id) {
            case "v4":
                return this.publicKey ? nodeId(this.publicKey) : undefined;
            default:
                throw new Error(ERR_INVALID_ID);
        }
    }
    getLocationMultiaddr = locationMultiaddrFromEnrFields.bind({}, this);
    get shardInfo() {
        if (this.rs && this.rsv) {
            log$a.warn("ENR contains both `rs` and `rsv` fields.");
        }
        return this.rs || this.rsv;
    }
    setLocationMultiaddr(multiaddr) {
        const protoNames = multiaddr.protoNames();
        if (protoNames.length !== 2 &&
            protoNames[1] !== "udp" &&
            protoNames[1] !== "tcp") {
            throw new Error("Invalid multiaddr");
        }
        const tuples = multiaddr.tuples();
        if (!tuples[0][1] || !tuples[1][1]) {
            throw new Error("Invalid multiaddr");
        }
        // IPv4
        if (tuples[0][0] === 4) {
            this.set("ip", tuples[0][1]);
            this.set(protoNames[1], tuples[1][1]);
        }
        else {
            this.set("ip6", tuples[0][1]);
            this.set(protoNames[1] + "6", tuples[1][1]);
        }
    }
    getAllLocationMultiaddrs() {
        const multiaddrs = [];
        for (const protocol of Object.values(TransportProtocolPerIpVersion)) {
            const ma = this.getLocationMultiaddr(protocol);
            if (ma)
                multiaddrs.push(ma);
        }
        const _multiaddrs = this.multiaddrs ?? [];
        return multiaddrs.concat(_multiaddrs).map((ma) => {
            if (this.peerId) {
                return ma.encapsulate(`/p2p/${this.peerId.toString()}`);
            }
            return ma;
        });
    }
    get peerInfo() {
        const id = this.peerId;
        if (!id)
            return;
        return {
            id,
            multiaddrs: this.getAllLocationMultiaddrs()
        };
    }
    /**
     * Returns the full multiaddr from the ENR fields matching the provided
     * `protocol` parameter.
     * To return full multiaddrs from the `multiaddrs` ENR field,
     * use { @link ENR.getFullMultiaddrs }.
     *
     * @param protocol
     */
    getFullMultiaddr(protocol) {
        if (this.peerId) {
            const locationMultiaddr = this.getLocationMultiaddr(protocol);
            if (locationMultiaddr) {
                return locationMultiaddr.encapsulate(`/p2p/${this.peerId.toString()}`);
            }
        }
        return;
    }
    /**
     * Returns the full multiaddrs from the `multiaddrs` ENR field.
     */
    getFullMultiaddrs() {
        if (this.peerId && this.multiaddrs) {
            const peerId = this.peerId;
            return this.multiaddrs.map((ma) => {
                return ma.encapsulate(`/p2p/${peerId.toString()}`);
            });
        }
        return [];
    }
    verify(data, signature) {
        if (!this.get("id") || this.id !== "v4") {
            throw new Error(ERR_INVALID_ID);
        }
        if (!this.publicKey) {
            throw new Error("Failed to verify ENR: No public key");
        }
        return verifySignature(signature, keccak256(data), this.publicKey);
    }
    async sign(data, privateKey) {
        switch (this.id) {
            case "v4":
                this.signature = await sign(privateKey, data);
                break;
            default:
                throw new Error(ERR_INVALID_ID);
        }
        return this.signature;
    }
}

const version$2 = "logger/5.8.0";

let _permanentCensorErrors = false;
let _censorErrors = false;
const LogLevels = { debug: 1, "default": 2, info: 2, warning: 3, error: 4, off: 5 };
let _logLevel = LogLevels["default"];
let _globalLogger = null;
function _checkNormalize() {
    try {
        const missing = [];
        // Make sure all forms of normalization are supported
        ["NFD", "NFC", "NFKD", "NFKC"].forEach((form) => {
            try {
                if ("test".normalize(form) !== "test") {
                    throw new Error("bad normalize");
                }
                ;
            }
            catch (error) {
                missing.push(form);
            }
        });
        if (missing.length) {
            throw new Error("missing " + missing.join(", "));
        }
        if (String.fromCharCode(0xe9).normalize("NFD") !== String.fromCharCode(0x65, 0x0301)) {
            throw new Error("broken implementation");
        }
    }
    catch (error) {
        return error.message;
    }
    return null;
}
const _normalizeError = _checkNormalize();
var LogLevel;
(function (LogLevel) {
    LogLevel["DEBUG"] = "DEBUG";
    LogLevel["INFO"] = "INFO";
    LogLevel["WARNING"] = "WARNING";
    LogLevel["ERROR"] = "ERROR";
    LogLevel["OFF"] = "OFF";
})(LogLevel || (LogLevel = {}));
var ErrorCode;
(function (ErrorCode) {
    ///////////////////
    // Generic Errors
    // Unknown Error
    ErrorCode["UNKNOWN_ERROR"] = "UNKNOWN_ERROR";
    // Not Implemented
    ErrorCode["NOT_IMPLEMENTED"] = "NOT_IMPLEMENTED";
    // Unsupported Operation
    //   - operation
    ErrorCode["UNSUPPORTED_OPERATION"] = "UNSUPPORTED_OPERATION";
    // Network Error (i.e. Ethereum Network, such as an invalid chain ID)
    //   - event ("noNetwork" is not re-thrown in provider.ready; otherwise thrown)
    ErrorCode["NETWORK_ERROR"] = "NETWORK_ERROR";
    // Some sort of bad response from the server
    ErrorCode["SERVER_ERROR"] = "SERVER_ERROR";
    // Timeout
    ErrorCode["TIMEOUT"] = "TIMEOUT";
    ///////////////////
    // Operational  Errors
    // Buffer Overrun
    ErrorCode["BUFFER_OVERRUN"] = "BUFFER_OVERRUN";
    // Numeric Fault
    //   - operation: the operation being executed
    //   - fault: the reason this faulted
    ErrorCode["NUMERIC_FAULT"] = "NUMERIC_FAULT";
    ///////////////////
    // Argument Errors
    // Missing new operator to an object
    //  - name: The name of the class
    ErrorCode["MISSING_NEW"] = "MISSING_NEW";
    // Invalid argument (e.g. value is incompatible with type) to a function:
    //   - argument: The argument name that was invalid
    //   - value: The value of the argument
    ErrorCode["INVALID_ARGUMENT"] = "INVALID_ARGUMENT";
    // Missing argument to a function:
    //   - count: The number of arguments received
    //   - expectedCount: The number of arguments expected
    ErrorCode["MISSING_ARGUMENT"] = "MISSING_ARGUMENT";
    // Too many arguments
    //   - count: The number of arguments received
    //   - expectedCount: The number of arguments expected
    ErrorCode["UNEXPECTED_ARGUMENT"] = "UNEXPECTED_ARGUMENT";
    ///////////////////
    // Blockchain Errors
    // Call exception
    //  - transaction: the transaction
    //  - address?: the contract address
    //  - args?: The arguments passed into the function
    //  - method?: The Solidity method signature
    //  - errorSignature?: The EIP848 error signature
    //  - errorArgs?: The EIP848 error parameters
    //  - reason: The reason (only for EIP848 "Error(string)")
    ErrorCode["CALL_EXCEPTION"] = "CALL_EXCEPTION";
    // Insufficient funds (< value + gasLimit * gasPrice)
    //   - transaction: the transaction attempted
    ErrorCode["INSUFFICIENT_FUNDS"] = "INSUFFICIENT_FUNDS";
    // Nonce has already been used
    //   - transaction: the transaction attempted
    ErrorCode["NONCE_EXPIRED"] = "NONCE_EXPIRED";
    // The replacement fee for the transaction is too low
    //   - transaction: the transaction attempted
    ErrorCode["REPLACEMENT_UNDERPRICED"] = "REPLACEMENT_UNDERPRICED";
    // The gas limit could not be estimated
    //   - transaction: the transaction passed to estimateGas
    ErrorCode["UNPREDICTABLE_GAS_LIMIT"] = "UNPREDICTABLE_GAS_LIMIT";
    // The transaction was replaced by one with a higher gas price
    //   - reason: "cancelled", "replaced" or "repriced"
    //   - cancelled: true if reason == "cancelled" or reason == "replaced")
    //   - hash: original transaction hash
    //   - replacement: the full TransactionsResponse for the replacement
    //   - receipt: the receipt of the replacement
    ErrorCode["TRANSACTION_REPLACED"] = "TRANSACTION_REPLACED";
    ///////////////////
    // Interaction Errors
    // The user rejected the action, such as signing a message or sending
    // a transaction
    ErrorCode["ACTION_REJECTED"] = "ACTION_REJECTED";
})(ErrorCode || (ErrorCode = {}));
const HEX = "0123456789abcdef";
class Logger {
    constructor(version) {
        Object.defineProperty(this, "version", {
            enumerable: true,
            value: version,
            writable: false
        });
    }
    _log(logLevel, args) {
        const level = logLevel.toLowerCase();
        if (LogLevels[level] == null) {
            this.throwArgumentError("invalid log level name", "logLevel", logLevel);
        }
        if (_logLevel > LogLevels[level]) {
            return;
        }
        console.log.apply(console, args);
    }
    debug(...args) {
        this._log(Logger.levels.DEBUG, args);
    }
    info(...args) {
        this._log(Logger.levels.INFO, args);
    }
    warn(...args) {
        this._log(Logger.levels.WARNING, args);
    }
    makeError(message, code, params) {
        // Errors are being censored
        if (_censorErrors) {
            return this.makeError("censored error", code, {});
        }
        if (!code) {
            code = Logger.errors.UNKNOWN_ERROR;
        }
        if (!params) {
            params = {};
        }
        const messageDetails = [];
        Object.keys(params).forEach((key) => {
            const value = params[key];
            try {
                if (value instanceof Uint8Array) {
                    let hex = "";
                    for (let i = 0; i < value.length; i++) {
                        hex += HEX[value[i] >> 4];
                        hex += HEX[value[i] & 0x0f];
                    }
                    messageDetails.push(key + "=Uint8Array(0x" + hex + ")");
                }
                else {
                    messageDetails.push(key + "=" + JSON.stringify(value));
                }
            }
            catch (error) {
                messageDetails.push(key + "=" + JSON.stringify(params[key].toString()));
            }
        });
        messageDetails.push(`code=${code}`);
        messageDetails.push(`version=${this.version}`);
        const reason = message;
        let url = "";
        switch (code) {
            case ErrorCode.NUMERIC_FAULT: {
                url = "NUMERIC_FAULT";
                const fault = message;
                switch (fault) {
                    case "overflow":
                    case "underflow":
                    case "division-by-zero":
                        url += "-" + fault;
                        break;
                    case "negative-power":
                    case "negative-width":
                        url += "-unsupported";
                        break;
                    case "unbound-bitwise-result":
                        url += "-unbound-result";
                        break;
                }
                break;
            }
            case ErrorCode.CALL_EXCEPTION:
            case ErrorCode.INSUFFICIENT_FUNDS:
            case ErrorCode.MISSING_NEW:
            case ErrorCode.NONCE_EXPIRED:
            case ErrorCode.REPLACEMENT_UNDERPRICED:
            case ErrorCode.TRANSACTION_REPLACED:
            case ErrorCode.UNPREDICTABLE_GAS_LIMIT:
                url = code;
                break;
        }
        if (url) {
            message += " [ See: https:/\/links.ethers.org/v5-errors-" + url + " ]";
        }
        if (messageDetails.length) {
            message += " (" + messageDetails.join(", ") + ")";
        }
        // @TODO: Any??
        const error = new Error(message);
        error.reason = reason;
        error.code = code;
        Object.keys(params).forEach(function (key) {
            error[key] = params[key];
        });
        return error;
    }
    throwError(message, code, params) {
        throw this.makeError(message, code, params);
    }
    throwArgumentError(message, name, value) {
        return this.throwError(message, Logger.errors.INVALID_ARGUMENT, {
            argument: name,
            value: value
        });
    }
    assert(condition, message, code, params) {
        if (!!condition) {
            return;
        }
        this.throwError(message, code, params);
    }
    assertArgument(condition, message, name, value) {
        if (!!condition) {
            return;
        }
        this.throwArgumentError(message, name, value);
    }
    checkNormalize(message) {
        if (_normalizeError) {
            this.throwError("platform missing String.prototype.normalize", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "String.prototype.normalize", form: _normalizeError
            });
        }
    }
    checkSafeUint53(value, message) {
        if (typeof (value) !== "number") {
            return;
        }
        if (message == null) {
            message = "value not safe";
        }
        if (value < 0 || value >= 0x1fffffffffffff) {
            this.throwError(message, Logger.errors.NUMERIC_FAULT, {
                operation: "checkSafeInteger",
                fault: "out-of-safe-range",
                value: value
            });
        }
        if (value % 1) {
            this.throwError(message, Logger.errors.NUMERIC_FAULT, {
                operation: "checkSafeInteger",
                fault: "non-integer",
                value: value
            });
        }
    }
    checkArgumentCount(count, expectedCount, message) {
        if (message) {
            message = ": " + message;
        }
        else {
            message = "";
        }
        if (count < expectedCount) {
            this.throwError("missing argument" + message, Logger.errors.MISSING_ARGUMENT, {
                count: count,
                expectedCount: expectedCount
            });
        }
        if (count > expectedCount) {
            this.throwError("too many arguments" + message, Logger.errors.UNEXPECTED_ARGUMENT, {
                count: count,
                expectedCount: expectedCount
            });
        }
    }
    checkNew(target, kind) {
        if (target === Object || target == null) {
            this.throwError("missing new", Logger.errors.MISSING_NEW, { name: kind.name });
        }
    }
    checkAbstract(target, kind) {
        if (target === kind) {
            this.throwError("cannot instantiate abstract class " + JSON.stringify(kind.name) + " directly; use a sub-class", Logger.errors.UNSUPPORTED_OPERATION, { name: target.name, operation: "new" });
        }
        else if (target === Object || target == null) {
            this.throwError("missing new", Logger.errors.MISSING_NEW, { name: kind.name });
        }
    }
    static globalLogger() {
        if (!_globalLogger) {
            _globalLogger = new Logger(version$2);
        }
        return _globalLogger;
    }
    static setCensorship(censorship, permanent) {
        if (!censorship && permanent) {
            this.globalLogger().throwError("cannot permanently disable censorship", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "setCensorship"
            });
        }
        if (_permanentCensorErrors) {
            if (!censorship) {
                return;
            }
            this.globalLogger().throwError("error censorship permanent", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "setCensorship"
            });
        }
        _censorErrors = !!censorship;
        _permanentCensorErrors = !!permanent;
    }
    static setLogLevel(logLevel) {
        const level = LogLevels[logLevel.toLowerCase()];
        if (level == null) {
            Logger.globalLogger().warn("invalid log level - " + logLevel);
            return;
        }
        _logLevel = level;
    }
    static from(version) {
        return new Logger(version);
    }
}
Logger.errors = ErrorCode;
Logger.levels = LogLevel;

const version$1 = "bytes/5.8.0";

const logger$1 = new Logger(version$1);
///////////////////////////////
function isHexable(value) {
    return !!(value.toHexString);
}
function addSlice(array) {
    if (array.slice) {
        return array;
    }
    array.slice = function () {
        const args = Array.prototype.slice.call(arguments);
        return addSlice(new Uint8Array(Array.prototype.slice.apply(array, args)));
    };
    return array;
}
function isBytesLike(value) {
    return ((isHexString(value) && !(value.length % 2)) || isBytes(value));
}
function isInteger(value) {
    return (typeof (value) === "number" && value == value && (value % 1) === 0);
}
function isBytes(value) {
    if (value == null) {
        return false;
    }
    if (value.constructor === Uint8Array) {
        return true;
    }
    if (typeof (value) === "string") {
        return false;
    }
    if (!isInteger(value.length) || value.length < 0) {
        return false;
    }
    for (let i = 0; i < value.length; i++) {
        const v = value[i];
        if (!isInteger(v) || v < 0 || v >= 256) {
            return false;
        }
    }
    return true;
}
function arrayify(value, options) {
    if (!options) {
        options = {};
    }
    if (typeof (value) === "number") {
        logger$1.checkSafeUint53(value, "invalid arrayify value");
        const result = [];
        while (value) {
            result.unshift(value & 0xff);
            value = parseInt(String(value / 256));
        }
        if (result.length === 0) {
            result.push(0);
        }
        return addSlice(new Uint8Array(result));
    }
    if (options.allowMissingPrefix && typeof (value) === "string" && value.substring(0, 2) !== "0x") {
        value = "0x" + value;
    }
    if (isHexable(value)) {
        value = value.toHexString();
    }
    if (isHexString(value)) {
        let hex = value.substring(2);
        if (hex.length % 2) {
            if (options.hexPad === "left") {
                hex = "0" + hex;
            }
            else if (options.hexPad === "right") {
                hex += "0";
            }
            else {
                logger$1.throwArgumentError("hex data is odd-length", "value", value);
            }
        }
        const result = [];
        for (let i = 0; i < hex.length; i += 2) {
            result.push(parseInt(hex.substring(i, i + 2), 16));
        }
        return addSlice(new Uint8Array(result));
    }
    if (isBytes(value)) {
        return addSlice(new Uint8Array(value));
    }
    return logger$1.throwArgumentError("invalid arrayify value", "value", value);
}
function isHexString(value, length) {
    if (typeof (value) !== "string" || !value.match(/^0x[0-9A-Fa-f]*$/)) {
        return false;
    }
    return true;
}
const HexCharacters = "0123456789abcdef";
function hexlify(value, options) {
    if (!options) {
        options = {};
    }
    if (typeof (value) === "number") {
        logger$1.checkSafeUint53(value, "invalid hexlify value");
        let hex = "";
        while (value) {
            hex = HexCharacters[value & 0xf] + hex;
            value = Math.floor(value / 16);
        }
        if (hex.length) {
            if (hex.length % 2) {
                hex = "0" + hex;
            }
            return "0x" + hex;
        }
        return "0x00";
    }
    if (typeof (value) === "bigint") {
        value = value.toString(16);
        if (value.length % 2) {
            return ("0x0" + value);
        }
        return "0x" + value;
    }
    if (options.allowMissingPrefix && typeof (value) === "string" && value.substring(0, 2) !== "0x") {
        value = "0x" + value;
    }
    if (isHexable(value)) {
        return value.toHexString();
    }
    if (isHexString(value)) {
        if (value.length % 2) {
            if (options.hexPad === "left") {
                value = "0x0" + value.substring(2);
            }
            else if (options.hexPad === "right") {
                value += "0";
            }
            else {
                logger$1.throwArgumentError("hex data is odd-length", "value", value);
            }
        }
        return value.toLowerCase();
    }
    if (isBytes(value)) {
        let result = "0x";
        for (let i = 0; i < value.length; i++) {
            let v = value[i];
            result += HexCharacters[(v & 0xf0) >> 4] + HexCharacters[v & 0x0f];
        }
        return result;
    }
    return logger$1.throwArgumentError("invalid hexlify value", "value", value);
}

const version = "rlp/5.8.0";

const logger = new Logger(version);
function arrayifyInteger(value) {
    const result = [];
    while (value) {
        result.unshift(value & 0xff);
        value >>= 8;
    }
    return result;
}
function unarrayifyInteger(data, offset, length) {
    let result = 0;
    for (let i = 0; i < length; i++) {
        result = (result * 256) + data[offset + i];
    }
    return result;
}
function _encode(object) {
    if (Array.isArray(object)) {
        let payload = [];
        object.forEach(function (child) {
            payload = payload.concat(_encode(child));
        });
        if (payload.length <= 55) {
            payload.unshift(0xc0 + payload.length);
            return payload;
        }
        const length = arrayifyInteger(payload.length);
        length.unshift(0xf7 + length.length);
        return length.concat(payload);
    }
    if (!isBytesLike(object)) {
        logger.throwArgumentError("RLP object must be BytesLike", "object", object);
    }
    const data = Array.prototype.slice.call(arrayify(object));
    if (data.length === 1 && data[0] <= 0x7f) {
        return data;
    }
    else if (data.length <= 55) {
        data.unshift(0x80 + data.length);
        return data;
    }
    const length = arrayifyInteger(data.length);
    length.unshift(0xb7 + length.length);
    return length.concat(data);
}
function encode(object) {
    return hexlify(_encode(object));
}
function _decodeChildren(data, offset, childOffset, length) {
    const result = [];
    while (childOffset < offset + 1 + length) {
        const decoded = _decode(data, childOffset);
        result.push(decoded.result);
        childOffset += decoded.consumed;
        if (childOffset > offset + 1 + length) {
            logger.throwError("child data too short", Logger.errors.BUFFER_OVERRUN, {});
        }
    }
    return { consumed: (1 + length), result: result };
}
// returns { consumed: number, result: Object }
function _decode(data, offset) {
    if (data.length === 0) {
        logger.throwError("data too short", Logger.errors.BUFFER_OVERRUN, {});
    }
    // Array with extra length prefix
    if (data[offset] >= 0xf8) {
        const lengthLength = data[offset] - 0xf7;
        if (offset + 1 + lengthLength > data.length) {
            logger.throwError("data short segment too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const length = unarrayifyInteger(data, offset + 1, lengthLength);
        if (offset + 1 + lengthLength + length > data.length) {
            logger.throwError("data long segment too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        return _decodeChildren(data, offset, offset + 1 + lengthLength, lengthLength + length);
    }
    else if (data[offset] >= 0xc0) {
        const length = data[offset] - 0xc0;
        if (offset + 1 + length > data.length) {
            logger.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        return _decodeChildren(data, offset, offset + 1, length);
    }
    else if (data[offset] >= 0xb8) {
        const lengthLength = data[offset] - 0xb7;
        if (offset + 1 + lengthLength > data.length) {
            logger.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const length = unarrayifyInteger(data, offset + 1, lengthLength);
        if (offset + 1 + lengthLength + length > data.length) {
            logger.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const result = hexlify(data.slice(offset + 1 + lengthLength, offset + 1 + lengthLength + length));
        return { consumed: (1 + lengthLength + length), result: result };
    }
    else if (data[offset] >= 0x80) {
        const length = data[offset] - 0x80;
        if (offset + 1 + length > data.length) {
            logger.throwError("data too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const result = hexlify(data.slice(offset + 1, offset + 1 + length));
        return { consumed: (1 + length), result: result };
    }
    return { consumed: 1, result: hexlify(data[offset]) };
}
function decode(data) {
    const bytes = arrayify(data);
    const decoded = _decode(bytes, 0);
    if (decoded.consumed !== bytes.length) {
        logger.throwArgumentError("invalid rlp data", "data", data);
    }
    return decoded.result;
}

const log$9 = new Logger$1("enr:decoder");
class EnrDecoder {
    static fromString(encoded) {
        if (!encoded.startsWith(ENR.RECORD_PREFIX)) {
            throw new Error(`"string encoded ENR must start with '${ENR.RECORD_PREFIX}'`);
        }
        return EnrDecoder.fromRLP(fromString(encoded.slice(4), "base64url"));
    }
    static fromRLP(encoded) {
        const decoded = decode(encoded).map(hexToBytes$1);
        return fromValues(decoded);
    }
}
async function fromValues(values) {
    const { signature, seq, kvs } = checkValues(values);
    const obj = {};
    for (let i = 0; i < kvs.length; i += 2) {
        try {
            obj[bytesToUtf8(kvs[i])] = kvs[i + 1];
        }
        catch (e) {
            log$9.error("Failed to decode ENR key to UTF-8, skipping it", kvs[i], e);
        }
    }
    const _seq = decodeSeq(seq);
    const enr = ENR.create(obj, _seq, signature);
    checkSignature(seq, kvs, enr, signature);
    return enr;
}
function decodeSeq(seq) {
    // If seq is an empty array, translate as value 0
    if (!seq.length)
        return BigInt(0);
    return BigInt("0x" + bytesToHex$1(seq));
}
function checkValues(values) {
    if (!Array.isArray(values)) {
        throw new Error("Decoded ENR must be an array");
    }
    if (values.length % 2 !== 0) {
        throw new Error("Decoded ENR must have an even number of elements");
    }
    const [signature, seq, ...kvs] = values;
    if (!signature || Array.isArray(signature)) {
        throw new Error("Decoded ENR invalid signature: must be a byte array");
    }
    if (!seq || Array.isArray(seq)) {
        throw new Error("Decoded ENR invalid sequence number: must be a byte array");
    }
    return { signature, seq, kvs };
}
function checkSignature(seq, kvs, enr, signature) {
    const rlpEncodedBytes = hexToBytes$1(encode([seq, ...kvs]));
    if (!enr.verify(rlpEncodedBytes, signature)) {
        throw new Error("Unable to verify ENR signature");
    }
}

class QuickLRU extends Map {
	#size = 0;
	#cache = new Map();
	#oldCache = new Map();
	#maxSize;
	#maxAge;
	#onEviction;

	constructor(options = {}) {
		super();

		if (!(options.maxSize && options.maxSize > 0)) {
			throw new TypeError('`maxSize` must be a number greater than 0');
		}

		if (typeof options.maxAge === 'number' && options.maxAge === 0) {
			throw new TypeError('`maxAge` must be a number greater than 0');
		}

		this.#maxSize = options.maxSize;
		this.#maxAge = options.maxAge || Number.POSITIVE_INFINITY;
		this.#onEviction = options.onEviction;
	}

	// For tests.
	get __oldCache() {
		return this.#oldCache;
	}

	#emitEvictions(cache) {
		if (typeof this.#onEviction !== 'function') {
			return;
		}

		for (const [key, item] of cache) {
			this.#onEviction(key, item.value);
		}
	}

	#deleteIfExpired(key, item) {
		if (typeof item.expiry === 'number' && item.expiry <= Date.now()) {
			if (typeof this.#onEviction === 'function') {
				this.#onEviction(key, item.value);
			}

			return this.delete(key);
		}

		return false;
	}

	#getOrDeleteIfExpired(key, item) {
		const deleted = this.#deleteIfExpired(key, item);
		if (deleted === false) {
			return item.value;
		}
	}

	#getItemValue(key, item) {
		return item.expiry ? this.#getOrDeleteIfExpired(key, item) : item.value;
	}

	#peek(key, cache) {
		const item = cache.get(key);

		return this.#getItemValue(key, item);
	}

	#set(key, value) {
		this.#cache.set(key, value);
		this.#size++;

		if (this.#size >= this.#maxSize) {
			this.#size = 0;
			this.#emitEvictions(this.#oldCache);
			this.#oldCache = this.#cache;
			this.#cache = new Map();
		}
	}

	#moveToRecent(key, item) {
		this.#oldCache.delete(key);
		this.#set(key, item);
	}

	* #entriesAscending() {
		for (const item of this.#oldCache) {
			const [key, value] = item;
			if (!this.#cache.has(key)) {
				const deleted = this.#deleteIfExpired(key, value);
				if (deleted === false) {
					yield item;
				}
			}
		}

		for (const item of this.#cache) {
			const [key, value] = item;
			const deleted = this.#deleteIfExpired(key, value);
			if (deleted === false) {
				yield item;
			}
		}
	}

	get(key) {
		if (this.#cache.has(key)) {
			const item = this.#cache.get(key);
			return this.#getItemValue(key, item);
		}

		if (this.#oldCache.has(key)) {
			const item = this.#oldCache.get(key);
			if (this.#deleteIfExpired(key, item) === false) {
				this.#moveToRecent(key, item);
				return item.value;
			}
		}
	}

	set(key, value, {maxAge = this.#maxAge} = {}) {
		const expiry = typeof maxAge === 'number' && maxAge !== Number.POSITIVE_INFINITY
			? (Date.now() + maxAge)
			: undefined;

		if (this.#cache.has(key)) {
			this.#cache.set(key, {
				value,
				expiry,
			});
		} else {
			this.#set(key, {value, expiry});
		}

		return this;
	}

	has(key) {
		if (this.#cache.has(key)) {
			return !this.#deleteIfExpired(key, this.#cache.get(key));
		}

		if (this.#oldCache.has(key)) {
			return !this.#deleteIfExpired(key, this.#oldCache.get(key));
		}

		return false;
	}

	peek(key) {
		if (this.#cache.has(key)) {
			return this.#peek(key, this.#cache);
		}

		if (this.#oldCache.has(key)) {
			return this.#peek(key, this.#oldCache);
		}
	}

	delete(key) {
		const deleted = this.#cache.delete(key);
		if (deleted) {
			this.#size--;
		}

		return this.#oldCache.delete(key) || deleted;
	}

	clear() {
		this.#cache.clear();
		this.#oldCache.clear();
		this.#size = 0;
	}

	resize(newSize) {
		if (!(newSize && newSize > 0)) {
			throw new TypeError('`maxSize` must be a number greater than 0');
		}

		const items = [...this.#entriesAscending()];
		const removeCount = items.length - newSize;
		if (removeCount < 0) {
			this.#cache = new Map(items);
			this.#oldCache = new Map();
			this.#size = items.length;
		} else {
			if (removeCount > 0) {
				this.#emitEvictions(items.slice(0, removeCount));
			}

			this.#oldCache = new Map(items.slice(removeCount));
			this.#cache = new Map();
			this.#size = 0;
		}

		this.#maxSize = newSize;
	}

	* keys() {
		for (const [key] of this) {
			yield key;
		}
	}

	* values() {
		for (const [, value] of this) {
			yield value;
		}
	}

	* [Symbol.iterator]() {
		for (const item of this.#cache) {
			const [key, value] = item;
			const deleted = this.#deleteIfExpired(key, value);
			if (deleted === false) {
				yield [key, value.value];
			}
		}

		for (const item of this.#oldCache) {
			const [key, value] = item;
			if (!this.#cache.has(key)) {
				const deleted = this.#deleteIfExpired(key, value);
				if (deleted === false) {
					yield [key, value.value];
				}
			}
		}
	}

	* entriesDescending() {
		let items = [...this.#cache];
		for (let i = items.length - 1; i >= 0; --i) {
			const item = items[i];
			const [key, value] = item;
			const deleted = this.#deleteIfExpired(key, value);
			if (deleted === false) {
				yield [key, value.value];
			}
		}

		items = [...this.#oldCache];
		for (let i = items.length - 1; i >= 0; --i) {
			const item = items[i];
			const [key, value] = item;
			if (!this.#cache.has(key)) {
				const deleted = this.#deleteIfExpired(key, value);
				if (deleted === false) {
					yield [key, value.value];
				}
			}
		}
	}

	* entriesAscending() {
		for (const [key, value] of this.#entriesAscending()) {
			yield [key, value.value];
		}
	}

	get size() {
		if (!this.#size) {
			return this.#oldCache.size;
		}

		let oldCacheSize = 0;
		for (const key of this.#oldCache.keys()) {
			if (!this.#cache.has(key)) {
				oldCacheSize++;
			}
		}

		return Math.min(this.#size + oldCacheSize, this.#maxSize);
	}

	get maxSize() {
		return this.#maxSize;
	}

	entries() {
		return this.entriesAscending();
	}

	forEach(callbackFunction, thisArgument = this) {
		for (const [key, value] of this.entriesAscending()) {
			callbackFunction.call(thisArgument, value, key, this);
		}
	}

	get [Symbol.toStringTag]() {
		return 'QuickLRU';
	}

	toString() {
		return `QuickLRU(${this.size}/${this.maxSize})`;
	}

	[Symbol.for('nodejs.util.inspect.custom')]() {
		return this.toString();
	}
}

/**
 * Build fetch resource for request
 */
function buildResource(serverResolver, hostname, recordType) {
    return `${serverResolver}?name=${hostname}&type=${recordType}`;
}
/**
 * Use fetch to find the record
 */
async function request(resource, signal) {
    const req = await fetch(resource, {
        headers: new Headers({
            accept: 'application/dns-json'
        }),
        signal
    });
    const res = await req.json();
    return res;
}
/**
 * Creates cache key composed by recordType and hostname
 *
 * @param {string} hostname
 * @param {string} recordType
 */
function getCacheKey(hostname, recordType) {
    return `${recordType}_${hostname}`;
}

const log$8 = Object.assign(weald('dns-over-http-resolver'), {
    error: weald('dns-over-http-resolver:error')
});
/**
 * DNS over HTTP resolver.
 * Uses a list of servers to resolve DNS records with HTTP requests.
 */
class Resolver {
    _cache;
    _TXTcache;
    _servers;
    _request;
    _abortControllers;
    /**
     * @class
     * @param {object} [options]
     * @param {number} [options.maxCache = 100] - maximum number of cached dns records
     * @param {Request} [options.request] - function to return DNSJSON
     */
    constructor(options = {}) {
        this._cache = new QuickLRU({ maxSize: options?.maxCache ?? 100 });
        this._TXTcache = new QuickLRU({ maxSize: options?.maxCache ?? 100 });
        this._servers = [
            'https://cloudflare-dns.com/dns-query',
            'https://dns.google/resolve'
        ];
        this._request = options.request ?? request;
        this._abortControllers = [];
    }
    /**
     * Cancel all outstanding DNS queries made by this resolver. Any outstanding
     * requests will be aborted and promises rejected.
     */
    cancel() {
        this._abortControllers.forEach(controller => { controller.abort(); });
    }
    /**
     * Get an array of the IP addresses currently configured for DNS resolution.
     * These addresses are formatted according to RFC 5952. It can include a custom port.
     */
    getServers() {
        return this._servers;
    }
    /**
     * Get a shuffled array of the IP addresses currently configured for DNS resolution.
     * These addresses are formatted according to RFC 5952. It can include a custom port.
     */
    _getShuffledServers() {
        const newServers = [...this._servers];
        for (let i = newServers.length - 1; i > 0; i--) {
            const j = Math.floor(Math.random() * i);
            const temp = newServers[i];
            newServers[i] = newServers[j];
            newServers[j] = temp;
        }
        return newServers;
    }
    /**
     * Sets the IP address and port of servers to be used when performing DNS resolution.
     *
     * @param {string[]} servers - array of RFC 5952 formatted addresses.
     */
    setServers(servers) {
        this._servers = servers;
    }
    async resolve(hostname, rrType = 'A') {
        switch (rrType) {
            case 'A':
                return this.resolve4(hostname);
            case 'AAAA':
                return this.resolve6(hostname);
            case 'TXT':
                return this.resolveTxt(hostname);
            default:
                throw new Error(`${rrType} is not supported`);
        }
    }
    /**
     * Uses the DNS protocol to resolve the given host name into IPv4 addresses
     *
     * @param {string} hostname - host name to resolve
     */
    async resolve4(hostname) {
        const recordType = 'A';
        const cached = this._cache.get(getCacheKey(hostname, recordType));
        if (cached != null) {
            return cached;
        }
        let aborted = false;
        for (const server of this._getShuffledServers()) {
            const controller = new AbortController();
            this._abortControllers.push(controller);
            try {
                const response = await this._request(buildResource(server, hostname, recordType), controller.signal);
                const data = response.Answer.map(a => a.data);
                const ttl = Math.min(...response.Answer.map(a => a.TTL));
                this._cache.set(getCacheKey(hostname, recordType), data, { maxAge: ttl });
                return data;
            }
            catch (err) {
                if (controller.signal.aborted) {
                    aborted = true;
                }
                log$8.error(`${server} could not resolve ${hostname} record ${recordType}`);
            }
            finally {
                this._abortControllers = this._abortControllers.filter(c => c !== controller);
            }
        }
        if (aborted) {
            throw Object.assign(new Error('queryA ECANCELLED'), {
                code: 'ECANCELLED'
            });
        }
        throw new Error(`Could not resolve ${hostname} record ${recordType}`);
    }
    /**
     * Uses the DNS protocol to resolve the given host name into IPv6 addresses
     *
     * @param {string} hostname - host name to resolve
     */
    async resolve6(hostname) {
        const recordType = 'AAAA';
        const cached = this._cache.get(getCacheKey(hostname, recordType));
        if (cached != null) {
            return cached;
        }
        let aborted = false;
        for (const server of this._getShuffledServers()) {
            const controller = new AbortController();
            this._abortControllers.push(controller);
            try {
                const response = await this._request(buildResource(server, hostname, recordType), controller.signal);
                const data = response.Answer.map(a => a.data);
                const ttl = Math.min(...response.Answer.map(a => a.TTL));
                this._cache.set(getCacheKey(hostname, recordType), data, { maxAge: ttl });
                return data;
            }
            catch (err) {
                if (controller.signal.aborted) {
                    aborted = true;
                }
                log$8.error(`${server} could not resolve ${hostname} record ${recordType}`);
            }
            finally {
                this._abortControllers = this._abortControllers.filter(c => c !== controller);
            }
        }
        if (aborted) {
            throw Object.assign(new Error('queryAaaa ECANCELLED'), {
                code: 'ECANCELLED'
            });
        }
        throw new Error(`Could not resolve ${hostname} record ${recordType}`);
    }
    /**
     * Uses the DNS protocol to resolve the given host name into a Text record
     *
     * @param {string} hostname - host name to resolve
     */
    async resolveTxt(hostname) {
        const recordType = 'TXT';
        const cached = this._TXTcache.get(getCacheKey(hostname, recordType));
        if (cached != null) {
            return cached;
        }
        let aborted = false;
        for (const server of this._getShuffledServers()) {
            const controller = new AbortController();
            this._abortControllers.push(controller);
            try {
                const response = await this._request(buildResource(server, hostname, recordType), controller.signal);
                const data = response.Answer.map(a => [a.data.replace(/['"]+/g, '')]);
                const ttl = Math.min(...response.Answer.map(a => a.TTL));
                this._TXTcache.set(getCacheKey(hostname, recordType), data, { maxAge: ttl });
                return data;
            }
            catch (err) {
                if (controller.signal.aborted) {
                    aborted = true;
                }
                log$8.error(`${server} could not resolve ${hostname} record ${recordType}`);
            }
            finally {
                this._abortControllers = this._abortControllers.filter(c => c !== controller);
            }
        }
        if (aborted) {
            throw Object.assign(new Error('queryTxt ECANCELLED'), {
                code: 'ECANCELLED'
            });
        }
        throw new Error(`Could not resolve ${hostname} record ${recordType}`);
    }
    clearCache() {
        this._cache.clear();
        this._TXTcache.clear();
    }
}

const log$7 = new Logger$1("dns-over-https");
class DnsOverHttps {
    resolver;
    /**
     * Create new Dns-Over-Http DNS client.
     *
     * @throws {code: string} If DNS query fails.
     */
    static async create() {
        return new DnsOverHttps();
    }
    constructor(resolver = new Resolver()) {
        this.resolver = resolver;
    }
    /**
     * Resolves a TXT record
     *
     * @param domain The domain name
     *
     * @throws if the query fails
     */
    async resolveTXT(domain) {
        let answers;
        try {
            answers = await this.resolver.resolveTxt(domain);
        }
        catch (error) {
            log$7.error("query failed: ", error);
            throw new Error("DNS query failed");
        }
        if (!answers)
            throw new Error(`Could not resolve ${domain}`);
        const result = [];
        answers.forEach((d) => {
            if (typeof d === "string") {
                result.push(d);
            }
            else if (Array.isArray(d)) {
                d.forEach((sd) => {
                    if (typeof sd === "string") {
                        result.push(sd);
                    }
                    else {
                        result.push(bytesToUtf8(sd));
                    }
                });
            }
            else {
                result.push(bytesToUtf8(d));
            }
        });
        return result;
    }
}

var base32$1 = {exports: {}};

/*
 * [hi-base32]{@link https://github.com/emn178/hi-base32}
 *
 * @version 0.5.0
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2015-2018
 * @license MIT
 */

(function (module) {
	/*jslint bitwise: true */
	(function () {

	  var root = typeof window === 'object' ? window : {};
	  var NODE_JS = !root.HI_BASE32_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;
	  if (NODE_JS) {
	    root = commonjsGlobal;
	  }
	  var COMMON_JS = !root.HI_BASE32_NO_COMMON_JS && 'object' === 'object' && module.exports;
	  var BASE32_ENCODE_CHAR = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'.split('');
	  var BASE32_DECODE_CHAR = {
	    'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8,
	    'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16,
	    'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24,
	    'Z': 25, '2': 26, '3': 27, '4': 28, '5': 29, '6': 30, '7': 31
	  };

	  var blocks = [0, 0, 0, 0, 0, 0, 0, 0];

	  var throwInvalidUtf8 = function (position, partial) {
	    if (partial.length > 10) {
	      partial = '...' + partial.substr(-10);
	    }
	    var err = new Error('Decoded data is not valid UTF-8.'
	      + ' Maybe try base32.decode.asBytes()?'
	      + ' Partial data after reading ' + position + ' bytes: ' + partial + ' <-');
	    err.position = position;
	    throw err;
	  };

	  var toUtf8String = function (bytes) {
	    var str = '', length = bytes.length, i = 0, followingChars = 0, b, c;
	    while (i < length) {
	      b = bytes[i++];
	      if (b <= 0x7F) {
	        str += String.fromCharCode(b);
	        continue;
	      } else if (b > 0xBF && b <= 0xDF) {
	        c = b & 0x1F;
	        followingChars = 1;
	      } else if (b <= 0xEF) {
	        c = b & 0x0F;
	        followingChars = 2;
	      } else if (b <= 0xF7) {
	        c = b & 0x07;
	        followingChars = 3;
	      } else {
	        throwInvalidUtf8(i, str);
	      }

	      for (var j = 0; j < followingChars; ++j) {
	        b = bytes[i++];
	        if (b < 0x80 || b > 0xBF) {
	          throwInvalidUtf8(i, str);
	        }
	        c <<= 6;
	        c += b & 0x3F;
	      }
	      if (c >= 0xD800 && c <= 0xDFFF) {
	        throwInvalidUtf8(i, str);
	      }
	      if (c > 0x10FFFF) {
	        throwInvalidUtf8(i, str);
	      }

	      if (c <= 0xFFFF) {
	        str += String.fromCharCode(c);
	      } else {
	        c -= 0x10000;
	        str += String.fromCharCode((c >> 10) + 0xD800);
	        str += String.fromCharCode((c & 0x3FF) + 0xDC00);
	      }
	    }
	    return str;
	  };

	  var decodeAsBytes = function (base32Str) {
	    if (base32Str === '') {
	      return [];
	    } else if (!/^[A-Z2-7=]+$/.test(base32Str)) {
	      throw new Error('Invalid base32 characters');
	    }
	    base32Str = base32Str.replace(/=/g, '');
	    var v1, v2, v3, v4, v5, v6, v7, v8, bytes = [], index = 0, length = base32Str.length;

	    // 4 char to 3 bytes
	    for (var i = 0, count = length >> 3 << 3; i < count;) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v8 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	      bytes[index++] = (v5 << 7 | v6 << 2 | v7 >>> 3) & 255;
	      bytes[index++] = (v7 << 5 | v8) & 255;
	    }

	    // remain bytes
	    var remain = length - count;
	    if (remain === 2) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	    } else if (remain === 4) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	    } else if (remain === 5) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	    } else if (remain === 7) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	      bytes[index++] = (v5 << 7 | v6 << 2 | v7 >>> 3) & 255;
	    }
	    return bytes;
	  };

	  var encodeAscii = function (str) {
	    var v1, v2, v3, v4, v5, base32Str = '', length = str.length;
	    for (var i = 0, count = parseInt(length / 5) * 5; i < count;) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i++);
	      v4 = str.charCodeAt(i++);
	      v5 = str.charCodeAt(i++);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	        BASE32_ENCODE_CHAR[v5 & 31];
	    }

	    // remain char
	    var remain = length - count;
	    if (remain === 1) {
	      v1 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	        '======';
	    } else if (remain === 2) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	        '====';
	    } else if (remain === 3) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	        '===';
	    } else if (remain === 4) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i++);
	      v4 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	        '=';
	    }
	    return base32Str;
	  };

	  var encodeUtf8 = function (str) {
	    var v1, v2, v3, v4, v5, code, end = false, base32Str = '',
	      index = 0, i, start = 0, length = str.length;
	      if (str === '') {
	        return base32Str;
	      }
	    do {
	      blocks[0] = blocks[5];
	      blocks[1] = blocks[6];
	      blocks[2] = blocks[7];
	      for (i = start; index < length && i < 5; ++index) {
	        code = str.charCodeAt(index);
	        if (code < 0x80) {
	          blocks[i++] = code;
	        } else if (code < 0x800) {
	          blocks[i++] = 0xc0 | (code >> 6);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        } else if (code < 0xd800 || code >= 0xe000) {
	          blocks[i++] = 0xe0 | (code >> 12);
	          blocks[i++] = 0x80 | ((code >> 6) & 0x3f);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        } else {
	          code = 0x10000 + (((code & 0x3ff) << 10) | (str.charCodeAt(++index) & 0x3ff));
	          blocks[i++] = 0xf0 | (code >> 18);
	          blocks[i++] = 0x80 | ((code >> 12) & 0x3f);
	          blocks[i++] = 0x80 | ((code >> 6) & 0x3f);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        }
	      }
	      start = i - 5;
	      if (index === length) {
	        ++index;
	      }
	      if (index > length && i < 6) {
	        end = true;
	      }
	      v1 = blocks[0];
	      if (i > 4) {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        v4 = blocks[3];
	        v5 = blocks[4];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	          BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	          BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	          BASE32_ENCODE_CHAR[v5 & 31];
	      } else if (i === 1) {
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	          '======';
	      } else if (i === 2) {
	        v2 = blocks[1];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	          '====';
	      } else if (i === 3) {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	          '===';
	      } else {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        v4 = blocks[3];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	          BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	          BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	          '=';
	      }
	    } while (!end);
	    return base32Str;
	  };

	  var encodeBytes = function (bytes) {
	    var v1, v2, v3, v4, v5, base32Str = '', length = bytes.length;
	    for (var i = 0, count = parseInt(length / 5) * 5; i < count;) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i++];
	      v4 = bytes[i++];
	      v5 = bytes[i++];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	        BASE32_ENCODE_CHAR[v5 & 31];
	    }

	    // remain char
	    var remain = length - count;
	    if (remain === 1) {
	      v1 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	        '======';
	    } else if (remain === 2) {
	      v1 = bytes[i++];
	      v2 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	        '====';
	    } else if (remain === 3) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	        '===';
	    } else if (remain === 4) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i++];
	      v4 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	        '=';
	    }
	    return base32Str;
	  };

	  var encode = function (input, asciiOnly) {
	    var notString = typeof(input) !== 'string';
	    if (notString && input.constructor === ArrayBuffer) {
	      input = new Uint8Array(input);
	    }
	    if (notString) {
	      return encodeBytes(input);
	    } else if (asciiOnly) {
	      return encodeAscii(input);
	    } else {
	      return encodeUtf8(input);
	    }
	  };

	  var decode = function (base32Str, asciiOnly) {
	    if (!asciiOnly) {
	      return toUtf8String(decodeAsBytes(base32Str));
	    }
	    if (base32Str === '') {
	      return '';
	    } else if (!/^[A-Z2-7=]+$/.test(base32Str)) {
	      throw new Error('Invalid base32 characters');
	    }
	    var v1, v2, v3, v4, v5, v6, v7, v8, str = '', length = base32Str.indexOf('=');
	    if (length === -1) {
	      length = base32Str.length;
	    }

	    // 8 char to 5 bytes
	    for (var i = 0, count = length >> 3 << 3; i < count;) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v8 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255) +
	        String.fromCharCode((v5 << 7 | v6 << 2 | v7 >>> 3) & 255) +
	        String.fromCharCode((v7 << 5 | v8) & 255);
	    }

	    // remain bytes
	    var remain = length - count;
	    if (remain === 2) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255);
	    } else if (remain === 4) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255);
	    } else if (remain === 5) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255);
	    } else if (remain === 7) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255) +
	        String.fromCharCode((v5 << 7 | v6 << 2 | v7 >>> 3) & 255);
	    }
	    return str;
	  };

	  var exports = {
	    encode: encode,
	    decode: decode
	  };
	  decode.asBytes = decodeAsBytes;

	  if (COMMON_JS) {
	    module.exports = exports;
	  } else {
	    root.base32 = exports;
	  }
	})(); 
} (base32$1));

var base32Exports = base32$1.exports;
var base32 = /*@__PURE__*/getDefaultExportFromCjs(base32Exports);

class ENRTree {
    static RECORD_PREFIX = ENR.RECORD_PREFIX;
    static TREE_PREFIX = "enrtree:";
    static BRANCH_PREFIX = "enrtree-branch:";
    static ROOT_PREFIX = "enrtree-root:";
    /**
     * Extracts the branch subdomain referenced by a DNS tree root string after verifying
     * the root record signature with its base32 compressed public key.
     */
    static parseAndVerifyRoot(root, publicKey) {
        if (!root.startsWith(this.ROOT_PREFIX))
            throw new Error(`ENRTree root entry must start with '${this.ROOT_PREFIX}'`);
        const rootValues = ENRTree.parseRootValues(root);
        const decodedPublicKey = base32.decode.asBytes(publicKey);
        // The signature is a 65-byte secp256k1 over the keccak256 hash
        // of the record content, excluding the `sig=` part, encoded as URL-safe base64 string
        // (Trailing recovery bit must be trimmed to pass `ecdsaVerify` method)
        const signedComponent = root.split(" sig")[0];
        const signedComponentBuffer = utf8ToBytes$1(signedComponent);
        const signatureBuffer = fromString(rootValues.signature, "base64url").slice(0, 64);
        const isVerified = verifySignature(signatureBuffer, keccak256(signedComponentBuffer), new Uint8Array(decodedPublicKey));
        if (!isVerified)
            throw new Error("Unable to verify ENRTree root signature");
        return rootValues.eRoot;
    }
    static parseRootValues(txt) {
        const matches = txt.match(/^enrtree-root:v1 e=([^ ]+) l=([^ ]+) seq=(\d+) sig=([^ ]+)$/);
        if (!Array.isArray(matches))
            throw new Error("Could not parse ENRTree root entry");
        matches.shift(); // The first entry is the full match
        const [eRoot, lRoot, seq, signature] = matches;
        if (!eRoot)
            throw new Error("Could not parse 'e' value from ENRTree root entry");
        if (!lRoot)
            throw new Error("Could not parse 'l' value from ENRTree root entry");
        if (!seq)
            throw new Error("Could not parse 'seq' value from ENRTree root entry");
        if (!signature)
            throw new Error("Could not parse 'sig' value from ENRTree root entry");
        return { eRoot, lRoot, seq: Number(seq), signature };
    }
    /**
     * Returns the public key and top level domain of an ENR tree entry.
     * The domain is the starting point for traversing a set of linked DNS TXT records
     * and the public key is used to verify the root entry record
     */
    static parseTree(tree) {
        if (!tree.startsWith(this.TREE_PREFIX))
            throw new Error(`ENRTree tree entry must start with '${this.TREE_PREFIX}'`);
        const matches = tree.match(/^enrtree:\/\/([^@]+)@(.+)$/);
        if (!Array.isArray(matches))
            throw new Error("Could not parse ENRTree tree entry");
        matches.shift(); // The first entry is the full match
        const [publicKey, domain] = matches;
        if (!publicKey)
            throw new Error("Could not parse public key from ENRTree tree entry");
        if (!domain)
            throw new Error("Could not parse domain from ENRTree tree entry");
        return { publicKey, domain };
    }
    /**
     * Returns subdomains listed in an ENR branch entry. These in turn lead to
     * either further branch entries or ENR records.
     */
    static parseBranch(branch) {
        if (!branch.startsWith(this.BRANCH_PREFIX))
            throw new Error(`ENRTree branch entry must start with '${this.BRANCH_PREFIX}'`);
        return branch.split(this.BRANCH_PREFIX)[1].split(",");
    }
}

const log$6 = new Logger$1("discovery:fetch_nodes");
/**
 * Fetch nodes using passed [[getNode]] until all wanted capabilities are
 * fulfilled or the number of [[getNode]] call exceeds the sum of
 * [[wantedNodeCapabilityCount]] plus [[errorTolerance]].
 */
async function fetchNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, errorTolerance, getNode) {
    const wanted = {
        relay: wantedNodeCapabilityCount.relay ?? 0,
        store: wantedNodeCapabilityCount.store ?? 0,
        filter: wantedNodeCapabilityCount.filter ?? 0,
        lightPush: wantedNodeCapabilityCount.lightPush ?? 0
    };
    const maxSearches = wanted.relay + wanted.store + wanted.filter + wanted.lightPush;
    const actual = {
        relay: 0,
        store: 0,
        filter: 0,
        lightPush: 0
    };
    let totalSearches = 0;
    const peers = [];
    while (!isSatisfied(wanted, actual) &&
        totalSearches < maxSearches + errorTolerance) {
        const peer = await getNode();
        if (peer && isNewPeer(peer, peers)) {
            // ENRs without a waku2 key are ignored.
            if (peer.waku2) {
                if (helpsSatisfyCapabilities(peer.waku2, wanted, actual)) {
                    addCapabilities(peer.waku2, actual);
                    peers.push(peer);
                }
            }
            log$6.info(`got new peer candidate from DNS address=${peer.nodeId}@${peer.ip}`);
        }
        totalSearches++;
    }
    return peers;
}
/**
 * Fetch nodes using passed [[getNode]] until all wanted capabilities are
 * fulfilled or the number of [[getNode]] call exceeds the sum of
 * [[wantedNodeCapabilityCount]] plus [[errorTolerance]].
 */
async function* yieldNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, errorTolerance, getNode) {
    const wanted = {
        relay: wantedNodeCapabilityCount.relay ?? 0,
        store: wantedNodeCapabilityCount.store ?? 0,
        filter: wantedNodeCapabilityCount.filter ?? 0,
        lightPush: wantedNodeCapabilityCount.lightPush ?? 0
    };
    const maxSearches = wanted.relay + wanted.store + wanted.filter + wanted.lightPush;
    const actual = {
        relay: 0,
        store: 0,
        filter: 0,
        lightPush: 0
    };
    let totalSearches = 0;
    const peerNodeIds = new Set();
    while (!isSatisfied(wanted, actual) &&
        totalSearches < maxSearches + errorTolerance) {
        const peer = await getNode();
        if (peer && peer.nodeId && !peerNodeIds.has(peer.nodeId)) {
            peerNodeIds.add(peer.nodeId);
            // ENRs without a waku2 key are ignored.
            if (peer.waku2) {
                if (helpsSatisfyCapabilities(peer.waku2, wanted, actual)) {
                    addCapabilities(peer.waku2, actual);
                    yield peer;
                }
            }
            log$6.info(`got new peer candidate from DNS address=${peer.nodeId}@${peer.ip}`);
        }
        totalSearches++;
    }
}
function isSatisfied(wanted, actual) {
    return (actual.relay >= wanted.relay &&
        actual.store >= wanted.store &&
        actual.filter >= wanted.filter &&
        actual.lightPush >= wanted.lightPush);
}
function isNewPeer(peer, peers) {
    if (!peer.nodeId)
        return false;
    for (const existingPeer of peers) {
        if (peer.nodeId === existingPeer.nodeId) {
            return false;
        }
    }
    return true;
}
function addCapabilities(node, total) {
    if (node.relay)
        total.relay += 1;
    if (node.store)
        total.store += 1;
    if (node.filter)
        total.filter += 1;
    if (node.lightPush)
        total.lightPush += 1;
}
/**
 * Checks if the proposed ENR [[node]] helps satisfy the [[wanted]] capabilities,
 * considering the [[actual]] capabilities of nodes retrieved so far..
 *
 * @throws If the function is called when the wanted capabilities are already fulfilled.
 */
function helpsSatisfyCapabilities(node, wanted, actual) {
    if (isSatisfied(wanted, actual)) {
        throw "Internal Error: Waku2 wanted capabilities are already fulfilled";
    }
    const missing = missingCapabilities(wanted, actual);
    return ((missing.relay && node.relay) ||
        (missing.store && node.store) ||
        (missing.filter && node.filter) ||
        (missing.lightPush && node.lightPush));
}
/**
 * Return a [[Waku2]] Object for which capabilities are set to true if they are
 * [[wanted]] yet missing from [[actual]].
 */
function missingCapabilities(wanted, actual) {
    return {
        relay: actual.relay < wanted.relay,
        store: actual.store < wanted.store,
        filter: actual.filter < wanted.filter,
        lightPush: actual.lightPush < wanted.lightPush
    };
}

const log$5 = new Logger$1("discovery:dns");
class DnsNodeDiscovery {
    dns;
    _DNSTreeCache;
    _errorTolerance = 10;
    static async dnsOverHttp(dnsClient) {
        if (!dnsClient) {
            dnsClient = await DnsOverHttps.create();
        }
        return new DnsNodeDiscovery(dnsClient);
    }
    /**
     * Returns a list of verified peers listed in an EIP-1459 DNS tree. Method may
     * return fewer peers than requested if @link wantedNodeCapabilityCount requires
     * larger quantity of peers than available or the number of errors/duplicate
     * peers encountered by randomized search exceeds the sum of the fields of
     * @link wantedNodeCapabilityCount plus the @link _errorTolerance factor.
     */
    async getPeers(enrTreeUrls, wantedNodeCapabilityCount) {
        const networkIndex = Math.floor(Math.random() * enrTreeUrls.length);
        const { publicKey, domain } = ENRTree.parseTree(enrTreeUrls[networkIndex]);
        const context = {
            domain,
            publicKey,
            visits: {}
        };
        const peers = await fetchNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, this._errorTolerance, () => this._search(domain, context));
        log$5.info("retrieved peers: ", peers.map((peer) => {
            return {
                id: peer.peerId?.toString(),
                multiaddrs: peer.multiaddrs?.map((ma) => ma.toString())
            };
        }));
        return peers;
    }
    constructor(dns) {
        this._DNSTreeCache = {};
        this.dns = dns;
    }
    /**
     * {@inheritDoc getPeers}
     */
    async *getNextPeer(enrTreeUrls, wantedNodeCapabilityCount) {
        const networkIndex = Math.floor(Math.random() * enrTreeUrls.length);
        const { publicKey, domain } = ENRTree.parseTree(enrTreeUrls[networkIndex]);
        const context = {
            domain,
            publicKey,
            visits: {}
        };
        for await (const peer of yieldNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, this._errorTolerance, () => this._search(domain, context))) {
            yield peer;
        }
    }
    /**
     * Runs a recursive, randomized descent of the DNS tree to retrieve a single
     * ENR record as an ENR. Returns null if parsing or DNS resolution fails.
     */
    async _search(subdomain, context) {
        try {
            const entry = await this._getTXTRecord(subdomain, context);
            context.visits[subdomain] = true;
            let next;
            let branches;
            const entryType = getEntryType(entry);
            try {
                switch (entryType) {
                    case ENRTree.ROOT_PREFIX:
                        next = ENRTree.parseAndVerifyRoot(entry, context.publicKey);
                        return await this._search(next, context);
                    case ENRTree.BRANCH_PREFIX:
                        branches = ENRTree.parseBranch(entry);
                        next = selectRandomPath(branches, context);
                        return await this._search(next, context);
                    case ENRTree.RECORD_PREFIX:
                        return EnrDecoder.fromString(entry);
                    default:
                        return null;
                }
            }
            catch (error) {
                log$5.error(`Failed to search DNS tree ${entryType} at subdomain ${subdomain}: ${error}`);
                return null;
            }
        }
        catch (error) {
            log$5.error(`Failed to retrieve TXT record at subdomain ${subdomain}: ${error}`);
            return null;
        }
    }
    /**
     * Retrieves the TXT record stored at a location from either
     * this DNS tree cache or via DNS query.
     *
     * @throws if the TXT Record contains non-UTF-8 values.
     */
    async _getTXTRecord(subdomain, context) {
        if (this._DNSTreeCache[subdomain]) {
            return this._DNSTreeCache[subdomain];
        }
        // Location is either the top level tree entry host or a subdomain of it.
        const location = subdomain !== context.domain
            ? `${subdomain}.${context.domain}`
            : context.domain;
        const response = await this.dns.resolveTXT(location);
        if (!response.length)
            throw new Error("Received empty result array while fetching TXT record");
        if (!response[0].length)
            throw new Error("Received empty TXT record");
        // Branch entries can be an array of strings of comma delimited subdomains, with
        // some subdomain strings split across the array elements
        const result = response.join("");
        this._DNSTreeCache[subdomain] = result;
        return result;
    }
}
function getEntryType(entry) {
    if (entry.startsWith(ENRTree.ROOT_PREFIX))
        return ENRTree.ROOT_PREFIX;
    if (entry.startsWith(ENRTree.BRANCH_PREFIX))
        return ENRTree.BRANCH_PREFIX;
    if (entry.startsWith(ENRTree.RECORD_PREFIX))
        return ENRTree.RECORD_PREFIX;
    return "";
}
/**
 * Returns a randomly selected subdomain string from the list provided by a branch
 * entry record.
 *
 * The client must track subdomains which are already resolved to avoid
 * going into an infinite loop b/c branch entries can contain
 * circular references. It’s in the client’s best interest to traverse the
 * tree in random order.
 */
function selectRandomPath(branches, context) {
    // Identify domains already visited in this traversal of the DNS tree.
    // Then filter against them to prevent cycles.
    const circularRefs = {};
    for (const [idx, subdomain] of branches.entries()) {
        if (context.visits[subdomain]) {
            circularRefs[idx] = true;
        }
    }
    // If all possible paths are circular...
    if (Object.keys(circularRefs).length === branches.length) {
        throw new Error("Unresolvable circular path detected");
    }
    // Randomly select a viable path
    let index;
    do {
        index = Math.floor(Math.random() * branches.length);
    } while (circularRefs[index]);
    return branches[index];
}

const log$4 = new Logger$1("peer-discovery-dns");
/**
 * Parse options and expose function to return bootstrap peer addresses.
 */
class PeerDiscoveryDns extends TypedEventEmitter {
    nextPeer;
    _started;
    _components;
    _options;
    constructor(components, options) {
        super();
        this._started = false;
        this._components = components;
        this._options = options;
        const { enrUrls } = options;
        log$4.info("Use following EIP-1459 ENR Tree URLs: ", enrUrls);
    }
    /**
     * Start discovery process
     */
    async start() {
        log$4.info("Starting peer discovery via dns");
        this._started = true;
        await this.findPeers();
    }
    async findPeers() {
        if (!this.nextPeer) {
            let { enrUrls } = this._options;
            if (!Array.isArray(enrUrls))
                enrUrls = [enrUrls];
            const { wantedNodeCapabilityCount } = this._options;
            const dns = await DnsNodeDiscovery.dnsOverHttp();
            this.nextPeer = dns.getNextPeer.bind(dns, enrUrls, wantedNodeCapabilityCount);
        }
        for await (const peerEnr of this.nextPeer()) {
            if (!this._started) {
                return;
            }
            const { peerInfo, shardInfo } = peerEnr;
            if (!peerInfo) {
                continue;
            }
            const tagsToUpdate = {
                [DEFAULT_BOOTSTRAP_TAG_NAME]: {
                    value: this._options.tagValue ?? DEFAULT_BOOTSTRAP_TAG_VALUE,
                    ttl: this._options.tagTTL ?? DEFAULT_BOOTSTRAP_TAG_TTL
                }
            };
            let isPeerChanged = false;
            const isPeerExists = await this._components.peerStore.has(peerInfo.id);
            if (isPeerExists) {
                const peer = await this._components.peerStore.get(peerInfo.id);
                const hasBootstrapTag = peer.tags.has(DEFAULT_BOOTSTRAP_TAG_NAME);
                if (!hasBootstrapTag) {
                    isPeerChanged = true;
                    await this._components.peerStore.merge(peerInfo.id, {
                        tags: tagsToUpdate
                    });
                }
            }
            else {
                isPeerChanged = true;
                await this._components.peerStore.save(peerInfo.id, {
                    tags: tagsToUpdate,
                    ...(shardInfo && {
                        metadata: {
                            shardInfo: encodeRelayShard(shardInfo)
                        }
                    })
                });
            }
            if (isPeerChanged) {
                this.dispatchEvent(new CustomEvent("peer", { detail: peerInfo }));
            }
        }
    }
    /**
     * Stop emitting events
     */
    stop() {
        this._started = false;
    }
    get [peerDiscoverySymbol]() {
        return true;
    }
    get [Symbol.toStringTag]() {
        return DNS_DISCOVERY_TAG;
    }
}
function wakuDnsDiscovery(enrUrls, wantedNodeCapabilityCount = DEFAULT_NODE_REQUIREMENTS) {
    return (components) => new PeerDiscoveryDns(components, { enrUrls, wantedNodeCapabilityCount });
}

/**
 * PeerExchangeRPC represents a message conforming to the Waku Peer Exchange protocol
 */
class PeerExchangeRPC {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createRequest(params) {
        const { numPeers } = params;
        return new PeerExchangeRPC({
            query: {
                numPeers: numPeers
            },
            response: undefined
        });
    }
    /**
     * Encode the current PeerExchangeRPC request to bytes
     * @returns Uint8Array
     */
    encode() {
        return PeerExchangeRPC$1.encode(this.proto);
    }
    /**
     * Decode the current PeerExchangeRPC request to bytes
     * @returns Uint8Array
     */
    static decode(bytes) {
        const res = PeerExchangeRPC$1.decode(bytes);
        return new PeerExchangeRPC(res);
    }
    get query() {
        return this.proto.query;
    }
    get response() {
        return this.proto.response;
    }
}

const PeerExchangeCodec = "/vac/waku/peer-exchange/2.0.0-alpha1";
const log$3 = new Logger$1("peer-exchange");
/**
 * Implementation of the Peer Exchange protocol (https://rfc.vac.dev/spec/34/)
 */
class WakuPeerExchange {
    components;
    streamManager;
    /**
     * @param components - libp2p components
     */
    constructor(components) {
        this.components = components;
        this.streamManager = new StreamManager(PeerExchangeCodec, components);
    }
    /**
     * Make a peer exchange query to a peer
     */
    async query(params) {
        const { numPeers, peerId } = params;
        const rpcQuery = PeerExchangeRPC.createRequest({
            numPeers: BigInt(numPeers)
        });
        const peer = await this.components.peerStore.get(peerId);
        if (!peer) {
            return {
                peerInfos: null,
                error: ProtocolError$1.NO_PEER_AVAILABLE
            };
        }
        let stream;
        try {
            stream = await this.streamManager.getStream(peerId);
        }
        catch (err) {
            log$3.error("Failed to get stream", err);
            return {
                peerInfos: null,
                error: ProtocolError$1.NO_STREAM_AVAILABLE
            };
        }
        const res = await pipe([rpcQuery.encode()], encode$3, stream, decode$2, async (source) => await all$1(source));
        try {
            const bytes = new Uint8ArrayList();
            res.forEach((chunk) => {
                bytes.append(chunk);
            });
            const { response } = PeerExchangeRPC.decode(bytes);
            if (!response) {
                log$3.error("PeerExchangeRPC message did not contains a `response` field");
                return {
                    peerInfos: null,
                    error: ProtocolError$1.EMPTY_PAYLOAD
                };
            }
            const peerInfos = await Promise.all(response.peerInfos
                .map((peerInfo) => peerInfo.enr)
                .filter(isDefined)
                .map(async (enr) => {
                return { ENR: await EnrDecoder.fromRLP(enr) };
            }));
            return {
                peerInfos,
                error: null
            };
        }
        catch (err) {
            log$3.error("Failed to decode push reply", err);
            return {
                peerInfos: null,
                error: ProtocolError$1.DECODE_FAILED
            };
        }
    }
}

const log$2 = new Logger$1("peer-exchange-discovery");
const DEFAULT_PEER_EXCHANGE_REQUEST_NODES = 10;
const DEFAULT_PEER_EXCHANGE_QUERY_INTERVAL_MS = 10 * 1000;
const DEFAULT_MAX_RETRIES = 3;
const DEFAULT_PEER_EXCHANGE_TAG_NAME = Tags.PEER_EXCHANGE;
const DEFAULT_PEER_EXCHANGE_TAG_VALUE = 50;
const DEFAULT_PEER_EXCHANGE_TAG_TTL = 100_000_000;
class PeerExchangeDiscovery extends TypedEventEmitter {
    components;
    peerExchange;
    options;
    isStarted;
    queryingPeers = new Set();
    queryAttempts = new Map();
    handleDiscoveredPeer = (event) => {
        const { protocols, peerId } = event.detail;
        if (!protocols.includes(PeerExchangeCodec) ||
            this.queryingPeers.has(peerId.toString()))
            return;
        this.queryingPeers.add(peerId.toString());
        this.startRecurringQueries(peerId).catch((error) => log$2.error(`Error querying peer ${error}`));
    };
    constructor(components, options = {}) {
        super();
        this.components = components;
        this.peerExchange = new WakuPeerExchange(components);
        this.options = options;
        this.isStarted = false;
    }
    /**
     * Start emitting events
     */
    start() {
        if (this.isStarted) {
            return;
        }
        this.dispatchEvent(new CustomEvent("waku:peer-exchange:started", { detail: true }));
        log$2.info("Starting peer exchange node discovery, discovering peers");
        // might be better to use "peer:identify" or "peer:update"
        this.components.events.addEventListener("peer:identify", this.handleDiscoveredPeer);
    }
    /**
     * Remove event listener
     */
    stop() {
        if (!this.isStarted)
            return;
        log$2.info("Stopping peer exchange node discovery");
        this.isStarted = false;
        this.queryingPeers.clear();
        this.components.events.removeEventListener("peer:identify", this.handleDiscoveredPeer);
    }
    get [peerDiscoverySymbol]() {
        return true;
    }
    get [Symbol.toStringTag]() {
        return "@waku/peer-exchange";
    }
    startRecurringQueries = async (peerId) => {
        const peerIdStr = peerId.toString();
        const { queryInterval = DEFAULT_PEER_EXCHANGE_QUERY_INTERVAL_MS, maxRetries = DEFAULT_MAX_RETRIES } = this.options;
        log$2.info(`Querying peer: ${peerIdStr} (attempt ${this.queryAttempts.get(peerIdStr) ?? 1})`);
        await this.query(peerId);
        const currentAttempt = this.queryAttempts.get(peerIdStr) ?? 1;
        if (currentAttempt > maxRetries) {
            this.abortQueriesForPeer(peerIdStr);
            return;
        }
        setTimeout(() => {
            this.queryAttempts.set(peerIdStr, currentAttempt + 1);
            this.startRecurringQueries(peerId).catch((error) => {
                log$2.error(`Error in startRecurringQueries: ${error}`);
            });
        }, queryInterval * currentAttempt);
    };
    async query(peerId) {
        const { error, peerInfos } = await this.peerExchange.query({
            numPeers: DEFAULT_PEER_EXCHANGE_REQUEST_NODES,
            peerId
        });
        if (error) {
            log$2.error("Peer exchange query failed", error);
            return { error, peerInfos: null };
        }
        for (const _peerInfo of peerInfos) {
            const { ENR } = _peerInfo;
            if (!ENR) {
                log$2.warn("No ENR in peerInfo object, skipping");
                continue;
            }
            const { peerId, peerInfo, shardInfo } = ENR;
            if (!peerId || !peerInfo) {
                continue;
            }
            const hasPeer = await this.components.peerStore.has(peerId);
            if (hasPeer) {
                const { hasMultiaddrDiff, hasShardDiff } = await this.checkPeerInfoDiff(peerInfo, shardInfo);
                if (hasMultiaddrDiff || hasShardDiff) {
                    log$2.info(`Peer ${peerId.toString()} has updated multiaddrs or shardInfo, updating`);
                    if (hasMultiaddrDiff) {
                        log$2.info(`Peer ${peerId.toString()} has updated multiaddrs, updating`);
                        await this.components.peerStore.patch(peerId, {
                            multiaddrs: peerInfo.multiaddrs
                        });
                    }
                    if (hasShardDiff && shardInfo) {
                        log$2.info(`Peer ${peerId.toString()} has updated shardInfo, updating`);
                        await this.components.peerStore.merge(peerId, {
                            metadata: {
                                shardInfo: encodeRelayShard(shardInfo)
                            }
                        });
                        this.dispatchEvent(new CustomEvent("peer", {
                            detail: {
                                id: peerId,
                                multiaddrs: peerInfo.multiaddrs
                            }
                        }));
                    }
                    continue;
                }
            }
            // update the tags for the peer
            await this.components.peerStore.save(peerId, {
                tags: {
                    [DEFAULT_PEER_EXCHANGE_TAG_NAME]: {
                        value: this.options.tagValue ?? DEFAULT_PEER_EXCHANGE_TAG_VALUE,
                        ttl: this.options.tagTTL ?? DEFAULT_PEER_EXCHANGE_TAG_TTL
                    }
                },
                ...(shardInfo && {
                    metadata: {
                        shardInfo: encodeRelayShard(shardInfo)
                    }
                }),
                ...(peerInfo.multiaddrs && {
                    multiaddrs: peerInfo.multiaddrs
                })
            });
            log$2.info(`Discovered peer: ${peerId.toString()}`);
            this.dispatchEvent(new CustomEvent("peer", {
                detail: {
                    id: peerId,
                    multiaddrs: peerInfo.multiaddrs
                }
            }));
        }
        return { error: null, peerInfos };
    }
    abortQueriesForPeer(peerIdStr) {
        log$2.info(`Aborting queries for peer: ${peerIdStr}`);
        this.queryingPeers.delete(peerIdStr);
        this.queryAttempts.delete(peerIdStr);
    }
    async checkPeerInfoDiff(peerInfo, shardInfo) {
        const { id: peerId } = peerInfo;
        const peer = await this.components.peerStore.get(peerId);
        const existingMultiaddrs = peer.addresses.map((a) => a.multiaddr.toString());
        const newMultiaddrs = peerInfo.multiaddrs.map((ma) => ma.toString());
        const hasMultiaddrDiff = existingMultiaddrs.some((ma) => !newMultiaddrs.includes(ma));
        let hasShardDiff = false;
        const existingShardInfoBytes = peer.metadata.get("shardInfo");
        if (existingShardInfoBytes) {
            const existingShardInfo = decodeRelayShard(existingShardInfoBytes);
            if (existingShardInfo || shardInfo) {
                hasShardDiff =
                    existingShardInfo.clusterId !== shardInfo?.clusterId ||
                        existingShardInfo.shards.some((shard) => !shardInfo?.shards.includes(shard));
            }
        }
        return { hasMultiaddrDiff, hasShardDiff };
    }
}
function wakuPeerExchangeDiscovery() {
    return (components) => new PeerExchangeDiscovery(components);
}

const log$1 = new Logger$1("local-cache-discovery");
const DEFAULT_LOCAL_TAG_NAME = Tags.LOCAL;
const DEFAULT_LOCAL_TAG_VALUE = 50;
const DEFAULT_LOCAL_TAG_TTL = 100_000_000;
class LocalPeerCacheDiscovery extends TypedEventEmitter {
    components;
    options;
    isStarted;
    peers = [];
    constructor(components, options) {
        super();
        this.components = components;
        this.options = options;
        this.isStarted = false;
        this.peers = this.getPeersFromLocalStorage();
    }
    get [Symbol.toStringTag]() {
        return "@waku/local-peer-cache-discovery";
    }
    async start() {
        if (this.isStarted)
            return;
        log$1.info("Starting Local Storage Discovery");
        this.components.events.addEventListener("peer:identify", this.handleNewPeers);
        for (const { id: idStr, address } of this.peers) {
            const peerId = peerIdFromString$1(idStr);
            if (await this.components.peerStore.has(peerId))
                continue;
            await this.components.peerStore.save(peerId, {
                multiaddrs: [multiaddr(address)],
                tags: {
                    [this.options?.tagName ?? DEFAULT_LOCAL_TAG_NAME]: {
                        value: this.options?.tagValue ?? DEFAULT_LOCAL_TAG_VALUE,
                        ttl: this.options?.tagTTL ?? DEFAULT_LOCAL_TAG_TTL
                    }
                }
            });
            this.dispatchEvent(new CustomEvent("peer", {
                detail: {
                    id: peerId,
                    multiaddrs: [multiaddr(address)]
                }
            }));
        }
        log$1.info(`Discovered ${this.peers.length} peers`);
        this.isStarted = true;
    }
    stop() {
        if (!this.isStarted)
            return;
        log$1.info("Stopping Local Storage Discovery");
        this.components.events.removeEventListener("peer:identify", this.handleNewPeers);
        this.isStarted = false;
        this.savePeersToLocalStorage();
    }
    handleNewPeers = (event) => {
        const { peerId, listenAddrs } = event.detail;
        const websocketMultiaddr = getWsMultiaddrFromMultiaddrs(listenAddrs);
        const localStoragePeers = this.getPeersFromLocalStorage();
        const existingPeerIndex = localStoragePeers.findIndex((_peer) => _peer.id === peerId.toString());
        if (existingPeerIndex >= 0) {
            localStoragePeers[existingPeerIndex].address =
                websocketMultiaddr.toString();
        }
        else {
            localStoragePeers.push({
                id: peerId.toString(),
                address: websocketMultiaddr.toString()
            });
        }
        this.peers = localStoragePeers;
        this.savePeersToLocalStorage();
    };
    getPeersFromLocalStorage() {
        try {
            const storedPeersData = localStorage.getItem("waku:peers");
            if (!storedPeersData)
                return [];
            const peers = JSON.parse(storedPeersData);
            return peers.filter(isValidStoredPeer);
        }
        catch (error) {
            log$1.error("Error parsing peers from local storage:", error);
            return [];
        }
    }
    savePeersToLocalStorage() {
        try {
            localStorage.setItem("waku:peers", JSON.stringify(this.peers));
        }
        catch (error) {
            log$1.error("Error saving peers to local storage:", error);
        }
    }
}
function isValidStoredPeer(peer) {
    return (peer &&
        typeof peer === "object" &&
        typeof peer.id === "string" &&
        typeof peer.address === "string");
}
function wakuLocalPeerCacheDiscovery() {
    return (components, options) => new LocalPeerCacheDiscovery(components, options);
}

function getPeerDiscoveries(enabled) {
    const dnsEnrTrees = [enrTree["SANDBOX"], enrTree["TEST"]];
    const discoveries = [];
    if (enabled?.dns) {
        discoveries.push(wakuDnsDiscovery(dnsEnrTrees));
    }
    if (enabled?.localPeerCache) {
        discoveries.push(wakuLocalPeerCacheDiscovery());
    }
    if (enabled?.peerExchange) {
        discoveries.push(wakuPeerExchangeDiscovery());
    }
    return discoveries;
}

const log = new Logger$1("sdk:create");
const DefaultUserAgent = "js-waku";
const DefaultPingMaxInboundStreams = 10;
async function defaultLibp2p(clusterId, options, userAgent) {
    if (!options?.hideWebSocketInfo && !isTestEnvironment()) {
        /* eslint-disable no-console */
        console.info("%cIgnore WebSocket connection failures", "background: gray; color: white; font-size: x-large");
        console.info("%cWaku tries to discover peers and some of them are expected to fail", "background: gray; color: white; font-size: x-large");
        /* eslint-enable no-console */
    }
    const filter = options?.filterMultiaddrs === false || isTestEnvironment()
        ? all
        : wss;
    return createLibp2p({
        transports: [webSockets({ filter: filter })],
        streamMuxers: [mplex()],
        connectionEncrypters: [noise()],
        ...options,
        services: {
            identify: identify({
                agentVersion: userAgent ?? DefaultUserAgent
            }),
            ping: ping({
                maxInboundStreams: options?.pingMaxInboundStreams ?? DefaultPingMaxInboundStreams
            }),
            metadata: wakuMetadata(clusterId),
            ...options?.services
        }
    }); // TODO: make libp2p include it;
}
const DEFAULT_DISCOVERIES_ENABLED = {
    dns: true,
    peerExchange: true,
    localPeerCache: true
};
async function createLibp2pAndUpdateOptions(options) {
    const networkConfig = options.networkConfig ?? DefaultNetworkConfig;
    const clusterId = networkConfig.clusterId ?? DEFAULT_CLUSTER_ID;
    log.info("Creating Waku node with cluster id: ", clusterId);
    const libp2pOptions = options?.libp2p ?? {};
    const peerDiscovery = libp2pOptions.peerDiscovery ?? [];
    if (options?.defaultBootstrap) {
        peerDiscovery.push(...getPeerDiscoveries({
            ...DEFAULT_DISCOVERIES_ENABLED,
            ...options.discovery
        }));
    }
    else {
        peerDiscovery.push(...getPeerDiscoveries(options.discovery));
    }
    const bootstrapPeers = [
        ...(options.bootstrapPeers || []),
        ...(options.store?.peers || [])
    ];
    if (bootstrapPeers.length) {
        peerDiscovery.push(bootstrap({ list: bootstrapPeers }));
    }
    libp2pOptions.peerDiscovery = peerDiscovery;
    return defaultLibp2p(clusterId, libp2pOptions, options?.userAgent);
}

/**
 * Create a Waku node that uses Waku Light Push, Filter and Store to send and
 * receive messages, enabling low resource consumption.
 * Uses Waku Filter V2 by default.
 */
async function createLightNode(options = {}) {
    const libp2p = await createLibp2pAndUpdateOptions(options);
    const node = new WakuNode(options, libp2p, {
        store: true,
        lightpush: true,
        filter: true
    });
    // only if `false` is passed explicitly
    if (options?.autoStart !== false) {
        await node.start();
    }
    return node;
}

export { CONNECTION_LOCKED_TAG, DEFAULT_CLUSTER_ID, DEFAULT_NUM_SHARDS, DNS_DISCOVERY_TAG, DecodedMessage, Decoder$1 as Decoder, DefaultNetworkConfig, DefaultShardInfo, Encoder$1 as Encoder, Filter, HealthStatus, LightPush, ProtocolError$1 as ProtocolError, Protocols, Store, Tags, WakuNode, bytesToUtf8, createDecoder, createEncoder, createLibp2pAndUpdateOptions, createLightNode, defaultLibp2p, utf8ToBytes$1 as utf8ToBytes, index$5 as utils, waitForRemotePeer, index as waku };
